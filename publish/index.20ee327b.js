var $parcel$global =
typeof globalThis !== 'undefined'
  ? globalThis
  : typeof self !== 'undefined'
  ? self
  : typeof window !== 'undefined'
  ? window
  : typeof global !== 'undefined'
  ? global
  : {};
var $parcel$modules = {};
var $parcel$inits = {};

var parcelRequire = $parcel$global["parcelRequired404"];
if (parcelRequire == null) {
  parcelRequire = function(id) {
    if (id in $parcel$modules) {
      return $parcel$modules[id].exports;
    }
    if (id in $parcel$inits) {
      var init = $parcel$inits[id];
      delete $parcel$inits[id];
      var module = {id: id, exports: {}};
      $parcel$modules[id] = module;
      init.call(module.exports, module, module.exports);
      return module.exports;
    }
    var err = new Error("Cannot find module '" + id + "'");
    err.code = 'MODULE_NOT_FOUND';
    throw err;
  };

  parcelRequire.register = function register(id, init) {
    $parcel$inits[id] = init;
  };

  $parcel$global["parcelRequired404"] = parcelRequire;
}
parcelRequire.register("euBNH", function(module, exports) {

var $6k4qw = parcelRequire("6k4qw");

var $6awZw = parcelRequire("6awZw");

var $au9AZ = parcelRequire("au9AZ");

var $26mhU = parcelRequire("26mhU");
function $a8d1306bd44d0690$var$_slicedToArray(arr, i) {
    return $6k4qw(arr) || $6awZw(arr, i) || $au9AZ(arr, i) || $26mhU();
}
module.exports = $a8d1306bd44d0690$var$_slicedToArray, module.exports.__esModule = true, module.exports["default"] = module.exports;

});
parcelRequire.register("6k4qw", function(module, exports) {
function $49a80b645ca567a6$var$_arrayWithHoles(arr) {
    if (Array.isArray(arr)) return arr;
}
module.exports = $49a80b645ca567a6$var$_arrayWithHoles, module.exports.__esModule = true, module.exports["default"] = module.exports;

});

parcelRequire.register("6awZw", function(module, exports) {
function $47dd44a2375686d9$var$_iterableToArrayLimit(arr, i) {
    var _i = arr == null ? null : typeof Symbol !== "undefined" && arr[Symbol.iterator] || arr["@@iterator"];
    if (_i == null) return;
    var _arr = [];
    var _n = true;
    var _d = false;
    var _s, _e;
    try {
        for(_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true){
            _arr.push(_s.value);
            if (i && _arr.length === i) break;
        }
    } catch (err) {
        _d = true;
        _e = err;
    } finally{
        try {
            if (!_n && _i["return"] != null) _i["return"]();
        } finally{
            if (_d) throw _e;
        }
    }
    return _arr;
}
module.exports = $47dd44a2375686d9$var$_iterableToArrayLimit, module.exports.__esModule = true, module.exports["default"] = module.exports;

});

parcelRequire.register("au9AZ", function(module, exports) {

var $eftAh = parcelRequire("eftAh");
function $7a24263393b9c0a2$var$_unsupportedIterableToArray(o, minLen) {
    if (!o) return;
    if (typeof o === "string") return $eftAh(o, minLen);
    var n = Object.prototype.toString.call(o).slice(8, -1);
    if (n === "Object" && o.constructor) n = o.constructor.name;
    if (n === "Map" || n === "Set") return Array.from(o);
    if (n === "Arguments" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return $eftAh(o, minLen);
}
module.exports = $7a24263393b9c0a2$var$_unsupportedIterableToArray, module.exports.__esModule = true, module.exports["default"] = module.exports;

});
parcelRequire.register("eftAh", function(module, exports) {
function $a5f96a32fe676997$var$_arrayLikeToArray(arr, len) {
    if (len == null || len > arr.length) len = arr.length;
    for(var i = 0, arr2 = new Array(len); i < len; i++)arr2[i] = arr[i];
    return arr2;
}
module.exports = $a5f96a32fe676997$var$_arrayLikeToArray, module.exports.__esModule = true, module.exports["default"] = module.exports;

});


parcelRequire.register("26mhU", function(module, exports) {
function $187d6e32f28f5358$var$_nonIterableRest() {
    throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.");
}
module.exports = $187d6e32f28f5358$var$_nonIterableRest, module.exports.__esModule = true, module.exports["default"] = module.exports;

});


parcelRequire.register("iJyNU", function(module, exports) {
function $038505e46743c204$var$_classCallCheck(instance, Constructor) {
    if (!(instance instanceof Constructor)) throw new TypeError("Cannot call a class as a function");
}
module.exports = $038505e46743c204$var$_classCallCheck, module.exports.__esModule = true, module.exports["default"] = module.exports;

});

parcelRequire.register("hJ6po", function(module, exports) {
function $ce7b9c3a9cfdc2c9$var$_defineProperties(target, props) {
    for(var i = 0; i < props.length; i++){
        var descriptor = props[i];
        descriptor.enumerable = descriptor.enumerable || false;
        descriptor.configurable = true;
        if ("value" in descriptor) descriptor.writable = true;
        Object.defineProperty(target, descriptor.key, descriptor);
    }
}
function $ce7b9c3a9cfdc2c9$var$_createClass(Constructor, protoProps, staticProps) {
    if (protoProps) $ce7b9c3a9cfdc2c9$var$_defineProperties(Constructor.prototype, protoProps);
    if (staticProps) $ce7b9c3a9cfdc2c9$var$_defineProperties(Constructor, staticProps);
    Object.defineProperty(Constructor, "prototype", {
        writable: false
    });
    return Constructor;
}
module.exports = $ce7b9c3a9cfdc2c9$var$_createClass, module.exports.__esModule = true, module.exports["default"] = module.exports;

});

var $21df9c1ea4331da7$exports = {};
const $ffd1d50d2c55b871$export$83d89fbfd8236492 = "14.7.77";


var $4765696a62faea77$exports = {};



(function(global, factory) {
    factory($4765696a62faea77$exports, (parcelRequire("euBNH")), (parcelRequire("iJyNU")), (parcelRequire("hJ6po")));
})($4765696a62faea77$exports, function(exports, _slicedToArray, _classCallCheck, _createClass) {
    "use strict";
    function _interopDefaultLegacy(e) {
        return e && typeof e === "object" && "default" in e ? e : {
            "default": e
        };
    }
    var _slicedToArray__default = /*#__PURE__*/ _interopDefaultLegacy(_slicedToArray);
    var _classCallCheck__default = /*#__PURE__*/ _interopDefaultLegacy(_classCallCheck);
    var _createClass__default = /*#__PURE__*/ _interopDefaultLegacy(_createClass);
    var createExtendedExponentialRampToValueAutomationEvent = function createExtendedExponentialRampToValueAutomationEvent(value, endTime, insertTime) {
        return {
            endTime: endTime,
            insertTime: insertTime,
            type: "exponentialRampToValue",
            value: value
        };
    };
    var createExtendedLinearRampToValueAutomationEvent = function createExtendedLinearRampToValueAutomationEvent(value, endTime, insertTime) {
        return {
            endTime: endTime,
            insertTime: insertTime,
            type: "linearRampToValue",
            value: value
        };
    };
    var createSetValueAutomationEvent = function createSetValueAutomationEvent(value, startTime) {
        return {
            startTime: startTime,
            type: "setValue",
            value: value
        };
    };
    var createSetValueCurveAutomationEvent = function createSetValueCurveAutomationEvent(values, startTime, duration) {
        return {
            duration: duration,
            startTime: startTime,
            type: "setValueCurve",
            values: values
        };
    };
    var getTargetValueAtTime = function getTargetValueAtTime(time, valueAtStartTime, _ref) {
        var startTime = _ref.startTime, target = _ref.target, timeConstant = _ref.timeConstant;
        return target + (valueAtStartTime - target) * Math.exp((startTime - time) / timeConstant);
    };
    var isExponentialRampToValueAutomationEvent = function isExponentialRampToValueAutomationEvent(automationEvent) {
        return automationEvent.type === "exponentialRampToValue";
    };
    var isLinearRampToValueAutomationEvent = function isLinearRampToValueAutomationEvent(automationEvent) {
        return automationEvent.type === "linearRampToValue";
    };
    var isAnyRampToValueAutomationEvent = function isAnyRampToValueAutomationEvent(automationEvent) {
        return isExponentialRampToValueAutomationEvent(automationEvent) || isLinearRampToValueAutomationEvent(automationEvent);
    };
    var isSetValueAutomationEvent = function isSetValueAutomationEvent(automationEvent) {
        return automationEvent.type === "setValue";
    };
    var isSetValueCurveAutomationEvent = function isSetValueCurveAutomationEvent(automationEvent) {
        return automationEvent.type === "setValueCurve";
    };
    var getValueOfAutomationEventAtIndexAtTime1 = function getValueOfAutomationEventAtIndexAtTime(automationEvents, index, time, defaultValue) {
        var automationEvent = automationEvents[index];
        return automationEvent === undefined ? defaultValue : isAnyRampToValueAutomationEvent(automationEvent) || isSetValueAutomationEvent(automationEvent) ? automationEvent.value : isSetValueCurveAutomationEvent(automationEvent) ? automationEvent.values[automationEvent.values.length - 1] : getTargetValueAtTime(time, getValueOfAutomationEventAtIndexAtTime(automationEvents, index - 1, automationEvent.startTime, defaultValue), automationEvent);
    };
    var getEndTimeAndValueOfPreviousAutomationEvent = function getEndTimeAndValueOfPreviousAutomationEvent(automationEvents, index, currentAutomationEvent, nextAutomationEvent, defaultValue) {
        return currentAutomationEvent === undefined ? [
            nextAutomationEvent.insertTime,
            defaultValue
        ] : isAnyRampToValueAutomationEvent(currentAutomationEvent) ? [
            currentAutomationEvent.endTime,
            currentAutomationEvent.value
        ] : isSetValueAutomationEvent(currentAutomationEvent) ? [
            currentAutomationEvent.startTime,
            currentAutomationEvent.value
        ] : isSetValueCurveAutomationEvent(currentAutomationEvent) ? [
            currentAutomationEvent.startTime + currentAutomationEvent.duration,
            currentAutomationEvent.values[currentAutomationEvent.values.length - 1]
        ] : [
            currentAutomationEvent.startTime,
            getValueOfAutomationEventAtIndexAtTime1(automationEvents, index - 1, currentAutomationEvent.startTime, defaultValue)
        ];
    };
    var isCancelAndHoldAutomationEvent = function isCancelAndHoldAutomationEvent(automationEvent) {
        return automationEvent.type === "cancelAndHold";
    };
    var isCancelScheduledValuesAutomationEvent = function isCancelScheduledValuesAutomationEvent(automationEvent) {
        return automationEvent.type === "cancelScheduledValues";
    };
    var getEventTime = function getEventTime(automationEvent) {
        if (isCancelAndHoldAutomationEvent(automationEvent) || isCancelScheduledValuesAutomationEvent(automationEvent)) return automationEvent.cancelTime;
        if (isExponentialRampToValueAutomationEvent(automationEvent) || isLinearRampToValueAutomationEvent(automationEvent)) return automationEvent.endTime;
        return automationEvent.startTime;
    };
    var getExponentialRampValueAtTime = function getExponentialRampValueAtTime(time, startTime, valueAtStartTime, _ref) {
        var endTime = _ref.endTime, value = _ref.value;
        if (valueAtStartTime === value) return value;
        if (0 < valueAtStartTime && 0 < value || valueAtStartTime < 0 && value < 0) return valueAtStartTime * Math.pow(value / valueAtStartTime, (time - startTime) / (endTime - startTime));
        return 0;
    };
    var getLinearRampValueAtTime = function getLinearRampValueAtTime(time, startTime, valueAtStartTime, _ref) {
        var endTime = _ref.endTime, value = _ref.value;
        return valueAtStartTime + (time - startTime) / (endTime - startTime) * (value - valueAtStartTime);
    };
    var interpolateValue = function interpolateValue(values, theoreticIndex) {
        var lowerIndex = Math.floor(theoreticIndex);
        var upperIndex = Math.ceil(theoreticIndex);
        if (lowerIndex === upperIndex) return values[lowerIndex];
        return (1 - (theoreticIndex - lowerIndex)) * values[lowerIndex] + (1 - (upperIndex - theoreticIndex)) * values[upperIndex];
    };
    var getValueCurveValueAtTime = function getValueCurveValueAtTime(time, _ref) {
        var duration = _ref.duration, startTime = _ref.startTime, values = _ref.values;
        var theoreticIndex = (time - startTime) / duration * (values.length - 1);
        return interpolateValue(values, theoreticIndex);
    };
    var isSetTargetAutomationEvent = function isSetTargetAutomationEvent(automationEvent) {
        return automationEvent.type === "setTarget";
    };
    var AutomationEventList1 = /*#__PURE__*/ function(_Symbol$iterator) {
        function AutomationEventList(defaultValue) {
            _classCallCheck__default["default"](this, AutomationEventList);
            this._automationEvents = [];
            this._currenTime = 0;
            this._defaultValue = defaultValue;
        }
        _createClass__default["default"](AutomationEventList, [
            {
                key: _Symbol$iterator,
                value: function value() {
                    return this._automationEvents[Symbol.iterator]();
                }
            },
            {
                key: "add",
                value: function add(automationEvent) {
                    var eventTime = getEventTime(automationEvent);
                    if (isCancelAndHoldAutomationEvent(automationEvent) || isCancelScheduledValuesAutomationEvent(automationEvent)) {
                        var index = this._automationEvents.findIndex(function(currentAutomationEvent) {
                            if (isCancelScheduledValuesAutomationEvent(automationEvent) && isSetValueCurveAutomationEvent(currentAutomationEvent)) return currentAutomationEvent.startTime + currentAutomationEvent.duration >= eventTime;
                            return getEventTime(currentAutomationEvent) >= eventTime;
                        });
                        var removedAutomationEvent = this._automationEvents[index];
                        if (index !== -1) this._automationEvents = this._automationEvents.slice(0, index);
                        if (isCancelAndHoldAutomationEvent(automationEvent)) {
                            var lastAutomationEvent = this._automationEvents[this._automationEvents.length - 1];
                            if (removedAutomationEvent !== undefined && isAnyRampToValueAutomationEvent(removedAutomationEvent)) {
                                if (isSetTargetAutomationEvent(lastAutomationEvent)) throw new Error("The internal list is malformed.");
                                var startTime = isSetValueCurveAutomationEvent(lastAutomationEvent) ? lastAutomationEvent.startTime + lastAutomationEvent.duration : getEventTime(lastAutomationEvent);
                                var startValue = isSetValueCurveAutomationEvent(lastAutomationEvent) ? lastAutomationEvent.values[lastAutomationEvent.values.length - 1] : lastAutomationEvent.value;
                                var value = isExponentialRampToValueAutomationEvent(removedAutomationEvent) ? getExponentialRampValueAtTime(eventTime, startTime, startValue, removedAutomationEvent) : getLinearRampValueAtTime(eventTime, startTime, startValue, removedAutomationEvent);
                                var truncatedAutomationEvent = isExponentialRampToValueAutomationEvent(removedAutomationEvent) ? createExtendedExponentialRampToValueAutomationEvent(value, eventTime, this._currenTime) : createExtendedLinearRampToValueAutomationEvent(value, eventTime, this._currenTime);
                                this._automationEvents.push(truncatedAutomationEvent);
                            }
                            if (lastAutomationEvent !== undefined && isSetTargetAutomationEvent(lastAutomationEvent)) this._automationEvents.push(createSetValueAutomationEvent(this.getValue(eventTime), eventTime));
                            if (lastAutomationEvent !== undefined && isSetValueCurveAutomationEvent(lastAutomationEvent) && lastAutomationEvent.startTime + lastAutomationEvent.duration > eventTime) this._automationEvents[this._automationEvents.length - 1] = createSetValueCurveAutomationEvent(new Float32Array([
                                6,
                                7
                            ]), lastAutomationEvent.startTime, eventTime - lastAutomationEvent.startTime);
                        }
                    } else {
                        var _index = this._automationEvents.findIndex(function(currentAutomationEvent) {
                            return getEventTime(currentAutomationEvent) > eventTime;
                        });
                        var previousAutomationEvent = _index === -1 ? this._automationEvents[this._automationEvents.length - 1] : this._automationEvents[_index - 1];
                        if (previousAutomationEvent !== undefined && isSetValueCurveAutomationEvent(previousAutomationEvent) && getEventTime(previousAutomationEvent) + previousAutomationEvent.duration > eventTime) return false;
                        var persistentAutomationEvent = isExponentialRampToValueAutomationEvent(automationEvent) ? createExtendedExponentialRampToValueAutomationEvent(automationEvent.value, automationEvent.endTime, this._currenTime) : isLinearRampToValueAutomationEvent(automationEvent) ? createExtendedLinearRampToValueAutomationEvent(automationEvent.value, eventTime, this._currenTime) : automationEvent;
                        if (_index === -1) this._automationEvents.push(persistentAutomationEvent);
                        else {
                            if (isSetValueCurveAutomationEvent(automationEvent) && eventTime + automationEvent.duration > getEventTime(this._automationEvents[_index])) return false;
                            this._automationEvents.splice(_index, 0, persistentAutomationEvent);
                        }
                    }
                    return true;
                }
            },
            {
                key: "flush",
                value: function flush(time) {
                    var index = this._automationEvents.findIndex(function(currentAutomationEvent) {
                        return getEventTime(currentAutomationEvent) > time;
                    });
                    if (index > 1) {
                        var remainingAutomationEvents = this._automationEvents.slice(index - 1);
                        var firstRemainingAutomationEvent = remainingAutomationEvents[0];
                        if (isSetTargetAutomationEvent(firstRemainingAutomationEvent)) remainingAutomationEvents.unshift(createSetValueAutomationEvent(getValueOfAutomationEventAtIndexAtTime1(this._automationEvents, index - 2, firstRemainingAutomationEvent.startTime, this._defaultValue), firstRemainingAutomationEvent.startTime));
                        this._automationEvents = remainingAutomationEvents;
                    }
                }
            },
            {
                key: "getValue",
                value: function getValue(time) {
                    if (this._automationEvents.length === 0) return this._defaultValue;
                    var indexOfNextEvent = this._automationEvents.findIndex(function(automationEvent) {
                        return getEventTime(automationEvent) > time;
                    });
                    var nextAutomationEvent = this._automationEvents[indexOfNextEvent];
                    var indexOfCurrentEvent = (indexOfNextEvent === -1 ? this._automationEvents.length : indexOfNextEvent) - 1;
                    var currentAutomationEvent = this._automationEvents[indexOfCurrentEvent];
                    if (currentAutomationEvent !== undefined && isSetTargetAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent) || nextAutomationEvent.insertTime > time)) return getTargetValueAtTime(time, getValueOfAutomationEventAtIndexAtTime1(this._automationEvents, indexOfCurrentEvent - 1, currentAutomationEvent.startTime, this._defaultValue), currentAutomationEvent);
                    if (currentAutomationEvent !== undefined && isSetValueAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent))) return currentAutomationEvent.value;
                    if (currentAutomationEvent !== undefined && isSetValueCurveAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent) || currentAutomationEvent.startTime + currentAutomationEvent.duration > time)) {
                        if (time < currentAutomationEvent.startTime + currentAutomationEvent.duration) return getValueCurveValueAtTime(time, currentAutomationEvent);
                        return currentAutomationEvent.values[currentAutomationEvent.values.length - 1];
                    }
                    if (currentAutomationEvent !== undefined && isAnyRampToValueAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent))) return currentAutomationEvent.value;
                    if (nextAutomationEvent !== undefined && isExponentialRampToValueAutomationEvent(nextAutomationEvent)) {
                        var _getEndTimeAndValueOf = getEndTimeAndValueOfPreviousAutomationEvent(this._automationEvents, indexOfCurrentEvent, currentAutomationEvent, nextAutomationEvent, this._defaultValue), _getEndTimeAndValueOf2 = _slicedToArray__default["default"](_getEndTimeAndValueOf, 2), startTime = _getEndTimeAndValueOf2[0], value = _getEndTimeAndValueOf2[1];
                        return getExponentialRampValueAtTime(time, startTime, value, nextAutomationEvent);
                    }
                    if (nextAutomationEvent !== undefined && isLinearRampToValueAutomationEvent(nextAutomationEvent)) {
                        var _getEndTimeAndValueOf3 = getEndTimeAndValueOfPreviousAutomationEvent(this._automationEvents, indexOfCurrentEvent, currentAutomationEvent, nextAutomationEvent, this._defaultValue), _getEndTimeAndValueOf4 = _slicedToArray__default["default"](_getEndTimeAndValueOf3, 2), _startTime = _getEndTimeAndValueOf4[0], _value = _getEndTimeAndValueOf4[1];
                        return getLinearRampValueAtTime(time, _startTime, _value, nextAutomationEvent);
                    }
                    return this._defaultValue;
                }
            }
        ]);
        return AutomationEventList;
    }(Symbol.iterator);
    var createCancelAndHoldAutomationEvent = function createCancelAndHoldAutomationEvent(cancelTime) {
        return {
            cancelTime: cancelTime,
            type: "cancelAndHold"
        };
    };
    var createCancelScheduledValuesAutomationEvent = function createCancelScheduledValuesAutomationEvent(cancelTime) {
        return {
            cancelTime: cancelTime,
            type: "cancelScheduledValues"
        };
    };
    var createExponentialRampToValueAutomationEvent = function createExponentialRampToValueAutomationEvent(value, endTime) {
        return {
            endTime: endTime,
            type: "exponentialRampToValue",
            value: value
        };
    };
    var createLinearRampToValueAutomationEvent = function createLinearRampToValueAutomationEvent(value, endTime) {
        return {
            endTime: endTime,
            type: "linearRampToValue",
            value: value
        };
    };
    var createSetTargetAutomationEvent = function createSetTargetAutomationEvent(target, startTime, timeConstant) {
        return {
            startTime: startTime,
            target: target,
            timeConstant: timeConstant,
            type: "setTarget"
        };
    };
    exports.AutomationEventList = AutomationEventList1;
    exports.createCancelAndHoldAutomationEvent = createCancelAndHoldAutomationEvent;
    exports.createCancelScheduledValuesAutomationEvent = createCancelScheduledValuesAutomationEvent;
    exports.createExponentialRampToValueAutomationEvent = createExponentialRampToValueAutomationEvent;
    exports.createLinearRampToValueAutomationEvent = createLinearRampToValueAutomationEvent;
    exports.createSetTargetAutomationEvent = createSetTargetAutomationEvent;
    exports.createSetValueAutomationEvent = createSetValueAutomationEvent;
    exports.createSetValueCurveAutomationEvent = createSetValueCurveAutomationEvent;
    Object.defineProperty(exports, "__esModule", {
        value: true
    });
});


const $e20fccd48d473655$export$aff31bd5258e9fd4 = ()=>new DOMException("", "AbortError");


const $e1b9ef044571c7b2$export$43d20cccdc976834 = (insertElementInSet)=>{
    return (activeInputs, source, [output, input, eventListener], ignoreDuplicates)=>{
        insertElementInSet(activeInputs[input], [
            source,
            output,
            eventListener
        ], (activeInputConnection)=>activeInputConnection[0] === source && activeInputConnection[1] === output, ignoreDuplicates);
    };
};


const $751bcb2732d93877$export$7ff07578cebde522 = (audioNodeConnectionsStore)=>{
    return (audioNode, audioNodeRenderer, nativeAudioNode)=>{
        const activeInputs = [];
        for(let i = 0; i < nativeAudioNode.numberOfInputs; i += 1)activeInputs.push(new Set());
        audioNodeConnectionsStore.set(audioNode, {
            activeInputs: activeInputs,
            outputs: new Set(),
            passiveInputs: new WeakMap(),
            renderer: audioNodeRenderer
        });
    };
};


const $db6875aab68aad9f$export$25226f7a087f88c3 = (audioParamConnectionsStore)=>{
    return (audioParam, audioParamRenderer)=>{
        audioParamConnectionsStore.set(audioParam, {
            activeInputs: new Set(),
            passiveInputs: new WeakMap(),
            renderer: audioParamRenderer
        });
    };
};


const $45092aa0415316c7$export$2b500979aea0913f = new WeakSet();
const $45092aa0415316c7$export$61ca80a8c8c6d728 = new WeakMap();
const $45092aa0415316c7$export$864a3cfb55580d0c = new WeakMap();
const $45092aa0415316c7$export$c5d3ff1f46a0185a = new WeakMap();
const $45092aa0415316c7$export$55484e3055c7a9e2 = new WeakMap();
const $45092aa0415316c7$export$7d17302229276f06 = new WeakMap();
const $45092aa0415316c7$export$c998cfefa4fd5136 = new WeakMap();
const $45092aa0415316c7$export$cf686a6a3e402092 = new WeakMap();
const $45092aa0415316c7$export$b9bea39f06f96914 = new WeakMap();
const $45092aa0415316c7$export$16d7878f7e059d67 = new WeakMap();


const $7cb9981b39093b43$var$handler = {
    construct () {
        return $7cb9981b39093b43$var$handler;
    }
};
const $7cb9981b39093b43$export$df064419399503e9 = (constructible)=>{
    try {
        const proxy = new Proxy(constructible, $7cb9981b39093b43$var$handler);
        new proxy(); // tslint:disable-line:no-unused-expression
    } catch  {
        return false;
    }
    return true;
};


/*
 * This massive regex tries to cover all the following cases.
 *
 * import './path';
 * import defaultImport from './path';
 * import { namedImport } from './path';
 * import { namedImport as renamendImport } from './path';
 * import * as namespaceImport from './path';
 * import defaultImport, { namedImport } from './path';
 * import defaultImport, { namedImport as renamendImport } from './path';
 * import defaultImport, * as namespaceImport from './path';
 */ const $45049d01de2a2a69$var$IMPORT_STATEMENT_REGEX = /^import(?:(?:[\s]+[\w]+|(?:[\s]+[\w]+[\s]*,)?[\s]*\{[\s]*[\w]+(?:[\s]+as[\s]+[\w]+)?(?:[\s]*,[\s]*[\w]+(?:[\s]+as[\s]+[\w]+)?)*[\s]*}|(?:[\s]+[\w]+[\s]*,)?[\s]*\*[\s]+as[\s]+[\w]+)[\s]+from)?(?:[\s]*)("([^"\\]|\\.)+"|'([^'\\]|\\.)+')(?:[\s]*);?/; // tslint:disable-line:max-line-length
const $45049d01de2a2a69$export$949058cf055dbb57 = (source, url)=>{
    const importStatements = [];
    let sourceWithoutImportStatements = source.replace(/^[\s]+/, "");
    let result = sourceWithoutImportStatements.match($45049d01de2a2a69$var$IMPORT_STATEMENT_REGEX);
    while(result !== null){
        const unresolvedUrl = result[1].slice(1, -1);
        const importStatementWithResolvedUrl = result[0].replace(/([\s]+)?;?$/, "").replace(unresolvedUrl, new URL(unresolvedUrl, url).toString());
        importStatements.push(importStatementWithResolvedUrl);
        sourceWithoutImportStatements = sourceWithoutImportStatements.slice(result[0].length).replace(/^[\s]+/, "");
        result = sourceWithoutImportStatements.match($45049d01de2a2a69$var$IMPORT_STATEMENT_REGEX);
    }
    return [
        importStatements.join(";"),
        sourceWithoutImportStatements
    ];
};


const $6cf8f231e9742452$var$verifyParameterDescriptors = (parameterDescriptors)=>{
    if (parameterDescriptors !== undefined && !Array.isArray(parameterDescriptors)) throw new TypeError("The parameterDescriptors property of given value for processorCtor is not an array.");
};
const $6cf8f231e9742452$var$verifyProcessorCtor = (processorCtor)=>{
    if (!(0, $7cb9981b39093b43$export$df064419399503e9)(processorCtor)) throw new TypeError("The given value for processorCtor should be a constructor.");
    if (processorCtor.prototype === null || typeof processorCtor.prototype !== "object") throw new TypeError("The given value for processorCtor should have a prototype.");
};
const $6cf8f231e9742452$export$16c6049a33c70efa = (cacheTestResult, createNotSupportedError, evaluateSource, exposeCurrentFrameAndCurrentTime, fetchSource, getNativeContext, getOrCreateBackupOfflineAudioContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, ongoingRequests, resolvedRequests, testAudioWorkletProcessorPostMessageSupport, window)=>{
    let index = 0;
    return (context, moduleURL, options = {
        credentials: "omit"
    })=>{
        const resolvedRequestsOfContext = resolvedRequests.get(context);
        if (resolvedRequestsOfContext !== undefined && resolvedRequestsOfContext.has(moduleURL)) return Promise.resolve();
        const ongoingRequestsOfContext = ongoingRequests.get(context);
        if (ongoingRequestsOfContext !== undefined) {
            const promiseOfOngoingRequest = ongoingRequestsOfContext.get(moduleURL);
            if (promiseOfOngoingRequest !== undefined) return promiseOfOngoingRequest;
        }
        const nativeContext = getNativeContext(context);
        // Bug #59: Safari does not implement the audioWorklet property.
        const promise = nativeContext.audioWorklet === undefined ? fetchSource(moduleURL).then(([source, absoluteUrl])=>{
            const [importStatements, sourceWithoutImportStatements] = (0, $45049d01de2a2a69$export$949058cf055dbb57)(source, absoluteUrl);
            /*
                 * This is the unminified version of the code used below:
                 *
                 * ```js
                 * ${ importStatements };
                 * ((a, b) => {
                 *     (a[b] = a[b] || [ ]).push(
                 *         (AudioWorkletProcessor, global, registerProcessor, sampleRate, self, window) => {
                 *             ${ sourceWithoutImportStatements }
                 *         }
                 *     );
                 * })(window, '_AWGS');
                 * ```
                 */ // tslint:disable-next-line:max-line-length
            const wrappedSource = `${importStatements};((a,b)=>{(a[b]=a[b]||[]).push((AudioWorkletProcessor,global,registerProcessor,sampleRate,self,window)=>{${sourceWithoutImportStatements}
})})(window,'_AWGS')`;
            // @todo Evaluating the given source code is a possible security problem.
            return evaluateSource(wrappedSource);
        }).then(()=>{
            const evaluateAudioWorkletGlobalScope = window._AWGS.pop();
            if (evaluateAudioWorkletGlobalScope === undefined) // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.
            throw new SyntaxError();
            exposeCurrentFrameAndCurrentTime(nativeContext.currentTime, nativeContext.sampleRate, ()=>evaluateAudioWorkletGlobalScope(class AudioWorkletProcessor {
                }, undefined, (name, processorCtor)=>{
                    if (name.trim() === "") throw createNotSupportedError();
                    const nodeNameToProcessorConstructorMap = (0, $45092aa0415316c7$export$b9bea39f06f96914).get(nativeContext);
                    if (nodeNameToProcessorConstructorMap !== undefined) {
                        if (nodeNameToProcessorConstructorMap.has(name)) throw createNotSupportedError();
                        $6cf8f231e9742452$var$verifyProcessorCtor(processorCtor);
                        $6cf8f231e9742452$var$verifyParameterDescriptors(processorCtor.parameterDescriptors);
                        nodeNameToProcessorConstructorMap.set(name, processorCtor);
                    } else {
                        $6cf8f231e9742452$var$verifyProcessorCtor(processorCtor);
                        $6cf8f231e9742452$var$verifyParameterDescriptors(processorCtor.parameterDescriptors);
                        (0, $45092aa0415316c7$export$b9bea39f06f96914).set(nativeContext, new Map([
                            [
                                name,
                                processorCtor
                            ]
                        ]));
                    }
                }, nativeContext.sampleRate, undefined, undefined));
        }) : Promise.all([
            fetchSource(moduleURL),
            Promise.resolve(cacheTestResult(testAudioWorkletProcessorPostMessageSupport, testAudioWorkletProcessorPostMessageSupport))
        ]).then(([[source, absoluteUrl], isSupportingPostMessage])=>{
            const currentIndex = index + 1;
            index = currentIndex;
            const [importStatements, sourceWithoutImportStatements] = (0, $45049d01de2a2a69$export$949058cf055dbb57)(source, absoluteUrl);
            /*
                 * Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.
                 *
                 * This is the unminified version of the code used below.
                 *
                 * ```js
                 * class extends AudioWorkletProcessor {
                 *
                 *     __buffers = new WeakSet();
                 *
                 *     constructor () {
                 *         super();
                 *
                 *         this.port.postMessage = ((postMessage) => {
                 *             return (message, transferables) => {
                 *                 const filteredTransferables = (transferables)
                 *                     ? transferables.filter((transferable) => !this.__buffers.has(transferable))
                 *                     : transferables;
                 *
                 *                 return postMessage.call(this.port, message, filteredTransferables);
                 *              };
                 *         })(this.port.postMessage);
                 *     }
                 * }
                 * ```
                 */ const patchedAudioWorkletProcessor = isSupportingPostMessage ? "AudioWorkletProcessor" : "class extends AudioWorkletProcessor {__b=new WeakSet();constructor(){super();(p=>p.postMessage=(q=>(m,t)=>q.call(p,m,t?t.filter(u=>!this.__b.has(u)):t))(p.postMessage))(this.port)}}";
            /*
                 * Bug #170: Chrome and Edge do call process() with an array with empty channelData for each input if no input is connected.
                 *
                 * Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.
                 *
                 * Bug #190: Safari doesn't throw an error when loading an unparsable module.
                 *
                 * This is the unminified version of the code used below:
                 *
                 * ```js
                 * `${ importStatements };
                 * ((AudioWorkletProcessor, registerProcessor) => {${ sourceWithoutImportStatements }
                 * })(
                 *     ${Â patchedAudioWorkletProcessor },
                 *     (name, processorCtor) => registerProcessor(name, class extends processorCtor {
                 *
                 *         __collectBuffers = (array) => {
                 *             array.forEach((element) => this.__buffers.add(element.buffer));
                 *         };
                 *
                 *         process (inputs, outputs, parameters) {
                 *             inputs.forEach(this.__collectBuffers);
                 *             outputs.forEach(this.__collectBuffers);
                 *             this.__collectBuffers(Object.values(parameters));
                 *
                 *             return super.process(
                 *                 (inputs.map((input) => input.some((channelData) => channelData.length === 0)) ? [ ] : input),
                 *                 outputs,
                 *                 parameters
                 *             );
                 *         }
                 *
                 *     })
                 * );
                 *
                 * registerProcessor(`__sac${currentIndex}`, class extends AudioWorkletProcessor{
                 *
                 *     process () {
                 *         return false;
                 *     }
                 *
                 * })`
                 * ```
                 */ const memberDefinition = isSupportingPostMessage ? "" : "__c = (a) => a.forEach(e=>this.__b.add(e.buffer));";
            const bufferRegistration = isSupportingPostMessage ? "" : "i.forEach(this.__c);o.forEach(this.__c);this.__c(Object.values(p));";
            const wrappedSource = `${importStatements};((AudioWorkletProcessor,registerProcessor)=>{${sourceWithoutImportStatements}
})(${patchedAudioWorkletProcessor},(n,p)=>registerProcessor(n,class extends p{${memberDefinition}process(i,o,p){${bufferRegistration}return super.process(i.map(j=>j.some(k=>k.length===0)?[]:j),o,p)}}));registerProcessor('__sac${currentIndex}',class extends AudioWorkletProcessor{process(){return !1}})`;
            const blob = new Blob([
                wrappedSource
            ], {
                type: "application/javascript; charset=utf-8"
            });
            const url = URL.createObjectURL(blob);
            return nativeContext.audioWorklet.addModule(url, options).then(()=>{
                if (isNativeOfflineAudioContext(nativeContext)) return nativeContext;
                // Bug #186: Chrome, Edge and Opera do not allow to create an AudioWorkletNode on a closed AudioContext.
                const backupOfflineAudioContext = getOrCreateBackupOfflineAudioContext(nativeContext);
                return backupOfflineAudioContext.audioWorklet.addModule(url, options).then(()=>backupOfflineAudioContext);
            }).then((nativeContextOrBackupOfflineAudioContext)=>{
                if (nativeAudioWorkletNodeConstructor === null) throw new SyntaxError();
                try {
                    // Bug #190: Safari doesn't throw an error when loading an unparsable module.
                    new nativeAudioWorkletNodeConstructor(nativeContextOrBackupOfflineAudioContext, `__sac${currentIndex}`); // tslint:disable-line:no-unused-expression
                } catch  {
                    throw new SyntaxError();
                }
            }).finally(()=>URL.revokeObjectURL(url));
        });
        if (ongoingRequestsOfContext === undefined) ongoingRequests.set(context, new Map([
            [
                moduleURL,
                promise
            ]
        ]));
        else ongoingRequestsOfContext.set(moduleURL, promise);
        promise.then(()=>{
            const updatedResolvedRequestsOfContext = resolvedRequests.get(context);
            if (updatedResolvedRequestsOfContext === undefined) resolvedRequests.set(context, new Set([
                moduleURL
            ]));
            else updatedResolvedRequestsOfContext.add(moduleURL);
        }).finally(()=>{
            const updatedOngoingRequestsOfContext = ongoingRequests.get(context);
            if (updatedOngoingRequestsOfContext !== undefined) updatedOngoingRequestsOfContext.delete(moduleURL);
        });
        return promise;
    };
};


const $838ea8ed33d27e81$export$520987e3ff3ffad3 = (map, key)=>{
    const value = map.get(key);
    if (value === undefined) throw new Error("A value with the given key could not be found.");
    return value;
};


const $115343c7346cd8e6$export$3f1b331b43a0e659 = (set, predicate)=>{
    const matchingElements = Array.from(set).filter(predicate);
    if (matchingElements.length > 1) throw Error("More than one element was found.");
    if (matchingElements.length === 0) throw Error("No element was found.");
    const [matchingElement] = matchingElements;
    set.delete(matchingElement);
    return matchingElement;
};


const $adf8394cf0998b48$export$26ec3ebc965d6cfd = (passiveInputs, source, output, input)=>{
    const passiveInputConnections = (0, $838ea8ed33d27e81$export$520987e3ff3ffad3)(passiveInputs, source);
    const matchingConnection = (0, $115343c7346cd8e6$export$3f1b331b43a0e659)(passiveInputConnections, (passiveInputConnection)=>passiveInputConnection[0] === output && passiveInputConnection[1] === input);
    if (passiveInputConnections.size === 0) passiveInputs.delete(source);
    return matchingConnection;
};





const $d6dd4c96535f9fa2$export$caac7ea54cb93b25 = (audioNode)=>{
    return (0, $838ea8ed33d27e81$export$520987e3ff3ffad3)((0, $45092aa0415316c7$export$c998cfefa4fd5136), audioNode);
};


const $e4b65d1b7a33a6ae$export$88a47afdc0e8539c = (audioNode)=>{
    if ((0, $45092aa0415316c7$export$2b500979aea0913f).has(audioNode)) throw new Error("The AudioNode is already stored.");
    (0, $45092aa0415316c7$export$2b500979aea0913f).add(audioNode);
    (0, $d6dd4c96535f9fa2$export$caac7ea54cb93b25)(audioNode).forEach((eventListener)=>eventListener(true));
};


const $140cc20865db247d$export$1293b9fc79a24682 = (audioNode)=>{
    return "port" in audioNode;
};




const $30e3b887134462bb$export$7c0830f3a5100dec = (audioNode)=>{
    if (!(0, $45092aa0415316c7$export$2b500979aea0913f).has(audioNode)) throw new Error("The AudioNode is not stored.");
    (0, $45092aa0415316c7$export$2b500979aea0913f).delete(audioNode);
    (0, $d6dd4c96535f9fa2$export$caac7ea54cb93b25)(audioNode).forEach((eventListener)=>eventListener(false));
};


const $14d833df3cd44d0b$export$c74023ca160dc207 = (audioNode, activeInputs)=>{
    if (!(0, $140cc20865db247d$export$1293b9fc79a24682)(audioNode) && activeInputs.every((connections)=>connections.size === 0)) (0, $30e3b887134462bb$export$7c0830f3a5100dec)(audioNode);
};


const $d20379ab3ffab405$export$1776cf0d295db1d7 = (addActiveInputConnectionToAudioNode, addPassiveInputConnectionToAudioNode, connectNativeAudioNodeToNativeAudioNode, deleteActiveInputConnectionToAudioNode, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getAudioNodeTailTime, getEventListenersOfAudioNode, getNativeAudioNode, insertElementInSet, isActiveAudioNode, isPartOfACycle, isPassiveAudioNode)=>{
    const tailTimeTimeoutIds = new WeakMap();
    return (source, destination, output, input, isOffline)=>{
        const { activeInputs: activeInputs , passiveInputs: passiveInputs  } = getAudioNodeConnections(destination);
        const { outputs: outputs  } = getAudioNodeConnections(source);
        const eventListeners = getEventListenersOfAudioNode(source);
        const eventListener = (isActive)=>{
            const nativeDestinationAudioNode = getNativeAudioNode(destination);
            const nativeSourceAudioNode = getNativeAudioNode(source);
            if (isActive) {
                const partialConnection = (0, $adf8394cf0998b48$export$26ec3ebc965d6cfd)(passiveInputs, source, output, input);
                addActiveInputConnectionToAudioNode(activeInputs, source, partialConnection, false);
                if (!isOffline && !isPartOfACycle(source)) connectNativeAudioNodeToNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output, input);
                if (isPassiveAudioNode(destination)) (0, $e4b65d1b7a33a6ae$export$88a47afdc0e8539c)(destination);
            } else {
                const partialConnection = deleteActiveInputConnectionToAudioNode(activeInputs, source, output, input);
                addPassiveInputConnectionToAudioNode(passiveInputs, input, partialConnection, false);
                if (!isOffline && !isPartOfACycle(source)) disconnectNativeAudioNodeFromNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output, input);
                const tailTime = getAudioNodeTailTime(destination);
                if (tailTime === 0) {
                    if (isActiveAudioNode(destination)) (0, $14d833df3cd44d0b$export$c74023ca160dc207)(destination, activeInputs);
                } else {
                    const tailTimeTimeoutId = tailTimeTimeoutIds.get(destination);
                    if (tailTimeTimeoutId !== undefined) clearTimeout(tailTimeTimeoutId);
                    tailTimeTimeoutIds.set(destination, setTimeout(()=>{
                        if (isActiveAudioNode(destination)) (0, $14d833df3cd44d0b$export$c74023ca160dc207)(destination, activeInputs);
                    }, tailTime * 1000));
                }
            }
        };
        if (insertElementInSet(outputs, [
            destination,
            output,
            input
        ], (outputConnection)=>outputConnection[0] === destination && outputConnection[1] === output && outputConnection[2] === input, true)) {
            eventListeners.add(eventListener);
            if (isActiveAudioNode(source)) addActiveInputConnectionToAudioNode(activeInputs, source, [
                output,
                input,
                eventListener
            ], true);
            else addPassiveInputConnectionToAudioNode(passiveInputs, input, [
                source,
                output,
                eventListener
            ], true);
            return true;
        }
        return false;
    };
};


const $608abbe6ab6cc7e7$export$67aa4e90be3a506b = (insertElementInSet)=>{
    return (passiveInputs, input, [source, output, eventListener], ignoreDuplicates)=>{
        const passiveInputConnections = passiveInputs.get(source);
        if (passiveInputConnections === undefined) passiveInputs.set(source, new Set([
            [
                output,
                input,
                eventListener
            ]
        ]));
        else insertElementInSet(passiveInputConnections, [
            output,
            input,
            eventListener
        ], (passiveInputConnection)=>passiveInputConnection[0] === output && passiveInputConnection[1] === input, ignoreDuplicates);
    };
};


const $9a2ab1599c9292df$export$c6991e18a29704b9 = (createNativeGainNode)=>{
    return (nativeContext, nativeAudioScheduledSourceNode)=>{
        const nativeGainNode = createNativeGainNode(nativeContext, {
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "discrete",
            gain: 0
        });
        nativeAudioScheduledSourceNode.connect(nativeGainNode).connect(nativeContext.destination);
        const disconnect = ()=>{
            nativeAudioScheduledSourceNode.removeEventListener("ended", disconnect);
            nativeAudioScheduledSourceNode.disconnect(nativeGainNode);
            nativeGainNode.disconnect();
        };
        nativeAudioScheduledSourceNode.addEventListener("ended", disconnect);
    };
};


const $f316e86eecb60d34$export$fd0136b1517d036f = (getUnrenderedAudioWorkletNodes)=>{
    return (nativeContext, audioWorkletNode)=>{
        getUnrenderedAudioWorkletNodes(nativeContext).add(audioWorkletNode);
    };
};


const $eae529b582453c5f$var$DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    fftSize: 2048,
    maxDecibels: -30,
    minDecibels: -100,
    smoothingTimeConstant: 0.8
};
const $eae529b582453c5f$export$569b2da15d7fe153 = (audionNodeConstructor, createAnalyserNodeRenderer, createIndexSizeError, createNativeAnalyserNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class AnalyserNode extends audionNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...$eae529b582453c5f$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeAnalyserNode = createNativeAnalyserNode(nativeContext, mergedOptions);
            const analyserNodeRenderer = isNativeOfflineAudioContext(nativeContext) ? createAnalyserNodeRenderer() : null;
            super(context, false, nativeAnalyserNode, analyserNodeRenderer);
            this._nativeAnalyserNode = nativeAnalyserNode;
        }
        get fftSize() {
            return this._nativeAnalyserNode.fftSize;
        }
        set fftSize(value) {
            this._nativeAnalyserNode.fftSize = value;
        }
        get frequencyBinCount() {
            return this._nativeAnalyserNode.frequencyBinCount;
        }
        get maxDecibels() {
            return this._nativeAnalyserNode.maxDecibels;
        }
        set maxDecibels(value) {
            // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.
            const maxDecibels = this._nativeAnalyserNode.maxDecibels;
            this._nativeAnalyserNode.maxDecibels = value;
            if (!(value > this._nativeAnalyserNode.minDecibels)) {
                this._nativeAnalyserNode.maxDecibels = maxDecibels;
                throw createIndexSizeError();
            }
        }
        get minDecibels() {
            return this._nativeAnalyserNode.minDecibels;
        }
        set minDecibels(value) {
            // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.
            const minDecibels = this._nativeAnalyserNode.minDecibels;
            this._nativeAnalyserNode.minDecibels = value;
            if (!(this._nativeAnalyserNode.maxDecibels > value)) {
                this._nativeAnalyserNode.minDecibels = minDecibels;
                throw createIndexSizeError();
            }
        }
        get smoothingTimeConstant() {
            return this._nativeAnalyserNode.smoothingTimeConstant;
        }
        set smoothingTimeConstant(value) {
            this._nativeAnalyserNode.smoothingTimeConstant = value;
        }
        getByteFrequencyData(array) {
            this._nativeAnalyserNode.getByteFrequencyData(array);
        }
        getByteTimeDomainData(array) {
            this._nativeAnalyserNode.getByteTimeDomainData(array);
        }
        getFloatFrequencyData(array) {
            this._nativeAnalyserNode.getFloatFrequencyData(array);
        }
        getFloatTimeDomainData(array) {
            this._nativeAnalyserNode.getFloatTimeDomainData(array);
        }
    };
};


const $f95943e20b45689b$export$4bd7a4bf54ca80bc = (nativeAudioNode, nativeContext)=>{
    return nativeAudioNode.context === nativeContext;
};


const $115369693fdf36f2$export$5fe3f5c2d995fe20 = (createNativeAnalyserNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeAnalyserNodes = new WeakMap();
        const createAnalyserNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeAnalyserNode = getNativeAudioNode(proxy);
            // If the initially used nativeAnalyserNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeAnalyserNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeAnalyserNode, nativeOfflineAudioContext);
            if (!nativeAnalyserNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeAnalyserNode.channelCount,
                    channelCountMode: nativeAnalyserNode.channelCountMode,
                    channelInterpretation: nativeAnalyserNode.channelInterpretation,
                    fftSize: nativeAnalyserNode.fftSize,
                    maxDecibels: nativeAnalyserNode.maxDecibels,
                    minDecibels: nativeAnalyserNode.minDecibels,
                    smoothingTimeConstant: nativeAnalyserNode.smoothingTimeConstant
                };
                nativeAnalyserNode = createNativeAnalyserNode(nativeOfflineAudioContext, options);
            }
            renderedNativeAnalyserNodes.set(nativeOfflineAudioContext, nativeAnalyserNode);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAnalyserNode);
            return nativeAnalyserNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeAnalyserNode = renderedNativeAnalyserNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAnalyserNode !== undefined) return Promise.resolve(renderedNativeAnalyserNode);
                return createAnalyserNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};


const $ab7234a0e06cc19b$export$54e424f510c54ced = (nativeAudioBuffer)=>{
    try {
        nativeAudioBuffer.copyToChannel(new Float32Array(1), 0, -1);
    } catch  {
        return false;
    }
    return true;
};


const $5e22421cd58df859$export$926e4aa3eed6ec13 = ()=>new DOMException("", "IndexSizeError");


const $2e77af801a4782d4$export$df65309cf6249598 = (audioBuffer)=>{
    audioBuffer.getChannelData = ((getChannelData)=>{
        return (channel)=>{
            try {
                return getChannelData.call(audioBuffer, channel);
            } catch (err) {
                if (err.code === 12) throw (0, $5e22421cd58df859$export$926e4aa3eed6ec13)();
                throw err;
            }
        };
    })(audioBuffer.getChannelData);
};


const $d331f10434d18ebe$var$DEFAULT_OPTIONS = {
    numberOfChannels: 1
};
const $d331f10434d18ebe$export$c8b88126795b7df2 = (audioBufferStore, cacheTestResult, createNotSupportedError, nativeAudioBufferConstructor, nativeOfflineAudioContextConstructor, testNativeAudioBufferConstructorSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds)=>{
    let nativeOfflineAudioContext = null;
    return class AudioBuffer {
        constructor(options){
            if (nativeOfflineAudioContextConstructor === null) throw new Error("Missing the native OfflineAudioContext constructor.");
            const { length: length , numberOfChannels: numberOfChannels , sampleRate: sampleRate  } = {
                ...$d331f10434d18ebe$var$DEFAULT_OPTIONS,
                ...options
            };
            if (nativeOfflineAudioContext === null) nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
            /*
             * Bug #99: Firefox does not throw a NotSupportedError when the numberOfChannels is zero. But it only does it when using the
             * factory function. But since Firefox also supports the constructor everything should be fine.
             */ const audioBuffer = nativeAudioBufferConstructor !== null && cacheTestResult(testNativeAudioBufferConstructorSupport, testNativeAudioBufferConstructorSupport) ? new nativeAudioBufferConstructor({
                length: length,
                numberOfChannels: numberOfChannels,
                sampleRate: sampleRate
            }) : nativeOfflineAudioContext.createBuffer(numberOfChannels, length, sampleRate);
            // Bug #99: Safari does not throw an error when the numberOfChannels is zero.
            if (audioBuffer.numberOfChannels === 0) throw createNotSupportedError();
            // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
            // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.
            if (typeof audioBuffer.copyFromChannel !== "function") {
                wrapAudioBufferCopyChannelMethods(audioBuffer);
                (0, $2e77af801a4782d4$export$df65309cf6249598)(audioBuffer);
            // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.
            } else if (!cacheTestResult((0, $ab7234a0e06cc19b$export$54e424f510c54ced), ()=>(0, $ab7234a0e06cc19b$export$54e424f510c54ced)(audioBuffer))) wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);
            audioBufferStore.add(audioBuffer);
            /*
             * This does violate all good pratices but it is necessary to allow this AudioBuffer to be used with native
             * (Offline)AudioContexts.
             */ return audioBuffer;
        }
        static [Symbol.hasInstance](instance) {
            return instance !== null && typeof instance === "object" && Object.getPrototypeOf(instance) === AudioBuffer.prototype || audioBufferStore.has(instance);
        }
    };
};


const $b1c06cbd433e26a1$export$ced6a5c63b103b52 = -340282346638528860000000000000000000000;
const $b1c06cbd433e26a1$export$ab43bedd17d6a167 = -$b1c06cbd433e26a1$export$ced6a5c63b103b52;



const $a52e8cf090f6ea8d$export$e44f0fc8e83fb084 = (audioNode)=>(0, $45092aa0415316c7$export$2b500979aea0913f).has(audioNode);




const $34eafaf1433ef6a8$var$DEFAULT_OPTIONS = {
    buffer: null,
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    // Bug #149: Safari does not yet support the detune AudioParam.
    loop: false,
    loopEnd: 0,
    loopStart: 0,
    playbackRate: 1
};
const $34eafaf1433ef6a8$export$6857b764b4428518 = (audioNodeConstructor, createAudioBufferSourceNodeRenderer, createAudioParam, createInvalidStateError, createNativeAudioBufferSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener)=>{
    return class AudioBufferSourceNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...$34eafaf1433ef6a8$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const audioBufferSourceNodeRenderer = isOffline ? createAudioBufferSourceNodeRenderer() : null;
            super(context, false, nativeAudioBufferSourceNode, audioBufferSourceNodeRenderer);
            this._audioBufferSourceNodeRenderer = audioBufferSourceNodeRenderer;
            this._isBufferNullified = false;
            this._isBufferSet = mergedOptions.buffer !== null;
            this._nativeAudioBufferSourceNode = nativeAudioBufferSourceNode;
            this._onended = null;
            // Bug #73: Safari does not export the correct values for maxValue and minValue.
            this._playbackRate = createAudioParam(this, isOffline, nativeAudioBufferSourceNode.playbackRate, (0, $b1c06cbd433e26a1$export$ab43bedd17d6a167), (0, $b1c06cbd433e26a1$export$ced6a5c63b103b52));
        }
        get buffer() {
            if (this._isBufferNullified) return null;
            return this._nativeAudioBufferSourceNode.buffer;
        }
        set buffer(value) {
            this._nativeAudioBufferSourceNode.buffer = value;
            // Bug #72: Only Chrome, Edge & Opera do not allow to reassign the buffer yet.
            if (value !== null) {
                if (this._isBufferSet) throw createInvalidStateError();
                this._isBufferSet = true;
            }
        }
        get loop() {
            return this._nativeAudioBufferSourceNode.loop;
        }
        set loop(value) {
            this._nativeAudioBufferSourceNode.loop = value;
        }
        get loopEnd() {
            return this._nativeAudioBufferSourceNode.loopEnd;
        }
        set loopEnd(value) {
            this._nativeAudioBufferSourceNode.loopEnd = value;
        }
        get loopStart() {
            return this._nativeAudioBufferSourceNode.loopStart;
        }
        set loopStart(value) {
            this._nativeAudioBufferSourceNode.loopStart = value;
        }
        get onended() {
            return this._onended;
        }
        set onended(value) {
            const wrappedListener = typeof value === "function" ? wrapEventListener(this, value) : null;
            this._nativeAudioBufferSourceNode.onended = wrappedListener;
            const nativeOnEnded = this._nativeAudioBufferSourceNode.onended;
            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;
        }
        get playbackRate() {
            return this._playbackRate;
        }
        start(when = 0, offset = 0, duration) {
            this._nativeAudioBufferSourceNode.start(when, offset, duration);
            if (this._audioBufferSourceNodeRenderer !== null) this._audioBufferSourceNodeRenderer.start = duration === undefined ? [
                when,
                offset
            ] : [
                when,
                offset,
                duration
            ];
            if (this.context.state !== "closed") {
                (0, $e4b65d1b7a33a6ae$export$88a47afdc0e8539c)(this);
                const resetInternalStateToPassive = ()=>{
                    this._nativeAudioBufferSourceNode.removeEventListener("ended", resetInternalStateToPassive);
                    if ((0, $a52e8cf090f6ea8d$export$e44f0fc8e83fb084)(this)) (0, $30e3b887134462bb$export$7c0830f3a5100dec)(this);
                };
                this._nativeAudioBufferSourceNode.addEventListener("ended", resetInternalStateToPassive);
            }
        }
        stop(when = 0) {
            this._nativeAudioBufferSourceNode.stop(when);
            if (this._audioBufferSourceNodeRenderer !== null) this._audioBufferSourceNodeRenderer.stop = when;
        }
    };
};



const $a4495543677998f1$export$82721be5d1bb22c5 = (connectAudioParam, createNativeAudioBufferSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeAudioBufferSourceNodes = new WeakMap();
        let start = null;
        let stop = null;
        const createAudioBufferSourceNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeAudioBufferSourceNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeAudioBufferSourceNode was not constructed on the same OfflineAudioContext it needs to be created
             * again.
             */ const nativeAudioBufferSourceNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeAudioBufferSourceNode, nativeOfflineAudioContext);
            if (!nativeAudioBufferSourceNodeIsOwnedByContext) {
                const options = {
                    buffer: nativeAudioBufferSourceNode.buffer,
                    channelCount: nativeAudioBufferSourceNode.channelCount,
                    channelCountMode: nativeAudioBufferSourceNode.channelCountMode,
                    channelInterpretation: nativeAudioBufferSourceNode.channelInterpretation,
                    // Bug #149: Safari does not yet support the detune AudioParam.
                    loop: nativeAudioBufferSourceNode.loop,
                    loopEnd: nativeAudioBufferSourceNode.loopEnd,
                    loopStart: nativeAudioBufferSourceNode.loopStart,
                    playbackRate: nativeAudioBufferSourceNode.playbackRate.value
                };
                nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, options);
                if (start !== null) nativeAudioBufferSourceNode.start(...start);
                if (stop !== null) nativeAudioBufferSourceNode.stop(stop);
            }
            renderedNativeAudioBufferSourceNodes.set(nativeOfflineAudioContext, nativeAudioBufferSourceNode);
            if (!nativeAudioBufferSourceNodeIsOwnedByContext) // Bug #149: Safari does not yet support the detune AudioParam.
            await renderAutomation(nativeOfflineAudioContext, proxy.playbackRate, nativeAudioBufferSourceNode.playbackRate);
            else // Bug #149: Safari does not yet support the detune AudioParam.
            await connectAudioParam(nativeOfflineAudioContext, proxy.playbackRate, nativeAudioBufferSourceNode.playbackRate);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioBufferSourceNode);
            return nativeAudioBufferSourceNode;
        };
        return {
            set start (value){
                start = value;
            },
            set stop (value){
                stop = value;
            },
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeAudioBufferSourceNode = renderedNativeAudioBufferSourceNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioBufferSourceNode !== undefined) return Promise.resolve(renderedNativeAudioBufferSourceNode);
                return createAudioBufferSourceNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};


const $16f063f78fb00312$export$b030d1cb39b66ce3 = (audioNode)=>{
    return "playbackRate" in audioNode;
};



const $aece41fb58d34b07$export$8bbceb3e2d3b886a = (audioNode)=>{
    return "frequency" in audioNode && "gain" in audioNode;
};


const $8c96dd02459682e3$export$2b5f11f35c31b1bf = (audioNode)=>{
    return "offset" in audioNode;
};


const $fcdaa06b2f76a802$export$c124c0514d4f41ab = (audioNode)=>{
    return !("frequency" in audioNode) && "gain" in audioNode;
};


const $488c80b484cdde6a$export$97bb3ed4238ea897 = (audioNode)=>{
    return "detune" in audioNode && "frequency" in audioNode;
};


const $e7068a8b95ef93d4$export$79ba82be14a0b006 = (audioNode)=>{
    return "pan" in audioNode;
};




const $82132aac47394666$export$6b29eee2af836dfc = (audioNode)=>{
    return (0, $838ea8ed33d27e81$export$520987e3ff3ffad3)((0, $45092aa0415316c7$export$61ca80a8c8c6d728), audioNode);
};




const $b3cb1d7500dafa25$export$1b11f454bf19657 = (audioParam)=>{
    return (0, $838ea8ed33d27e81$export$520987e3ff3ffad3)((0, $45092aa0415316c7$export$c5d3ff1f46a0185a), audioParam);
};




const $2e2caa3cc605008c$export$e16f533d410eeca0 = (audioNode, trace)=>{
    const { activeInputs: activeInputs  } = (0, $82132aac47394666$export$6b29eee2af836dfc)(audioNode);
    activeInputs.forEach((connections)=>connections.forEach(([source])=>{
            if (!trace.includes(audioNode)) $2e2caa3cc605008c$export$e16f533d410eeca0(source, [
                ...trace,
                audioNode
            ]);
        }));
    const audioParams = (0, $16f063f78fb00312$export$b030d1cb39b66ce3)(audioNode) ? [
        // Bug #149: Safari does not yet support the detune AudioParam.
        audioNode.playbackRate
    ] : (0, $140cc20865db247d$export$1293b9fc79a24682)(audioNode) ? Array.from(audioNode.parameters.values()) : (0, $aece41fb58d34b07$export$8bbceb3e2d3b886a)(audioNode) ? [
        audioNode.Q,
        audioNode.detune,
        audioNode.frequency,
        audioNode.gain
    ] : (0, $8c96dd02459682e3$export$2b5f11f35c31b1bf)(audioNode) ? [
        audioNode.offset
    ] : (0, $fcdaa06b2f76a802$export$c124c0514d4f41ab)(audioNode) ? [
        audioNode.gain
    ] : (0, $488c80b484cdde6a$export$97bb3ed4238ea897)(audioNode) ? [
        audioNode.detune,
        audioNode.frequency
    ] : (0, $e7068a8b95ef93d4$export$79ba82be14a0b006)(audioNode) ? [
        audioNode.pan
    ] : [];
    for (const audioParam of audioParams){
        const audioParamConnections = (0, $b3cb1d7500dafa25$export$1b11f454bf19657)(audioParam);
        if (audioParamConnections !== undefined) audioParamConnections.activeInputs.forEach(([source])=>$2e2caa3cc605008c$export$e16f533d410eeca0(source, trace));
    }
    if ((0, $a52e8cf090f6ea8d$export$e44f0fc8e83fb084)(audioNode)) (0, $30e3b887134462bb$export$7c0830f3a5100dec)(audioNode);
};


const $d831926c266dcbcf$export$cbd606bc629ea938 = (context)=>{
    (0, $2e2caa3cc605008c$export$e16f533d410eeca0)(context.destination, []);
};


const $bc5e404df0d80636$export$82d5f0e102842fbe = (latencyHint)=>{
    return latencyHint === undefined || typeof latencyHint === "number" || typeof latencyHint === "string" && (latencyHint === "balanced" || latencyHint === "interactive" || latencyHint === "playback");
};


const $d05f510371680fae$export$c6fe175def53ff71 = (baseAudioContextConstructor, createInvalidStateError, createNotSupportedError, createUnknownError, mediaElementAudioSourceNodeConstructor, mediaStreamAudioDestinationNodeConstructor, mediaStreamAudioSourceNodeConstructor, mediaStreamTrackAudioSourceNodeConstructor, nativeAudioContextConstructor)=>{
    return class AudioContext extends baseAudioContextConstructor {
        constructor(options = {}){
            if (nativeAudioContextConstructor === null) throw new Error("Missing the native AudioContext constructor.");
            let nativeAudioContext;
            try {
                nativeAudioContext = new nativeAudioContextConstructor(options);
            } catch (err) {
                // Bug #192 Safari does throw a SyntaxError if the sampleRate is not supported.
                if (err.code === 12 && err.message === "sampleRate is not in range") throw createNotSupportedError();
                throw err;
            }
            // Bug #131 Safari returns null when there are four other AudioContexts running already.
            if (nativeAudioContext === null) throw createUnknownError();
            // Bug #51 Only Chrome, Edge and Opera throw an error if the given latencyHint is invalid.
            if (!(0, $bc5e404df0d80636$export$82d5f0e102842fbe)(options.latencyHint)) throw new TypeError(`The provided value '${options.latencyHint}' is not a valid enum value of type AudioContextLatencyCategory.`);
            // Bug #150 Safari does not support setting the sampleRate.
            if (options.sampleRate !== undefined && nativeAudioContext.sampleRate !== options.sampleRate) throw createNotSupportedError();
            super(nativeAudioContext, 2);
            const { latencyHint: latencyHint  } = options;
            const { sampleRate: sampleRate  } = nativeAudioContext;
            // @todo The values for 'balanced', 'interactive' and 'playback' are just copied from Chrome's implementation.
            this._baseLatency = typeof nativeAudioContext.baseLatency === "number" ? nativeAudioContext.baseLatency : latencyHint === "balanced" ? 512 / sampleRate : latencyHint === "interactive" || latencyHint === undefined ? 256 / sampleRate : latencyHint === "playback" ? 1024 / sampleRate : /*
                                   * @todo The min (256) and max (16384) values are taken from the allowed bufferSize values of a
                                   * ScriptProcessorNode.
                                   */ Math.max(2, Math.min(128, Math.round(latencyHint * sampleRate / 128))) * 128 / sampleRate;
            this._nativeAudioContext = nativeAudioContext;
            // Bug #188: Safari will set the context's state to 'interrupted' in case the user switches tabs.
            if (nativeAudioContextConstructor.name === "webkitAudioContext") {
                this._nativeGainNode = nativeAudioContext.createGain();
                this._nativeOscillatorNode = nativeAudioContext.createOscillator();
                this._nativeGainNode.gain.value = 1e-37;
                this._nativeOscillatorNode.connect(this._nativeGainNode).connect(nativeAudioContext.destination);
                this._nativeOscillatorNode.start();
            } else {
                this._nativeGainNode = null;
                this._nativeOscillatorNode = null;
            }
            this._state = null;
            /*
             * Bug #34: Chrome, Edge and Opera pretend to be running right away, but fire an onstatechange event when the state actually
             * changes to 'running'.
             */ if (nativeAudioContext.state === "running") {
                this._state = "suspended";
                const revokeState = ()=>{
                    if (this._state === "suspended") this._state = null;
                    nativeAudioContext.removeEventListener("statechange", revokeState);
                };
                nativeAudioContext.addEventListener("statechange", revokeState);
            }
        }
        get baseLatency() {
            return this._baseLatency;
        }
        get state() {
            return this._state !== null ? this._state : this._nativeAudioContext.state;
        }
        close() {
            // Bug #35: Firefox does not throw an error if the AudioContext was closed before.
            if (this.state === "closed") return this._nativeAudioContext.close().then(()=>{
                throw createInvalidStateError();
            });
            // Bug #34: If the state was set to suspended before it should be revoked now.
            if (this._state === "suspended") this._state = null;
            return this._nativeAudioContext.close().then(()=>{
                if (this._nativeGainNode !== null && this._nativeOscillatorNode !== null) {
                    this._nativeOscillatorNode.stop();
                    this._nativeGainNode.disconnect();
                    this._nativeOscillatorNode.disconnect();
                }
                (0, $d831926c266dcbcf$export$cbd606bc629ea938)(this);
            });
        }
        createMediaElementSource(mediaElement) {
            return new mediaElementAudioSourceNodeConstructor(this, {
                mediaElement: mediaElement
            });
        }
        createMediaStreamDestination() {
            return new mediaStreamAudioDestinationNodeConstructor(this);
        }
        createMediaStreamSource(mediaStream) {
            return new mediaStreamAudioSourceNodeConstructor(this, {
                mediaStream: mediaStream
            });
        }
        createMediaStreamTrackSource(mediaStreamTrack) {
            return new mediaStreamTrackAudioSourceNodeConstructor(this, {
                mediaStreamTrack: mediaStreamTrack
            });
        }
        resume() {
            if (this._state === "suspended") return new Promise((resolve, reject)=>{
                const resolvePromise = ()=>{
                    this._nativeAudioContext.removeEventListener("statechange", resolvePromise);
                    if (this._nativeAudioContext.state === "running") resolve();
                    else this.resume().then(resolve, reject);
                };
                this._nativeAudioContext.addEventListener("statechange", resolvePromise);
            });
            return this._nativeAudioContext.resume().catch((err)=>{
                // Bug #55: Chrome, Edge and Opera do throw an InvalidAccessError instead of an InvalidStateError.
                // Bug #56: Safari invokes the catch handler but without an error.
                if (err === undefined || err.code === 15) throw createInvalidStateError();
                throw err;
            });
        }
        suspend() {
            return this._nativeAudioContext.suspend().catch((err)=>{
                // Bug #56: Safari invokes the catch handler but without an error.
                if (err === undefined) throw createInvalidStateError();
                throw err;
            });
        }
    };
};


const $615d78d315d73e79$export$cbbb0c3ba3f5dd5b = (audioNodeConstructor, createAudioDestinationNodeRenderer, createIndexSizeError, createInvalidStateError, createNativeAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext, renderInputsOfAudioNode)=>{
    return class AudioDestinationNode extends audioNodeConstructor {
        constructor(context, channelCount){
            const nativeContext = getNativeContext(context);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const nativeAudioDestinationNode = createNativeAudioDestinationNode(nativeContext, channelCount, isOffline);
            const audioDestinationNodeRenderer = isOffline ? createAudioDestinationNodeRenderer(renderInputsOfAudioNode) : null;
            super(context, false, nativeAudioDestinationNode, audioDestinationNodeRenderer);
            this._isNodeOfNativeOfflineAudioContext = isOffline;
            this._nativeAudioDestinationNode = nativeAudioDestinationNode;
        }
        get channelCount() {
            return this._nativeAudioDestinationNode.channelCount;
        }
        set channelCount(value) {
            // Bug #52: Chrome, Edge, Opera & Safari do not throw an exception at all.
            // Bug #54: Firefox does throw an IndexSizeError.
            if (this._isNodeOfNativeOfflineAudioContext) throw createInvalidStateError();
            // Bug #47: The AudioDestinationNode in Safari does not initialize the maxChannelCount property correctly.
            if (value > this._nativeAudioDestinationNode.maxChannelCount) throw createIndexSizeError();
            this._nativeAudioDestinationNode.channelCount = value;
        }
        get channelCountMode() {
            return this._nativeAudioDestinationNode.channelCountMode;
        }
        set channelCountMode(value) {
            // Bug #53: No browser does throw an exception yet.
            if (this._isNodeOfNativeOfflineAudioContext) throw createInvalidStateError();
            this._nativeAudioDestinationNode.channelCountMode = value;
        }
        get maxChannelCount() {
            return this._nativeAudioDestinationNode.maxChannelCount;
        }
    };
};


const $83c842f9a51e64b0$export$d44f3f5d4e42ced2 = (renderInputsOfAudioNode)=>{
    const renderedNativeAudioDestinationNodes = new WeakMap();
    const createAudioDestinationNode = async (proxy, nativeOfflineAudioContext)=>{
        const nativeAudioDestinationNode = nativeOfflineAudioContext.destination;
        renderedNativeAudioDestinationNodes.set(nativeOfflineAudioContext, nativeAudioDestinationNode);
        await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioDestinationNode);
        return nativeAudioDestinationNode;
    };
    return {
        render (proxy, nativeOfflineAudioContext) {
            const renderedNativeAudioDestinationNode = renderedNativeAudioDestinationNodes.get(nativeOfflineAudioContext);
            if (renderedNativeAudioDestinationNode !== undefined) return Promise.resolve(renderedNativeAudioDestinationNode);
            return createAudioDestinationNode(proxy, nativeOfflineAudioContext);
        }
    };
};



const $28f8df2bee08a6f8$export$3e70692c55bd5b52 = (createAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeScriptProcessorNode, createNotSupportedError, getFirstSample, isNativeOfflineAudioContext, overwriteAccessors)=>{
    return (context, nativeContext)=>{
        const nativeListener = nativeContext.listener;
        // Bug #117: Only Chrome, Edge & Opera support the new interface already.
        const createFakeAudioParams = ()=>{
            const buffer = new Float32Array(1);
            const channelMergerNode = createNativeChannelMergerNode(nativeContext, {
                channelCount: 1,
                channelCountMode: "explicit",
                channelInterpretation: "speakers",
                numberOfInputs: 9
            });
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            let isScriptProcessorNodeCreated = false;
            let lastOrientation = [
                0,
                0,
                -1,
                0,
                1,
                0
            ];
            let lastPosition = [
                0,
                0,
                0
            ];
            const createScriptProcessorNode = ()=>{
                if (isScriptProcessorNodeCreated) return;
                isScriptProcessorNodeCreated = true;
                const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, 256, 9, 0);
                // tslint:disable-next-line:deprecation
                scriptProcessorNode.onaudioprocess = ({ inputBuffer: inputBuffer  })=>{
                    const orientation = [
                        getFirstSample(inputBuffer, buffer, 0),
                        getFirstSample(inputBuffer, buffer, 1),
                        getFirstSample(inputBuffer, buffer, 2),
                        getFirstSample(inputBuffer, buffer, 3),
                        getFirstSample(inputBuffer, buffer, 4),
                        getFirstSample(inputBuffer, buffer, 5)
                    ];
                    if (orientation.some((value, index)=>value !== lastOrientation[index])) {
                        nativeListener.setOrientation(...orientation); // tslint:disable-line:deprecation
                        lastOrientation = orientation;
                    }
                    const positon = [
                        getFirstSample(inputBuffer, buffer, 6),
                        getFirstSample(inputBuffer, buffer, 7),
                        getFirstSample(inputBuffer, buffer, 8)
                    ];
                    if (positon.some((value, index)=>value !== lastPosition[index])) {
                        nativeListener.setPosition(...positon); // tslint:disable-line:deprecation
                        lastPosition = positon;
                    }
                };
                channelMergerNode.connect(scriptProcessorNode);
            };
            const createSetOrientation = (index)=>(value)=>{
                    if (value !== lastOrientation[index]) {
                        lastOrientation[index] = value;
                        nativeListener.setOrientation(...lastOrientation); // tslint:disable-line:deprecation
                    }
                };
            const createSetPosition = (index)=>(value)=>{
                    if (value !== lastPosition[index]) {
                        lastPosition[index] = value;
                        nativeListener.setPosition(...lastPosition); // tslint:disable-line:deprecation
                    }
                };
            const createFakeAudioParam = (input, initialValue, setValue)=>{
                const constantSourceNode = createNativeConstantSourceNode(nativeContext, {
                    channelCount: 1,
                    channelCountMode: "explicit",
                    channelInterpretation: "discrete",
                    offset: initialValue
                });
                constantSourceNode.connect(channelMergerNode, 0, input);
                // @todo This should be stopped when the context is closed.
                constantSourceNode.start();
                Object.defineProperty(constantSourceNode.offset, "defaultValue", {
                    get () {
                        return initialValue;
                    }
                });
                /*
                 * Bug #62 & #74: Safari does not support ConstantSourceNodes and does not export the correct values for maxValue and
                 * minValue for GainNodes.
                 */ const audioParam = createAudioParam({
                    context: context
                }, isOffline, constantSourceNode.offset, (0, $b1c06cbd433e26a1$export$ab43bedd17d6a167), (0, $b1c06cbd433e26a1$export$ced6a5c63b103b52));
                overwriteAccessors(audioParam, "value", (get)=>()=>get.call(audioParam), (set)=>(value)=>{
                        try {
                            set.call(audioParam, value);
                        } catch (err) {
                            if (err.code !== 9) throw err;
                        }
                        createScriptProcessorNode();
                        if (isOffline) // Bug #117: Using setOrientation() and setPosition() doesn't work with an OfflineAudioContext.
                        setValue(value);
                    });
                audioParam.cancelAndHoldAtTime = ((cancelAndHoldAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = cancelAndHoldAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.cancelAndHoldAtTime);
                audioParam.cancelScheduledValues = ((cancelScheduledValues)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = cancelScheduledValues.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.cancelScheduledValues);
                audioParam.exponentialRampToValueAtTime = ((exponentialRampToValueAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = exponentialRampToValueAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.exponentialRampToValueAtTime);
                audioParam.linearRampToValueAtTime = ((linearRampToValueAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = linearRampToValueAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.linearRampToValueAtTime);
                audioParam.setTargetAtTime = ((setTargetAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = setTargetAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.setTargetAtTime);
                audioParam.setValueAtTime = ((setValueAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = setValueAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.setValueAtTime);
                audioParam.setValueCurveAtTime = ((setValueCurveAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = setValueCurveAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.setValueCurveAtTime);
                return audioParam;
            };
            return {
                forwardX: createFakeAudioParam(0, 0, createSetOrientation(0)),
                forwardY: createFakeAudioParam(1, 0, createSetOrientation(1)),
                forwardZ: createFakeAudioParam(2, -1, createSetOrientation(2)),
                positionX: createFakeAudioParam(6, 0, createSetPosition(0)),
                positionY: createFakeAudioParam(7, 0, createSetPosition(1)),
                positionZ: createFakeAudioParam(8, 0, createSetPosition(2)),
                upX: createFakeAudioParam(3, 0, createSetOrientation(3)),
                upY: createFakeAudioParam(4, 1, createSetOrientation(4)),
                upZ: createFakeAudioParam(5, 0, createSetOrientation(5))
            };
        };
        const { forwardX: forwardX , forwardY: forwardY , forwardZ: forwardZ , positionX: positionX , positionY: positionY , positionZ: positionZ , upX: upX , upY: upY , upZ: upZ  } = nativeListener.forwardX === undefined ? createFakeAudioParams() : nativeListener;
        return {
            get forwardX () {
                return forwardX;
            },
            get forwardY () {
                return forwardY;
            },
            get forwardZ () {
                return forwardZ;
            },
            get positionX () {
                return positionX;
            },
            get positionY () {
                return positionY;
            },
            get positionZ () {
                return positionZ;
            },
            get upX () {
                return upX;
            },
            get upY () {
                return upY;
            },
            get upZ () {
                return upZ;
            }
        };
    };
};



const $659689b3be408df4$export$85cd8e93eb858e81 = (audioNodeOrAudioParam)=>{
    return "context" in audioNodeOrAudioParam;
};



const $6fabcecde01c3a66$export$419d66ef3a96a878 = (outputConnection)=>{
    return (0, $659689b3be408df4$export$85cd8e93eb858e81)(outputConnection[0]);
};


const $2cb97ab8cc5662cd$export$64505511c8abc942 = (set, element, predicate, ignoreDuplicates)=>{
    for (const lmnt of set)if (predicate(lmnt)) {
        if (ignoreDuplicates) return false;
        throw Error("The set contains at least one similar element.");
    }
    set.add(element);
    return true;
};


const $f8e37185debab93a$export$3dfe9f7f712d42df = (activeInputs, source, [output, eventListener], ignoreDuplicates)=>{
    (0, $2cb97ab8cc5662cd$export$64505511c8abc942)(activeInputs, [
        source,
        output,
        eventListener
    ], (activeInputConnection)=>activeInputConnection[0] === source && activeInputConnection[1] === output, ignoreDuplicates);
};



const $71b57763610f4d38$export$2a7c0e6916aa50e4 = (passiveInputs, [source, output, eventListener], ignoreDuplicates)=>{
    const passiveInputConnections = passiveInputs.get(source);
    if (passiveInputConnections === undefined) passiveInputs.set(source, new Set([
        [
            output,
            eventListener
        ]
    ]));
    else (0, $2cb97ab8cc5662cd$export$64505511c8abc942)(passiveInputConnections, [
        output,
        eventListener
    ], (passiveInputConnection)=>passiveInputConnection[0] === output, ignoreDuplicates);
};


const $77ab69d57b7e7a12$export$ac2aef07f705aa48 = (nativeAudioNodeOrNativeAudioNodeFaker)=>{
    return "inputs" in nativeAudioNodeOrNativeAudioNodeFaker;
};


const $9561d33b242cedb0$export$b92162b3199b4461 = (nativeSourceAudioNode, nativeDestinationAudioNode, output, input)=>{
    if ((0, $77ab69d57b7e7a12$export$ac2aef07f705aa48)(nativeDestinationAudioNode)) {
        const fakeNativeDestinationAudioNode = nativeDestinationAudioNode.inputs[input];
        nativeSourceAudioNode.connect(fakeNativeDestinationAudioNode, output, 0);
        return [
            fakeNativeDestinationAudioNode,
            output,
            0
        ];
    }
    nativeSourceAudioNode.connect(nativeDestinationAudioNode, output, input);
    return [
        nativeDestinationAudioNode,
        output,
        input
    ];
};


const $b38eb489586ebaba$export$6cc4c86d6b87a4b8 = (activeInputConnections, source, output)=>{
    for (const activeInputConnection of activeInputConnections)if (activeInputConnection[0] === source && activeInputConnection[1] === output) {
        activeInputConnections.delete(activeInputConnection);
        return activeInputConnection;
    }
    return null;
};



const $64eec171ede5309a$export$dc5a8616367736a9 = (activeInputs, source, output)=>{
    return (0, $115343c7346cd8e6$export$3f1b331b43a0e659)(activeInputs, (activeInputConnection)=>activeInputConnection[0] === source && activeInputConnection[1] === output);
};



const $47d4a778512365f1$export$b5a32c2e2eac4137 = (audioNode, eventListener)=>{
    const eventListeners = (0, $d6dd4c96535f9fa2$export$caac7ea54cb93b25)(audioNode);
    if (!eventListeners.delete(eventListener)) throw new Error("Missing the expected event listener.");
};





const $ab9030c7bf52f2b2$export$368aa16ce008e2f4 = (passiveInputs, source, output)=>{
    const passiveInputConnections = (0, $838ea8ed33d27e81$export$520987e3ff3ffad3)(passiveInputs, source);
    const matchingConnection = (0, $115343c7346cd8e6$export$3f1b331b43a0e659)(passiveInputConnections, (passiveInputConnection)=>passiveInputConnection[0] === output);
    if (passiveInputConnections.size === 0) passiveInputs.delete(source);
    return matchingConnection;
};



const $147c083052099f38$export$a19b495df4b88921 = (nativeSourceAudioNode, nativeDestinationAudioNode, output, input)=>{
    if ((0, $77ab69d57b7e7a12$export$ac2aef07f705aa48)(nativeDestinationAudioNode)) nativeSourceAudioNode.disconnect(nativeDestinationAudioNode.inputs[input], output, 0);
    else nativeSourceAudioNode.disconnect(nativeDestinationAudioNode, output, input);
};







const $91004965fac1b491$export$e719c0d45ea16d08 = (audioNode)=>{
    return (0, $838ea8ed33d27e81$export$520987e3ff3ffad3)((0, $45092aa0415316c7$export$864a3cfb55580d0c), audioNode);
};




const $172aa88b2fc4c949$export$fad3d843b2a56ffb = (audioParam)=>{
    return (0, $838ea8ed33d27e81$export$520987e3ff3ffad3)((0, $45092aa0415316c7$export$55484e3055c7a9e2), audioParam);
};





const $ff7fd1ee6b8a1725$export$8658a39a04a404d5 = (audioNode)=>{
    return (0, $45092aa0415316c7$export$cf686a6a3e402092).has(audioNode);
};



const $2e47ed05befd6218$export$79a7cb9fa56970e = (audioNode)=>{
    return !(0, $45092aa0415316c7$export$2b500979aea0913f).has(audioNode);
};




const $9fe0b527cd9e6df2$export$f938a299860627 = (nativeAudioContext, nativeAudioWorkletNodeConstructor)=>{
    return new Promise((resolve)=>{
        /*
         * This bug existed in Safari up until v14.0.2. Since AudioWorklets were not supported in Safari until v14.1 the presence of the
         * constructor for an AudioWorkletNode can be used here to skip the test.
         */ if (nativeAudioWorkletNodeConstructor !== null) resolve(true);
        else {
            const analyzer = nativeAudioContext.createScriptProcessor(256, 1, 1); // tslint:disable-line deprecation
            const dummy = nativeAudioContext.createGain();
            // Bug #95: Safari does not play one sample buffers.
            const ones = nativeAudioContext.createBuffer(1, 2, 44100);
            const channelData = ones.getChannelData(0);
            channelData[0] = 1;
            channelData[1] = 1;
            const source = nativeAudioContext.createBufferSource();
            source.buffer = ones;
            source.loop = true;
            source.connect(analyzer).connect(nativeAudioContext.destination);
            source.connect(dummy);
            source.disconnect(dummy);
            // tslint:disable-next-line:deprecation
            analyzer.onaudioprocess = (event)=>{
                const chnnlDt = event.inputBuffer.getChannelData(0); // tslint:disable-line deprecation
                if (Array.prototype.some.call(chnnlDt, (sample)=>sample === 1)) resolve(true);
                else resolve(false);
                source.stop();
                analyzer.onaudioprocess = null; // tslint:disable-line:deprecation
                source.disconnect(analyzer);
                analyzer.disconnect(nativeAudioContext.destination);
            };
            source.start();
        }
    });
};


const $d804a4a58e0a126a$export$f8092aa3a6fcf50f = (cycles, visitor)=>{
    const counts = new Map();
    for (const cycle of cycles)for (const audioNode1 of cycle){
        const count = counts.get(audioNode1);
        counts.set(audioNode1, count === undefined ? 1 : count + 1);
    }
    counts.forEach((count, audioNode)=>visitor(audioNode, count));
};


const $6c08598be15fa4cc$export$d647358384f164e0 = (nativeAudioNodeOrAudioParam)=>{
    return "context" in nativeAudioNodeOrAudioParam;
};


const $0b091055c85a7e95$export$d4ca24d0078a887f = (nativeAudioNode)=>{
    const connections = new Map();
    nativeAudioNode.connect = ((connect)=>{
        // tslint:disable-next-line:invalid-void no-inferrable-types
        return (destination, output = 0, input = 0)=>{
            const returnValue = (0, $6c08598be15fa4cc$export$d647358384f164e0)(destination) ? connect(destination, output, input) : connect(destination, output);
            // Save the new connection only if the calls to connect above didn't throw an error.
            const connectionsToDestination = connections.get(destination);
            if (connectionsToDestination === undefined) connections.set(destination, [
                {
                    input: input,
                    output: output
                }
            ]);
            else if (connectionsToDestination.every((connection)=>connection.input !== input || connection.output !== output)) connectionsToDestination.push({
                input: input,
                output: output
            });
            return returnValue;
        };
    })(nativeAudioNode.connect.bind(nativeAudioNode));
    nativeAudioNode.disconnect = ((disconnect)=>{
        return (destinationOrOutput, output, input)=>{
            disconnect.apply(nativeAudioNode);
            if (destinationOrOutput === undefined) connections.clear();
            else if (typeof destinationOrOutput === "number") for (const [destination, connectionsToDestination] of connections){
                const filteredConnections = connectionsToDestination.filter((connection)=>connection.output !== destinationOrOutput);
                if (filteredConnections.length === 0) connections.delete(destination);
                else connections.set(destination, filteredConnections);
            }
            else if (connections.has(destinationOrOutput)) {
                if (output === undefined) connections.delete(destinationOrOutput);
                else {
                    const connectionsToDestination = connections.get(destinationOrOutput);
                    if (connectionsToDestination !== undefined) {
                        const filteredConnections = connectionsToDestination.filter((connection)=>connection.output !== output && (connection.input !== input || input === undefined));
                        if (filteredConnections.length === 0) connections.delete(destinationOrOutput);
                        else connections.set(destinationOrOutput, filteredConnections);
                    }
                }
            }
            for (const [destination1, connectionsToDestination1] of connections)connectionsToDestination1.forEach((connection)=>{
                if ((0, $6c08598be15fa4cc$export$d647358384f164e0)(destination1)) nativeAudioNode.connect(destination1, connection.output, connection.input);
                else nativeAudioNode.connect(destination1, connection.output);
            });
        };
    })(nativeAudioNode.disconnect);
};


const $45ba32bea7b08f76$var$addConnectionToAudioParamOfAudioContext = (source, destination, output, isOffline)=>{
    const { activeInputs: activeInputs , passiveInputs: passiveInputs  } = (0, $b3cb1d7500dafa25$export$1b11f454bf19657)(destination);
    const { outputs: outputs  } = (0, $82132aac47394666$export$6b29eee2af836dfc)(source);
    const eventListeners = (0, $d6dd4c96535f9fa2$export$caac7ea54cb93b25)(source);
    const eventListener = (isActive)=>{
        const nativeAudioNode = (0, $91004965fac1b491$export$e719c0d45ea16d08)(source);
        const nativeAudioParam = (0, $172aa88b2fc4c949$export$fad3d843b2a56ffb)(destination);
        if (isActive) {
            const partialConnection = (0, $ab9030c7bf52f2b2$export$368aa16ce008e2f4)(passiveInputs, source, output);
            (0, $f8e37185debab93a$export$3dfe9f7f712d42df)(activeInputs, source, partialConnection, false);
            if (!isOffline && !(0, $ff7fd1ee6b8a1725$export$8658a39a04a404d5)(source)) nativeAudioNode.connect(nativeAudioParam, output);
        } else {
            const partialConnection = (0, $64eec171ede5309a$export$dc5a8616367736a9)(activeInputs, source, output);
            (0, $71b57763610f4d38$export$2a7c0e6916aa50e4)(passiveInputs, partialConnection, false);
            if (!isOffline && !(0, $ff7fd1ee6b8a1725$export$8658a39a04a404d5)(source)) nativeAudioNode.disconnect(nativeAudioParam, output);
        }
    };
    if ((0, $2cb97ab8cc5662cd$export$64505511c8abc942)(outputs, [
        destination,
        output
    ], (outputConnection)=>outputConnection[0] === destination && outputConnection[1] === output, true)) {
        eventListeners.add(eventListener);
        if ((0, $a52e8cf090f6ea8d$export$e44f0fc8e83fb084)(source)) (0, $f8e37185debab93a$export$3dfe9f7f712d42df)(activeInputs, source, [
            output,
            eventListener
        ], true);
        else (0, $71b57763610f4d38$export$2a7c0e6916aa50e4)(passiveInputs, [
            source,
            output,
            eventListener
        ], true);
        return true;
    }
    return false;
};
const $45ba32bea7b08f76$var$deleteInputConnectionOfAudioNode = (source, destination, output, input)=>{
    const { activeInputs: activeInputs , passiveInputs: passiveInputs  } = (0, $82132aac47394666$export$6b29eee2af836dfc)(destination);
    const activeInputConnection = (0, $b38eb489586ebaba$export$6cc4c86d6b87a4b8)(activeInputs[input], source, output);
    if (activeInputConnection === null) {
        const passiveInputConnection = (0, $adf8394cf0998b48$export$26ec3ebc965d6cfd)(passiveInputs, source, output, input);
        return [
            passiveInputConnection[2],
            false
        ];
    }
    return [
        activeInputConnection[2],
        true
    ];
};
const $45ba32bea7b08f76$var$deleteInputConnectionOfAudioParam = (source, destination, output)=>{
    const { activeInputs: activeInputs , passiveInputs: passiveInputs  } = (0, $b3cb1d7500dafa25$export$1b11f454bf19657)(destination);
    const activeInputConnection = (0, $b38eb489586ebaba$export$6cc4c86d6b87a4b8)(activeInputs, source, output);
    if (activeInputConnection === null) {
        const passiveInputConnection = (0, $ab9030c7bf52f2b2$export$368aa16ce008e2f4)(passiveInputs, source, output);
        return [
            passiveInputConnection[1],
            false
        ];
    }
    return [
        activeInputConnection[2],
        true
    ];
};
const $45ba32bea7b08f76$var$deleteInputsOfAudioNode = (source, isOffline, destination, output, input)=>{
    const [listener, isActive] = $45ba32bea7b08f76$var$deleteInputConnectionOfAudioNode(source, destination, output, input);
    if (listener !== null) {
        (0, $47d4a778512365f1$export$b5a32c2e2eac4137)(source, listener);
        if (isActive && !isOffline && !(0, $ff7fd1ee6b8a1725$export$8658a39a04a404d5)(source)) (0, $147c083052099f38$export$a19b495df4b88921)((0, $91004965fac1b491$export$e719c0d45ea16d08)(source), (0, $91004965fac1b491$export$e719c0d45ea16d08)(destination), output, input);
    }
    if ((0, $a52e8cf090f6ea8d$export$e44f0fc8e83fb084)(destination)) {
        const { activeInputs: activeInputs  } = (0, $82132aac47394666$export$6b29eee2af836dfc)(destination);
        (0, $14d833df3cd44d0b$export$c74023ca160dc207)(destination, activeInputs);
    }
};
const $45ba32bea7b08f76$var$deleteInputsOfAudioParam = (source, isOffline, destination, output)=>{
    const [listener, isActive] = $45ba32bea7b08f76$var$deleteInputConnectionOfAudioParam(source, destination, output);
    if (listener !== null) {
        (0, $47d4a778512365f1$export$b5a32c2e2eac4137)(source, listener);
        if (isActive && !isOffline && !(0, $ff7fd1ee6b8a1725$export$8658a39a04a404d5)(source)) (0, $91004965fac1b491$export$e719c0d45ea16d08)(source).disconnect((0, $172aa88b2fc4c949$export$fad3d843b2a56ffb)(destination), output);
    }
};
const $45ba32bea7b08f76$var$deleteAnyConnection = (source, isOffline)=>{
    const audioNodeConnectionsOfSource = (0, $82132aac47394666$export$6b29eee2af836dfc)(source);
    const destinations = [];
    for (const outputConnection of audioNodeConnectionsOfSource.outputs){
        if ((0, $6fabcecde01c3a66$export$419d66ef3a96a878)(outputConnection)) $45ba32bea7b08f76$var$deleteInputsOfAudioNode(source, isOffline, ...outputConnection);
        else $45ba32bea7b08f76$var$deleteInputsOfAudioParam(source, isOffline, ...outputConnection);
        destinations.push(outputConnection[0]);
    }
    audioNodeConnectionsOfSource.outputs.clear();
    return destinations;
};
const $45ba32bea7b08f76$var$deleteConnectionAtOutput = (source, isOffline, output)=>{
    const audioNodeConnectionsOfSource = (0, $82132aac47394666$export$6b29eee2af836dfc)(source);
    const destinations = [];
    for (const outputConnection of audioNodeConnectionsOfSource.outputs)if (outputConnection[1] === output) {
        if ((0, $6fabcecde01c3a66$export$419d66ef3a96a878)(outputConnection)) $45ba32bea7b08f76$var$deleteInputsOfAudioNode(source, isOffline, ...outputConnection);
        else $45ba32bea7b08f76$var$deleteInputsOfAudioParam(source, isOffline, ...outputConnection);
        destinations.push(outputConnection[0]);
        audioNodeConnectionsOfSource.outputs.delete(outputConnection);
    }
    return destinations;
};
const $45ba32bea7b08f76$var$deleteConnectionToDestination = (source, isOffline, destination, output, input)=>{
    const audioNodeConnectionsOfSource = (0, $82132aac47394666$export$6b29eee2af836dfc)(source);
    return Array.from(audioNodeConnectionsOfSource.outputs).filter((outputConnection)=>outputConnection[0] === destination && (output === undefined || outputConnection[1] === output) && (input === undefined || outputConnection[2] === input)).map((outputConnection)=>{
        if ((0, $6fabcecde01c3a66$export$419d66ef3a96a878)(outputConnection)) $45ba32bea7b08f76$var$deleteInputsOfAudioNode(source, isOffline, ...outputConnection);
        else $45ba32bea7b08f76$var$deleteInputsOfAudioParam(source, isOffline, ...outputConnection);
        audioNodeConnectionsOfSource.outputs.delete(outputConnection);
        return outputConnection[0];
    });
};
const $45ba32bea7b08f76$export$20e3fa4f981cb01d = (addAudioNodeConnections, addConnectionToAudioNode, cacheTestResult, createIncrementCycleCounter, createIndexSizeError, createInvalidAccessError, createNotSupportedError, decrementCycleCounter, detectCycles, eventTargetConstructor, getNativeContext, isNativeAudioContext, isNativeAudioNode, isNativeAudioParam, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor)=>{
    return class AudioNode extends eventTargetConstructor {
        constructor(context, isActive, nativeAudioNode, audioNodeRenderer){
            super(nativeAudioNode);
            this._context = context;
            this._nativeAudioNode = nativeAudioNode;
            const nativeContext = getNativeContext(context);
            // Bug #12: Safari does not support to disconnect a specific destination.
            if (isNativeAudioContext(nativeContext) && true !== cacheTestResult((0, $9fe0b527cd9e6df2$export$f938a299860627), ()=>{
                return (0, $9fe0b527cd9e6df2$export$f938a299860627)(nativeContext, nativeAudioWorkletNodeConstructor);
            })) (0, $0b091055c85a7e95$export$d4ca24d0078a887f)(nativeAudioNode);
            (0, $45092aa0415316c7$export$864a3cfb55580d0c).set(this, nativeAudioNode);
            (0, $45092aa0415316c7$export$c998cfefa4fd5136).set(this, new Set());
            if (context.state !== "closed" && isActive) (0, $e4b65d1b7a33a6ae$export$88a47afdc0e8539c)(this);
            addAudioNodeConnections(this, audioNodeRenderer, nativeAudioNode);
        }
        get channelCount() {
            return this._nativeAudioNode.channelCount;
        }
        set channelCount(value) {
            this._nativeAudioNode.channelCount = value;
        }
        get channelCountMode() {
            return this._nativeAudioNode.channelCountMode;
        }
        set channelCountMode(value) {
            this._nativeAudioNode.channelCountMode = value;
        }
        get channelInterpretation() {
            return this._nativeAudioNode.channelInterpretation;
        }
        set channelInterpretation(value) {
            this._nativeAudioNode.channelInterpretation = value;
        }
        get context() {
            return this._context;
        }
        get numberOfInputs() {
            return this._nativeAudioNode.numberOfInputs;
        }
        get numberOfOutputs() {
            return this._nativeAudioNode.numberOfOutputs;
        }
        // tslint:disable-next-line:invalid-void
        connect(destination, output = 0, input = 0) {
            // Bug #174: Safari does expose a wrong numberOfOutputs for MediaStreamAudioDestinationNodes.
            if (output < 0 || output >= this._nativeAudioNode.numberOfOutputs) throw createIndexSizeError();
            const nativeContext = getNativeContext(this._context);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            if (isNativeAudioNode(destination) || isNativeAudioParam(destination)) throw createInvalidAccessError();
            if ((0, $659689b3be408df4$export$85cd8e93eb858e81)(destination)) {
                const nativeDestinationAudioNode = (0, $91004965fac1b491$export$e719c0d45ea16d08)(destination);
                try {
                    const connection = (0, $9561d33b242cedb0$export$b92162b3199b4461)(this._nativeAudioNode, nativeDestinationAudioNode, output, input);
                    const isPassive = (0, $2e47ed05befd6218$export$79a7cb9fa56970e)(this);
                    if (isOffline || isPassive) this._nativeAudioNode.disconnect(...connection);
                    if (this.context.state !== "closed" && !isPassive && (0, $2e47ed05befd6218$export$79a7cb9fa56970e)(destination)) (0, $e4b65d1b7a33a6ae$export$88a47afdc0e8539c)(destination);
                } catch (err) {
                    // Bug #41: Safari does not throw the correct exception so far.
                    if (err.code === 12) throw createInvalidAccessError();
                    throw err;
                }
                const isNewConnectionToAudioNode = addConnectionToAudioNode(this, destination, output, input, isOffline);
                // Bug #164: Only Firefox detects cycles so far.
                if (isNewConnectionToAudioNode) {
                    const cycles = detectCycles([
                        this
                    ], destination);
                    (0, $d804a4a58e0a126a$export$f8092aa3a6fcf50f)(cycles, createIncrementCycleCounter(isOffline));
                }
                return destination;
            }
            const nativeAudioParam = (0, $172aa88b2fc4c949$export$fad3d843b2a56ffb)(destination);
            /*
             * Bug #73, #147 & #153: Safari does not support to connect an input signal to the playbackRate AudioParam of an
             * AudioBufferSourceNode. This can't be easily detected and that's why the outdated name property is used here to identify
             * Safari. In addition to that the maxValue property is used to only detect the affected versions below v14.0.2.
             */ if (nativeAudioParam.name === "playbackRate" && nativeAudioParam.maxValue === 1024) throw createNotSupportedError();
            try {
                this._nativeAudioNode.connect(nativeAudioParam, output);
                if (isOffline || (0, $2e47ed05befd6218$export$79a7cb9fa56970e)(this)) this._nativeAudioNode.disconnect(nativeAudioParam, output);
            } catch (err) {
                // Bug #58: Safari doesn't throw an InvalidAccessError yet.
                if (err.code === 12) throw createInvalidAccessError();
                throw err;
            }
            const isNewConnectionToAudioParam = $45ba32bea7b08f76$var$addConnectionToAudioParamOfAudioContext(this, destination, output, isOffline);
            // Bug #164: Only Firefox detects cycles so far.
            if (isNewConnectionToAudioParam) {
                const cycles = detectCycles([
                    this
                ], destination);
                (0, $d804a4a58e0a126a$export$f8092aa3a6fcf50f)(cycles, createIncrementCycleCounter(isOffline));
            }
        }
        disconnect(destinationOrOutput, output, input) {
            let destinations;
            const nativeContext = getNativeContext(this._context);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            if (destinationOrOutput === undefined) destinations = $45ba32bea7b08f76$var$deleteAnyConnection(this, isOffline);
            else if (typeof destinationOrOutput === "number") {
                if (destinationOrOutput < 0 || destinationOrOutput >= this.numberOfOutputs) throw createIndexSizeError();
                destinations = $45ba32bea7b08f76$var$deleteConnectionAtOutput(this, isOffline, destinationOrOutput);
            } else {
                if (output !== undefined && (output < 0 || output >= this.numberOfOutputs)) throw createIndexSizeError();
                if ((0, $659689b3be408df4$export$85cd8e93eb858e81)(destinationOrOutput) && input !== undefined && (input < 0 || input >= destinationOrOutput.numberOfInputs)) throw createIndexSizeError();
                destinations = $45ba32bea7b08f76$var$deleteConnectionToDestination(this, isOffline, destinationOrOutput, output, input);
                if (destinations.length === 0) throw createInvalidAccessError();
            }
            // Bug #164: Only Firefox detects cycles so far.
            for (const destination of destinations){
                const cycles = detectCycles([
                    this
                ], destination);
                (0, $d804a4a58e0a126a$export$f8092aa3a6fcf50f)(cycles, decrementCycleCounter);
            }
        }
    };
};



const $d0eac1364ca1b1f7$export$25d3edb077748cfc = (addAudioParamConnections, audioParamAudioNodeStore, audioParamStore, createAudioParamRenderer, createCancelAndHoldAutomationEvent, createCancelScheduledValuesAutomationEvent, createExponentialRampToValueAutomationEvent, createLinearRampToValueAutomationEvent, createSetTargetAutomationEvent, createSetValueAutomationEvent, createSetValueCurveAutomationEvent, nativeAudioContextConstructor, setValueAtTimeUntilPossible)=>{
    return (audioNode, isAudioParamOfOfflineAudioContext, nativeAudioParam, maxValue = null, minValue = null)=>{
        const automationEventList = new (0, $4765696a62faea77$exports.AutomationEventList)(nativeAudioParam.defaultValue);
        const audioParamRenderer = isAudioParamOfOfflineAudioContext ? createAudioParamRenderer(automationEventList) : null;
        const audioParam = {
            get defaultValue () {
                return nativeAudioParam.defaultValue;
            },
            get maxValue () {
                return maxValue === null ? nativeAudioParam.maxValue : maxValue;
            },
            get minValue () {
                return minValue === null ? nativeAudioParam.minValue : minValue;
            },
            get value () {
                return nativeAudioParam.value;
            },
            set value (value){
                nativeAudioParam.value = value;
                // Bug #98: Firefox & Safari do not yet treat the value setter like a call to setValueAtTime().
                audioParam.setValueAtTime(value, audioNode.context.currentTime);
            },
            cancelAndHoldAtTime (cancelTime) {
                // Bug #28: Firefox & Safari do not yet implement cancelAndHoldAtTime().
                if (typeof nativeAudioParam.cancelAndHoldAtTime === "function") {
                    if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                    automationEventList.add(createCancelAndHoldAutomationEvent(cancelTime));
                    nativeAudioParam.cancelAndHoldAtTime(cancelTime);
                } else {
                    const previousLastEvent = Array.from(automationEventList).pop();
                    if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                    automationEventList.add(createCancelAndHoldAutomationEvent(cancelTime));
                    const currentLastEvent = Array.from(automationEventList).pop();
                    nativeAudioParam.cancelScheduledValues(cancelTime);
                    if (previousLastEvent !== currentLastEvent && currentLastEvent !== undefined) {
                        if (currentLastEvent.type === "exponentialRampToValue") nativeAudioParam.exponentialRampToValueAtTime(currentLastEvent.value, currentLastEvent.endTime);
                        else if (currentLastEvent.type === "linearRampToValue") nativeAudioParam.linearRampToValueAtTime(currentLastEvent.value, currentLastEvent.endTime);
                        else if (currentLastEvent.type === "setValue") nativeAudioParam.setValueAtTime(currentLastEvent.value, currentLastEvent.startTime);
                        else if (currentLastEvent.type === "setValueCurve") nativeAudioParam.setValueCurveAtTime(currentLastEvent.values, currentLastEvent.startTime, currentLastEvent.duration);
                    }
                }
                return audioParam;
            },
            cancelScheduledValues (cancelTime) {
                if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                automationEventList.add(createCancelScheduledValuesAutomationEvent(cancelTime));
                nativeAudioParam.cancelScheduledValues(cancelTime);
                return audioParam;
            },
            exponentialRampToValueAtTime (value, endTime) {
                // Bug #45: Safari does not throw an error yet.
                if (value === 0) throw new RangeError();
                // Bug #187: Safari does not throw an error yet.
                if (!Number.isFinite(endTime) || endTime < 0) throw new RangeError();
                if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                automationEventList.add(createExponentialRampToValueAutomationEvent(value, endTime));
                nativeAudioParam.exponentialRampToValueAtTime(value, endTime);
                return audioParam;
            },
            linearRampToValueAtTime (value, endTime) {
                if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                automationEventList.add(createLinearRampToValueAutomationEvent(value, endTime));
                nativeAudioParam.linearRampToValueAtTime(value, endTime);
                return audioParam;
            },
            setTargetAtTime (target, startTime, timeConstant) {
                if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                automationEventList.add(createSetTargetAutomationEvent(target, startTime, timeConstant));
                nativeAudioParam.setTargetAtTime(target, startTime, timeConstant);
                return audioParam;
            },
            setValueAtTime (value, startTime) {
                if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                automationEventList.add(createSetValueAutomationEvent(value, startTime));
                nativeAudioParam.setValueAtTime(value, startTime);
                return audioParam;
            },
            setValueCurveAtTime (values, startTime, duration) {
                // Bug 183: Safari only accepts a Float32Array.
                const convertedValues = values instanceof Float32Array ? values : new Float32Array(values);
                /*
                 * Bug #152: Safari does not correctly interpolate the values of the curve.
                 * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the
                 * existence of the webkitAudioContext is used as a workaround here.
                 */ if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === "webkitAudioContext") {
                    const endTime = startTime + duration;
                    const sampleRate = audioNode.context.sampleRate;
                    const firstSample = Math.ceil(startTime * sampleRate);
                    const lastSample = Math.floor(endTime * sampleRate);
                    const numberOfInterpolatedValues = lastSample - firstSample;
                    const interpolatedValues = new Float32Array(numberOfInterpolatedValues);
                    for(let i = 0; i < numberOfInterpolatedValues; i += 1){
                        const theoreticIndex = (convertedValues.length - 1) / duration * ((firstSample + i) / sampleRate - startTime);
                        const lowerIndex = Math.floor(theoreticIndex);
                        const upperIndex = Math.ceil(theoreticIndex);
                        interpolatedValues[i] = lowerIndex === upperIndex ? convertedValues[lowerIndex] : (1 - (theoreticIndex - lowerIndex)) * convertedValues[lowerIndex] + (1 - (upperIndex - theoreticIndex)) * convertedValues[upperIndex];
                    }
                    if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                    automationEventList.add(createSetValueCurveAutomationEvent(interpolatedValues, startTime, duration));
                    nativeAudioParam.setValueCurveAtTime(interpolatedValues, startTime, duration);
                    const timeOfLastSample = lastSample / sampleRate;
                    if (timeOfLastSample < endTime) setValueAtTimeUntilPossible(audioParam, interpolatedValues[interpolatedValues.length - 1], timeOfLastSample);
                    setValueAtTimeUntilPossible(audioParam, convertedValues[convertedValues.length - 1], endTime);
                } else {
                    if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                    automationEventList.add(createSetValueCurveAutomationEvent(convertedValues, startTime, duration));
                    nativeAudioParam.setValueCurveAtTime(convertedValues, startTime, duration);
                }
                return audioParam;
            }
        };
        audioParamStore.set(audioParam, nativeAudioParam);
        audioParamAudioNodeStore.set(audioParam, audioNode);
        addAudioParamConnections(audioParam, audioParamRenderer);
        return audioParam;
    };
};


const $ba5705d1c52da529$export$8858f507eb103ac6 = (automationEventList)=>{
    return {
        replay (audioParam) {
            for (const automationEvent of automationEventList){
                if (automationEvent.type === "exponentialRampToValue") {
                    const { endTime: endTime , value: value  } = automationEvent;
                    audioParam.exponentialRampToValueAtTime(value, endTime);
                } else if (automationEvent.type === "linearRampToValue") {
                    const { endTime: endTime , value: value  } = automationEvent;
                    audioParam.linearRampToValueAtTime(value, endTime);
                } else if (automationEvent.type === "setTarget") {
                    const { startTime: startTime , target: target , timeConstant: timeConstant  } = automationEvent;
                    audioParam.setTargetAtTime(target, startTime, timeConstant);
                } else if (automationEvent.type === "setValue") {
                    const { startTime: startTime , value: value  } = automationEvent;
                    audioParam.setValueAtTime(value, startTime);
                } else if (automationEvent.type === "setValueCurve") {
                    const { duration: duration , startTime: startTime , values: values  } = automationEvent;
                    audioParam.setValueCurveAtTime(values, startTime, duration);
                } else throw new Error("Can't apply an unknown automation.");
            }
        }
    };
};



class $5bfcd23ee6d93a68$export$5da0cf80a3ca75d6 {
    constructor(parameters){
        this._map = new Map(parameters);
    }
    get size() {
        return this._map.size;
    }
    entries() {
        return this._map.entries();
    }
    forEach(callback, thisArg = null) {
        return this._map.forEach((value, key)=>callback.call(thisArg, value, key, this));
    }
    get(name) {
        return this._map.get(name);
    }
    has(name) {
        return this._map.has(name);
    }
    keys() {
        return this._map.keys();
    }
    values() {
        return this._map.values();
    }
}


const $4887df8ecec6be4d$var$DEFAULT_OPTIONS = {
    channelCount: 2,
    // Bug #61: The channelCountMode should be 'max' according to the spec but is set to 'explicit' to achieve consistent behavior.
    channelCountMode: "explicit",
    channelInterpretation: "speakers",
    numberOfInputs: 1,
    numberOfOutputs: 1,
    parameterData: {},
    processorOptions: {}
};
const $4887df8ecec6be4d$export$48302d37fa2cf062 = (addUnrenderedAudioWorkletNode, audioNodeConstructor, createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, getAudioNodeConnections, getBackupOfflineAudioContext, getNativeContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, sanitizeAudioWorkletNodeOptions, setActiveAudioWorkletNodeInputs, testAudioWorkletNodeOptionsClonability, wrapEventListener)=>{
    return class AudioWorkletNode extends audioNodeConstructor {
        constructor(context, name, options){
            var _a;
            const nativeContext = getNativeContext(context);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const mergedOptions = sanitizeAudioWorkletNodeOptions({
                ...$4887df8ecec6be4d$var$DEFAULT_OPTIONS,
                ...options
            });
            // Bug #191: Safari doesn't throw an error if the options aren't clonable.
            testAudioWorkletNodeOptionsClonability(mergedOptions);
            const nodeNameToProcessorConstructorMap = (0, $45092aa0415316c7$export$b9bea39f06f96914).get(nativeContext);
            const processorConstructor = nodeNameToProcessorConstructorMap === null || nodeNameToProcessorConstructorMap === void 0 ? void 0 : nodeNameToProcessorConstructorMap.get(name);
            // Bug #186: Chrome, Edge and Opera do not allow to create an AudioWorkletNode on a closed AudioContext.
            const nativeContextOrBackupOfflineAudioContext = isOffline || nativeContext.state !== "closed" ? nativeContext : (_a = getBackupOfflineAudioContext(nativeContext)) !== null && _a !== void 0 ? _a : nativeContext;
            const nativeAudioWorkletNode = createNativeAudioWorkletNode(nativeContextOrBackupOfflineAudioContext, isOffline ? null : context.baseLatency, nativeAudioWorkletNodeConstructor, name, processorConstructor, mergedOptions);
            const audioWorkletNodeRenderer = isOffline ? createAudioWorkletNodeRenderer(name, mergedOptions, processorConstructor) : null;
            /*
             * @todo Add a mechanism to switch an AudioWorkletNode to passive once the process() function of the AudioWorkletProcessor
             * returns false.
             */ super(context, true, nativeAudioWorkletNode, audioWorkletNodeRenderer);
            const parameters = [];
            nativeAudioWorkletNode.parameters.forEach((nativeAudioParam, nm)=>{
                const audioParam = createAudioParam(this, isOffline, nativeAudioParam);
                parameters.push([
                    nm,
                    audioParam
                ]);
            });
            this._nativeAudioWorkletNode = nativeAudioWorkletNode;
            this._onprocessorerror = null;
            this._parameters = new (0, $5bfcd23ee6d93a68$export$5da0cf80a3ca75d6)(parameters);
            /*
             * Bug #86 & #87: Invoking the renderer of an AudioWorkletNode might be necessary if it has no direct or indirect connection to
             * the destination.
             */ if (isOffline) addUnrenderedAudioWorkletNode(nativeContext, this);
            const { activeInputs: activeInputs  } = getAudioNodeConnections(this);
            setActiveAudioWorkletNodeInputs(nativeAudioWorkletNode, activeInputs);
        }
        get onprocessorerror() {
            return this._onprocessorerror;
        }
        set onprocessorerror(value) {
            const wrappedListener = typeof value === "function" ? wrapEventListener(this, value) : null;
            this._nativeAudioWorkletNode.onprocessorerror = wrappedListener;
            const nativeOnProcessorError = this._nativeAudioWorkletNode.onprocessorerror;
            this._onprocessorerror = nativeOnProcessorError !== null && nativeOnProcessorError === wrappedListener ? value : nativeOnProcessorError;
        }
        get parameters() {
            if (this._parameters === null) // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.
            return this._nativeAudioWorkletNode.parameters;
            return this._parameters;
        }
        get port() {
            return this._nativeAudioWorkletNode.port;
        }
    };
};


function $b7b6361fd4dedbae$export$e3c6e435bf217093(audioBuffer, // @todo There is currently no way to define something like { [ key: number | string ]: Float32Array }
parent, key, channelNumber, bufferOffset) {
    if (typeof audioBuffer.copyFromChannel === "function") {
        // The byteLength will be 0 when the ArrayBuffer was transferred.
        if (parent[key].byteLength === 0) parent[key] = new Float32Array(128);
        audioBuffer.copyFromChannel(parent[key], channelNumber, bufferOffset);
    // Bug #5: Safari does not support copyFromChannel().
    } else {
        const channelData = audioBuffer.getChannelData(channelNumber);
        // The byteLength will be 0 when the ArrayBuffer was transferred.
        if (parent[key].byteLength === 0) parent[key] = channelData.slice(bufferOffset, bufferOffset + 128);
        else {
            const slicedInput = new Float32Array(channelData.buffer, bufferOffset * Float32Array.BYTES_PER_ELEMENT, 128);
            parent[key].set(slicedInput);
        }
    }
}


const $cd25e5111351f21f$export$6bb6d131144bd753 = (audioBuffer, parent, key, channelNumber, bufferOffset)=>{
    if (typeof audioBuffer.copyToChannel === "function") // The byteLength will be 0 when the ArrayBuffer was transferred.
    {
        if (parent[key].byteLength !== 0) audioBuffer.copyToChannel(parent[key], channelNumber, bufferOffset);
    } else // The byteLength will be 0 when the ArrayBuffer was transferred.
    if (parent[key].byteLength !== 0) audioBuffer.getChannelData(channelNumber).set(parent[key], bufferOffset);
};


const $a954efb50ecf21d3$export$495a31436d188d6d = (x, y)=>{
    const arrays = [];
    for(let i = 0; i < x; i += 1){
        const array = [];
        const length = typeof y === "number" ? y : y[i];
        for(let j = 0; j < length; j += 1)array.push(new Float32Array(128));
        arrays.push(array);
    }
    return arrays;
};






const $ed9d278a90d1a445$export$d948bbdb8f0d97d7 = (nativeOfflineAudioContext, proxy)=>{
    const nodeToProcessorMap = (0, $838ea8ed33d27e81$export$520987e3ff3ffad3)((0, $45092aa0415316c7$export$16d7878f7e059d67), nativeOfflineAudioContext);
    const nativeAudioWorkletNode = (0, $91004965fac1b491$export$e719c0d45ea16d08)(proxy);
    return (0, $838ea8ed33d27e81$export$520987e3ff3ffad3)(nodeToProcessorMap, nativeAudioWorkletNode);
};



const $73e5f5f4a9d714e0$var$processBuffer = async (proxy, renderedBuffer, nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime)=>{
    // Ceil the length to the next full render quantum.
    // Bug #17: Safari does not yet expose the length.
    const length = renderedBuffer === null ? Math.ceil(proxy.context.length / 128) * 128 : renderedBuffer.length;
    const numberOfInputChannels = options.channelCount * options.numberOfInputs;
    const numberOfOutputChannels = outputChannelCount.reduce((sum, value)=>sum + value, 0);
    const processedBuffer = numberOfOutputChannels === 0 ? null : nativeOfflineAudioContext.createBuffer(numberOfOutputChannels, length, nativeOfflineAudioContext.sampleRate);
    if (processorConstructor === undefined) throw new Error("Missing the processor constructor.");
    const audioNodeConnections = (0, $82132aac47394666$export$6b29eee2af836dfc)(proxy);
    const audioWorkletProcessor = await (0, $ed9d278a90d1a445$export$d948bbdb8f0d97d7)(nativeOfflineAudioContext, proxy);
    const inputs = (0, $a954efb50ecf21d3$export$495a31436d188d6d)(options.numberOfInputs, options.channelCount);
    const outputs = (0, $a954efb50ecf21d3$export$495a31436d188d6d)(options.numberOfOutputs, outputChannelCount);
    const parameters = Array.from(proxy.parameters.keys()).reduce((prmtrs, name)=>({
            ...prmtrs,
            [name]: new Float32Array(128)
        }), {});
    for(let i = 0; i < length; i += 128){
        if (options.numberOfInputs > 0 && renderedBuffer !== null) {
            for(let j = 0; j < options.numberOfInputs; j += 1)for(let k = 0; k < options.channelCount; k += 1)(0, $b7b6361fd4dedbae$export$e3c6e435bf217093)(renderedBuffer, inputs[j], k, k, i);
        }
        if (processorConstructor.parameterDescriptors !== undefined && renderedBuffer !== null) processorConstructor.parameterDescriptors.forEach(({ name: name  }, index)=>{
            (0, $b7b6361fd4dedbae$export$e3c6e435bf217093)(renderedBuffer, parameters, name, numberOfInputChannels + index, i);
        });
        for(let j = 0; j < options.numberOfInputs; j += 1){
            for(let k = 0; k < outputChannelCount[j]; k += 1)// The byteLength will be 0 when the ArrayBuffer was transferred.
            if (outputs[j][k].byteLength === 0) outputs[j][k] = new Float32Array(128);
        }
        try {
            const potentiallyEmptyInputs = inputs.map((input, index)=>{
                if (audioNodeConnections.activeInputs[index].size === 0) return [];
                return input;
            });
            const activeSourceFlag = exposeCurrentFrameAndCurrentTime(i / nativeOfflineAudioContext.sampleRate, nativeOfflineAudioContext.sampleRate, ()=>audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters));
            if (processedBuffer !== null) for(let j = 0, outputChannelSplitterNodeOutput = 0; j < options.numberOfOutputs; j += 1){
                for(let k = 0; k < outputChannelCount[j]; k += 1)(0, $cd25e5111351f21f$export$6bb6d131144bd753)(processedBuffer, outputs[j], k, outputChannelSplitterNodeOutput + k, i);
                outputChannelSplitterNodeOutput += outputChannelCount[j];
            }
            if (!activeSourceFlag) break;
        } catch (error) {
            proxy.dispatchEvent(new ErrorEvent("processorerror", {
                colno: error.colno,
                filename: error.filename,
                lineno: error.lineno,
                message: error.message
            }));
            break;
        }
    }
    return processedBuffer;
};
const $73e5f5f4a9d714e0$export$3a898af5d2b29a5b = (connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getNativeAudioNode, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext)=>{
    return (name, options, processorConstructor)=>{
        const renderedNativeAudioNodes = new WeakMap();
        let processedBufferPromise = null;
        const createAudioNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeAudioWorkletNode = getNativeAudioNode(proxy);
            let nativeOutputNodes = null;
            const nativeAudioWorkletNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeAudioWorkletNode, nativeOfflineAudioContext);
            const outputChannelCount = Array.isArray(options.outputChannelCount) ? options.outputChannelCount : Array.from(options.outputChannelCount);
            // Bug #61: Only Chrome, Edge, Firefox & Opera have an implementation of the AudioWorkletNode yet.
            if (nativeAudioWorkletNodeConstructor === null) {
                const numberOfOutputChannels = outputChannelCount.reduce((sum, value)=>sum + value, 0);
                const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, {
                    channelCount: Math.max(1, numberOfOutputChannels),
                    channelCountMode: "explicit",
                    channelInterpretation: "discrete",
                    numberOfOutputs: Math.max(1, numberOfOutputChannels)
                });
                const outputChannelMergerNodes = [];
                for(let i = 0; i < proxy.numberOfOutputs; i += 1)outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeOfflineAudioContext, {
                    channelCount: 1,
                    channelCountMode: "explicit",
                    channelInterpretation: "speakers",
                    numberOfInputs: outputChannelCount[i]
                }));
                const outputGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                    channelCount: options.channelCount,
                    channelCountMode: options.channelCountMode,
                    channelInterpretation: options.channelInterpretation,
                    gain: 1
                });
                outputGainNode.connect = connectMultipleOutputs.bind(null, outputChannelMergerNodes);
                outputGainNode.disconnect = disconnectMultipleOutputs.bind(null, outputChannelMergerNodes);
                nativeOutputNodes = [
                    outputChannelSplitterNode,
                    outputChannelMergerNodes,
                    outputGainNode
                ];
            } else if (!nativeAudioWorkletNodeIsOwnedByContext) nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeOfflineAudioContext, name);
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeOutputNodes === null ? nativeAudioWorkletNode : nativeOutputNodes[2]);
            if (nativeOutputNodes !== null) {
                if (processedBufferPromise === null) {
                    if (processorConstructor === undefined) throw new Error("Missing the processor constructor.");
                    if (nativeOfflineAudioContextConstructor === null) throw new Error("Missing the native OfflineAudioContext constructor.");
                    // Bug #47: The AudioDestinationNode in Safari gets not initialized correctly.
                    const numberOfInputChannels = proxy.channelCount * proxy.numberOfInputs;
                    const numberOfParameters = processorConstructor.parameterDescriptors === undefined ? 0 : processorConstructor.parameterDescriptors.length;
                    const numberOfChannels = numberOfInputChannels + numberOfParameters;
                    const renderBuffer = async ()=>{
                        const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(numberOfChannels, // Ceil the length to the next full render quantum.
                        // Bug #17: Safari does not yet expose the length.
                        Math.ceil(proxy.context.length / 128) * 128, nativeOfflineAudioContext.sampleRate);
                        const gainNodes = [];
                        const inputChannelSplitterNodes = [];
                        for(let i = 0; i < options.numberOfInputs; i += 1){
                            gainNodes.push(createNativeGainNode(partialOfflineAudioContext, {
                                channelCount: options.channelCount,
                                channelCountMode: options.channelCountMode,
                                channelInterpretation: options.channelInterpretation,
                                gain: 1
                            }));
                            inputChannelSplitterNodes.push(createNativeChannelSplitterNode(partialOfflineAudioContext, {
                                channelCount: options.channelCount,
                                channelCountMode: "explicit",
                                channelInterpretation: "discrete",
                                numberOfOutputs: options.channelCount
                            }));
                        }
                        const constantSourceNodes = await Promise.all(Array.from(proxy.parameters.values()).map(async (audioParam)=>{
                            const constantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {
                                channelCount: 1,
                                channelCountMode: "explicit",
                                channelInterpretation: "discrete",
                                offset: audioParam.value
                            });
                            await renderAutomation(partialOfflineAudioContext, audioParam, constantSourceNode.offset);
                            return constantSourceNode;
                        }));
                        const inputChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {
                            channelCount: 1,
                            channelCountMode: "explicit",
                            channelInterpretation: "speakers",
                            numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)
                        });
                        for(let i1 = 0; i1 < options.numberOfInputs; i1 += 1){
                            gainNodes[i1].connect(inputChannelSplitterNodes[i1]);
                            for(let j = 0; j < options.channelCount; j += 1)inputChannelSplitterNodes[i1].connect(inputChannelMergerNode, j, i1 * options.channelCount + j);
                        }
                        for (const [index, constantSourceNode1] of constantSourceNodes.entries()){
                            constantSourceNode1.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);
                            constantSourceNode1.start(0);
                        }
                        inputChannelMergerNode.connect(partialOfflineAudioContext.destination);
                        await Promise.all(gainNodes.map((gainNode)=>renderInputsOfAudioNode(proxy, partialOfflineAudioContext, gainNode)));
                        return renderNativeOfflineAudioContext(partialOfflineAudioContext);
                    };
                    processedBufferPromise = $73e5f5f4a9d714e0$var$processBuffer(proxy, numberOfChannels === 0 ? null : await renderBuffer(), nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime);
                }
                const processedBuffer = await processedBufferPromise;
                const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {
                    buffer: null,
                    channelCount: 2,
                    channelCountMode: "max",
                    channelInterpretation: "speakers",
                    loop: false,
                    loopEnd: 0,
                    loopStart: 0,
                    playbackRate: 1
                });
                const [outputChannelSplitterNode, outputChannelMergerNodes, outputGainNode] = nativeOutputNodes;
                if (processedBuffer !== null) {
                    audioBufferSourceNode.buffer = processedBuffer;
                    audioBufferSourceNode.start(0);
                }
                audioBufferSourceNode.connect(outputChannelSplitterNode);
                for(let i2 = 0, outputChannelSplitterNodeOutput = 0; i2 < proxy.numberOfOutputs; i2 += 1){
                    const outputChannelMergerNode = outputChannelMergerNodes[i2];
                    for(let j = 0; j < outputChannelCount[i2]; j += 1)outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);
                    outputChannelSplitterNodeOutput += outputChannelCount[i2];
                }
                return outputGainNode;
            }
            if (!nativeAudioWorkletNodeIsOwnedByContext) for (const [nm, audioParam2] of proxy.parameters.entries())await renderAutomation(nativeOfflineAudioContext, audioParam2, // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.
            nativeAudioWorkletNode.parameters.get(nm));
            else for (const [nm1, audioParam1] of proxy.parameters.entries())await connectAudioParam(nativeOfflineAudioContext, audioParam1, // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.
            nativeAudioWorkletNode.parameters.get(nm1));
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioWorkletNode);
            return nativeAudioWorkletNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                deleteUnrenderedAudioWorkletNode(nativeOfflineAudioContext, proxy);
                const renderedNativeAudioWorkletNodeOrGainNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioWorkletNodeOrGainNode !== undefined) return Promise.resolve(renderedNativeAudioWorkletNodeOrGainNode);
                return createAudioNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};


const $3b9761fb51dbb0f5$export$7824d6f4713e1e35 = (addAudioWorkletModule, analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, convolverNodeConstructor, decodeAudioData, delayNodeConstructor, dynamicsCompressorNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor, pannerNodeConstructor, periodicWaveConstructor, stereoPannerNodeConstructor, waveShaperNodeConstructor)=>{
    return class BaseAudioContext extends minimalBaseAudioContextConstructor {
        constructor(_nativeContext, numberOfChannels){
            super(_nativeContext, numberOfChannels);
            this._nativeContext = _nativeContext;
            this._audioWorklet = addAudioWorkletModule === undefined ? undefined : {
                addModule: (moduleURL, options)=>{
                    return addAudioWorkletModule(this, moduleURL, options);
                }
            };
        }
        get audioWorklet() {
            return this._audioWorklet;
        }
        createAnalyser() {
            return new analyserNodeConstructor(this);
        }
        createBiquadFilter() {
            return new biquadFilterNodeConstructor(this);
        }
        createBuffer(numberOfChannels, length, sampleRate) {
            return new audioBufferConstructor({
                length: length,
                numberOfChannels: numberOfChannels,
                sampleRate: sampleRate
            });
        }
        createBufferSource() {
            return new audioBufferSourceNodeConstructor(this);
        }
        createChannelMerger(numberOfInputs = 6) {
            return new channelMergerNodeConstructor(this, {
                numberOfInputs: numberOfInputs
            });
        }
        createChannelSplitter(numberOfOutputs = 6) {
            return new channelSplitterNodeConstructor(this, {
                numberOfOutputs: numberOfOutputs
            });
        }
        createConstantSource() {
            return new constantSourceNodeConstructor(this);
        }
        createConvolver() {
            return new convolverNodeConstructor(this);
        }
        createDelay(maxDelayTime = 1) {
            return new delayNodeConstructor(this, {
                maxDelayTime: maxDelayTime
            });
        }
        createDynamicsCompressor() {
            return new dynamicsCompressorNodeConstructor(this);
        }
        createGain() {
            return new gainNodeConstructor(this);
        }
        createIIRFilter(feedforward, feedback) {
            return new iIRFilterNodeConstructor(this, {
                feedback: feedback,
                feedforward: feedforward
            });
        }
        createOscillator() {
            return new oscillatorNodeConstructor(this);
        }
        createPanner() {
            return new pannerNodeConstructor(this);
        }
        createPeriodicWave(real, imag, constraints = {
            disableNormalization: false
        }) {
            return new periodicWaveConstructor(this, {
                ...constraints,
                imag: imag,
                real: real
            });
        }
        createStereoPanner() {
            return new stereoPannerNodeConstructor(this);
        }
        createWaveShaper() {
            return new waveShaperNodeConstructor(this);
        }
        decodeAudioData(audioData, successCallback, errorCallback) {
            return decodeAudioData(this._nativeContext, audioData).then((audioBuffer)=>{
                if (typeof successCallback === "function") successCallback(audioBuffer);
                return audioBuffer;
            }, (err)=>{
                if (typeof errorCallback === "function") errorCallback(err);
                throw err;
            });
        }
    };
};



const $5626cc38a66fbbf6$var$DEFAULT_OPTIONS = {
    Q: 1,
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    detune: 0,
    frequency: 350,
    gain: 0,
    type: "lowpass"
};
const $5626cc38a66fbbf6$export$aa421daabad177b5 = (audioNodeConstructor, createAudioParam, createBiquadFilterNodeRenderer, createInvalidAccessError, createNativeBiquadFilterNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class BiquadFilterNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...$5626cc38a66fbbf6$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const biquadFilterNodeRenderer = isOffline ? createBiquadFilterNodeRenderer() : null;
            super(context, false, nativeBiquadFilterNode, biquadFilterNodeRenderer);
            // Bug #80: Safari does not export the correct values for maxValue and minValue.
            this._Q = createAudioParam(this, isOffline, nativeBiquadFilterNode.Q, (0, $b1c06cbd433e26a1$export$ab43bedd17d6a167), (0, $b1c06cbd433e26a1$export$ced6a5c63b103b52));
            // Bug #78: Firefox & Safari do not export the correct values for maxValue and minValue.
            this._detune = createAudioParam(this, isOffline, nativeBiquadFilterNode.detune, 1200 * Math.log2((0, $b1c06cbd433e26a1$export$ab43bedd17d6a167)), -1200 * Math.log2((0, $b1c06cbd433e26a1$export$ab43bedd17d6a167)));
            // Bug #77: Firefox & Safari do not export the correct value for minValue.
            this._frequency = createAudioParam(this, isOffline, nativeBiquadFilterNode.frequency, context.sampleRate / 2, 0);
            // Bug #79: Firefox & Safari do not export the correct values for maxValue and minValue.
            this._gain = createAudioParam(this, isOffline, nativeBiquadFilterNode.gain, 40 * Math.log10((0, $b1c06cbd433e26a1$export$ab43bedd17d6a167)), (0, $b1c06cbd433e26a1$export$ced6a5c63b103b52));
            this._nativeBiquadFilterNode = nativeBiquadFilterNode;
            // @todo Determine a meaningful tail-time instead of just using one second.
            setAudioNodeTailTime(this, 1);
        }
        get detune() {
            return this._detune;
        }
        get frequency() {
            return this._frequency;
        }
        get gain() {
            return this._gain;
        }
        get Q() {
            return this._Q;
        }
        get type() {
            return this._nativeBiquadFilterNode.type;
        }
        set type(value) {
            this._nativeBiquadFilterNode.type = value;
        }
        getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {
            // Bug #189: Safari does throw an InvalidStateError.
            try {
                this._nativeBiquadFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);
            } catch (err) {
                if (err.code === 11) throw createInvalidAccessError();
                throw err;
            }
            // Bug #68: Safari does not throw an error if the parameters differ in their length.
            if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) throw createInvalidAccessError();
        }
    };
};



const $648a49d61d66668f$export$1532cc6682032d84 = (connectAudioParam, createNativeBiquadFilterNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeBiquadFilterNodes = new WeakMap();
        const createBiquadFilterNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeBiquadFilterNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeBiquadFilterNode was not constructed on the same OfflineAudioContext it needs to be created
             * again.
             */ const nativeBiquadFilterNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeBiquadFilterNode, nativeOfflineAudioContext);
            if (!nativeBiquadFilterNodeIsOwnedByContext) {
                const options = {
                    Q: nativeBiquadFilterNode.Q.value,
                    channelCount: nativeBiquadFilterNode.channelCount,
                    channelCountMode: nativeBiquadFilterNode.channelCountMode,
                    channelInterpretation: nativeBiquadFilterNode.channelInterpretation,
                    detune: nativeBiquadFilterNode.detune.value,
                    frequency: nativeBiquadFilterNode.frequency.value,
                    gain: nativeBiquadFilterNode.gain.value,
                    type: nativeBiquadFilterNode.type
                };
                nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeOfflineAudioContext, options);
            }
            renderedNativeBiquadFilterNodes.set(nativeOfflineAudioContext, nativeBiquadFilterNode);
            if (!nativeBiquadFilterNodeIsOwnedByContext) {
                await renderAutomation(nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q);
                await renderAutomation(nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune);
                await renderAutomation(nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency);
                await renderAutomation(nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain);
            } else {
                await connectAudioParam(nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q);
                await connectAudioParam(nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune);
                await connectAudioParam(nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency);
                await connectAudioParam(nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain);
            }
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeBiquadFilterNode);
            return nativeBiquadFilterNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeBiquadFilterNode = renderedNativeBiquadFilterNodes.get(nativeOfflineAudioContext);
                if (renderedNativeBiquadFilterNode !== undefined) return Promise.resolve(renderedNativeBiquadFilterNode);
                return createBiquadFilterNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};


const $7c87a57a3e4e78d1$export$e72d622686b5f6c7 = (ongoingTests, testResults)=>{
    return (tester, test)=>{
        const cachedTestResult = testResults.get(tester);
        if (cachedTestResult !== undefined) return cachedTestResult;
        const ongoingTest = ongoingTests.get(tester);
        if (ongoingTest !== undefined) return ongoingTest;
        try {
            const synchronousTestResult = test();
            if (synchronousTestResult instanceof Promise) {
                ongoingTests.set(tester, synchronousTestResult);
                return synchronousTestResult.catch(()=>false).then((finalTestResult)=>{
                    ongoingTests.delete(tester);
                    testResults.set(tester, finalTestResult);
                    return finalTestResult;
                });
            }
            testResults.set(tester, synchronousTestResult);
            return synchronousTestResult;
        } catch  {
            testResults.set(tester, false);
            return false;
        }
    };
};


const $9914bd5698d6d720$var$DEFAULT_OPTIONS = {
    channelCount: 1,
    channelCountMode: "explicit",
    channelInterpretation: "speakers",
    numberOfInputs: 6
};
const $9914bd5698d6d720$export$a65a5a400135d27 = (audioNodeConstructor, createChannelMergerNodeRenderer, createNativeChannelMergerNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class ChannelMergerNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...$9914bd5698d6d720$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeChannelMergerNode = createNativeChannelMergerNode(nativeContext, mergedOptions);
            const channelMergerNodeRenderer = isNativeOfflineAudioContext(nativeContext) ? createChannelMergerNodeRenderer() : null;
            super(context, false, nativeChannelMergerNode, channelMergerNodeRenderer);
        }
    };
};



const $9c62d9a5222cb634$export$79056cbe2b10cae5 = (createNativeChannelMergerNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeAudioNodes = new WeakMap();
        const createAudioNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeAudioNode = getNativeAudioNode(proxy);
            // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeAudioNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeAudioNode, nativeOfflineAudioContext);
            if (!nativeAudioNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeAudioNode.channelCount,
                    channelCountMode: nativeAudioNode.channelCountMode,
                    channelInterpretation: nativeAudioNode.channelInterpretation,
                    numberOfInputs: nativeAudioNode.numberOfInputs
                };
                nativeAudioNode = createNativeChannelMergerNode(nativeOfflineAudioContext, options);
            }
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioNode);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode);
            return nativeAudioNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioNode !== undefined) return Promise.resolve(renderedNativeAudioNode);
                return createAudioNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};


const $428734a9d6f3ff0b$var$DEFAULT_OPTIONS = {
    channelCount: 6,
    channelCountMode: "explicit",
    channelInterpretation: "discrete",
    numberOfOutputs: 6
};
const $428734a9d6f3ff0b$export$ce9d996cafa605b = (audioNodeConstructor, createChannelSplitterNodeRenderer, createNativeChannelSplitterNode, getNativeContext, isNativeOfflineAudioContext, sanitizeChannelSplitterOptions)=>{
    return class ChannelSplitterNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = sanitizeChannelSplitterOptions({
                ...$428734a9d6f3ff0b$var$DEFAULT_OPTIONS,
                ...options
            });
            const nativeChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, mergedOptions);
            const channelSplitterNodeRenderer = isNativeOfflineAudioContext(nativeContext) ? createChannelSplitterNodeRenderer() : null;
            super(context, false, nativeChannelSplitterNode, channelSplitterNodeRenderer);
        }
    };
};



const $cfe1fc595bf80c45$export$d815cad16abde9c3 = (createNativeChannelSplitterNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeAudioNodes = new WeakMap();
        const createAudioNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeAudioNode = getNativeAudioNode(proxy);
            // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeAudioNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeAudioNode, nativeOfflineAudioContext);
            if (!nativeAudioNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeAudioNode.channelCount,
                    channelCountMode: nativeAudioNode.channelCountMode,
                    channelInterpretation: nativeAudioNode.channelInterpretation,
                    numberOfOutputs: nativeAudioNode.numberOfOutputs
                };
                nativeAudioNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, options);
            }
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioNode);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode);
            return nativeAudioNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioNode !== undefined) return Promise.resolve(renderedNativeAudioNode);
                return createAudioNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};


const $8992e81c70c72605$export$1e69fdca2ad79f10 = (renderInputsOfAudioParam)=>{
    return (nativeOfflineAudioContext, audioParam, nativeAudioParam)=>{
        return renderInputsOfAudioParam(audioParam, nativeOfflineAudioContext, nativeAudioParam);
    };
};



const $f29cfd6579875e35$export$5f708e50316bf1a = (createIndexSizeError)=>{
    return (outputAudioNodes, destination, output = 0, input = 0)=>{
        const outputAudioNode = outputAudioNodes[output];
        if (outputAudioNode === undefined) throw createIndexSizeError();
        if ((0, $6c08598be15fa4cc$export$d647358384f164e0)(destination)) return outputAudioNode.connect(destination, 0, input);
        return outputAudioNode.connect(destination, 0);
    };
};


const $5a894e221bf91800$export$e82b2b63ea82dc82 = (createNativeAudioBufferSourceNode)=>{
    return (nativeContext, nativeAudioNode)=>{
        const nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, {
            buffer: null,
            channelCount: 2,
            channelCountMode: "max",
            channelInterpretation: "speakers",
            loop: false,
            loopEnd: 0,
            loopStart: 0,
            playbackRate: 1
        });
        const nativeAudioBuffer = nativeContext.createBuffer(1, 2, 44100);
        nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;
        nativeAudioBufferSourceNode.loop = true;
        nativeAudioBufferSourceNode.connect(nativeAudioNode);
        nativeAudioBufferSourceNode.start();
        return ()=>{
            nativeAudioBufferSourceNode.stop();
            nativeAudioBufferSourceNode.disconnect(nativeAudioNode);
        };
    };
};






const $d86f7b3e69ec2393$var$DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    offset: 1
};
const $d86f7b3e69ec2393$export$a02a9a6200996500 = (audioNodeConstructor, createAudioParam, createConstantSourceNodeRendererFactory, createNativeConstantSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener)=>{
    return class ConstantSourceNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...$d86f7b3e69ec2393$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeConstantSourceNode = createNativeConstantSourceNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const constantSourceNodeRenderer = isOffline ? createConstantSourceNodeRendererFactory() : null;
            super(context, false, nativeConstantSourceNode, constantSourceNodeRenderer);
            this._constantSourceNodeRenderer = constantSourceNodeRenderer;
            this._nativeConstantSourceNode = nativeConstantSourceNode;
            /*
             * Bug #62 & #74: Safari does not support ConstantSourceNodes and does not export the correct values for maxValue and minValue
             * for GainNodes.
             */ this._offset = createAudioParam(this, isOffline, nativeConstantSourceNode.offset, (0, $b1c06cbd433e26a1$export$ab43bedd17d6a167), (0, $b1c06cbd433e26a1$export$ced6a5c63b103b52));
            this._onended = null;
        }
        get offset() {
            return this._offset;
        }
        get onended() {
            return this._onended;
        }
        set onended(value) {
            const wrappedListener = typeof value === "function" ? wrapEventListener(this, value) : null;
            this._nativeConstantSourceNode.onended = wrappedListener;
            const nativeOnEnded = this._nativeConstantSourceNode.onended;
            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;
        }
        start(when = 0) {
            this._nativeConstantSourceNode.start(when);
            if (this._constantSourceNodeRenderer !== null) this._constantSourceNodeRenderer.start = when;
            if (this.context.state !== "closed") {
                (0, $e4b65d1b7a33a6ae$export$88a47afdc0e8539c)(this);
                const resetInternalStateToPassive = ()=>{
                    this._nativeConstantSourceNode.removeEventListener("ended", resetInternalStateToPassive);
                    if ((0, $a52e8cf090f6ea8d$export$e44f0fc8e83fb084)(this)) (0, $30e3b887134462bb$export$7c0830f3a5100dec)(this);
                };
                this._nativeConstantSourceNode.addEventListener("ended", resetInternalStateToPassive);
            }
        }
        stop(when = 0) {
            this._nativeConstantSourceNode.stop(when);
            if (this._constantSourceNodeRenderer !== null) this._constantSourceNodeRenderer.stop = when;
        }
    };
};



const $8129e008e11233c4$export$bc541a3c87b45a7d = (connectAudioParam, createNativeConstantSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeConstantSourceNodes = new WeakMap();
        let start = null;
        let stop = null;
        const createConstantSourceNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeConstantSourceNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeConstantSourceNode was not constructed on the same OfflineAudioContext it needs to be created
             * again.
             */ const nativeConstantSourceNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeConstantSourceNode, nativeOfflineAudioContext);
            if (!nativeConstantSourceNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeConstantSourceNode.channelCount,
                    channelCountMode: nativeConstantSourceNode.channelCountMode,
                    channelInterpretation: nativeConstantSourceNode.channelInterpretation,
                    offset: nativeConstantSourceNode.offset.value
                };
                nativeConstantSourceNode = createNativeConstantSourceNode(nativeOfflineAudioContext, options);
                if (start !== null) nativeConstantSourceNode.start(start);
                if (stop !== null) nativeConstantSourceNode.stop(stop);
            }
            renderedNativeConstantSourceNodes.set(nativeOfflineAudioContext, nativeConstantSourceNode);
            if (!nativeConstantSourceNodeIsOwnedByContext) await renderAutomation(nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset);
            else await connectAudioParam(nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConstantSourceNode);
            return nativeConstantSourceNode;
        };
        return {
            set start (value){
                start = value;
            },
            set stop (value){
                stop = value;
            },
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeConstantSourceNode = renderedNativeConstantSourceNodes.get(nativeOfflineAudioContext);
                if (renderedNativeConstantSourceNode !== undefined) return Promise.resolve(renderedNativeConstantSourceNode);
                return createConstantSourceNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};


const $c5f519196ef2423e$export$540e228106d2c471 = (unit32Array)=>{
    return (value)=>{
        unit32Array[0] = value;
        return unit32Array[0];
    };
};


const $391774b3d5d015d0$var$DEFAULT_OPTIONS = {
    buffer: null,
    channelCount: 2,
    channelCountMode: "clamped-max",
    channelInterpretation: "speakers",
    disableNormalization: false
};
const $391774b3d5d015d0$export$4894173a4b4ee485 = (audioNodeConstructor, createConvolverNodeRenderer, createNativeConvolverNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class ConvolverNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...$391774b3d5d015d0$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeConvolverNode = createNativeConvolverNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const convolverNodeRenderer = isOffline ? createConvolverNodeRenderer() : null;
            super(context, false, nativeConvolverNode, convolverNodeRenderer);
            this._isBufferNullified = false;
            this._nativeConvolverNode = nativeConvolverNode;
            if (mergedOptions.buffer !== null) setAudioNodeTailTime(this, mergedOptions.buffer.duration);
        }
        get buffer() {
            if (this._isBufferNullified) return null;
            return this._nativeConvolverNode.buffer;
        }
        set buffer(value) {
            this._nativeConvolverNode.buffer = value;
            // Bug #115: Safari does not allow to set the buffer to null.
            if (value === null && this._nativeConvolverNode.buffer !== null) {
                const nativeContext = this._nativeConvolverNode.context;
                this._nativeConvolverNode.buffer = nativeContext.createBuffer(1, 1, 44100);
                this._isBufferNullified = true;
                setAudioNodeTailTime(this, 0);
            } else {
                this._isBufferNullified = false;
                setAudioNodeTailTime(this, this._nativeConvolverNode.buffer === null ? 0 : this._nativeConvolverNode.buffer.duration);
            }
        }
        get normalize() {
            return this._nativeConvolverNode.normalize;
        }
        set normalize(value) {
            this._nativeConvolverNode.normalize = value;
        }
    };
};




const $f3ffd1bf4bfdfd06$export$5b278ccdb1a6393 = (createNativeConvolverNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeConvolverNodes = new WeakMap();
        const createConvolverNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeConvolverNode = getNativeAudioNode(proxy);
            // If the initially used nativeConvolverNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeConvolverNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeConvolverNode, nativeOfflineAudioContext);
            if (!nativeConvolverNodeIsOwnedByContext) {
                const options = {
                    buffer: nativeConvolverNode.buffer,
                    channelCount: nativeConvolverNode.channelCount,
                    channelCountMode: nativeConvolverNode.channelCountMode,
                    channelInterpretation: nativeConvolverNode.channelInterpretation,
                    disableNormalization: !nativeConvolverNode.normalize
                };
                nativeConvolverNode = createNativeConvolverNode(nativeOfflineAudioContext, options);
            }
            renderedNativeConvolverNodes.set(nativeOfflineAudioContext, nativeConvolverNode);
            if ((0, $77ab69d57b7e7a12$export$ac2aef07f705aa48)(nativeConvolverNode)) await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConvolverNode.inputs[0]);
            else await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConvolverNode);
            return nativeConvolverNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeConvolverNode = renderedNativeConvolverNodes.get(nativeOfflineAudioContext);
                if (renderedNativeConvolverNode !== undefined) return Promise.resolve(renderedNativeConvolverNode);
                return createConvolverNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};


const $358421f0a53ddf49$export$ab44e304a31eb0ae = (createNotSupportedError, nativeOfflineAudioContextConstructor)=>{
    return (numberOfChannels, length, sampleRate)=>{
        if (nativeOfflineAudioContextConstructor === null) throw new Error("Missing the native OfflineAudioContext constructor.");
        try {
            return new nativeOfflineAudioContextConstructor(numberOfChannels, length, sampleRate);
        } catch (err) {
            // Bug #143, #144 & #146: Safari throws a SyntaxError when numberOfChannels, length or sampleRate are invalid.
            if (err.name === "SyntaxError") throw createNotSupportedError();
            throw err;
        }
    };
};


const $90aaf2df262a09a1$export$fc1a599a84ca01a8 = ()=>new DOMException("", "DataCloneError");


const $8cbc043fe3491184$export$2d33e41548107ad3 = (arrayBuffer)=>{
    const { port1: port1 , port2: port2  } = new MessageChannel();
    return new Promise((resolve)=>{
        const closeAndResolve = ()=>{
            port2.onmessage = null;
            port1.close();
            port2.close();
            resolve();
        };
        port2.onmessage = ()=>closeAndResolve();
        try {
            port1.postMessage(arrayBuffer, [
                arrayBuffer
            ]);
        } finally{
            closeAndResolve();
        }
    });
};



const $3c9f526d1dcde320$export$d83e4a6039bccfb = (audioBufferStore, cacheTestResult, createDataCloneError, createEncodingError, detachedArrayBuffers, getNativeContext, isNativeContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, testPromiseSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds)=>{
    return (anyContext, audioData)=>{
        const nativeContext = isNativeContext(anyContext) ? anyContext : getNativeContext(anyContext);
        // Bug #43: Only Chrome, Edge and Opera do throw a DataCloneError.
        if (detachedArrayBuffers.has(audioData)) {
            const err = createDataCloneError();
            return Promise.reject(err);
        }
        // The audioData parameter maybe of a type which can't be added to a WeakSet.
        try {
            detachedArrayBuffers.add(audioData);
        } catch  {
        // Ignore errors.
        }
        // Bug #21: Safari does not support promises yet.
        if (cacheTestResult(testPromiseSupport, ()=>testPromiseSupport(nativeContext))) return nativeContext.decodeAudioData(audioData).then((audioBuffer)=>{
            // Bug #133: Safari does neuter the ArrayBuffer.
            (0, $8cbc043fe3491184$export$2d33e41548107ad3)(audioData).catch(()=>{
            // Ignore errors.
            });
            // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.
            if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, ()=>testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer))) wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);
            audioBufferStore.add(audioBuffer);
            return audioBuffer;
        });
        // Bug #21: Safari does not return a Promise yet.
        return new Promise((resolve, reject)=>{
            const complete = async ()=>{
                // Bug #133: Safari does neuter the ArrayBuffer.
                try {
                    await (0, $8cbc043fe3491184$export$2d33e41548107ad3)(audioData);
                } catch  {
                // Ignore errors.
                }
            };
            const fail = (err)=>{
                reject(err);
                complete();
            };
            // Bug #26: Safari throws a synchronous error.
            try {
                // Bug #1: Safari requires a successCallback.
                nativeContext.decodeAudioData(audioData, (audioBuffer)=>{
                    // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
                    // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.
                    if (typeof audioBuffer.copyFromChannel !== "function") {
                        wrapAudioBufferCopyChannelMethods(audioBuffer);
                        (0, $2e77af801a4782d4$export$df65309cf6249598)(audioBuffer);
                    }
                    audioBufferStore.add(audioBuffer);
                    complete().then(()=>resolve(audioBuffer));
                }, (err)=>{
                    // Bug #4: Safari returns null instead of an error.
                    if (err === null) fail(createEncodingError());
                    else fail(err);
                });
            } catch (err) {
                fail(err);
            }
        });
    };
};



const $3e58ea8f410c8370$export$93f58f9268fde9f6 = (connectNativeAudioNodeToNativeAudioNode, cycleCounters, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, getNativeContext, isActiveAudioNode, isNativeOfflineAudioContext)=>{
    return (audioNode, count)=>{
        const cycleCounter = cycleCounters.get(audioNode);
        if (cycleCounter === undefined) throw new Error("Missing the expected cycle count.");
        const nativeContext = getNativeContext(audioNode.context);
        const isOffline = isNativeOfflineAudioContext(nativeContext);
        if (cycleCounter === count) {
            cycleCounters.delete(audioNode);
            if (!isOffline && isActiveAudioNode(audioNode)) {
                const nativeSourceAudioNode = getNativeAudioNode(audioNode);
                const { outputs: outputs  } = getAudioNodeConnections(audioNode);
                for (const output of outputs)if ((0, $6fabcecde01c3a66$export$419d66ef3a96a878)(output)) {
                    const nativeDestinationAudioNode = getNativeAudioNode(output[0]);
                    connectNativeAudioNodeToNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output[1], output[2]);
                } else {
                    const nativeDestinationAudioParam = getNativeAudioParam(output[0]);
                    nativeSourceAudioNode.connect(nativeDestinationAudioParam, output[1]);
                }
            }
        } else cycleCounters.set(audioNode, cycleCounter - count);
    };
};


const $891c129c739fee1a$var$DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    delayTime: 0,
    maxDelayTime: 1
};
const $891c129c739fee1a$export$b89a0215c1c607e3 = (audioNodeConstructor, createAudioParam, createDelayNodeRenderer, createNativeDelayNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class DelayNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...$891c129c739fee1a$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeDelayNode = createNativeDelayNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const delayNodeRenderer = isOffline ? createDelayNodeRenderer(mergedOptions.maxDelayTime) : null;
            super(context, false, nativeDelayNode, delayNodeRenderer);
            this._delayTime = createAudioParam(this, isOffline, nativeDelayNode.delayTime);
            setAudioNodeTailTime(this, mergedOptions.maxDelayTime);
        }
        get delayTime() {
            return this._delayTime;
        }
    };
};



const $6968cde2bce7c88d$export$d03c2308083a28e5 = (connectAudioParam, createNativeDelayNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return (maxDelayTime)=>{
        const renderedNativeDelayNodes = new WeakMap();
        const createDelayNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeDelayNode = getNativeAudioNode(proxy);
            // If the initially used nativeDelayNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeDelayNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeDelayNode, nativeOfflineAudioContext);
            if (!nativeDelayNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeDelayNode.channelCount,
                    channelCountMode: nativeDelayNode.channelCountMode,
                    channelInterpretation: nativeDelayNode.channelInterpretation,
                    delayTime: nativeDelayNode.delayTime.value,
                    maxDelayTime: maxDelayTime
                };
                nativeDelayNode = createNativeDelayNode(nativeOfflineAudioContext, options);
            }
            renderedNativeDelayNodes.set(nativeOfflineAudioContext, nativeDelayNode);
            if (!nativeDelayNodeIsOwnedByContext) await renderAutomation(nativeOfflineAudioContext, proxy.delayTime, nativeDelayNode.delayTime);
            else await connectAudioParam(nativeOfflineAudioContext, proxy.delayTime, nativeDelayNode.delayTime);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeDelayNode);
            return nativeDelayNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeDelayNode = renderedNativeDelayNodes.get(nativeOfflineAudioContext);
                if (renderedNativeDelayNode !== undefined) return Promise.resolve(renderedNativeDelayNode);
                return createDelayNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};


const $477fe5e73ad92df6$export$1f7c0152b9e322ae = (pickElementFromSet)=>{
    return (activeInputs, source, output, input)=>{
        return pickElementFromSet(activeInputs[input], (activeInputConnection)=>activeInputConnection[0] === source && activeInputConnection[1] === output);
    };
};


const $e9000ac5eec278e9$export$92df121abbf21dca = (getUnrenderedAudioWorkletNodes)=>{
    return (nativeContext, audioWorkletNode)=>{
        getUnrenderedAudioWorkletNodes(nativeContext).delete(audioWorkletNode);
    };
};



const $5717d87c19dd9550$export$c283d436eafbd9b2 = (audioNode)=>{
    return "delayTime" in audioNode;
};


const $40fa50096cb00484$export$b4f8d2824d9887dc = (audioParamAudioNodeStore, getAudioNodeConnections, getValueForKey)=>{
    return function detectCycles(chain, nextLink) {
        const audioNode = (0, $659689b3be408df4$export$85cd8e93eb858e81)(nextLink) ? nextLink : getValueForKey(audioParamAudioNodeStore, nextLink);
        if ((0, $5717d87c19dd9550$export$c283d436eafbd9b2)(audioNode)) return [];
        if (chain[0] === audioNode) return [
            chain
        ];
        if (chain.includes(audioNode)) return [];
        const { outputs: outputs  } = getAudioNodeConnections(audioNode);
        return Array.from(outputs).map((outputConnection)=>detectCycles([
                ...chain,
                audioNode
            ], outputConnection[0])).reduce((mergedCycles, nestedCycles)=>mergedCycles.concat(nestedCycles), []);
    };
};



const $0dde459ead155eae$var$getOutputAudioNodeAtIndex = (createIndexSizeError, outputAudioNodes, output)=>{
    const outputAudioNode = outputAudioNodes[output];
    if (outputAudioNode === undefined) throw createIndexSizeError();
    return outputAudioNode;
};
const $0dde459ead155eae$export$78a992fad11cd00e = (createIndexSizeError)=>{
    return (outputAudioNodes, destinationOrOutput, output, input = 0)=>{
        if (destinationOrOutput === undefined) return outputAudioNodes.forEach((outputAudioNode)=>outputAudioNode.disconnect());
        if (typeof destinationOrOutput === "number") return $0dde459ead155eae$var$getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, destinationOrOutput).disconnect();
        if ((0, $6c08598be15fa4cc$export$d647358384f164e0)(destinationOrOutput)) {
            if (output === undefined) return outputAudioNodes.forEach((outputAudioNode)=>outputAudioNode.disconnect(destinationOrOutput));
            if (input === undefined) return $0dde459ead155eae$var$getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0);
            return $0dde459ead155eae$var$getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0, input);
        }
        if (output === undefined) return outputAudioNodes.forEach((outputAudioNode)=>outputAudioNode.disconnect(destinationOrOutput));
        return $0dde459ead155eae$var$getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0);
    };
};


const $bf0956ea33de903c$var$DEFAULT_OPTIONS = {
    attack: 0.003,
    channelCount: 2,
    channelCountMode: "clamped-max",
    channelInterpretation: "speakers",
    knee: 30,
    ratio: 12,
    release: 0.25,
    threshold: -24
};
const $bf0956ea33de903c$export$60ec6725c2d45fc8 = (audioNodeConstructor, createAudioParam, createDynamicsCompressorNodeRenderer, createNativeDynamicsCompressorNode, createNotSupportedError, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class DynamicsCompressorNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...$bf0956ea33de903c$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeDynamicsCompressorNode = createNativeDynamicsCompressorNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const dynamicsCompressorNodeRenderer = isOffline ? createDynamicsCompressorNodeRenderer() : null;
            super(context, false, nativeDynamicsCompressorNode, dynamicsCompressorNodeRenderer);
            this._attack = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.attack);
            this._knee = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.knee);
            this._nativeDynamicsCompressorNode = nativeDynamicsCompressorNode;
            this._ratio = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.ratio);
            this._release = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.release);
            this._threshold = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.threshold);
            setAudioNodeTailTime(this, 0.006);
        }
        get attack() {
            return this._attack;
        }
        // Bug #108: Safari allows a channelCount of three and above which is why the getter and setter needs to be overwritten here.
        get channelCount() {
            return this._nativeDynamicsCompressorNode.channelCount;
        }
        set channelCount(value) {
            const previousChannelCount = this._nativeDynamicsCompressorNode.channelCount;
            this._nativeDynamicsCompressorNode.channelCount = value;
            if (value > 2) {
                this._nativeDynamicsCompressorNode.channelCount = previousChannelCount;
                throw createNotSupportedError();
            }
        }
        /*
         * Bug #109: Only Chrome, Firefox and Opera disallow a channelCountMode of 'max' yet which is why the getter and setter needs to be
         * overwritten here.
         */ get channelCountMode() {
            return this._nativeDynamicsCompressorNode.channelCountMode;
        }
        set channelCountMode(value) {
            const previousChannelCount = this._nativeDynamicsCompressorNode.channelCountMode;
            this._nativeDynamicsCompressorNode.channelCountMode = value;
            if (value === "max") {
                this._nativeDynamicsCompressorNode.channelCountMode = previousChannelCount;
                throw createNotSupportedError();
            }
        }
        get knee() {
            return this._knee;
        }
        get ratio() {
            return this._ratio;
        }
        get reduction() {
            // Bug #111: Safari returns an AudioParam instead of a number.
            if (typeof this._nativeDynamicsCompressorNode.reduction.value === "number") return this._nativeDynamicsCompressorNode.reduction.value;
            return this._nativeDynamicsCompressorNode.reduction;
        }
        get release() {
            return this._release;
        }
        get threshold() {
            return this._threshold;
        }
    };
};



const $ba58754860d16983$export$1b1e82cc3f0a2c8 = (connectAudioParam, createNativeDynamicsCompressorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeDynamicsCompressorNodes = new WeakMap();
        const createDynamicsCompressorNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeDynamicsCompressorNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeDynamicsCompressorNode was not constructed on the same OfflineAudioContext it needs to be
             * created again.
             */ const nativeDynamicsCompressorNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeDynamicsCompressorNode, nativeOfflineAudioContext);
            if (!nativeDynamicsCompressorNodeIsOwnedByContext) {
                const options = {
                    attack: nativeDynamicsCompressorNode.attack.value,
                    channelCount: nativeDynamicsCompressorNode.channelCount,
                    channelCountMode: nativeDynamicsCompressorNode.channelCountMode,
                    channelInterpretation: nativeDynamicsCompressorNode.channelInterpretation,
                    knee: nativeDynamicsCompressorNode.knee.value,
                    ratio: nativeDynamicsCompressorNode.ratio.value,
                    release: nativeDynamicsCompressorNode.release.value,
                    threshold: nativeDynamicsCompressorNode.threshold.value
                };
                nativeDynamicsCompressorNode = createNativeDynamicsCompressorNode(nativeOfflineAudioContext, options);
            }
            renderedNativeDynamicsCompressorNodes.set(nativeOfflineAudioContext, nativeDynamicsCompressorNode);
            if (!nativeDynamicsCompressorNodeIsOwnedByContext) {
                await renderAutomation(nativeOfflineAudioContext, proxy.attack, nativeDynamicsCompressorNode.attack);
                await renderAutomation(nativeOfflineAudioContext, proxy.knee, nativeDynamicsCompressorNode.knee);
                await renderAutomation(nativeOfflineAudioContext, proxy.ratio, nativeDynamicsCompressorNode.ratio);
                await renderAutomation(nativeOfflineAudioContext, proxy.release, nativeDynamicsCompressorNode.release);
                await renderAutomation(nativeOfflineAudioContext, proxy.threshold, nativeDynamicsCompressorNode.threshold);
            } else {
                await connectAudioParam(nativeOfflineAudioContext, proxy.attack, nativeDynamicsCompressorNode.attack);
                await connectAudioParam(nativeOfflineAudioContext, proxy.knee, nativeDynamicsCompressorNode.knee);
                await connectAudioParam(nativeOfflineAudioContext, proxy.ratio, nativeDynamicsCompressorNode.ratio);
                await connectAudioParam(nativeOfflineAudioContext, proxy.release, nativeDynamicsCompressorNode.release);
                await connectAudioParam(nativeOfflineAudioContext, proxy.threshold, nativeDynamicsCompressorNode.threshold);
            }
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeDynamicsCompressorNode);
            return nativeDynamicsCompressorNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeDynamicsCompressorNode = renderedNativeDynamicsCompressorNodes.get(nativeOfflineAudioContext);
                if (renderedNativeDynamicsCompressorNode !== undefined) return Promise.resolve(renderedNativeDynamicsCompressorNode);
                return createDynamicsCompressorNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};


const $c6480c21a9b77362$export$6372d3d9069bc778 = ()=>new DOMException("", "EncodingError");


const $580f414c25754405$export$43b563d089dd1d8 = (window)=>{
    return (source)=>new Promise((resolve, reject)=>{
            if (window === null) {
                // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.
                reject(new SyntaxError());
                return;
            }
            const head = window.document.head;
            if (head === null) // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.
            reject(new SyntaxError());
            else {
                const script = window.document.createElement("script");
                // @todo Safari doesn't like URLs with a type of 'application/javascript; charset=utf-8'.
                const blob = new Blob([
                    source
                ], {
                    type: "application/javascript"
                });
                const url = URL.createObjectURL(blob);
                const originalOnErrorHandler = window.onerror;
                const removeErrorEventListenerAndRevokeUrl = ()=>{
                    window.onerror = originalOnErrorHandler;
                    URL.revokeObjectURL(url);
                };
                window.onerror = (message, src, lineno, colno, error)=>{
                    // @todo Edge thinks the source is the one of the html document.
                    if (src === url || src === window.location.href && lineno === 1 && colno === 1) {
                        removeErrorEventListenerAndRevokeUrl();
                        reject(error);
                        return false;
                    }
                    if (originalOnErrorHandler !== null) return originalOnErrorHandler(message, src, lineno, colno, error);
                };
                script.onerror = ()=>{
                    removeErrorEventListenerAndRevokeUrl();
                    // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.
                    reject(new SyntaxError());
                };
                script.onload = ()=>{
                    removeErrorEventListenerAndRevokeUrl();
                    resolve();
                };
                script.src = url;
                script.type = "module";
                head.appendChild(script);
            }
        });
};


const $eb27148c76e60649$export$a512af3fc2ab91f2 = (wrapEventListener)=>{
    return class EventTarget {
        constructor(_nativeEventTarget){
            this._nativeEventTarget = _nativeEventTarget;
            this._listeners = new WeakMap();
        }
        addEventListener(type, listener, options) {
            if (listener !== null) {
                let wrappedEventListener = this._listeners.get(listener);
                if (wrappedEventListener === undefined) {
                    wrappedEventListener = wrapEventListener(this, listener);
                    if (typeof listener === "function") this._listeners.set(listener, wrappedEventListener);
                }
                this._nativeEventTarget.addEventListener(type, wrappedEventListener, options);
            }
        }
        dispatchEvent(event) {
            return this._nativeEventTarget.dispatchEvent(event);
        }
        removeEventListener(type, listener, options) {
            const wrappedEventListener = listener === null ? undefined : this._listeners.get(listener);
            this._nativeEventTarget.removeEventListener(type, wrappedEventListener === undefined ? null : wrappedEventListener, options);
        }
    };
};


const $a049692fe9048d3a$export$c43b8ab5e8913cbb = (window)=>{
    return (currentTime, sampleRate, fn)=>{
        Object.defineProperties(window, {
            currentFrame: {
                configurable: true,
                get () {
                    return Math.round(currentTime * sampleRate);
                }
            },
            currentTime: {
                configurable: true,
                get () {
                    return currentTime;
                }
            }
        });
        try {
            return fn();
        } finally{
            if (window !== null) {
                delete window.currentFrame;
                delete window.currentTime;
            }
        }
    };
};


const $8f1fddea8d9746a6$export$c7282a393375a8ca = (createAbortError)=>{
    return async (url)=>{
        try {
            const response = await fetch(url);
            if (response.ok) return [
                await response.text(),
                response.url
            ];
        } catch  {
        // Ignore errors.
        } // tslint:disable-line:no-empty
        throw createAbortError();
    };
};



const $b09df3934a68d1ac$var$DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    gain: 1
};
const $b09df3934a68d1ac$export$7b37b693b55bf5d7 = (audioNodeConstructor, createAudioParam, createGainNodeRenderer, createNativeGainNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class GainNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...$b09df3934a68d1ac$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeGainNode = createNativeGainNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const gainNodeRenderer = isOffline ? createGainNodeRenderer() : null;
            super(context, false, nativeGainNode, gainNodeRenderer);
            // Bug #74: Safari does not export the correct values for maxValue and minValue.
            this._gain = createAudioParam(this, isOffline, nativeGainNode.gain, (0, $b1c06cbd433e26a1$export$ab43bedd17d6a167), (0, $b1c06cbd433e26a1$export$ced6a5c63b103b52));
        }
        get gain() {
            return this._gain;
        }
    };
};



const $0521b0be5b77d36f$export$7312404e5bea9cd = (connectAudioParam, createNativeGainNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeGainNodes = new WeakMap();
        const createGainNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeGainNode = getNativeAudioNode(proxy);
            // If the initially used nativeGainNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeGainNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeGainNode, nativeOfflineAudioContext);
            if (!nativeGainNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeGainNode.channelCount,
                    channelCountMode: nativeGainNode.channelCountMode,
                    channelInterpretation: nativeGainNode.channelInterpretation,
                    gain: nativeGainNode.gain.value
                };
                nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, options);
            }
            renderedNativeGainNodes.set(nativeOfflineAudioContext, nativeGainNode);
            if (!nativeGainNodeIsOwnedByContext) await renderAutomation(nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain);
            else await connectAudioParam(nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeGainNode);
            return nativeGainNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeGainNode = renderedNativeGainNodes.get(nativeOfflineAudioContext);
                if (renderedNativeGainNode !== undefined) return Promise.resolve(renderedNativeGainNode);
                return createGainNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};


const $f563f21289bb8166$export$8b01844840684f8d = (activeAudioWorkletNodeInputsStore, getValueForKey)=>{
    return (nativeAudioWorkletNode)=>getValueForKey(activeAudioWorkletNodeInputsStore, nativeAudioWorkletNode);
};


const $1c0990f0eabc339c$export$97bb1acefff8970e = (getAudioNodeConnections)=>{
    return (audioNode)=>{
        const audioNodeConnections = getAudioNodeConnections(audioNode);
        if (audioNodeConnections.renderer === null) throw new Error("Missing the renderer of the given AudioNode in the audio graph.");
        return audioNodeConnections.renderer;
    };
};


const $f379da479c52f5b2$export$4abc3abd061bc2cc = (audioNodeTailTimeStore)=>{
    return (audioNode)=>{
        var _a;
        return (_a = audioNodeTailTimeStore.get(audioNode)) !== null && _a !== void 0 ? _a : 0;
    };
};


const $d6767de90b841a3b$export$1653dd3e76bcb1b0 = (getAudioParamConnections)=>{
    return (audioParam)=>{
        const audioParamConnections = getAudioParamConnections(audioParam);
        if (audioParamConnections.renderer === null) throw new Error("Missing the renderer of the given AudioParam in the audio graph.");
        return audioParamConnections.renderer;
    };
};


const $32c25768643dbcd8$export$afecf147821b5609 = (backupOfflineAudioContextStore)=>{
    return (nativeContext)=>{
        return backupOfflineAudioContextStore.get(nativeContext);
    };
};


const $12252263e7ea8a6f$export$5a1c4cd5830ea09b = ()=>new DOMException("", "InvalidStateError");


const $6c2ddbefdfe0db9b$export$797a319a8065fb37 = (contextStore)=>{
    return (context)=>{
        const nativeContext = contextStore.get(context);
        if (nativeContext === undefined) throw (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b)();
        return nativeContext;
    };
};


const $e6d091ae8e3fe914$export$70df0ae42e1340c8 = (backupOfflineAudioContextStore, nativeOfflineAudioContextConstructor)=>{
    return (nativeContext)=>{
        let backupOfflineAudioContext = backupOfflineAudioContextStore.get(nativeContext);
        if (backupOfflineAudioContext !== undefined) return backupOfflineAudioContext;
        if (nativeOfflineAudioContextConstructor === null) throw new Error("Missing the native OfflineAudioContext constructor.");
        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.
        backupOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        backupOfflineAudioContextStore.set(nativeContext, backupOfflineAudioContext);
        return backupOfflineAudioContext;
    };
};


const $1c2a4b9507caf1a4$export$43ef7eb1ae3d2f40 = (unrenderedAudioWorkletNodeStore)=>{
    return (nativeContext)=>{
        const unrenderedAudioWorkletNodes = unrenderedAudioWorkletNodeStore.get(nativeContext);
        if (unrenderedAudioWorkletNodes === undefined) throw new Error("The context has no set of AudioWorkletNodes.");
        return unrenderedAudioWorkletNodes;
    };
};


const $365f5e3658bdb1fe$export$254c536c2ca9b917 = ()=>new DOMException("", "InvalidAccessError");


const $206148d9842d74bf$export$8170ec2d1debbbdd = (nativeIIRFilterNode)=>{
    nativeIIRFilterNode.getFrequencyResponse = ((getFrequencyResponse)=>{
        return (frequencyHz, magResponse, phaseResponse)=>{
            if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) throw (0, $365f5e3658bdb1fe$export$254c536c2ca9b917)();
            return getFrequencyResponse.call(nativeIIRFilterNode, frequencyHz, magResponse, phaseResponse);
        };
    })(nativeIIRFilterNode.getFrequencyResponse);
};


const $f187530af5fffe8c$var$DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers"
};
const $f187530af5fffe8c$export$a22f1eb785a05608 = (audioNodeConstructor, createNativeIIRFilterNode, createIIRFilterNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class IIRFilterNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const mergedOptions = {
                ...$f187530af5fffe8c$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeIIRFilterNode = createNativeIIRFilterNode(nativeContext, isOffline ? null : context.baseLatency, mergedOptions);
            const iirFilterNodeRenderer = isOffline ? createIIRFilterNodeRenderer(mergedOptions.feedback, mergedOptions.feedforward) : null;
            super(context, false, nativeIIRFilterNode, iirFilterNodeRenderer);
            // Bug #23 & #24: FirefoxDeveloper does not throw an InvalidAccessError.
            // @todo Write a test which allows other browsers to remain unpatched.
            (0, $206148d9842d74bf$export$8170ec2d1debbbdd)(nativeIIRFilterNode);
            this._nativeIIRFilterNode = nativeIIRFilterNode;
            // @todo Determine a meaningful tail-time instead of just using one second.
            setAudioNodeTailTime(this, 1);
        }
        getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {
            return this._nativeIIRFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);
        }
    };
};


const $179d622d0c75ff26$export$7fa1177e7d2178dd = (feedback, feedbackLength, feedforward, feedforwardLength, minLength, xBuffer, yBuffer, bufferIndex, bufferLength, input, output)=>{
    const inputLength = input.length;
    let i = bufferIndex;
    for(let j = 0; j < inputLength; j += 1){
        let y = feedforward[0] * input[j];
        for(let k = 1; k < minLength; k += 1){
            const x = i - k & bufferLength - 1; // tslint:disable-line:no-bitwise
            y += feedforward[k] * xBuffer[x];
            y -= feedback[k] * yBuffer[x];
        }
        for(let k1 = minLength; k1 < feedforwardLength; k1 += 1)y += feedforward[k1] * xBuffer[i - k1 & bufferLength - 1]; // tslint:disable-line:no-bitwise
        for(let k2 = minLength; k2 < feedbackLength; k2 += 1)y -= feedback[k2] * yBuffer[i - k2 & bufferLength - 1]; // tslint:disable-line:no-bitwise
        xBuffer[i] = input[j];
        yBuffer[i] = y;
        i = i + 1 & bufferLength - 1; // tslint:disable-line:no-bitwise
        output[j] = y;
    }
    return i;
};



const $9a90b3aeee504dd7$var$filterFullBuffer = (renderedBuffer, nativeOfflineAudioContext, feedback, feedforward)=>{
    const convertedFeedback = feedback instanceof Float64Array ? feedback : new Float64Array(feedback);
    const convertedFeedforward = feedforward instanceof Float64Array ? feedforward : new Float64Array(feedforward);
    const feedbackLength = convertedFeedback.length;
    const feedforwardLength = convertedFeedforward.length;
    const minLength = Math.min(feedbackLength, feedforwardLength);
    if (convertedFeedback[0] !== 1) {
        for(let i = 0; i < feedbackLength; i += 1)convertedFeedforward[i] /= convertedFeedback[0];
        for(let i1 = 1; i1 < feedforwardLength; i1 += 1)convertedFeedback[i1] /= convertedFeedback[0];
    }
    const bufferLength = 32;
    const xBuffer = new Float32Array(bufferLength);
    const yBuffer = new Float32Array(bufferLength);
    const filteredBuffer = nativeOfflineAudioContext.createBuffer(renderedBuffer.numberOfChannels, renderedBuffer.length, renderedBuffer.sampleRate);
    const numberOfChannels = renderedBuffer.numberOfChannels;
    for(let i = 0; i < numberOfChannels; i += 1){
        const input = renderedBuffer.getChannelData(i);
        const output = filteredBuffer.getChannelData(i);
        xBuffer.fill(0);
        yBuffer.fill(0);
        (0, $179d622d0c75ff26$export$7fa1177e7d2178dd)(convertedFeedback, feedbackLength, convertedFeedforward, feedforwardLength, minLength, xBuffer, yBuffer, 0, bufferLength, input, output);
    }
    return filteredBuffer;
};
const $9a90b3aeee504dd7$export$329316f0ca6cf17e = (createNativeAudioBufferSourceNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderInputsOfAudioNode, renderNativeOfflineAudioContext)=>{
    return (feedback, feedforward)=>{
        const renderedNativeAudioNodes = new WeakMap();
        let filteredBufferPromise = null;
        const createAudioNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeAudioBufferSourceNode = null;
            let nativeIIRFilterNode = getNativeAudioNode(proxy);
            // If the initially used nativeIIRFilterNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeIIRFilterNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeIIRFilterNode, nativeOfflineAudioContext);
            // Bug #9: Safari does not support IIRFilterNodes.
            if (nativeOfflineAudioContext.createIIRFilter === undefined) nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {
                buffer: null,
                channelCount: 2,
                channelCountMode: "max",
                channelInterpretation: "speakers",
                loop: false,
                loopEnd: 0,
                loopStart: 0,
                playbackRate: 1
            });
            else if (!nativeIIRFilterNodeIsOwnedByContext) // @todo TypeScript defines the parameters of createIIRFilter() as arrays of numbers.
            nativeIIRFilterNode = nativeOfflineAudioContext.createIIRFilter(feedforward, feedback);
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioBufferSourceNode === null ? nativeIIRFilterNode : nativeAudioBufferSourceNode);
            if (nativeAudioBufferSourceNode !== null) {
                if (filteredBufferPromise === null) {
                    if (nativeOfflineAudioContextConstructor === null) throw new Error("Missing the native OfflineAudioContext constructor.");
                    const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(// Bug #47: The AudioDestinationNode in Safari gets not initialized correctly.
                    proxy.context.destination.channelCount, // Bug #17: Safari does not yet expose the length.
                    proxy.context.length, nativeOfflineAudioContext.sampleRate);
                    filteredBufferPromise = (async ()=>{
                        await renderInputsOfAudioNode(proxy, partialOfflineAudioContext, partialOfflineAudioContext.destination);
                        const renderedBuffer = await renderNativeOfflineAudioContext(partialOfflineAudioContext);
                        return $9a90b3aeee504dd7$var$filterFullBuffer(renderedBuffer, nativeOfflineAudioContext, feedback, feedforward);
                    })();
                }
                const filteredBuffer = await filteredBufferPromise;
                nativeAudioBufferSourceNode.buffer = filteredBuffer;
                nativeAudioBufferSourceNode.start(0);
                return nativeAudioBufferSourceNode;
            }
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeIIRFilterNode);
            return nativeIIRFilterNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioNode !== undefined) return Promise.resolve(renderedNativeAudioNode);
                return createAudioNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};



const $4d0326c0f9d09f93$export$e306a463e9286bbd = (cycleCounters, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, isActiveAudioNode)=>{
    return (isOffline)=>{
        return (audioNode, count)=>{
            const cycleCounter = cycleCounters.get(audioNode);
            if (cycleCounter === undefined) {
                if (!isOffline && isActiveAudioNode(audioNode)) {
                    const nativeSourceAudioNode = getNativeAudioNode(audioNode);
                    const { outputs: outputs  } = getAudioNodeConnections(audioNode);
                    for (const output of outputs)if ((0, $6fabcecde01c3a66$export$419d66ef3a96a878)(output)) {
                        const nativeDestinationAudioNode = getNativeAudioNode(output[0]);
                        disconnectNativeAudioNodeFromNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output[1], output[2]);
                    } else {
                        const nativeDestinationAudioParam = getNativeAudioParam(output[0]);
                        nativeSourceAudioNode.disconnect(nativeDestinationAudioParam, output[1]);
                    }
                }
                cycleCounters.set(audioNode, count);
            } else cycleCounters.set(audioNode, cycleCounter + count);
        };
    };
};





const $04e2826196eab8ca$export$7030a6f3318876b = (contextStore, isNativeAudioContext)=>{
    return (anything)=>{
        const nativeContext = contextStore.get(anything);
        return isNativeAudioContext(nativeContext) || isNativeAudioContext(anything);
    };
};


const $3adf3251cc26ee23$export$150a35c855945f9d = (audioNodeStore, isNativeAudioNode)=>{
    return (anything)=>audioNodeStore.has(anything) || isNativeAudioNode(anything);
};


const $111a900d3117bb7d$export$41505fc8888255a0 = (audioParamStore, isNativeAudioParam)=>{
    return (anything)=>audioParamStore.has(anything) || isNativeAudioParam(anything);
};


const $fa6a37efafacc48d$export$845691ce8ebc2907 = (contextStore, isNativeOfflineAudioContext)=>{
    return (anything)=>{
        const nativeContext = contextStore.get(anything);
        return isNativeOfflineAudioContext(nativeContext) || isNativeOfflineAudioContext(anything);
    };
};


const $e6dcf60ee968f7b7$export$5d44272df169092e = (nativeAudioContextConstructor)=>{
    return (anything)=>{
        return nativeAudioContextConstructor !== null && anything instanceof nativeAudioContextConstructor;
    };
};


const $deab5577981f9cf3$export$96f2bb6e8a5795ea = (window)=>{
    return (anything)=>{
        return window !== null && typeof window.AudioNode === "function" && anything instanceof window.AudioNode;
    };
};


const $3bdb9cabcc884b13$export$7c3a44537acaf24e = (window)=>{
    return (anything)=>{
        return window !== null && typeof window.AudioParam === "function" && anything instanceof window.AudioParam;
    };
};


const $5d79ae3733f1a816$export$a7c969701e5471d0 = (isNativeAudioContext, isNativeOfflineAudioContext)=>{
    return (anything)=>{
        return isNativeAudioContext(anything) || isNativeOfflineAudioContext(anything);
    };
};


const $a21b7ebb07b6ed07$export$722bd4bab77df75a = (nativeOfflineAudioContextConstructor)=>{
    return (anything)=>{
        return nativeOfflineAudioContextConstructor !== null && anything instanceof nativeOfflineAudioContextConstructor;
    };
};


const $846a59dfb4657901$export$2e9a7e6b17a9abae = (window)=>window !== null && window.isSecureContext;


const $0a2afdc8e1fe81ef$export$a245ecb43f54c4de = async (cacheTestResult, testAudioBufferCopyChannelMethodsSubarraySupport, testAudioContextCloseMethodSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextOptionsSupport, testAudioNodeConnectMethodSupport, testAudioWorkletProcessorNoOutputsSupport, testChannelMergerNodeChannelCountSupport, testConstantSourceNodeAccurateSchedulingSupport, testConvolverNodeBufferReassignabilitySupport, testConvolverNodeChannelCountSupport, testDomExceptionContrucorSupport, testIsSecureContextSupport, testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, testStereoPannerNodeDefaultValueSupport, testTransferablesSupport)=>{
    if (cacheTestResult(testAudioBufferCopyChannelMethodsSubarraySupport, testAudioBufferCopyChannelMethodsSubarraySupport) && cacheTestResult(testAudioContextCloseMethodSupport, testAudioContextCloseMethodSupport) && cacheTestResult(testAudioContextOptionsSupport, testAudioContextOptionsSupport) && cacheTestResult(testAudioNodeConnectMethodSupport, testAudioNodeConnectMethodSupport) && cacheTestResult(testChannelMergerNodeChannelCountSupport, testChannelMergerNodeChannelCountSupport) && cacheTestResult(testConstantSourceNodeAccurateSchedulingSupport, testConstantSourceNodeAccurateSchedulingSupport) && cacheTestResult(testConvolverNodeBufferReassignabilitySupport, testConvolverNodeBufferReassignabilitySupport) && cacheTestResult(testConvolverNodeChannelCountSupport, testConvolverNodeChannelCountSupport) && cacheTestResult(testDomExceptionContrucorSupport, testDomExceptionContrucorSupport) && cacheTestResult(testIsSecureContextSupport, testIsSecureContextSupport) && cacheTestResult(testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport)) {
        const results = await Promise.all([
            cacheTestResult(testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport),
            cacheTestResult(testAudioWorkletProcessorNoOutputsSupport, testAudioWorkletProcessorNoOutputsSupport),
            cacheTestResult(testStereoPannerNodeDefaultValueSupport, testStereoPannerNodeDefaultValueSupport),
            cacheTestResult(testTransferablesSupport, testTransferablesSupport)
        ]);
        return results.every((result)=>result);
    }
    return false;
};


const $7e54bbea88042f73$export$d24d3af0853fd021 = (audioNodeConstructor, createNativeMediaElementAudioSourceNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class MediaElementAudioSourceNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const nativeMediaElementAudioSourceNode = createNativeMediaElementAudioSourceNode(nativeContext, options);
            // Bug #171: Safari allows to create a MediaElementAudioSourceNode with an OfflineAudioContext.
            if (isNativeOfflineAudioContext(nativeContext)) throw TypeError();
            super(context, true, nativeMediaElementAudioSourceNode, null);
            this._nativeMediaElementAudioSourceNode = nativeMediaElementAudioSourceNode;
        }
        get mediaElement() {
            return this._nativeMediaElementAudioSourceNode.mediaElement;
        }
    };
};


const $8d43c0fa51667b8e$var$DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "explicit",
    channelInterpretation: "speakers"
};
const $8d43c0fa51667b8e$export$5d3ee2470cd2874 = (audioNodeConstructor, createNativeMediaStreamAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class MediaStreamAudioDestinationNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            // Bug #173: Safari allows to create a MediaStreamAudioDestinationNode with an OfflineAudioContext.
            if (isNativeOfflineAudioContext(nativeContext)) throw new TypeError();
            const mergedOptions = {
                ...$8d43c0fa51667b8e$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeMediaStreamAudioDestinationNode = createNativeMediaStreamAudioDestinationNode(nativeContext, mergedOptions);
            super(context, false, nativeMediaStreamAudioDestinationNode, null);
            this._nativeMediaStreamAudioDestinationNode = nativeMediaStreamAudioDestinationNode;
        }
        get stream() {
            return this._nativeMediaStreamAudioDestinationNode.stream;
        }
    };
};


const $3f763324265efb18$export$a42e10687df73a9d = (audioNodeConstructor, createNativeMediaStreamAudioSourceNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class MediaStreamAudioSourceNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const nativeMediaStreamAudioSourceNode = createNativeMediaStreamAudioSourceNode(nativeContext, options);
            // Bug #172: Safari allows to create a MediaStreamAudioSourceNode with an OfflineAudioContext.
            if (isNativeOfflineAudioContext(nativeContext)) throw new TypeError();
            super(context, true, nativeMediaStreamAudioSourceNode, null);
            this._nativeMediaStreamAudioSourceNode = nativeMediaStreamAudioSourceNode;
        }
        get mediaStream() {
            return this._nativeMediaStreamAudioSourceNode.mediaStream;
        }
    };
};


const $7a9eb73582b65b9c$export$24f27d34fdf823bc = (audioNodeConstructor, createNativeMediaStreamTrackAudioSourceNode, getNativeContext)=>{
    return class MediaStreamTrackAudioSourceNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const nativeMediaStreamTrackAudioSourceNode = createNativeMediaStreamTrackAudioSourceNode(nativeContext, options);
            super(context, true, nativeMediaStreamTrackAudioSourceNode, null);
        }
    };
};




const $257e38a5716f492b$export$8a5e66f668b2e9e8 = (createInvalidStateError, createNotSupportedError, createUnknownError, minimalBaseAudioContextConstructor, nativeAudioContextConstructor)=>{
    return class MinimalAudioContext extends minimalBaseAudioContextConstructor {
        constructor(options = {}){
            if (nativeAudioContextConstructor === null) throw new Error("Missing the native AudioContext constructor.");
            let nativeAudioContext;
            try {
                nativeAudioContext = new nativeAudioContextConstructor(options);
            } catch (err) {
                // Bug #192 Safari does throw a SyntaxError if the sampleRate is not supported.
                if (err.code === 12 && err.message === "sampleRate is not in range") throw createNotSupportedError();
                throw err;
            }
            // Bug #131 Safari returns null when there are four other AudioContexts running already.
            if (nativeAudioContext === null) throw createUnknownError();
            // Bug #51 Only Chrome Edge, and Opera throw an error if the given latencyHint is invalid.
            if (!(0, $bc5e404df0d80636$export$82d5f0e102842fbe)(options.latencyHint)) throw new TypeError(`The provided value '${options.latencyHint}' is not a valid enum value of type AudioContextLatencyCategory.`);
            // Bug #150 Safari does not support setting the sampleRate.
            if (options.sampleRate !== undefined && nativeAudioContext.sampleRate !== options.sampleRate) throw createNotSupportedError();
            super(nativeAudioContext, 2);
            const { latencyHint: latencyHint  } = options;
            const { sampleRate: sampleRate  } = nativeAudioContext;
            // @todo The values for 'balanced', 'interactive' and 'playback' are just copied from Chrome's implementation.
            this._baseLatency = typeof nativeAudioContext.baseLatency === "number" ? nativeAudioContext.baseLatency : latencyHint === "balanced" ? 512 / sampleRate : latencyHint === "interactive" || latencyHint === undefined ? 256 / sampleRate : latencyHint === "playback" ? 1024 / sampleRate : /*
                                   * @todo The min (256) and max (16384) values are taken from the allowed bufferSize values of a
                                   * ScriptProcessorNode.
                                   */ Math.max(2, Math.min(128, Math.round(latencyHint * sampleRate / 128))) * 128 / sampleRate;
            this._nativeAudioContext = nativeAudioContext;
            // Bug #188: Safari will set the context's state to 'interrupted' in case the user switches tabs.
            if (nativeAudioContextConstructor.name === "webkitAudioContext") {
                this._nativeGainNode = nativeAudioContext.createGain();
                this._nativeOscillatorNode = nativeAudioContext.createOscillator();
                this._nativeGainNode.gain.value = 1e-37;
                this._nativeOscillatorNode.connect(this._nativeGainNode).connect(nativeAudioContext.destination);
                this._nativeOscillatorNode.start();
            } else {
                this._nativeGainNode = null;
                this._nativeOscillatorNode = null;
            }
            this._state = null;
            /*
             * Bug #34: Chrome, Edge and Opera pretend to be running right away, but fire an onstatechange event when the state actually
             * changes to 'running'.
             */ if (nativeAudioContext.state === "running") {
                this._state = "suspended";
                const revokeState = ()=>{
                    if (this._state === "suspended") this._state = null;
                    nativeAudioContext.removeEventListener("statechange", revokeState);
                };
                nativeAudioContext.addEventListener("statechange", revokeState);
            }
        }
        get baseLatency() {
            return this._baseLatency;
        }
        get state() {
            return this._state !== null ? this._state : this._nativeAudioContext.state;
        }
        close() {
            // Bug #35: Firefox does not throw an error if the AudioContext was closed before.
            if (this.state === "closed") return this._nativeAudioContext.close().then(()=>{
                throw createInvalidStateError();
            });
            // Bug #34: If the state was set to suspended before it should be revoked now.
            if (this._state === "suspended") this._state = null;
            return this._nativeAudioContext.close().then(()=>{
                if (this._nativeGainNode !== null && this._nativeOscillatorNode !== null) {
                    this._nativeOscillatorNode.stop();
                    this._nativeGainNode.disconnect();
                    this._nativeOscillatorNode.disconnect();
                }
                (0, $d831926c266dcbcf$export$cbd606bc629ea938)(this);
            });
        }
        resume() {
            if (this._state === "suspended") return new Promise((resolve, reject)=>{
                const resolvePromise = ()=>{
                    this._nativeAudioContext.removeEventListener("statechange", resolvePromise);
                    if (this._nativeAudioContext.state === "running") resolve();
                    else this.resume().then(resolve, reject);
                };
                this._nativeAudioContext.addEventListener("statechange", resolvePromise);
            });
            return this._nativeAudioContext.resume().catch((err)=>{
                // Bug #55: Chrome, Edge and Opera do throw an InvalidAccessError instead of an InvalidStateError.
                // Bug #56: Safari invokes the catch handler but without an error.
                if (err === undefined || err.code === 15) throw createInvalidStateError();
                throw err;
            });
        }
        suspend() {
            return this._nativeAudioContext.suspend().catch((err)=>{
                // Bug #56: Safari invokes the catch handler but without an error.
                if (err === undefined) throw createInvalidStateError();
                throw err;
            });
        }
    };
};



const $8473550d2b626bca$export$3f49d9c870ba2692 = (audioDestinationNodeConstructor, createAudioListener, eventTargetConstructor, isNativeOfflineAudioContext, unrenderedAudioWorkletNodeStore, wrapEventListener)=>{
    return class MinimalBaseAudioContext extends eventTargetConstructor {
        constructor(_nativeContext, numberOfChannels){
            super(_nativeContext);
            this._nativeContext = _nativeContext;
            (0, $45092aa0415316c7$export$7d17302229276f06).set(this, _nativeContext);
            if (isNativeOfflineAudioContext(_nativeContext)) unrenderedAudioWorkletNodeStore.set(_nativeContext, new Set());
            this._destination = new audioDestinationNodeConstructor(this, numberOfChannels);
            this._listener = createAudioListener(this, _nativeContext);
            this._onstatechange = null;
        }
        get currentTime() {
            return this._nativeContext.currentTime;
        }
        get destination() {
            return this._destination;
        }
        get listener() {
            return this._listener;
        }
        get onstatechange() {
            return this._onstatechange;
        }
        set onstatechange(value) {
            const wrappedListener = typeof value === "function" ? wrapEventListener(this, value) : null;
            this._nativeContext.onstatechange = wrappedListener;
            const nativeOnStateChange = this._nativeContext.onstatechange;
            this._onstatechange = nativeOnStateChange !== null && nativeOnStateChange === wrappedListener ? value : nativeOnStateChange;
        }
        get sampleRate() {
            return this._nativeContext.sampleRate;
        }
        get state() {
            return this._nativeContext.state;
        }
    };
};



const $02e438f09c588964$export$9ec44223b1284cd4 = (nativeContext)=>{
    // This 12 numbers represent the 48 bytes of an empty WAVE file with a single sample.
    const uint32Array = new Uint32Array([
        1179011410,
        40,
        1163280727,
        544501094,
        16,
        131073,
        44100,
        176400,
        1048580,
        1635017060,
        4,
        0
    ]);
    try {
        // Bug #1: Safari requires a successCallback.
        const promise = nativeContext.decodeAudioData(uint32Array.buffer, ()=>{
        // Ignore the success callback.
        });
        if (promise === undefined) return false;
        promise.catch(()=>{
        // Ignore rejected errors.
        });
        return true;
    } catch  {
    // Ignore errors.
    }
    return false;
};


const $b2d360608fd94c64$var$DEFAULT_OPTIONS = {
    numberOfChannels: 1
};
const $b2d360608fd94c64$export$3d487af37fe7f521 = (cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, minimalBaseAudioContextConstructor, startRendering)=>{
    return class MinimalOfflineAudioContext extends minimalBaseAudioContextConstructor {
        constructor(options){
            const { length: length , numberOfChannels: numberOfChannels , sampleRate: sampleRate  } = {
                ...$b2d360608fd94c64$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeOfflineAudioContext = createNativeOfflineAudioContext(numberOfChannels, length, sampleRate);
            // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.
            if (!cacheTestResult((0, $02e438f09c588964$export$9ec44223b1284cd4), ()=>(0, $02e438f09c588964$export$9ec44223b1284cd4)(nativeOfflineAudioContext))) nativeOfflineAudioContext.addEventListener("statechange", (()=>{
                let i = 0;
                const delayStateChangeEvent = (event)=>{
                    if (this._state === "running") {
                        if (i > 0) {
                            nativeOfflineAudioContext.removeEventListener("statechange", delayStateChangeEvent);
                            event.stopImmediatePropagation();
                            this._waitForThePromiseToSettle(event);
                        } else i += 1;
                    }
                };
                return delayStateChangeEvent;
            })());
            super(nativeOfflineAudioContext, numberOfChannels);
            this._length = length;
            this._nativeOfflineAudioContext = nativeOfflineAudioContext;
            this._state = null;
        }
        get length() {
            // Bug #17: Safari does not yet expose the length.
            if (this._nativeOfflineAudioContext.length === undefined) return this._length;
            return this._nativeOfflineAudioContext.length;
        }
        get state() {
            return this._state === null ? this._nativeOfflineAudioContext.state : this._state;
        }
        startRendering() {
            /*
             * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore
             * the state of the nativeOfflineAudioContext might no transition to running immediately.
             */ if (this._state === "running") return Promise.reject(createInvalidStateError());
            this._state = "running";
            return startRendering(this.destination, this._nativeOfflineAudioContext).finally(()=>{
                this._state = null;
                (0, $d831926c266dcbcf$export$cbd606bc629ea938)(this);
            });
        }
        _waitForThePromiseToSettle(event) {
            if (this._state === null) this._nativeOfflineAudioContext.dispatchEvent(event);
            else setTimeout(()=>this._waitForThePromiseToSettle(event));
        }
    };
};


const $2225d588bbca3bbc$export$9f33b5a0b80f2717 = (insertElementInSet, isNativeAudioNode)=>{
    return (nativeAudioNode, whenConnected, whenDisconnected)=>{
        const connections = new Set();
        nativeAudioNode.connect = ((connect)=>{
            // tslint:disable-next-line:invalid-void no-inferrable-types
            return (destination, output = 0, input = 0)=>{
                const wasDisconnected = connections.size === 0;
                if (isNativeAudioNode(destination)) {
                    // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.
                    connect.call(nativeAudioNode, destination, output, input);
                    insertElementInSet(connections, [
                        destination,
                        output,
                        input
                    ], (connection)=>connection[0] === destination && connection[1] === output && connection[2] === input, true);
                    if (wasDisconnected) whenConnected();
                    return destination;
                }
                connect.call(nativeAudioNode, destination, output);
                insertElementInSet(connections, [
                    destination,
                    output
                ], (connection)=>connection[0] === destination && connection[1] === output, true);
                if (wasDisconnected) whenConnected();
                return;
            };
        })(nativeAudioNode.connect);
        nativeAudioNode.disconnect = ((disconnect)=>{
            return (destinationOrOutput, output, input)=>{
                const wasConnected = connections.size > 0;
                if (destinationOrOutput === undefined) {
                    disconnect.apply(nativeAudioNode);
                    connections.clear();
                } else if (typeof destinationOrOutput === "number") {
                    // @todo TypeScript cannot infer the overloaded signature with 1 argument yet.
                    disconnect.call(nativeAudioNode, destinationOrOutput);
                    for (const connection of connections)if (connection[1] === destinationOrOutput) connections.delete(connection);
                } else {
                    if (isNativeAudioNode(destinationOrOutput)) // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.
                    disconnect.call(nativeAudioNode, destinationOrOutput, output, input);
                    else // @todo TypeScript cannot infer the overloaded signature with 2 arguments yet.
                    disconnect.call(nativeAudioNode, destinationOrOutput, output);
                    for (const connection of connections)if (connection[0] === destinationOrOutput && (output === undefined || connection[1] === output) && (input === undefined || connection[2] === input)) connections.delete(connection);
                }
                const isDisconnected = connections.size === 0;
                if (wasConnected && isDisconnected) whenDisconnected();
            };
        })(nativeAudioNode.disconnect);
        return nativeAudioNode;
    };
};


const $b5d07fd47cad4d6a$export$26855c8d5a8f5839 = (nativeAudioNode, options, option)=>{
    const value = options[option];
    if (value !== undefined && value !== nativeAudioNode[option]) nativeAudioNode[option] = value;
};



const $a4603b9c665125c7$export$a741a487b656b6ff = (nativeAudioNode, options)=>{
    (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeAudioNode, options, "channelCount");
    (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeAudioNode, options, "channelCountMode");
    (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeAudioNode, options, "channelInterpretation");
};


const $90a812cbcb284e9b$export$1cb15f891b4f5e5e = (nativeAnalyserNode)=>{
    return typeof nativeAnalyserNode.getFloatTimeDomainData === "function";
};


const $b7dad64d97bff886$export$df32660d042dab2e = (nativeAnalyserNode)=>{
    nativeAnalyserNode.getFloatTimeDomainData = (array)=>{
        const byteTimeDomainData = new Uint8Array(array.length);
        nativeAnalyserNode.getByteTimeDomainData(byteTimeDomainData);
        const length = Math.max(byteTimeDomainData.length, nativeAnalyserNode.fftSize);
        for(let i = 0; i < length; i += 1)array[i] = (byteTimeDomainData[i] - 128) * 0.0078125;
        return array;
    };
};


const $2cb9b20e39baeef5$export$36e704ad7c903a26 = (cacheTestResult, createIndexSizeError)=>{
    return (nativeContext, options)=>{
        const nativeAnalyserNode = nativeContext.createAnalyser();
        // Bug #37: Firefox does not create an AnalyserNode with the default properties.
        (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeAnalyserNode, options);
        // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.
        if (!(options.maxDecibels > options.minDecibels)) throw createIndexSizeError();
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeAnalyserNode, options, "fftSize");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeAnalyserNode, options, "maxDecibels");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeAnalyserNode, options, "minDecibels");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeAnalyserNode, options, "smoothingTimeConstant");
        // Bug #36: Safari does not support getFloatTimeDomainData() yet.
        if (!cacheTestResult((0, $90a812cbcb284e9b$export$1cb15f891b4f5e5e), ()=>(0, $90a812cbcb284e9b$export$1cb15f891b4f5e5e)(nativeAnalyserNode))) (0, $b7dad64d97bff886$export$df32660d042dab2e)(nativeAnalyserNode);
        return nativeAnalyserNode;
    };
};


const $f92c7034c4236288$export$1ddb6a79e564be96 = (window)=>{
    if (window === null) return null;
    if (window.hasOwnProperty("AudioBuffer")) return window.AudioBuffer;
    return null;
};


const $f582d88ae3bf1b2e$export$4778de978774ec4f = (nativeAudioNode, options, audioParam)=>{
    const value = options[audioParam];
    if (value !== undefined && value !== nativeAudioNode[audioParam].value) nativeAudioNode[audioParam].value = value;
};





const $81dc72708fee624d$export$6b4321a414ed55c5 = (nativeAudioBufferSourceNode)=>{
    nativeAudioBufferSourceNode.start = ((start)=>{
        let isScheduled = false;
        return (when = 0, offset = 0, duration)=>{
            if (isScheduled) throw (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b)();
            start.call(nativeAudioBufferSourceNode, when, offset, duration);
            isScheduled = true;
        };
    })(nativeAudioBufferSourceNode.start);
};


const $eb08f9dbe8c62f1b$export$987b3a4087e6578c = (nativeAudioScheduledSourceNode)=>{
    nativeAudioScheduledSourceNode.start = ((start)=>{
        return (when = 0, offset = 0, duration)=>{
            if (typeof duration === "number" && duration < 0 || offset < 0 || when < 0) throw new RangeError("The parameters can't be negative.");
            // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.
            start.call(nativeAudioScheduledSourceNode, when, offset, duration);
        };
    })(nativeAudioScheduledSourceNode.start);
};


const $c598037cc1f57231$export$7adf5b1e83aad45 = (nativeAudioScheduledSourceNode)=>{
    nativeAudioScheduledSourceNode.stop = ((stop)=>{
        return (when = 0)=>{
            if (when < 0) throw new RangeError("The parameter can't be negative.");
            stop.call(nativeAudioScheduledSourceNode, when);
        };
    })(nativeAudioScheduledSourceNode.stop);
};


const $307420c32fae1fc4$export$4f48c993f264b207 = (addSilentConnection, cacheTestResult, testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, testAudioBufferSourceNodeStartMethodOffsetClampingSupport, testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioBufferSourceNodeStartMethodOffsetClampling, wrapAudioBufferSourceNodeStopMethodNullifiedBuffer, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls)=>{
    return (nativeContext, options)=>{
        const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
        (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeAudioBufferSourceNode, options);
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeAudioBufferSourceNode, options, "playbackRate");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeAudioBufferSourceNode, options, "buffer");
        // Bug #149: Safari does not yet support the detune AudioParam.
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeAudioBufferSourceNode, options, "loop");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeAudioBufferSourceNode, options, "loopEnd");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeAudioBufferSourceNode, options, "loopStart");
        // Bug #69: Safari does allow calls to start() of an already scheduled AudioBufferSourceNode.
        if (!cacheTestResult(testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, ()=>testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport(nativeContext))) (0, $81dc72708fee624d$export$6b4321a414ed55c5)(nativeAudioBufferSourceNode);
        // Bug #154 & #155: Safari does not handle offsets which are equal to or greater than the duration of the buffer.
        if (!cacheTestResult(testAudioBufferSourceNodeStartMethodOffsetClampingSupport, ()=>testAudioBufferSourceNodeStartMethodOffsetClampingSupport(nativeContext))) wrapAudioBufferSourceNodeStartMethodOffsetClampling(nativeAudioBufferSourceNode);
        // Bug #162: Safari does throw an error when stop() is called on an AudioBufferSourceNode which has no buffer assigned to it.
        if (!cacheTestResult(testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, ()=>testAudioBufferSourceNodeStopMethodNullifiedBufferSupport(nativeContext))) wrapAudioBufferSourceNodeStopMethodNullifiedBuffer(nativeAudioBufferSourceNode, nativeContext);
        // Bug #44: Safari does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) (0, $eb08f9dbe8c62f1b$export$987b3a4087e6578c)(nativeAudioBufferSourceNode);
        // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, ()=>testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext))) wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeAudioBufferSourceNode, nativeContext);
        // Bug #44: Only Firefox does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) (0, $c598037cc1f57231$export$7adf5b1e83aad45)(nativeAudioBufferSourceNode);
        // Bug #175: Safari will not fire an ended event if the AudioBufferSourceNode is unconnected.
        addSilentConnection(nativeContext, nativeAudioBufferSourceNode);
        return nativeAudioBufferSourceNode;
    };
};


const $792783d50bf09b55$export$3a22fc4046f7b4ec = (window)=>{
    if (window === null) return null;
    if (window.hasOwnProperty("AudioContext")) return window.AudioContext;
    return window.hasOwnProperty("webkitAudioContext") ? window.webkitAudioContext : null;
};


const $b385ebedfeec267d$export$d3097038f258fce = (createNativeGainNode, overwriteAccessors)=>{
    return (nativeContext, channelCount, isNodeOfNativeOfflineAudioContext)=>{
        const nativeAudioDestinationNode = nativeContext.destination;
        // Bug #132: Safari does not have the correct channelCount.
        if (nativeAudioDestinationNode.channelCount !== channelCount) try {
            nativeAudioDestinationNode.channelCount = channelCount;
        } catch  {
        // Bug #169: Safari throws an error on each attempt to change the channelCount.
        }
        // Bug #83: Safari does not have the correct channelCountMode.
        if (isNodeOfNativeOfflineAudioContext && nativeAudioDestinationNode.channelCountMode !== "explicit") nativeAudioDestinationNode.channelCountMode = "explicit";
        // Bug #47: The AudioDestinationNode in Safari does not initialize the maxChannelCount property correctly.
        if (nativeAudioDestinationNode.maxChannelCount === 0) Object.defineProperty(nativeAudioDestinationNode, "maxChannelCount", {
            value: channelCount
        });
        // Bug #168: No browser does yet have an AudioDestinationNode with an output.
        const gainNode = createNativeGainNode(nativeContext, {
            channelCount: channelCount,
            channelCountMode: nativeAudioDestinationNode.channelCountMode,
            channelInterpretation: nativeAudioDestinationNode.channelInterpretation,
            gain: 1
        });
        overwriteAccessors(gainNode, "channelCount", (get)=>()=>get.call(gainNode), (set)=>(value)=>{
                set.call(gainNode, value);
                try {
                    nativeAudioDestinationNode.channelCount = value;
                } catch (err) {
                    // Bug #169: Safari throws an error on each attempt to change the channelCount.
                    if (value > nativeAudioDestinationNode.maxChannelCount) throw err;
                }
            });
        overwriteAccessors(gainNode, "channelCountMode", (get)=>()=>get.call(gainNode), (set)=>(value)=>{
                set.call(gainNode, value);
                nativeAudioDestinationNode.channelCountMode = value;
            });
        overwriteAccessors(gainNode, "channelInterpretation", (get)=>()=>get.call(gainNode), (set)=>(value)=>{
                set.call(gainNode, value);
                nativeAudioDestinationNode.channelInterpretation = value;
            });
        Object.defineProperty(gainNode, "maxChannelCount", {
            get: ()=>nativeAudioDestinationNode.maxChannelCount
        });
        // @todo This should be disconnected when the context is closed.
        gainNode.connect(nativeAudioDestinationNode);
        return gainNode;
    };
};


const $bfe566b60cab0cea$export$b0ef4818c07d1453 = (window)=>{
    if (window === null) return null;
    return window.hasOwnProperty("AudioWorkletNode") ? window.AudioWorkletNode : null;
};


const $e6eac0e58b814a6d$export$8bad4bda0c154746 = (audioWorkletNodeOptions)=>{
    const { port1: port1  } = new MessageChannel();
    try {
        // This will throw an error if the audioWorkletNodeOptions are not clonable.
        port1.postMessage(audioWorkletNodeOptions);
    } finally{
        port1.close();
    }
};


const $05daef3b9aca3079$export$a6399b47836cd044 = (createInvalidStateError, createNativeAudioWorkletNodeFaker, createNativeGainNode, createNotSupportedError, monitorConnections)=>{
    return (nativeContext, baseLatency, nativeAudioWorkletNodeConstructor, name, processorConstructor, options)=>{
        if (nativeAudioWorkletNodeConstructor !== null) try {
            const nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeContext, name, options);
            const patchedEventListeners = new Map();
            let onprocessorerror = null;
            Object.defineProperties(nativeAudioWorkletNode, {
                /*
                     * Bug #61: Overwriting the property accessors for channelCount and channelCountMode is necessary as long as some
                     * browsers have no native implementation to achieve a consistent behavior.
                     */ channelCount: {
                    get: ()=>options.channelCount,
                    set: ()=>{
                        throw createInvalidStateError();
                    }
                },
                channelCountMode: {
                    get: ()=>"explicit",
                    set: ()=>{
                        throw createInvalidStateError();
                    }
                },
                // Bug #156: Chrome and Edge do not yet fire an ErrorEvent.
                onprocessorerror: {
                    get: ()=>onprocessorerror,
                    set: (value)=>{
                        if (typeof onprocessorerror === "function") nativeAudioWorkletNode.removeEventListener("processorerror", onprocessorerror);
                        onprocessorerror = typeof value === "function" ? value : null;
                        if (typeof onprocessorerror === "function") nativeAudioWorkletNode.addEventListener("processorerror", onprocessorerror);
                    }
                }
            });
            nativeAudioWorkletNode.addEventListener = ((addEventListener)=>{
                return (...args)=>{
                    if (args[0] === "processorerror") {
                        const unpatchedEventListener = typeof args[1] === "function" ? args[1] : typeof args[1] === "object" && args[1] !== null && typeof args[1].handleEvent === "function" ? args[1].handleEvent : null;
                        if (unpatchedEventListener !== null) {
                            const patchedEventListener = patchedEventListeners.get(args[1]);
                            if (patchedEventListener !== undefined) args[1] = patchedEventListener;
                            else {
                                args[1] = (event)=>{
                                    // Bug #178: Chrome, Edge and Opera do fire an event of type error.
                                    if (event.type === "error") {
                                        Object.defineProperties(event, {
                                            type: {
                                                value: "processorerror"
                                            }
                                        });
                                        unpatchedEventListener(event);
                                    } else unpatchedEventListener(new ErrorEvent(args[0], {
                                        ...event
                                    }));
                                };
                                patchedEventListeners.set(unpatchedEventListener, args[1]);
                            }
                        }
                    }
                    // Bug #178: Chrome, Edge and Opera do fire an event of type error.
                    addEventListener.call(nativeAudioWorkletNode, "error", args[1], args[2]);
                    return addEventListener.call(nativeAudioWorkletNode, ...args);
                };
            })(nativeAudioWorkletNode.addEventListener);
            nativeAudioWorkletNode.removeEventListener = ((removeEventListener)=>{
                return (...args)=>{
                    if (args[0] === "processorerror") {
                        const patchedEventListener = patchedEventListeners.get(args[1]);
                        if (patchedEventListener !== undefined) {
                            patchedEventListeners.delete(args[1]);
                            args[1] = patchedEventListener;
                        }
                    }
                    // Bug #178: Chrome, Edge and Opera do fire an event of type error.
                    removeEventListener.call(nativeAudioWorkletNode, "error", args[1], args[2]);
                    return removeEventListener.call(nativeAudioWorkletNode, args[0], args[1], args[2]);
                };
            })(nativeAudioWorkletNode.removeEventListener);
            /*
                 * Bug #86: Chrome and Edge do not invoke the process() function if the corresponding AudioWorkletNode is unconnected but
                 * has an output.
                 */ if (options.numberOfOutputs !== 0) {
                const nativeGainNode = createNativeGainNode(nativeContext, {
                    channelCount: 1,
                    channelCountMode: "explicit",
                    channelInterpretation: "discrete",
                    gain: 0
                });
                nativeAudioWorkletNode.connect(nativeGainNode).connect(nativeContext.destination);
                const whenConnected = ()=>nativeGainNode.disconnect();
                const whenDisconnected = ()=>nativeGainNode.connect(nativeContext.destination);
                // @todo Disconnect the connection when the process() function of the AudioWorkletNode returns false.
                return monitorConnections(nativeAudioWorkletNode, whenConnected, whenDisconnected);
            }
            return nativeAudioWorkletNode;
        } catch (err) {
            // Bug #60: Chrome, Edge & Opera throw an InvalidStateError instead of a NotSupportedError.
            if (err.code === 11) throw createNotSupportedError();
            throw err;
        }
        // Bug #61: Only Chrome & Opera have an implementation of the AudioWorkletNode yet.
        if (processorConstructor === undefined) throw createNotSupportedError();
        (0, $e6eac0e58b814a6d$export$8bad4bda0c154746)(options);
        return createNativeAudioWorkletNodeFaker(nativeContext, baseLatency, processorConstructor, options);
    };
};



const $a05502b74397db33$export$c3c4ba87244c2bf4 = (baseLatency, sampleRate)=>{
    if (baseLatency === null) return 512;
    return Math.max(512, Math.min(16384, Math.pow(2, Math.round(Math.log2(baseLatency * sampleRate)))));
};





const $d13f3a529396eab5$export$45f6aa3433a4eb0 = (audioWorkletNodeOptions)=>{
    return new Promise((resolve, reject)=>{
        const { port1: port1 , port2: port2  } = new MessageChannel();
        port1.onmessage = ({ data: data  })=>{
            port1.close();
            port2.close();
            resolve(data);
        };
        port1.onmessageerror = ({ data: data  })=>{
            port1.close();
            port2.close();
            reject(data);
        };
        // This will throw an error if the audioWorkletNodeOptions are not clonable.
        port2.postMessage(audioWorkletNodeOptions);
    });
};


const $63bdd454ddee682d$export$62410a657c3adf1d = async (processorConstructor, audioWorkletNodeOptions)=>{
    const clonedAudioWorkletNodeOptions = await (0, $d13f3a529396eab5$export$45f6aa3433a4eb0)(audioWorkletNodeOptions);
    return new processorConstructor(clonedAudioWorkletNodeOptions);
};


const $d29d84eccde795b7$export$5200a42feb14a7b7 = (nativeContext, nativeAudioWorkletNode, processorConstructor, audioWorkletNodeOptions)=>{
    let nodeToProcessorMap = (0, $45092aa0415316c7$export$16d7878f7e059d67).get(nativeContext);
    if (nodeToProcessorMap === undefined) {
        nodeToProcessorMap = new WeakMap();
        (0, $45092aa0415316c7$export$16d7878f7e059d67).set(nativeContext, nodeToProcessorMap);
    }
    const audioWorkletProcessorPromise = (0, $63bdd454ddee682d$export$62410a657c3adf1d)(processorConstructor, audioWorkletNodeOptions);
    nodeToProcessorMap.set(nativeAudioWorkletNode, audioWorkletProcessorPromise);
    return audioWorkletProcessorPromise;
};




const $16898f3baaba3ba9$export$ea40f9f600f0adcb = (connectMultipleOutputs, createIndexSizeError, createInvalidStateError, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, createNativeScriptProcessorNode, createNotSupportedError, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getActiveAudioWorkletNodeInputs, monitorConnections)=>{
    return (nativeContext, baseLatency, processorConstructor, options)=>{
        if (options.numberOfInputs === 0 && options.numberOfOutputs === 0) throw createNotSupportedError();
        const outputChannelCount = Array.isArray(options.outputChannelCount) ? options.outputChannelCount : Array.from(options.outputChannelCount);
        // @todo Check if any of the channelCount values is greater than the implementation's maximum number of channels.
        if (outputChannelCount.some((channelCount)=>channelCount < 1)) throw createNotSupportedError();
        if (outputChannelCount.length !== options.numberOfOutputs) throw createIndexSizeError();
        // Bug #61: This is not part of the standard but required for the faker to work.
        if (options.channelCountMode !== "explicit") throw createNotSupportedError();
        const numberOfInputChannels = options.channelCount * options.numberOfInputs;
        const numberOfOutputChannels = outputChannelCount.reduce((sum, value)=>sum + value, 0);
        const numberOfParameters = processorConstructor.parameterDescriptors === undefined ? 0 : processorConstructor.parameterDescriptors.length;
        // Bug #61: This is not part of the standard but required for the faker to work.
        if (numberOfInputChannels + numberOfParameters > 6 || numberOfOutputChannels > 6) throw createNotSupportedError();
        const messageChannel = new MessageChannel();
        const gainNodes = [];
        const inputChannelSplitterNodes = [];
        for(let i3 = 0; i3 < options.numberOfInputs; i3 += 1){
            gainNodes.push(createNativeGainNode(nativeContext, {
                channelCount: options.channelCount,
                channelCountMode: options.channelCountMode,
                channelInterpretation: options.channelInterpretation,
                gain: 1
            }));
            inputChannelSplitterNodes.push(createNativeChannelSplitterNode(nativeContext, {
                channelCount: options.channelCount,
                channelCountMode: "explicit",
                channelInterpretation: "discrete",
                numberOfOutputs: options.channelCount
            }));
        }
        const constantSourceNodes = [];
        if (processorConstructor.parameterDescriptors !== undefined) for (const { defaultValue: defaultValue , maxValue: maxValue , minValue: minValue , name: name1  } of processorConstructor.parameterDescriptors){
            const constantSourceNode = createNativeConstantSourceNode(nativeContext, {
                channelCount: 1,
                channelCountMode: "explicit",
                channelInterpretation: "discrete",
                offset: options.parameterData[name1] !== undefined ? options.parameterData[name1] : defaultValue === undefined ? 0 : defaultValue
            });
            Object.defineProperties(constantSourceNode.offset, {
                defaultValue: {
                    get: ()=>defaultValue === undefined ? 0 : defaultValue
                },
                maxValue: {
                    get: ()=>maxValue === undefined ? (0, $b1c06cbd433e26a1$export$ab43bedd17d6a167) : maxValue
                },
                minValue: {
                    get: ()=>minValue === undefined ? (0, $b1c06cbd433e26a1$export$ced6a5c63b103b52) : minValue
                }
            });
            constantSourceNodes.push(constantSourceNode);
        }
        const inputChannelMergerNode = createNativeChannelMergerNode(nativeContext, {
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "speakers",
            numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)
        });
        const bufferSize = (0, $a05502b74397db33$export$c3c4ba87244c2bf4)(baseLatency, nativeContext.sampleRate);
        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, bufferSize, numberOfInputChannels + numberOfParameters, // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.
        Math.max(1, numberOfOutputChannels));
        const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, {
            channelCount: Math.max(1, numberOfOutputChannels),
            channelCountMode: "explicit",
            channelInterpretation: "discrete",
            numberOfOutputs: Math.max(1, numberOfOutputChannels)
        });
        const outputChannelMergerNodes = [];
        for(let i1 = 0; i1 < options.numberOfOutputs; i1 += 1)outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeContext, {
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "speakers",
            numberOfInputs: outputChannelCount[i1]
        }));
        for(let i2 = 0; i2 < options.numberOfInputs; i2 += 1){
            gainNodes[i2].connect(inputChannelSplitterNodes[i2]);
            for(let j = 0; j < options.channelCount; j += 1)inputChannelSplitterNodes[i2].connect(inputChannelMergerNode, j, i2 * options.channelCount + j);
        }
        const parameterMap = new (0, $5bfcd23ee6d93a68$export$5da0cf80a3ca75d6)(processorConstructor.parameterDescriptors === undefined ? [] : processorConstructor.parameterDescriptors.map(({ name: name  }, index)=>{
            const constantSourceNode = constantSourceNodes[index];
            constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);
            constantSourceNode.start(0);
            return [
                name,
                constantSourceNode.offset
            ];
        }));
        inputChannelMergerNode.connect(scriptProcessorNode);
        let channelInterpretation = options.channelInterpretation;
        let onprocessorerror = null;
        // Bug #87: Expose at least one output to make this node connectable.
        const outputAudioNodes = options.numberOfOutputs === 0 ? [
            scriptProcessorNode
        ] : outputChannelMergerNodes;
        const nativeAudioWorkletNodeFaker = {
            get bufferSize () {
                return bufferSize;
            },
            get channelCount () {
                return options.channelCount;
            },
            set channelCount (_){
                // Bug #61: This is not part of the standard but required for the faker to work.
                throw createInvalidStateError();
            },
            get channelCountMode () {
                return options.channelCountMode;
            },
            set channelCountMode (_){
                // Bug #61: This is not part of the standard but required for the faker to work.
                throw createInvalidStateError();
            },
            get channelInterpretation () {
                return channelInterpretation;
            },
            set channelInterpretation (value){
                for (const gainNode of gainNodes)gainNode.channelInterpretation = value;
                channelInterpretation = value;
            },
            get context () {
                return scriptProcessorNode.context;
            },
            get inputs () {
                return gainNodes;
            },
            get numberOfInputs () {
                return options.numberOfInputs;
            },
            get numberOfOutputs () {
                return options.numberOfOutputs;
            },
            get onprocessorerror () {
                return onprocessorerror;
            },
            set onprocessorerror (value){
                if (typeof onprocessorerror === "function") nativeAudioWorkletNodeFaker.removeEventListener("processorerror", onprocessorerror);
                onprocessorerror = typeof value === "function" ? value : null;
                if (typeof onprocessorerror === "function") nativeAudioWorkletNodeFaker.addEventListener("processorerror", onprocessorerror);
            },
            get parameters () {
                return parameterMap;
            },
            get port () {
                return messageChannel.port2;
            },
            addEventListener (...args) {
                return scriptProcessorNode.addEventListener(args[0], args[1], args[2]);
            },
            connect: connectMultipleOutputs.bind(null, outputAudioNodes),
            disconnect: disconnectMultipleOutputs.bind(null, outputAudioNodes),
            dispatchEvent (...args) {
                return scriptProcessorNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return scriptProcessorNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        const patchedEventListeners = new Map();
        messageChannel.port1.addEventListener = ((addEventListener)=>{
            return (...args)=>{
                if (args[0] === "message") {
                    const unpatchedEventListener = typeof args[1] === "function" ? args[1] : typeof args[1] === "object" && args[1] !== null && typeof args[1].handleEvent === "function" ? args[1].handleEvent : null;
                    if (unpatchedEventListener !== null) {
                        const patchedEventListener = patchedEventListeners.get(args[1]);
                        if (patchedEventListener !== undefined) args[1] = patchedEventListener;
                        else {
                            args[1] = (event)=>{
                                exposeCurrentFrameAndCurrentTime(nativeContext.currentTime, nativeContext.sampleRate, ()=>unpatchedEventListener(event));
                            };
                            patchedEventListeners.set(unpatchedEventListener, args[1]);
                        }
                    }
                }
                return addEventListener.call(messageChannel.port1, args[0], args[1], args[2]);
            };
        })(messageChannel.port1.addEventListener);
        messageChannel.port1.removeEventListener = ((removeEventListener)=>{
            return (...args)=>{
                if (args[0] === "message") {
                    const patchedEventListener = patchedEventListeners.get(args[1]);
                    if (patchedEventListener !== undefined) {
                        patchedEventListeners.delete(args[1]);
                        args[1] = patchedEventListener;
                    }
                }
                return removeEventListener.call(messageChannel.port1, args[0], args[1], args[2]);
            };
        })(messageChannel.port1.removeEventListener);
        let onmessage = null;
        Object.defineProperty(messageChannel.port1, "onmessage", {
            get: ()=>onmessage,
            set: (value)=>{
                if (typeof onmessage === "function") messageChannel.port1.removeEventListener("message", onmessage);
                onmessage = typeof value === "function" ? value : null;
                if (typeof onmessage === "function") {
                    messageChannel.port1.addEventListener("message", onmessage);
                    messageChannel.port1.start();
                }
            }
        });
        processorConstructor.prototype.port = messageChannel.port1;
        let audioWorkletProcessor = null;
        const audioWorkletProcessorPromise = (0, $d29d84eccde795b7$export$5200a42feb14a7b7)(nativeContext, nativeAudioWorkletNodeFaker, processorConstructor, options);
        audioWorkletProcessorPromise.then((dWrkltPrcssr)=>audioWorkletProcessor = dWrkltPrcssr);
        const inputs = (0, $a954efb50ecf21d3$export$495a31436d188d6d)(options.numberOfInputs, options.channelCount);
        const outputs = (0, $a954efb50ecf21d3$export$495a31436d188d6d)(options.numberOfOutputs, outputChannelCount);
        const parameters = processorConstructor.parameterDescriptors === undefined ? [] : processorConstructor.parameterDescriptors.reduce((prmtrs, { name: name  })=>({
                ...prmtrs,
                [name]: new Float32Array(128)
            }), {});
        let isActive = true;
        const disconnectOutputsGraph = ()=>{
            if (options.numberOfOutputs > 0) scriptProcessorNode.disconnect(outputChannelSplitterNode);
            for(let i = 0, outputChannelSplitterNodeOutput = 0; i < options.numberOfOutputs; i += 1){
                const outputChannelMergerNode = outputChannelMergerNodes[i];
                for(let j = 0; j < outputChannelCount[i]; j += 1)outputChannelSplitterNode.disconnect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);
                outputChannelSplitterNodeOutput += outputChannelCount[i];
            }
        };
        const activeInputIndexes = new Map();
        // tslint:disable-next-line:deprecation
        scriptProcessorNode.onaudioprocess = ({ inputBuffer: inputBuffer , outputBuffer: outputBuffer  })=>{
            if (audioWorkletProcessor !== null) {
                const activeInputs = getActiveAudioWorkletNodeInputs(nativeAudioWorkletNodeFaker);
                for(let i = 0; i < bufferSize; i += 128){
                    for(let j = 0; j < options.numberOfInputs; j += 1)for(let k = 0; k < options.channelCount; k += 1)(0, $b7b6361fd4dedbae$export$e3c6e435bf217093)(inputBuffer, inputs[j], k, k, i);
                    if (processorConstructor.parameterDescriptors !== undefined) processorConstructor.parameterDescriptors.forEach(({ name: name  }, index)=>{
                        (0, $b7b6361fd4dedbae$export$e3c6e435bf217093)(inputBuffer, parameters, name, numberOfInputChannels + index, i);
                    });
                    for(let j1 = 0; j1 < options.numberOfInputs; j1 += 1){
                        for(let k = 0; k < outputChannelCount[j1]; k += 1)// The byteLength will be 0 when the ArrayBuffer was transferred.
                        if (outputs[j1][k].byteLength === 0) outputs[j1][k] = new Float32Array(128);
                    }
                    try {
                        const potentiallyEmptyInputs = inputs.map((input, index)=>{
                            const activeInput = activeInputs[index];
                            if (activeInput.size > 0) {
                                activeInputIndexes.set(index, bufferSize / 128);
                                return input;
                            }
                            const count = activeInputIndexes.get(index);
                            if (count === undefined) return [];
                            if (input.every((channelData)=>channelData.every((sample)=>sample === 0))) {
                                if (count === 1) activeInputIndexes.delete(index);
                                else activeInputIndexes.set(index, count - 1);
                            }
                            return input;
                        });
                        const activeSourceFlag = exposeCurrentFrameAndCurrentTime(nativeContext.currentTime + i / nativeContext.sampleRate, nativeContext.sampleRate, ()=>audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters));
                        isActive = activeSourceFlag;
                        for(let j = 0, outputChannelSplitterNodeOutput = 0; j < options.numberOfOutputs; j += 1){
                            for(let k = 0; k < outputChannelCount[j]; k += 1)(0, $cd25e5111351f21f$export$6bb6d131144bd753)(outputBuffer, outputs[j], k, outputChannelSplitterNodeOutput + k, i);
                            outputChannelSplitterNodeOutput += outputChannelCount[j];
                        }
                    } catch (error) {
                        isActive = false;
                        nativeAudioWorkletNodeFaker.dispatchEvent(new ErrorEvent("processorerror", {
                            colno: error.colno,
                            filename: error.filename,
                            lineno: error.lineno,
                            message: error.message
                        }));
                    }
                    if (!isActive) {
                        for(let j = 0; j < options.numberOfInputs; j += 1){
                            gainNodes[j].disconnect(inputChannelSplitterNodes[j]);
                            for(let k = 0; k < options.channelCount; k += 1)inputChannelSplitterNodes[i].disconnect(inputChannelMergerNode, k, j * options.channelCount + k);
                        }
                        if (processorConstructor.parameterDescriptors !== undefined) {
                            const length = processorConstructor.parameterDescriptors.length;
                            for(let j = 0; j < length; j += 1){
                                const constantSourceNode = constantSourceNodes[j];
                                constantSourceNode.disconnect(inputChannelMergerNode, 0, numberOfInputChannels + j);
                                constantSourceNode.stop();
                            }
                        }
                        inputChannelMergerNode.disconnect(scriptProcessorNode);
                        scriptProcessorNode.onaudioprocess = null; // tslint:disable-line:deprecation
                        if (isConnected) disconnectOutputsGraph();
                        else disconnectFakeGraph();
                        break;
                    }
                }
            }
        };
        let isConnected = false;
        // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.
        const nativeGainNode = createNativeGainNode(nativeContext, {
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "discrete",
            gain: 0
        });
        const connectFakeGraph = ()=>scriptProcessorNode.connect(nativeGainNode).connect(nativeContext.destination);
        const disconnectFakeGraph = ()=>{
            scriptProcessorNode.disconnect(nativeGainNode);
            nativeGainNode.disconnect();
        };
        const whenConnected = ()=>{
            if (isActive) {
                disconnectFakeGraph();
                if (options.numberOfOutputs > 0) scriptProcessorNode.connect(outputChannelSplitterNode);
                for(let i = 0, outputChannelSplitterNodeOutput = 0; i < options.numberOfOutputs; i += 1){
                    const outputChannelMergerNode = outputChannelMergerNodes[i];
                    for(let j = 0; j < outputChannelCount[i]; j += 1)outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);
                    outputChannelSplitterNodeOutput += outputChannelCount[i];
                }
            }
            isConnected = true;
        };
        const whenDisconnected = ()=>{
            if (isActive) {
                connectFakeGraph();
                disconnectOutputsGraph();
            }
            isConnected = false;
        };
        connectFakeGraph();
        return monitorConnections(nativeAudioWorkletNodeFaker, whenConnected, whenDisconnected);
    };
};





const $8c4ffb908a10983f$export$97e69c8dbd260f85 = (nativeContext, options)=>{
    const nativeBiquadFilterNode = nativeContext.createBiquadFilter();
    (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeBiquadFilterNode, options);
    (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeBiquadFilterNode, options, "Q");
    (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeBiquadFilterNode, options, "detune");
    (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeBiquadFilterNode, options, "frequency");
    (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeBiquadFilterNode, options, "gain");
    (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeBiquadFilterNode, options, "type");
    return nativeBiquadFilterNode;
};



const $25fec0ffa6e9acb4$export$99fe194415d94151 = (nativeAudioContextConstructor, wrapChannelMergerNode)=>{
    return (nativeContext, options)=>{
        const nativeChannelMergerNode = nativeContext.createChannelMerger(options.numberOfInputs);
        /*
         * Bug #20: Safari requires a connection of any kind to treat the input signal correctly.
         * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the existence of
         * the webkitAudioContext is used as a workaround here.
         */ if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === "webkitAudioContext") wrapChannelMergerNode(nativeContext, nativeChannelMergerNode);
        (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeChannelMergerNode, options);
        return nativeChannelMergerNode;
    };
};




const $77c1de70add4e6bf$export$62f6b3ab91fa4589 = (channelSplitterNode)=>{
    const channelCount = channelSplitterNode.numberOfOutputs;
    // Bug #97: Safari does not throw an error when attempting to change the channelCount to something other than its initial value.
    Object.defineProperty(channelSplitterNode, "channelCount", {
        get: ()=>channelCount,
        set: (value)=>{
            if (value !== channelCount) throw (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b)();
        }
    });
    // Bug #30: Safari does not throw an error when attempting to change the channelCountMode to something other than explicit.
    Object.defineProperty(channelSplitterNode, "channelCountMode", {
        get: ()=>"explicit",
        set: (value)=>{
            if (value !== "explicit") throw (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b)();
        }
    });
    // Bug #32: Safari does not throw an error when attempting to change the channelInterpretation to something other than discrete.
    Object.defineProperty(channelSplitterNode, "channelInterpretation", {
        get: ()=>"discrete",
        set: (value)=>{
            if (value !== "discrete") throw (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b)();
        }
    });
};


const $bc9026dcb0dcb567$export$17649533bf213707 = (nativeContext, options)=>{
    const nativeChannelSplitterNode = nativeContext.createChannelSplitter(options.numberOfOutputs);
    // Bug #96: Safari does not have the correct channelCount.
    // Bug #29: Safari does not have the correct channelCountMode.
    // Bug #31: Safari does not have the correct channelInterpretation.
    (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeChannelSplitterNode, options);
    // Bug #29, #30, #31, #32, #96 & #97: Only Chrome, Edge, Firefox & Opera partially support the spec yet.
    (0, $77c1de70add4e6bf$export$62f6b3ab91fa4589)(nativeChannelSplitterNode);
    return nativeChannelSplitterNode;
};






const $a94975f5203cc134$export$2dd44f7bb3dd8089 = (addSilentConnection, cacheTestResult, createNativeConstantSourceNodeFaker, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport)=>{
    return (nativeContext, options)=>{
        // Bug #62: Safari does not support ConstantSourceNodes.
        if (nativeContext.createConstantSource === undefined) return createNativeConstantSourceNodeFaker(nativeContext, options);
        const nativeConstantSourceNode = nativeContext.createConstantSource();
        (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeConstantSourceNode, options);
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeConstantSourceNode, options, "offset");
        // Bug #44: Safari does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) (0, $eb08f9dbe8c62f1b$export$987b3a4087e6578c)(nativeConstantSourceNode);
        // Bug #44: Only Firefox does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) (0, $c598037cc1f57231$export$7adf5b1e83aad45)(nativeConstantSourceNode);
        // Bug #175: Safari will not fire an ended event if the ConstantSourceNode is unconnected.
        addSilentConnection(nativeContext, nativeConstantSourceNode);
        return nativeConstantSourceNode;
    };
};


const $f50dfa358e381b90$export$19c8a106f82dff14 = (original, interceptor)=>{
    original.connect = interceptor.connect.bind(interceptor);
    original.disconnect = interceptor.disconnect.bind(interceptor);
    return original;
};


const $1651ef53e16686cd$export$360749cf3d02285a = (addSilentConnection, createNativeAudioBufferSourceNode, createNativeGainNode, monitorConnections)=>{
    return (nativeContext, { offset: offset , ...audioNodeOptions })=>{
        const audioBuffer = nativeContext.createBuffer(1, 2, 44100);
        const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, {
            buffer: null,
            channelCount: 2,
            channelCountMode: "max",
            channelInterpretation: "speakers",
            loop: false,
            loopEnd: 0,
            loopStart: 0,
            playbackRate: 1
        });
        const gainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: offset
        });
        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
        const channelData = audioBuffer.getChannelData(0);
        // Bug #95: Safari does not play or loop one sample buffers.
        channelData[0] = 1;
        channelData[1] = 1;
        audioBufferSourceNode.buffer = audioBuffer;
        audioBufferSourceNode.loop = true;
        const nativeConstantSourceNodeFaker = {
            get bufferSize () {
                return undefined;
            },
            get channelCount () {
                return gainNode.channelCount;
            },
            set channelCount (value){
                gainNode.channelCount = value;
            },
            get channelCountMode () {
                return gainNode.channelCountMode;
            },
            set channelCountMode (value){
                gainNode.channelCountMode = value;
            },
            get channelInterpretation () {
                return gainNode.channelInterpretation;
            },
            set channelInterpretation (value){
                gainNode.channelInterpretation = value;
            },
            get context () {
                return gainNode.context;
            },
            get inputs () {
                return [];
            },
            get numberOfInputs () {
                return audioBufferSourceNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return gainNode.numberOfOutputs;
            },
            get offset () {
                return gainNode.gain;
            },
            get onended () {
                return audioBufferSourceNode.onended;
            },
            set onended (value){
                audioBufferSourceNode.onended = value;
            },
            addEventListener (...args) {
                return audioBufferSourceNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return audioBufferSourceNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return audioBufferSourceNode.removeEventListener(args[0], args[1], args[2]);
            },
            start (when = 0) {
                audioBufferSourceNode.start.call(audioBufferSourceNode, when);
            },
            stop (when = 0) {
                audioBufferSourceNode.stop.call(audioBufferSourceNode, when);
            }
        };
        const whenConnected = ()=>audioBufferSourceNode.connect(gainNode);
        const whenDisconnected = ()=>audioBufferSourceNode.disconnect(gainNode);
        // Bug #175: Safari will not fire an ended event if the AudioBufferSourceNode is unconnected.
        addSilentConnection(nativeContext, audioBufferSourceNode);
        return monitorConnections((0, $f50dfa358e381b90$export$19c8a106f82dff14)(nativeConstantSourceNodeFaker, gainNode), whenConnected, whenDisconnected);
    };
};




const $ba518ad47f75b625$export$afdcf89d13ff62e = (createNotSupportedError, overwriteAccessors)=>{
    return (nativeContext, options)=>{
        const nativeConvolverNode = nativeContext.createConvolver();
        (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeConvolverNode, options);
        // The normalize property needs to be set before setting the buffer.
        if (options.disableNormalization === nativeConvolverNode.normalize) nativeConvolverNode.normalize = !options.disableNormalization;
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeConvolverNode, options, "buffer");
        // Bug #113: Safari does allow to set the channelCount to a value larger than 2.
        if (options.channelCount > 2) throw createNotSupportedError();
        overwriteAccessors(nativeConvolverNode, "channelCount", (get)=>()=>get.call(nativeConvolverNode), (set)=>(value)=>{
                if (value > 2) throw createNotSupportedError();
                return set.call(nativeConvolverNode, value);
            });
        // Bug #114: Safari allows to set the channelCountMode to 'max'.
        if (options.channelCountMode === "max") throw createNotSupportedError();
        overwriteAccessors(nativeConvolverNode, "channelCountMode", (get)=>()=>get.call(nativeConvolverNode), (set)=>(value)=>{
                if (value === "max") throw createNotSupportedError();
                return set.call(nativeConvolverNode, value);
            });
        return nativeConvolverNode;
    };
};




const $823fb61947f30fc5$export$f7dd6d407a2109ef = (nativeContext, options)=>{
    const nativeDelayNode = nativeContext.createDelay(options.maxDelayTime);
    (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeDelayNode, options);
    (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeDelayNode, options, "delayTime");
    return nativeDelayNode;
};




const $1634e82587ef6934$export$f19d90a0cd4a2ecc = (createNotSupportedError)=>{
    return (nativeContext, options)=>{
        const nativeDynamicsCompressorNode = nativeContext.createDynamicsCompressor();
        (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeDynamicsCompressorNode, options);
        // Bug #108: Safari allows a channelCount of three and above.
        if (options.channelCount > 2) throw createNotSupportedError();
        // Bug #109: Only Chrome, Firefox and Opera disallow a channelCountMode of 'max'.
        if (options.channelCountMode === "max") throw createNotSupportedError();
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeDynamicsCompressorNode, options, "attack");
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeDynamicsCompressorNode, options, "knee");
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeDynamicsCompressorNode, options, "ratio");
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeDynamicsCompressorNode, options, "release");
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeDynamicsCompressorNode, options, "threshold");
        return nativeDynamicsCompressorNode;
    };
};




const $71f48eec1b56edf3$export$7cf909169b9c4d6f = (nativeContext, options)=>{
    const nativeGainNode = nativeContext.createGain();
    (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeGainNode, options);
    (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeGainNode, options, "gain");
    return nativeGainNode;
};



const $28ba387b3ce04508$export$3c1aed24ed6efd9d = (createNativeIIRFilterNodeFaker)=>{
    return (nativeContext, baseLatency, options)=>{
        // Bug #9: Safari does not support IIRFilterNodes.
        if (nativeContext.createIIRFilter === undefined) return createNativeIIRFilterNodeFaker(nativeContext, baseLatency, options);
        // @todo TypeScript defines the parameters of createIIRFilter() as arrays of numbers.
        const nativeIIRFilterNode = nativeContext.createIIRFilter(options.feedforward, options.feedback);
        (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeIIRFilterNode, options);
        return nativeIIRFilterNode;
    };
};





function $116fcdd65e044d11$var$divide(a, b) {
    const denominator = b[0] * b[0] + b[1] * b[1];
    return [
        (a[0] * b[0] + a[1] * b[1]) / denominator,
        (a[1] * b[0] - a[0] * b[1]) / denominator
    ];
}
function $116fcdd65e044d11$var$multiply(a, b) {
    return [
        a[0] * b[0] - a[1] * b[1],
        a[0] * b[1] + a[1] * b[0]
    ];
}
function $116fcdd65e044d11$var$evaluatePolynomial(coefficient, z) {
    let result = [
        0,
        0
    ];
    for(let i = coefficient.length - 1; i >= 0; i -= 1){
        result = $116fcdd65e044d11$var$multiply(result, z);
        result[0] += coefficient[i];
    }
    return result;
}
const $116fcdd65e044d11$export$49dca6a724f463b = (createInvalidAccessError, createInvalidStateError, createNativeScriptProcessorNode, createNotSupportedError)=>{
    return (nativeContext, baseLatency, { channelCount: channelCount , channelCountMode: channelCountMode , channelInterpretation: channelInterpretation , feedback: feedback , feedforward: feedforward  })=>{
        const bufferSize = (0, $a05502b74397db33$export$c3c4ba87244c2bf4)(baseLatency, nativeContext.sampleRate);
        const convertedFeedback = feedback instanceof Float64Array ? feedback : new Float64Array(feedback);
        const convertedFeedforward = feedforward instanceof Float64Array ? feedforward : new Float64Array(feedforward);
        const feedbackLength = convertedFeedback.length;
        const feedforwardLength = convertedFeedforward.length;
        const minLength = Math.min(feedbackLength, feedforwardLength);
        if (feedbackLength === 0 || feedbackLength > 20) throw createNotSupportedError();
        if (convertedFeedback[0] === 0) throw createInvalidStateError();
        if (feedforwardLength === 0 || feedforwardLength > 20) throw createNotSupportedError();
        if (convertedFeedforward[0] === 0) throw createInvalidStateError();
        if (convertedFeedback[0] !== 1) {
            for(let i = 0; i < feedforwardLength; i += 1)convertedFeedforward[i] /= convertedFeedback[0];
            for(let i1 = 1; i1 < feedbackLength; i1 += 1)convertedFeedback[i1] /= convertedFeedback[0];
        }
        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, bufferSize, channelCount, channelCount);
        scriptProcessorNode.channelCount = channelCount;
        scriptProcessorNode.channelCountMode = channelCountMode;
        scriptProcessorNode.channelInterpretation = channelInterpretation;
        const bufferLength = 32;
        const bufferIndexes = [];
        const xBuffers = [];
        const yBuffers = [];
        for(let i2 = 0; i2 < channelCount; i2 += 1){
            bufferIndexes.push(0);
            const xBuffer = new Float32Array(bufferLength);
            const yBuffer = new Float32Array(bufferLength);
            xBuffer.fill(0);
            yBuffer.fill(0);
            xBuffers.push(xBuffer);
            yBuffers.push(yBuffer);
        }
        // tslint:disable-next-line:deprecation
        scriptProcessorNode.onaudioprocess = (event)=>{
            const inputBuffer = event.inputBuffer;
            const outputBuffer = event.outputBuffer;
            const numberOfChannels = inputBuffer.numberOfChannels;
            for(let i = 0; i < numberOfChannels; i += 1){
                const input = inputBuffer.getChannelData(i);
                const output = outputBuffer.getChannelData(i);
                bufferIndexes[i] = (0, $179d622d0c75ff26$export$7fa1177e7d2178dd)(convertedFeedback, feedbackLength, convertedFeedforward, feedforwardLength, minLength, xBuffers[i], yBuffers[i], bufferIndexes[i], bufferLength, input, output);
            }
        };
        const nyquist = nativeContext.sampleRate / 2;
        const nativeIIRFilterNodeFaker = {
            get bufferSize () {
                return bufferSize;
            },
            get channelCount () {
                return scriptProcessorNode.channelCount;
            },
            set channelCount (value){
                scriptProcessorNode.channelCount = value;
            },
            get channelCountMode () {
                return scriptProcessorNode.channelCountMode;
            },
            set channelCountMode (value){
                scriptProcessorNode.channelCountMode = value;
            },
            get channelInterpretation () {
                return scriptProcessorNode.channelInterpretation;
            },
            set channelInterpretation (value){
                scriptProcessorNode.channelInterpretation = value;
            },
            get context () {
                return scriptProcessorNode.context;
            },
            get inputs () {
                return [
                    scriptProcessorNode
                ];
            },
            get numberOfInputs () {
                return scriptProcessorNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return scriptProcessorNode.numberOfOutputs;
            },
            addEventListener (...args) {
                // @todo Dissallow adding an audioprocess listener.
                return scriptProcessorNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return scriptProcessorNode.dispatchEvent(args[0]);
            },
            getFrequencyResponse (frequencyHz, magResponse, phaseResponse) {
                if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) throw createInvalidAccessError();
                const length = frequencyHz.length;
                for(let i = 0; i < length; i += 1){
                    const omega = -Math.PI * (frequencyHz[i] / nyquist);
                    const z = [
                        Math.cos(omega),
                        Math.sin(omega)
                    ];
                    const numerator = $116fcdd65e044d11$var$evaluatePolynomial(convertedFeedforward, z);
                    const denominator = $116fcdd65e044d11$var$evaluatePolynomial(convertedFeedback, z);
                    const response = $116fcdd65e044d11$var$divide(numerator, denominator);
                    magResponse[i] = Math.sqrt(response[0] * response[0] + response[1] * response[1]);
                    phaseResponse[i] = Math.atan2(response[1], response[0]);
                }
            },
            removeEventListener (...args) {
                return scriptProcessorNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        return (0, $f50dfa358e381b90$export$19c8a106f82dff14)(nativeIIRFilterNodeFaker, scriptProcessorNode);
    };
};


const $ba0f7b60145e25d7$export$2b1682bf41b4d16b = (nativeAudioContext, options)=>{
    return nativeAudioContext.createMediaElementSource(options.mediaElement);
};



const $9410eeed5fd8d656$export$acb51039efa3405d = (nativeAudioContext, options)=>{
    const nativeMediaStreamAudioDestinationNode = nativeAudioContext.createMediaStreamDestination();
    (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeMediaStreamAudioDestinationNode, options);
    // Bug #174: Safari does expose a wrong numberOfOutputs.
    if (nativeMediaStreamAudioDestinationNode.numberOfOutputs === 1) Object.defineProperty(nativeMediaStreamAudioDestinationNode, "numberOfOutputs", {
        get: ()=>0
    });
    return nativeMediaStreamAudioDestinationNode;
};


const $7397b291c753f419$export$ad3e497ef44fc577 = (nativeAudioContext, { mediaStream: mediaStream  })=>{
    const audioStreamTracks = mediaStream.getAudioTracks();
    /*
     * Bug #151: Safari does not use the audio track as input anymore if it gets removed from the mediaStream after construction.
     * Bug #159: Safari picks the first audio track if the MediaStream has more than one audio track.
     */ audioStreamTracks.sort((a, b)=>a.id < b.id ? -1 : a.id > b.id ? 1 : 0);
    const filteredAudioStreamTracks = audioStreamTracks.slice(0, 1);
    const nativeMediaStreamAudioSourceNode = nativeAudioContext.createMediaStreamSource(new MediaStream(filteredAudioStreamTracks));
    /*
     * Bug #151 & #159: The given mediaStream gets reconstructed before it gets passed to the native node which is why the accessor needs
     * to be overwritten as it would otherwise expose the reconstructed version.
     */ Object.defineProperty(nativeMediaStreamAudioSourceNode, "mediaStream", {
        value: mediaStream
    });
    return nativeMediaStreamAudioSourceNode;
};


const $adf577b329eb4b9c$export$87e46bc6eb8ed6ac = (createInvalidStateError, isNativeOfflineAudioContext)=>{
    return (nativeAudioContext, { mediaStreamTrack: mediaStreamTrack  })=>{
        // Bug #121: Only Firefox does yet support the MediaStreamTrackAudioSourceNode.
        if (typeof nativeAudioContext.createMediaStreamTrackSource === "function") return nativeAudioContext.createMediaStreamTrackSource(mediaStreamTrack);
        const mediaStream = new MediaStream([
            mediaStreamTrack
        ]);
        const nativeMediaStreamAudioSourceNode = nativeAudioContext.createMediaStreamSource(mediaStream);
        // Bug #120: Firefox does not throw an error if the mediaStream has no audio track.
        if (mediaStreamTrack.kind !== "audio") throw createInvalidStateError();
        // Bug #172: Safari allows to create a MediaStreamAudioSourceNode with an OfflineAudioContext.
        if (isNativeOfflineAudioContext(nativeAudioContext)) throw new TypeError();
        return nativeMediaStreamAudioSourceNode;
    };
};


const $7ed72cbb8b4eb4b1$export$e628a2a5fd5b78b9 = (window)=>{
    if (window === null) return null;
    if (window.hasOwnProperty("OfflineAudioContext")) return window.OfflineAudioContext;
    return window.hasOwnProperty("webkitOfflineAudioContext") ? window.webkitOfflineAudioContext : null;
};







const $1e109504cb557d07$export$a40e02c218ae01d3 = (addSilentConnection, cacheTestResult, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls)=>{
    return (nativeContext, options)=>{
        const nativeOscillatorNode = nativeContext.createOscillator();
        (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeOscillatorNode, options);
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeOscillatorNode, options, "detune");
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeOscillatorNode, options, "frequency");
        if (options.periodicWave !== undefined) nativeOscillatorNode.setPeriodicWave(options.periodicWave);
        else (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeOscillatorNode, options, "type");
        // Bug #44: Only Chrome, Edge & Opera throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) (0, $eb08f9dbe8c62f1b$export$987b3a4087e6578c)(nativeOscillatorNode);
        // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, ()=>testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext))) wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeOscillatorNode, nativeContext);
        // Bug #44: Only Firefox does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) (0, $c598037cc1f57231$export$7adf5b1e83aad45)(nativeOscillatorNode);
        // Bug #175: Safari will not fire an ended event if the OscillatorNode is unconnected.
        addSilentConnection(nativeContext, nativeOscillatorNode);
        return nativeOscillatorNode;
    };
};





const $67e03e834ff263c9$export$8e3c89af72a58833 = (createNativePannerNodeFaker)=>{
    return (nativeContext, options)=>{
        const nativePannerNode = nativeContext.createPanner();
        // Bug #124: Safari does not support modifying the orientation and the position with AudioParams.
        if (nativePannerNode.orientationX === undefined) return createNativePannerNodeFaker(nativeContext, options);
        (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativePannerNode, options);
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativePannerNode, options, "orientationX");
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativePannerNode, options, "orientationY");
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativePannerNode, options, "orientationZ");
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativePannerNode, options, "positionX");
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativePannerNode, options, "positionY");
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativePannerNode, options, "positionZ");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativePannerNode, options, "coneInnerAngle");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativePannerNode, options, "coneOuterAngle");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativePannerNode, options, "coneOuterGain");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativePannerNode, options, "distanceModel");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativePannerNode, options, "maxDistance");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativePannerNode, options, "panningModel");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativePannerNode, options, "refDistance");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativePannerNode, options, "rolloffFactor");
        return nativePannerNode;
    };
};




const $38050e19c37591ce$export$f04468477689c1b4 = (connectNativeAudioNodeToNativeAudioNode, createInvalidStateError, createNativeChannelMergerNode, createNativeGainNode, createNativeScriptProcessorNode, createNativeWaveShaperNode, createNotSupportedError, disconnectNativeAudioNodeFromNativeAudioNode, getFirstSample, monitorConnections)=>{
    return (nativeContext, { coneInnerAngle: coneInnerAngle , coneOuterAngle: coneOuterAngle , coneOuterGain: coneOuterGain , distanceModel: distanceModel , maxDistance: maxDistance , orientationX: orientationX , orientationY: orientationY , orientationZ: orientationZ , panningModel: panningModel , positionX: positionX , positionY: positionY , positionZ: positionZ , refDistance: refDistance , rolloffFactor: rolloffFactor , ...audioNodeOptions })=>{
        const pannerNode = nativeContext.createPanner();
        // Bug #125: Safari does not throw an error yet.
        if (audioNodeOptions.channelCount > 2) throw createNotSupportedError();
        // Bug #126: Safari does not throw an error yet.
        if (audioNodeOptions.channelCountMode === "max") throw createNotSupportedError();
        (0, $a4603b9c665125c7$export$a741a487b656b6ff)(pannerNode, audioNodeOptions);
        const SINGLE_CHANNEL_OPTIONS = {
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "discrete"
        };
        const channelMergerNode = createNativeChannelMergerNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            channelInterpretation: "speakers",
            numberOfInputs: 6
        });
        const inputGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: 1
        });
        const orientationXGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 1
        });
        const orientationYGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const orientationZGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const positionXGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const positionYGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const positionZGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, 256, 6, 1);
        const waveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            curve: new Float32Array([
                1,
                1
            ]),
            oversample: "none"
        });
        let lastOrientation = [
            orientationX,
            orientationY,
            orientationZ
        ];
        let lastPosition = [
            positionX,
            positionY,
            positionZ
        ];
        const buffer = new Float32Array(1);
        // tslint:disable-next-line:deprecation
        scriptProcessorNode.onaudioprocess = ({ inputBuffer: inputBuffer  })=>{
            const orientation = [
                getFirstSample(inputBuffer, buffer, 0),
                getFirstSample(inputBuffer, buffer, 1),
                getFirstSample(inputBuffer, buffer, 2)
            ];
            if (orientation.some((value, index)=>value !== lastOrientation[index])) {
                pannerNode.setOrientation(...orientation); // tslint:disable-line:deprecation
                lastOrientation = orientation;
            }
            const positon = [
                getFirstSample(inputBuffer, buffer, 3),
                getFirstSample(inputBuffer, buffer, 4),
                getFirstSample(inputBuffer, buffer, 5)
            ];
            if (positon.some((value, index)=>value !== lastPosition[index])) {
                pannerNode.setPosition(...positon); // tslint:disable-line:deprecation
                lastPosition = positon;
            }
        };
        Object.defineProperty(orientationYGainNode.gain, "defaultValue", {
            get: ()=>0
        });
        Object.defineProperty(orientationZGainNode.gain, "defaultValue", {
            get: ()=>0
        });
        Object.defineProperty(positionXGainNode.gain, "defaultValue", {
            get: ()=>0
        });
        Object.defineProperty(positionYGainNode.gain, "defaultValue", {
            get: ()=>0
        });
        Object.defineProperty(positionZGainNode.gain, "defaultValue", {
            get: ()=>0
        });
        const nativePannerNodeFaker = {
            get bufferSize () {
                return undefined;
            },
            get channelCount () {
                return pannerNode.channelCount;
            },
            set channelCount (value){
                // Bug #125: Safari does not throw an error yet.
                if (value > 2) throw createNotSupportedError();
                inputGainNode.channelCount = value;
                pannerNode.channelCount = value;
            },
            get channelCountMode () {
                return pannerNode.channelCountMode;
            },
            set channelCountMode (value){
                // Bug #126: Safari does not throw an error yet.
                if (value === "max") throw createNotSupportedError();
                inputGainNode.channelCountMode = value;
                pannerNode.channelCountMode = value;
            },
            get channelInterpretation () {
                return pannerNode.channelInterpretation;
            },
            set channelInterpretation (value){
                inputGainNode.channelInterpretation = value;
                pannerNode.channelInterpretation = value;
            },
            get coneInnerAngle () {
                return pannerNode.coneInnerAngle;
            },
            set coneInnerAngle (value){
                pannerNode.coneInnerAngle = value;
            },
            get coneOuterAngle () {
                return pannerNode.coneOuterAngle;
            },
            set coneOuterAngle (value){
                pannerNode.coneOuterAngle = value;
            },
            get coneOuterGain () {
                return pannerNode.coneOuterGain;
            },
            set coneOuterGain (value){
                // Bug #127: Safari does not throw an InvalidStateError yet.
                if (value < 0 || value > 1) throw createInvalidStateError();
                pannerNode.coneOuterGain = value;
            },
            get context () {
                return pannerNode.context;
            },
            get distanceModel () {
                return pannerNode.distanceModel;
            },
            set distanceModel (value){
                pannerNode.distanceModel = value;
            },
            get inputs () {
                return [
                    inputGainNode
                ];
            },
            get maxDistance () {
                return pannerNode.maxDistance;
            },
            set maxDistance (value){
                // Bug #128: Safari does not throw an error yet.
                if (value < 0) throw new RangeError();
                pannerNode.maxDistance = value;
            },
            get numberOfInputs () {
                return pannerNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return pannerNode.numberOfOutputs;
            },
            get orientationX () {
                return orientationXGainNode.gain;
            },
            get orientationY () {
                return orientationYGainNode.gain;
            },
            get orientationZ () {
                return orientationZGainNode.gain;
            },
            get panningModel () {
                return pannerNode.panningModel;
            },
            set panningModel (value){
                pannerNode.panningModel = value;
            },
            get positionX () {
                return positionXGainNode.gain;
            },
            get positionY () {
                return positionYGainNode.gain;
            },
            get positionZ () {
                return positionZGainNode.gain;
            },
            get refDistance () {
                return pannerNode.refDistance;
            },
            set refDistance (value){
                // Bug #129: Safari does not throw an error yet.
                if (value < 0) throw new RangeError();
                pannerNode.refDistance = value;
            },
            get rolloffFactor () {
                return pannerNode.rolloffFactor;
            },
            set rolloffFactor (value){
                // Bug #130: Safari does not throw an error yet.
                if (value < 0) throw new RangeError();
                pannerNode.rolloffFactor = value;
            },
            addEventListener (...args) {
                return inputGainNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return inputGainNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return inputGainNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        if (coneInnerAngle !== nativePannerNodeFaker.coneInnerAngle) nativePannerNodeFaker.coneInnerAngle = coneInnerAngle;
        if (coneOuterAngle !== nativePannerNodeFaker.coneOuterAngle) nativePannerNodeFaker.coneOuterAngle = coneOuterAngle;
        if (coneOuterGain !== nativePannerNodeFaker.coneOuterGain) nativePannerNodeFaker.coneOuterGain = coneOuterGain;
        if (distanceModel !== nativePannerNodeFaker.distanceModel) nativePannerNodeFaker.distanceModel = distanceModel;
        if (maxDistance !== nativePannerNodeFaker.maxDistance) nativePannerNodeFaker.maxDistance = maxDistance;
        if (orientationX !== nativePannerNodeFaker.orientationX.value) nativePannerNodeFaker.orientationX.value = orientationX;
        if (orientationY !== nativePannerNodeFaker.orientationY.value) nativePannerNodeFaker.orientationY.value = orientationY;
        if (orientationZ !== nativePannerNodeFaker.orientationZ.value) nativePannerNodeFaker.orientationZ.value = orientationZ;
        if (panningModel !== nativePannerNodeFaker.panningModel) nativePannerNodeFaker.panningModel = panningModel;
        if (positionX !== nativePannerNodeFaker.positionX.value) nativePannerNodeFaker.positionX.value = positionX;
        if (positionY !== nativePannerNodeFaker.positionY.value) nativePannerNodeFaker.positionY.value = positionY;
        if (positionZ !== nativePannerNodeFaker.positionZ.value) nativePannerNodeFaker.positionZ.value = positionZ;
        if (refDistance !== nativePannerNodeFaker.refDistance) nativePannerNodeFaker.refDistance = refDistance;
        if (rolloffFactor !== nativePannerNodeFaker.rolloffFactor) nativePannerNodeFaker.rolloffFactor = rolloffFactor;
        if (lastOrientation[0] !== 1 || lastOrientation[1] !== 0 || lastOrientation[2] !== 0) pannerNode.setOrientation(...lastOrientation); // tslint:disable-line:deprecation
        if (lastPosition[0] !== 0 || lastPosition[1] !== 0 || lastPosition[2] !== 0) pannerNode.setPosition(...lastPosition); // tslint:disable-line:deprecation
        const whenConnected = ()=>{
            inputGainNode.connect(pannerNode);
            // Bug #119: Safari does not fully support the WaveShaperNode.
            connectNativeAudioNodeToNativeAudioNode(inputGainNode, waveShaperNode, 0, 0);
            waveShaperNode.connect(orientationXGainNode).connect(channelMergerNode, 0, 0);
            waveShaperNode.connect(orientationYGainNode).connect(channelMergerNode, 0, 1);
            waveShaperNode.connect(orientationZGainNode).connect(channelMergerNode, 0, 2);
            waveShaperNode.connect(positionXGainNode).connect(channelMergerNode, 0, 3);
            waveShaperNode.connect(positionYGainNode).connect(channelMergerNode, 0, 4);
            waveShaperNode.connect(positionZGainNode).connect(channelMergerNode, 0, 5);
            channelMergerNode.connect(scriptProcessorNode).connect(nativeContext.destination);
        };
        const whenDisconnected = ()=>{
            inputGainNode.disconnect(pannerNode);
            // Bug #119: Safari does not fully support the WaveShaperNode.
            disconnectNativeAudioNodeFromNativeAudioNode(inputGainNode, waveShaperNode, 0, 0);
            waveShaperNode.disconnect(orientationXGainNode);
            orientationXGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(orientationYGainNode);
            orientationYGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(orientationZGainNode);
            orientationZGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(positionXGainNode);
            positionXGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(positionYGainNode);
            positionYGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(positionZGainNode);
            positionZGainNode.disconnect(channelMergerNode);
            channelMergerNode.disconnect(scriptProcessorNode);
            scriptProcessorNode.disconnect(nativeContext.destination);
        };
        return monitorConnections((0, $f50dfa358e381b90$export$19c8a106f82dff14)(nativePannerNodeFaker, pannerNode), whenConnected, whenDisconnected);
    };
};


const $5dddcd8afd51ba39$export$3f519524c23feca0 = (createIndexSizeError)=>{
    return (nativeContext, { disableNormalization: disableNormalization , imag: imag , real: real  })=>{
        // Bug #180: Safari does not allow to use ordinary arrays.
        const convertedImag = imag instanceof Float32Array ? imag : new Float32Array(imag);
        const convertedReal = real instanceof Float32Array ? real : new Float32Array(real);
        const nativePeriodicWave = nativeContext.createPeriodicWave(convertedReal, convertedImag, {
            disableNormalization: disableNormalization
        });
        // Bug #181: Safari does not throw an IndexSizeError so far if the given arrays have less than two values.
        if (Array.from(imag).length < 2) throw createIndexSizeError();
        return nativePeriodicWave;
    };
};


const $de474b62d5dbb70a$export$9f784f497a6d6acb = (nativeContext, bufferSize, numberOfInputChannels, numberOfOutputChannels)=>{
    return nativeContext.createScriptProcessor(bufferSize, numberOfInputChannels, numberOfOutputChannels); // tslint:disable-line deprecation
};




const $c9529036294e4e7d$export$247580dcf7d2f2c4 = (createNativeStereoPannerNodeFaker, createNotSupportedError)=>{
    return (nativeContext, options)=>{
        const channelCountMode = options.channelCountMode;
        /*
         * Bug #105: The channelCountMode of 'clamped-max' should be supported. However it is not possible to write a polyfill for Safari
         * which supports it and therefore it can't be supported at all.
         */ if (channelCountMode === "clamped-max") throw createNotSupportedError();
        // Bug #105: Safari does not support the StereoPannerNode.
        if (nativeContext.createStereoPanner === undefined) return createNativeStereoPannerNodeFaker(nativeContext, options);
        const nativeStereoPannerNode = nativeContext.createStereoPanner();
        (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeStereoPannerNode, options);
        (0, $f582d88ae3bf1b2e$export$4778de978774ec4f)(nativeStereoPannerNode, options, "pan");
        /*
         * Bug #105: The channelCountMode of 'clamped-max' should be supported. However it is not possible to write a polyfill for Safari
         * which supports it and therefore it can't be supported at all.
         */ Object.defineProperty(nativeStereoPannerNode, "channelCountMode", {
            get: ()=>channelCountMode,
            set: (value)=>{
                if (value !== channelCountMode) throw createNotSupportedError();
            }
        });
        return nativeStereoPannerNode;
    };
};



const $8b47882dc0c94faf$export$5fe2a787c06b2d34 = (createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeGainNode, createNativeWaveShaperNode, createNotSupportedError, monitorConnections)=>{
    // The curve has a size of 14bit plus 1 value to have an exact representation for zero. This value has been determined experimentally.
    const CURVE_SIZE = 16385;
    const DC_CURVE = new Float32Array([
        1,
        1
    ]);
    const HALF_PI = Math.PI / 2;
    const SINGLE_CHANNEL_OPTIONS = {
        channelCount: 1,
        channelCountMode: "explicit",
        channelInterpretation: "discrete"
    };
    const SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS = {
        ...SINGLE_CHANNEL_OPTIONS,
        oversample: "none"
    };
    const buildInternalGraphForMono = (nativeContext, inputGainNode, panGainNode, channelMergerNode)=>{
        const leftWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const rightWaveShaperCurve = new Float32Array(CURVE_SIZE);
        for(let i = 0; i < CURVE_SIZE; i += 1){
            const x = i / (CURVE_SIZE - 1) * HALF_PI;
            leftWaveShaperCurve[i] = Math.cos(x);
            rightWaveShaperCurve[i] = Math.sin(x);
        }
        const leftGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const leftWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: leftWaveShaperCurve
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const panWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: DC_CURVE
        });
        const rightGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const rightWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: rightWaveShaperCurve
        });
        return {
            connectGraph () {
                inputGainNode.connect(leftGainNode);
                inputGainNode.connect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);
                inputGainNode.connect(rightGainNode);
                panWaveShaperNode.connect(panGainNode);
                panGainNode.connect(leftWaveShaperNode.inputs === undefined ? leftWaveShaperNode : leftWaveShaperNode.inputs[0]);
                panGainNode.connect(rightWaveShaperNode.inputs === undefined ? rightWaveShaperNode : rightWaveShaperNode.inputs[0]);
                leftWaveShaperNode.connect(leftGainNode.gain);
                rightWaveShaperNode.connect(rightGainNode.gain);
                leftGainNode.connect(channelMergerNode, 0, 0);
                rightGainNode.connect(channelMergerNode, 0, 1);
            },
            disconnectGraph () {
                inputGainNode.disconnect(leftGainNode);
                inputGainNode.disconnect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);
                inputGainNode.disconnect(rightGainNode);
                panWaveShaperNode.disconnect(panGainNode);
                panGainNode.disconnect(leftWaveShaperNode.inputs === undefined ? leftWaveShaperNode : leftWaveShaperNode.inputs[0]);
                panGainNode.disconnect(rightWaveShaperNode.inputs === undefined ? rightWaveShaperNode : rightWaveShaperNode.inputs[0]);
                leftWaveShaperNode.disconnect(leftGainNode.gain);
                rightWaveShaperNode.disconnect(rightGainNode.gain);
                leftGainNode.disconnect(channelMergerNode, 0, 0);
                rightGainNode.disconnect(channelMergerNode, 0, 1);
            }
        };
    };
    const buildInternalGraphForStereo = (nativeContext, inputGainNode, panGainNode, channelMergerNode)=>{
        const leftInputForLeftOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const leftInputForRightOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const rightInputForLeftOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const rightInputForRightOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const centerIndex = Math.floor(CURVE_SIZE / 2);
        for(let i = 0; i < CURVE_SIZE; i += 1)if (i > centerIndex) {
            const x = (i - centerIndex) / (CURVE_SIZE - 1 - centerIndex) * HALF_PI;
            leftInputForLeftOutputWaveShaperCurve[i] = Math.cos(x);
            leftInputForRightOutputWaveShaperCurve[i] = Math.sin(x);
            rightInputForLeftOutputWaveShaperCurve[i] = 0;
            rightInputForRightOutputWaveShaperCurve[i] = 1;
        } else {
            const x = i / (CURVE_SIZE - 1 - centerIndex) * HALF_PI;
            leftInputForLeftOutputWaveShaperCurve[i] = 1;
            leftInputForRightOutputWaveShaperCurve[i] = 0;
            rightInputForLeftOutputWaveShaperCurve[i] = Math.cos(x);
            rightInputForRightOutputWaveShaperCurve[i] = Math.sin(x);
        }
        const channelSplitterNode = createNativeChannelSplitterNode(nativeContext, {
            channelCount: 2,
            channelCountMode: "explicit",
            channelInterpretation: "discrete",
            numberOfOutputs: 2
        });
        const leftInputForLeftOutputGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const leftInputForLeftOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: leftInputForLeftOutputWaveShaperCurve
        });
        const leftInputForRightOutputGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const leftInputForRightOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: leftInputForRightOutputWaveShaperCurve
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const panWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: DC_CURVE
        });
        const rightInputForLeftOutputGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const rightInputForLeftOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: rightInputForLeftOutputWaveShaperCurve
        });
        const rightInputForRightOutputGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const rightInputForRightOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: rightInputForRightOutputWaveShaperCurve
        });
        return {
            connectGraph () {
                inputGainNode.connect(channelSplitterNode);
                inputGainNode.connect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);
                channelSplitterNode.connect(leftInputForLeftOutputGainNode, 0);
                channelSplitterNode.connect(leftInputForRightOutputGainNode, 0);
                channelSplitterNode.connect(rightInputForLeftOutputGainNode, 1);
                channelSplitterNode.connect(rightInputForRightOutputGainNode, 1);
                panWaveShaperNode.connect(panGainNode);
                panGainNode.connect(leftInputForLeftOutputWaveShaperNode.inputs === undefined ? leftInputForLeftOutputWaveShaperNode : leftInputForLeftOutputWaveShaperNode.inputs[0]);
                panGainNode.connect(leftInputForRightOutputWaveShaperNode.inputs === undefined ? leftInputForRightOutputWaveShaperNode : leftInputForRightOutputWaveShaperNode.inputs[0]);
                panGainNode.connect(rightInputForLeftOutputWaveShaperNode.inputs === undefined ? rightInputForLeftOutputWaveShaperNode : rightInputForLeftOutputWaveShaperNode.inputs[0]);
                panGainNode.connect(rightInputForRightOutputWaveShaperNode.inputs === undefined ? rightInputForRightOutputWaveShaperNode : rightInputForRightOutputWaveShaperNode.inputs[0]);
                leftInputForLeftOutputWaveShaperNode.connect(leftInputForLeftOutputGainNode.gain);
                leftInputForRightOutputWaveShaperNode.connect(leftInputForRightOutputGainNode.gain);
                rightInputForLeftOutputWaveShaperNode.connect(rightInputForLeftOutputGainNode.gain);
                rightInputForRightOutputWaveShaperNode.connect(rightInputForRightOutputGainNode.gain);
                leftInputForLeftOutputGainNode.connect(channelMergerNode, 0, 0);
                rightInputForLeftOutputGainNode.connect(channelMergerNode, 0, 0);
                leftInputForRightOutputGainNode.connect(channelMergerNode, 0, 1);
                rightInputForRightOutputGainNode.connect(channelMergerNode, 0, 1);
            },
            disconnectGraph () {
                inputGainNode.disconnect(channelSplitterNode);
                inputGainNode.disconnect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);
                channelSplitterNode.disconnect(leftInputForLeftOutputGainNode, 0);
                channelSplitterNode.disconnect(leftInputForRightOutputGainNode, 0);
                channelSplitterNode.disconnect(rightInputForLeftOutputGainNode, 1);
                channelSplitterNode.disconnect(rightInputForRightOutputGainNode, 1);
                panWaveShaperNode.disconnect(panGainNode);
                panGainNode.disconnect(leftInputForLeftOutputWaveShaperNode.inputs === undefined ? leftInputForLeftOutputWaveShaperNode : leftInputForLeftOutputWaveShaperNode.inputs[0]);
                panGainNode.disconnect(leftInputForRightOutputWaveShaperNode.inputs === undefined ? leftInputForRightOutputWaveShaperNode : leftInputForRightOutputWaveShaperNode.inputs[0]);
                panGainNode.disconnect(rightInputForLeftOutputWaveShaperNode.inputs === undefined ? rightInputForLeftOutputWaveShaperNode : rightInputForLeftOutputWaveShaperNode.inputs[0]);
                panGainNode.disconnect(rightInputForRightOutputWaveShaperNode.inputs === undefined ? rightInputForRightOutputWaveShaperNode : rightInputForRightOutputWaveShaperNode.inputs[0]);
                leftInputForLeftOutputWaveShaperNode.disconnect(leftInputForLeftOutputGainNode.gain);
                leftInputForRightOutputWaveShaperNode.disconnect(leftInputForRightOutputGainNode.gain);
                rightInputForLeftOutputWaveShaperNode.disconnect(rightInputForLeftOutputGainNode.gain);
                rightInputForRightOutputWaveShaperNode.disconnect(rightInputForRightOutputGainNode.gain);
                leftInputForLeftOutputGainNode.disconnect(channelMergerNode, 0, 0);
                rightInputForLeftOutputGainNode.disconnect(channelMergerNode, 0, 0);
                leftInputForRightOutputGainNode.disconnect(channelMergerNode, 0, 1);
                rightInputForRightOutputGainNode.disconnect(channelMergerNode, 0, 1);
            }
        };
    };
    const buildInternalGraph = (nativeContext, channelCount, inputGainNode, panGainNode, channelMergerNode)=>{
        if (channelCount === 1) return buildInternalGraphForMono(nativeContext, inputGainNode, panGainNode, channelMergerNode);
        if (channelCount === 2) return buildInternalGraphForStereo(nativeContext, inputGainNode, panGainNode, channelMergerNode);
        throw createNotSupportedError();
    };
    return (nativeContext, { channelCount: channelCount , channelCountMode: channelCountMode , pan: pan , ...audioNodeOptions })=>{
        if (channelCountMode === "max") throw createNotSupportedError();
        const channelMergerNode = createNativeChannelMergerNode(nativeContext, {
            ...audioNodeOptions,
            channelCount: 1,
            channelCountMode: channelCountMode,
            numberOfInputs: 2
        });
        const inputGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            channelCount: channelCount,
            channelCountMode: channelCountMode,
            gain: 1
        });
        const panGainNode = createNativeGainNode(nativeContext, {
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "discrete",
            gain: pan
        });
        let { connectGraph: connectGraph , disconnectGraph: disconnectGraph  } = buildInternalGraph(nativeContext, channelCount, inputGainNode, panGainNode, channelMergerNode);
        Object.defineProperty(panGainNode.gain, "defaultValue", {
            get: ()=>0
        });
        Object.defineProperty(panGainNode.gain, "maxValue", {
            get: ()=>1
        });
        Object.defineProperty(panGainNode.gain, "minValue", {
            get: ()=>-1
        });
        const nativeStereoPannerNodeFakerFactory = {
            get bufferSize () {
                return undefined;
            },
            get channelCount () {
                return inputGainNode.channelCount;
            },
            set channelCount (value){
                if (inputGainNode.channelCount !== value) {
                    if (isConnected) disconnectGraph();
                    ({ connectGraph: connectGraph , disconnectGraph: disconnectGraph  } = buildInternalGraph(nativeContext, value, inputGainNode, panGainNode, channelMergerNode));
                    if (isConnected) connectGraph();
                }
                inputGainNode.channelCount = value;
            },
            get channelCountMode () {
                return inputGainNode.channelCountMode;
            },
            set channelCountMode (value){
                if (value === "clamped-max" || value === "max") throw createNotSupportedError();
                inputGainNode.channelCountMode = value;
            },
            get channelInterpretation () {
                return inputGainNode.channelInterpretation;
            },
            set channelInterpretation (value){
                inputGainNode.channelInterpretation = value;
            },
            get context () {
                return inputGainNode.context;
            },
            get inputs () {
                return [
                    inputGainNode
                ];
            },
            get numberOfInputs () {
                return inputGainNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return inputGainNode.numberOfOutputs;
            },
            get pan () {
                return panGainNode.gain;
            },
            addEventListener (...args) {
                return inputGainNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return inputGainNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return inputGainNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        let isConnected = false;
        const whenConnected = ()=>{
            connectGraph();
            isConnected = true;
        };
        const whenDisconnected = ()=>{
            disconnectGraph();
            isConnected = false;
        };
        return monitorConnections((0, $f50dfa358e381b90$export$19c8a106f82dff14)(nativeStereoPannerNodeFakerFactory, channelMergerNode), whenConnected, whenDisconnected);
    };
};




const $f3b47b1ee9b886b8$export$75168c4c8ce320c4 = (createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeWaveShaperNodeFaker, isDCCurve, monitorConnections, nativeAudioContextConstructor, overwriteAccessors)=>{
    return (nativeContext, options)=>{
        const nativeWaveShaperNode = nativeContext.createWaveShaper();
        /*
         * Bug #119: Safari does not correctly map the values.
         * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the existence of
         * the webkitAudioContext is used as a workaround here. Testing for the automationRate property is necessary because this workaround
         * isn't necessary anymore since v14.0.2 of Safari.
         */ if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === "webkitAudioContext" && nativeContext.createGain().gain.automationRate === undefined) return createNativeWaveShaperNodeFaker(nativeContext, options);
        (0, $a4603b9c665125c7$export$a741a487b656b6ff)(nativeWaveShaperNode, options);
        const curve = options.curve === null || options.curve instanceof Float32Array ? options.curve : new Float32Array(options.curve);
        // Bug #104: Chrome, Edge and Opera will throw an InvalidAccessError when the curve has less than two samples.
        if (curve !== null && curve.length < 2) throw createInvalidStateError();
        // Only values of type Float32Array can be assigned to the curve property.
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeWaveShaperNode, {
            curve: curve
        }, "curve");
        (0, $b5d07fd47cad4d6a$export$26855c8d5a8f5839)(nativeWaveShaperNode, options, "oversample");
        let disconnectNativeAudioBufferSourceNode = null;
        let isConnected = false;
        overwriteAccessors(nativeWaveShaperNode, "curve", (get)=>()=>get.call(nativeWaveShaperNode), (set)=>(value)=>{
                set.call(nativeWaveShaperNode, value);
                if (isConnected) {
                    if (isDCCurve(value) && disconnectNativeAudioBufferSourceNode === null) disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, nativeWaveShaperNode);
                    else if (!isDCCurve(value) && disconnectNativeAudioBufferSourceNode !== null) {
                        disconnectNativeAudioBufferSourceNode();
                        disconnectNativeAudioBufferSourceNode = null;
                    }
                }
                return value;
            });
        const whenConnected = ()=>{
            isConnected = true;
            if (isDCCurve(nativeWaveShaperNode.curve)) disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, nativeWaveShaperNode);
        };
        const whenDisconnected = ()=>{
            isConnected = false;
            if (disconnectNativeAudioBufferSourceNode !== null) {
                disconnectNativeAudioBufferSourceNode();
                disconnectNativeAudioBufferSourceNode = null;
            }
        };
        return monitorConnections(nativeWaveShaperNode, whenConnected, whenDisconnected);
    };
};




const $0f28b6d4737c93a6$export$f5f0b26abc22907e = (createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeGainNode, isDCCurve, monitorConnections)=>{
    return (nativeContext, { curve: curve , oversample: oversample , ...audioNodeOptions })=>{
        const negativeWaveShaperNode = nativeContext.createWaveShaper();
        const positiveWaveShaperNode = nativeContext.createWaveShaper();
        (0, $a4603b9c665125c7$export$a741a487b656b6ff)(negativeWaveShaperNode, audioNodeOptions);
        (0, $a4603b9c665125c7$export$a741a487b656b6ff)(positiveWaveShaperNode, audioNodeOptions);
        const inputGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: 1
        });
        const invertGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: -1
        });
        const outputGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: 1
        });
        const revertGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: -1
        });
        let disconnectNativeAudioBufferSourceNode = null;
        let isConnected = false;
        let unmodifiedCurve = null;
        const nativeWaveShaperNodeFaker = {
            get bufferSize () {
                return undefined;
            },
            get channelCount () {
                return negativeWaveShaperNode.channelCount;
            },
            set channelCount (value){
                inputGainNode.channelCount = value;
                invertGainNode.channelCount = value;
                negativeWaveShaperNode.channelCount = value;
                outputGainNode.channelCount = value;
                positiveWaveShaperNode.channelCount = value;
                revertGainNode.channelCount = value;
            },
            get channelCountMode () {
                return negativeWaveShaperNode.channelCountMode;
            },
            set channelCountMode (value){
                inputGainNode.channelCountMode = value;
                invertGainNode.channelCountMode = value;
                negativeWaveShaperNode.channelCountMode = value;
                outputGainNode.channelCountMode = value;
                positiveWaveShaperNode.channelCountMode = value;
                revertGainNode.channelCountMode = value;
            },
            get channelInterpretation () {
                return negativeWaveShaperNode.channelInterpretation;
            },
            set channelInterpretation (value){
                inputGainNode.channelInterpretation = value;
                invertGainNode.channelInterpretation = value;
                negativeWaveShaperNode.channelInterpretation = value;
                outputGainNode.channelInterpretation = value;
                positiveWaveShaperNode.channelInterpretation = value;
                revertGainNode.channelInterpretation = value;
            },
            get context () {
                return negativeWaveShaperNode.context;
            },
            get curve () {
                return unmodifiedCurve;
            },
            set curve (value){
                // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.
                if (value !== null && value.length < 2) throw createInvalidStateError();
                if (value === null) {
                    negativeWaveShaperNode.curve = value;
                    positiveWaveShaperNode.curve = value;
                } else {
                    const curveLength = value.length;
                    const negativeCurve = new Float32Array(curveLength + 2 - curveLength % 2);
                    const positiveCurve = new Float32Array(curveLength + 2 - curveLength % 2);
                    negativeCurve[0] = value[0];
                    positiveCurve[0] = -value[curveLength - 1];
                    const length = Math.ceil((curveLength + 1) / 2);
                    const centerIndex = (curveLength + 1) / 2 - 1;
                    for(let i = 1; i < length; i += 1){
                        const theoreticIndex = i / length * centerIndex;
                        const lowerIndex = Math.floor(theoreticIndex);
                        const upperIndex = Math.ceil(theoreticIndex);
                        negativeCurve[i] = lowerIndex === upperIndex ? value[lowerIndex] : (1 - (theoreticIndex - lowerIndex)) * value[lowerIndex] + (1 - (upperIndex - theoreticIndex)) * value[upperIndex];
                        positiveCurve[i] = lowerIndex === upperIndex ? -value[curveLength - 1 - lowerIndex] : -((1 - (theoreticIndex - lowerIndex)) * value[curveLength - 1 - lowerIndex]) - (1 - (upperIndex - theoreticIndex)) * value[curveLength - 1 - upperIndex];
                    }
                    negativeCurve[length] = curveLength % 2 === 1 ? value[length - 1] : (value[length - 2] + value[length - 1]) / 2;
                    negativeWaveShaperNode.curve = negativeCurve;
                    positiveWaveShaperNode.curve = positiveCurve;
                }
                unmodifiedCurve = value;
                if (isConnected) {
                    if (isDCCurve(unmodifiedCurve) && disconnectNativeAudioBufferSourceNode === null) disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, inputGainNode);
                    else if (disconnectNativeAudioBufferSourceNode !== null) {
                        disconnectNativeAudioBufferSourceNode();
                        disconnectNativeAudioBufferSourceNode = null;
                    }
                }
            },
            get inputs () {
                return [
                    inputGainNode
                ];
            },
            get numberOfInputs () {
                return negativeWaveShaperNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return negativeWaveShaperNode.numberOfOutputs;
            },
            get oversample () {
                return negativeWaveShaperNode.oversample;
            },
            set oversample (value){
                negativeWaveShaperNode.oversample = value;
                positiveWaveShaperNode.oversample = value;
            },
            addEventListener (...args) {
                return inputGainNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return inputGainNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return inputGainNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        if (curve !== null) // Only values of type Float32Array can be assigned to the curve property.
        nativeWaveShaperNodeFaker.curve = curve instanceof Float32Array ? curve : new Float32Array(curve);
        if (oversample !== nativeWaveShaperNodeFaker.oversample) nativeWaveShaperNodeFaker.oversample = oversample;
        const whenConnected = ()=>{
            inputGainNode.connect(negativeWaveShaperNode).connect(outputGainNode);
            inputGainNode.connect(invertGainNode).connect(positiveWaveShaperNode).connect(revertGainNode).connect(outputGainNode);
            isConnected = true;
            if (isDCCurve(unmodifiedCurve)) disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, inputGainNode);
        };
        const whenDisconnected = ()=>{
            inputGainNode.disconnect(negativeWaveShaperNode);
            negativeWaveShaperNode.disconnect(outputGainNode);
            inputGainNode.disconnect(invertGainNode);
            invertGainNode.disconnect(positiveWaveShaperNode);
            positiveWaveShaperNode.disconnect(revertGainNode);
            revertGainNode.disconnect(outputGainNode);
            isConnected = false;
            if (disconnectNativeAudioBufferSourceNode !== null) {
                disconnectNativeAudioBufferSourceNode();
                disconnectNativeAudioBufferSourceNode = null;
            }
        };
        return monitorConnections((0, $f50dfa358e381b90$export$19c8a106f82dff14)(nativeWaveShaperNodeFaker, outputGainNode), whenConnected, whenDisconnected);
    };
};


const $724da61d5e6b149b$export$dbebdb13622d486c = ()=>new DOMException("", "NotSupportedError");




const $71cd54f99465e1c1$var$DEFAULT_OPTIONS = {
    numberOfChannels: 1
};
const $71cd54f99465e1c1$export$a9b5caf52b398870 = (baseAudioContextConstructor, cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, startRendering)=>{
    return class OfflineAudioContext extends baseAudioContextConstructor {
        constructor(a, b, c){
            let options;
            if (typeof a === "number" && b !== undefined && c !== undefined) options = {
                length: b,
                numberOfChannels: a,
                sampleRate: c
            };
            else if (typeof a === "object") options = a;
            else throw new Error("The given parameters are not valid.");
            const { length: length , numberOfChannels: numberOfChannels , sampleRate: sampleRate  } = {
                ...$71cd54f99465e1c1$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeOfflineAudioContext = createNativeOfflineAudioContext(numberOfChannels, length, sampleRate);
            // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.
            if (!cacheTestResult((0, $02e438f09c588964$export$9ec44223b1284cd4), ()=>(0, $02e438f09c588964$export$9ec44223b1284cd4)(nativeOfflineAudioContext))) nativeOfflineAudioContext.addEventListener("statechange", (()=>{
                let i = 0;
                const delayStateChangeEvent = (event)=>{
                    if (this._state === "running") {
                        if (i > 0) {
                            nativeOfflineAudioContext.removeEventListener("statechange", delayStateChangeEvent);
                            event.stopImmediatePropagation();
                            this._waitForThePromiseToSettle(event);
                        } else i += 1;
                    }
                };
                return delayStateChangeEvent;
            })());
            super(nativeOfflineAudioContext, numberOfChannels);
            this._length = length;
            this._nativeOfflineAudioContext = nativeOfflineAudioContext;
            this._state = null;
        }
        get length() {
            // Bug #17: Safari does not yet expose the length.
            if (this._nativeOfflineAudioContext.length === undefined) return this._length;
            return this._nativeOfflineAudioContext.length;
        }
        get state() {
            return this._state === null ? this._nativeOfflineAudioContext.state : this._state;
        }
        startRendering() {
            /*
             * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore
             * the state of the nativeOfflineAudioContext might no transition to running immediately.
             */ if (this._state === "running") return Promise.reject(createInvalidStateError());
            this._state = "running";
            return startRendering(this.destination, this._nativeOfflineAudioContext).finally(()=>{
                this._state = null;
                (0, $d831926c266dcbcf$export$cbd606bc629ea938)(this);
            });
        }
        _waitForThePromiseToSettle(event) {
            if (this._state === null) this._nativeOfflineAudioContext.dispatchEvent(event);
            else setTimeout(()=>this._waitForThePromiseToSettle(event));
        }
    };
};





const $a62880cbf04a4a17$var$DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    detune: 0,
    frequency: 440,
    periodicWave: undefined,
    type: "sine"
};
const $a62880cbf04a4a17$export$c1c3584074b042b3 = (audioNodeConstructor, createAudioParam, createNativeOscillatorNode, createOscillatorNodeRenderer, getNativeContext, isNativeOfflineAudioContext, wrapEventListener)=>{
    return class OscillatorNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...$a62880cbf04a4a17$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeOscillatorNode = createNativeOscillatorNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const oscillatorNodeRenderer = isOffline ? createOscillatorNodeRenderer() : null;
            const nyquist = context.sampleRate / 2;
            super(context, false, nativeOscillatorNode, oscillatorNodeRenderer);
            // Bug #81: Firefox & Safari do not export the correct values for maxValue and minValue.
            this._detune = createAudioParam(this, isOffline, nativeOscillatorNode.detune, 153600, -153600);
            // Bug #76: Safari does not export the correct values for maxValue and minValue.
            this._frequency = createAudioParam(this, isOffline, nativeOscillatorNode.frequency, nyquist, -nyquist);
            this._nativeOscillatorNode = nativeOscillatorNode;
            this._onended = null;
            this._oscillatorNodeRenderer = oscillatorNodeRenderer;
            if (this._oscillatorNodeRenderer !== null && mergedOptions.periodicWave !== undefined) this._oscillatorNodeRenderer.periodicWave = mergedOptions.periodicWave;
        }
        get detune() {
            return this._detune;
        }
        get frequency() {
            return this._frequency;
        }
        get onended() {
            return this._onended;
        }
        set onended(value) {
            const wrappedListener = typeof value === "function" ? wrapEventListener(this, value) : null;
            this._nativeOscillatorNode.onended = wrappedListener;
            const nativeOnEnded = this._nativeOscillatorNode.onended;
            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;
        }
        get type() {
            return this._nativeOscillatorNode.type;
        }
        set type(value) {
            this._nativeOscillatorNode.type = value;
            if (this._oscillatorNodeRenderer !== null) this._oscillatorNodeRenderer.periodicWave = null;
        }
        setPeriodicWave(periodicWave) {
            this._nativeOscillatorNode.setPeriodicWave(periodicWave);
            if (this._oscillatorNodeRenderer !== null) this._oscillatorNodeRenderer.periodicWave = periodicWave;
        }
        start(when = 0) {
            this._nativeOscillatorNode.start(when);
            if (this._oscillatorNodeRenderer !== null) this._oscillatorNodeRenderer.start = when;
            if (this.context.state !== "closed") {
                (0, $e4b65d1b7a33a6ae$export$88a47afdc0e8539c)(this);
                const resetInternalStateToPassive = ()=>{
                    this._nativeOscillatorNode.removeEventListener("ended", resetInternalStateToPassive);
                    if ((0, $a52e8cf090f6ea8d$export$e44f0fc8e83fb084)(this)) (0, $30e3b887134462bb$export$7c0830f3a5100dec)(this);
                };
                this._nativeOscillatorNode.addEventListener("ended", resetInternalStateToPassive);
            }
        }
        stop(when = 0) {
            this._nativeOscillatorNode.stop(when);
            if (this._oscillatorNodeRenderer !== null) this._oscillatorNodeRenderer.stop = when;
        }
    };
};



const $6def87b551bd6da0$export$99143538b3590be5 = (connectAudioParam, createNativeOscillatorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeOscillatorNodes = new WeakMap();
        let periodicWave = null;
        let start = null;
        let stop = null;
        const createOscillatorNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeOscillatorNode = getNativeAudioNode(proxy);
            // If the initially used nativeOscillatorNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeOscillatorNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeOscillatorNode, nativeOfflineAudioContext);
            if (!nativeOscillatorNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeOscillatorNode.channelCount,
                    channelCountMode: nativeOscillatorNode.channelCountMode,
                    channelInterpretation: nativeOscillatorNode.channelInterpretation,
                    detune: nativeOscillatorNode.detune.value,
                    frequency: nativeOscillatorNode.frequency.value,
                    periodicWave: periodicWave === null ? undefined : periodicWave,
                    type: nativeOscillatorNode.type
                };
                nativeOscillatorNode = createNativeOscillatorNode(nativeOfflineAudioContext, options);
                if (start !== null) nativeOscillatorNode.start(start);
                if (stop !== null) nativeOscillatorNode.stop(stop);
            }
            renderedNativeOscillatorNodes.set(nativeOfflineAudioContext, nativeOscillatorNode);
            if (!nativeOscillatorNodeIsOwnedByContext) {
                await renderAutomation(nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune);
                await renderAutomation(nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency);
            } else {
                await connectAudioParam(nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune);
                await connectAudioParam(nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency);
            }
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeOscillatorNode);
            return nativeOscillatorNode;
        };
        return {
            set periodicWave (value){
                periodicWave = value;
            },
            set start (value){
                start = value;
            },
            set stop (value){
                stop = value;
            },
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeOscillatorNode = renderedNativeOscillatorNodes.get(nativeOfflineAudioContext);
                if (renderedNativeOscillatorNode !== undefined) return Promise.resolve(renderedNativeOscillatorNode);
                return createOscillatorNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};



const $eeaadc307a57ff75$var$DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "clamped-max",
    channelInterpretation: "speakers",
    coneInnerAngle: 360,
    coneOuterAngle: 360,
    coneOuterGain: 0,
    distanceModel: "inverse",
    maxDistance: 10000,
    orientationX: 1,
    orientationY: 0,
    orientationZ: 0,
    panningModel: "equalpower",
    positionX: 0,
    positionY: 0,
    positionZ: 0,
    refDistance: 1,
    rolloffFactor: 1
};
const $eeaadc307a57ff75$export$91b046021cf98bac = (audioNodeConstructor, createAudioParam, createNativePannerNode, createPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class PannerNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...$eeaadc307a57ff75$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativePannerNode = createNativePannerNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const pannerNodeRenderer = isOffline ? createPannerNodeRenderer() : null;
            super(context, false, nativePannerNode, pannerNodeRenderer);
            this._nativePannerNode = nativePannerNode;
            // Bug #74: Safari does not export the correct values for maxValue and minValue.
            this._orientationX = createAudioParam(this, isOffline, nativePannerNode.orientationX, (0, $b1c06cbd433e26a1$export$ab43bedd17d6a167), (0, $b1c06cbd433e26a1$export$ced6a5c63b103b52));
            this._orientationY = createAudioParam(this, isOffline, nativePannerNode.orientationY, (0, $b1c06cbd433e26a1$export$ab43bedd17d6a167), (0, $b1c06cbd433e26a1$export$ced6a5c63b103b52));
            this._orientationZ = createAudioParam(this, isOffline, nativePannerNode.orientationZ, (0, $b1c06cbd433e26a1$export$ab43bedd17d6a167), (0, $b1c06cbd433e26a1$export$ced6a5c63b103b52));
            this._positionX = createAudioParam(this, isOffline, nativePannerNode.positionX, (0, $b1c06cbd433e26a1$export$ab43bedd17d6a167), (0, $b1c06cbd433e26a1$export$ced6a5c63b103b52));
            this._positionY = createAudioParam(this, isOffline, nativePannerNode.positionY, (0, $b1c06cbd433e26a1$export$ab43bedd17d6a167), (0, $b1c06cbd433e26a1$export$ced6a5c63b103b52));
            this._positionZ = createAudioParam(this, isOffline, nativePannerNode.positionZ, (0, $b1c06cbd433e26a1$export$ab43bedd17d6a167), (0, $b1c06cbd433e26a1$export$ced6a5c63b103b52));
            // @todo Determine a meaningful tail-time instead of just using one second.
            setAudioNodeTailTime(this, 1);
        }
        get coneInnerAngle() {
            return this._nativePannerNode.coneInnerAngle;
        }
        set coneInnerAngle(value) {
            this._nativePannerNode.coneInnerAngle = value;
        }
        get coneOuterAngle() {
            return this._nativePannerNode.coneOuterAngle;
        }
        set coneOuterAngle(value) {
            this._nativePannerNode.coneOuterAngle = value;
        }
        get coneOuterGain() {
            return this._nativePannerNode.coneOuterGain;
        }
        set coneOuterGain(value) {
            this._nativePannerNode.coneOuterGain = value;
        }
        get distanceModel() {
            return this._nativePannerNode.distanceModel;
        }
        set distanceModel(value) {
            this._nativePannerNode.distanceModel = value;
        }
        get maxDistance() {
            return this._nativePannerNode.maxDistance;
        }
        set maxDistance(value) {
            this._nativePannerNode.maxDistance = value;
        }
        get orientationX() {
            return this._orientationX;
        }
        get orientationY() {
            return this._orientationY;
        }
        get orientationZ() {
            return this._orientationZ;
        }
        get panningModel() {
            return this._nativePannerNode.panningModel;
        }
        set panningModel(value) {
            this._nativePannerNode.panningModel = value;
        }
        get positionX() {
            return this._positionX;
        }
        get positionY() {
            return this._positionY;
        }
        get positionZ() {
            return this._positionZ;
        }
        get refDistance() {
            return this._nativePannerNode.refDistance;
        }
        set refDistance(value) {
            this._nativePannerNode.refDistance = value;
        }
        get rolloffFactor() {
            return this._nativePannerNode.rolloffFactor;
        }
        set rolloffFactor(value) {
            this._nativePannerNode.rolloffFactor = value;
        }
    };
};




const $e0ac4d195ddcf52f$export$ccd091498494025 = (connectAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeGainNode, createNativePannerNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext)=>{
    return ()=>{
        const renderedNativeAudioNodes = new WeakMap();
        let renderedBufferPromise = null;
        const createAudioNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeGainNode = null;
            let nativePannerNode = getNativeAudioNode(proxy);
            const commonAudioNodeOptions = {
                channelCount: nativePannerNode.channelCount,
                channelCountMode: nativePannerNode.channelCountMode,
                channelInterpretation: nativePannerNode.channelInterpretation
            };
            const commonNativePannerNodeOptions = {
                ...commonAudioNodeOptions,
                coneInnerAngle: nativePannerNode.coneInnerAngle,
                coneOuterAngle: nativePannerNode.coneOuterAngle,
                coneOuterGain: nativePannerNode.coneOuterGain,
                distanceModel: nativePannerNode.distanceModel,
                maxDistance: nativePannerNode.maxDistance,
                panningModel: nativePannerNode.panningModel,
                refDistance: nativePannerNode.refDistance,
                rolloffFactor: nativePannerNode.rolloffFactor
            };
            // If the initially used nativePannerNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativePannerNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativePannerNode, nativeOfflineAudioContext);
            // Bug #124: Safari does not support modifying the orientation and the position with AudioParams.
            if ("bufferSize" in nativePannerNode) nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                ...commonAudioNodeOptions,
                gain: 1
            });
            else if (!nativePannerNodeIsOwnedByContext) {
                const options = {
                    ...commonNativePannerNodeOptions,
                    orientationX: nativePannerNode.orientationX.value,
                    orientationY: nativePannerNode.orientationY.value,
                    orientationZ: nativePannerNode.orientationZ.value,
                    positionX: nativePannerNode.positionX.value,
                    positionY: nativePannerNode.positionY.value,
                    positionZ: nativePannerNode.positionZ.value
                };
                nativePannerNode = createNativePannerNode(nativeOfflineAudioContext, options);
            }
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeGainNode === null ? nativePannerNode : nativeGainNode);
            if (nativeGainNode !== null) {
                if (renderedBufferPromise === null) {
                    if (nativeOfflineAudioContextConstructor === null) throw new Error("Missing the native OfflineAudioContext constructor.");
                    const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(6, // Bug #17: Safari does not yet expose the length.
                    proxy.context.length, nativeOfflineAudioContext.sampleRate);
                    const nativeChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {
                        channelCount: 1,
                        channelCountMode: "explicit",
                        channelInterpretation: "speakers",
                        numberOfInputs: 6
                    });
                    nativeChannelMergerNode.connect(partialOfflineAudioContext.destination);
                    renderedBufferPromise = (async ()=>{
                        const nativeConstantSourceNodes = await Promise.all([
                            proxy.orientationX,
                            proxy.orientationY,
                            proxy.orientationZ,
                            proxy.positionX,
                            proxy.positionY,
                            proxy.positionZ
                        ].map(async (audioParam, index)=>{
                            const nativeConstantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {
                                channelCount: 1,
                                channelCountMode: "explicit",
                                channelInterpretation: "discrete",
                                offset: index === 0 ? 1 : 0
                            });
                            await renderAutomation(partialOfflineAudioContext, audioParam, nativeConstantSourceNode.offset);
                            return nativeConstantSourceNode;
                        }));
                        for(let i = 0; i < 6; i += 1){
                            nativeConstantSourceNodes[i].connect(nativeChannelMergerNode, 0, i);
                            nativeConstantSourceNodes[i].start(0);
                        }
                        return renderNativeOfflineAudioContext(partialOfflineAudioContext);
                    })();
                }
                const renderedBuffer = await renderedBufferPromise;
                const inputGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                    ...commonAudioNodeOptions,
                    gain: 1
                });
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, inputGainNode);
                const channelDatas = [];
                for(let i2 = 0; i2 < renderedBuffer.numberOfChannels; i2 += 1)channelDatas.push(renderedBuffer.getChannelData(i2));
                let lastOrientation = [
                    channelDatas[0][0],
                    channelDatas[1][0],
                    channelDatas[2][0]
                ];
                let lastPosition = [
                    channelDatas[3][0],
                    channelDatas[4][0],
                    channelDatas[5][0]
                ];
                let gateGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                    ...commonAudioNodeOptions,
                    gain: 1
                });
                let partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, {
                    ...commonNativePannerNodeOptions,
                    orientationX: lastOrientation[0],
                    orientationY: lastOrientation[1],
                    orientationZ: lastOrientation[2],
                    positionX: lastPosition[0],
                    positionY: lastPosition[1],
                    positionZ: lastPosition[2]
                });
                inputGainNode.connect(gateGainNode).connect(partialPannerNode.inputs[0]);
                partialPannerNode.connect(nativeGainNode);
                for(let i1 = 128; i1 < renderedBuffer.length; i1 += 128){
                    const orientation = [
                        channelDatas[0][i1],
                        channelDatas[1][i1],
                        channelDatas[2][i1]
                    ];
                    const positon = [
                        channelDatas[3][i1],
                        channelDatas[4][i1],
                        channelDatas[5][i1]
                    ];
                    if (orientation.some((value, index)=>value !== lastOrientation[index]) || positon.some((value, index)=>value !== lastPosition[index])) {
                        lastOrientation = orientation;
                        lastPosition = positon;
                        const currentTime = i1 / nativeOfflineAudioContext.sampleRate;
                        gateGainNode.gain.setValueAtTime(0, currentTime);
                        gateGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                            ...commonAudioNodeOptions,
                            gain: 0
                        });
                        partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, {
                            ...commonNativePannerNodeOptions,
                            orientationX: lastOrientation[0],
                            orientationY: lastOrientation[1],
                            orientationZ: lastOrientation[2],
                            positionX: lastPosition[0],
                            positionY: lastPosition[1],
                            positionZ: lastPosition[2]
                        });
                        gateGainNode.gain.setValueAtTime(1, currentTime);
                        inputGainNode.connect(gateGainNode).connect(partialPannerNode.inputs[0]);
                        partialPannerNode.connect(nativeGainNode);
                    }
                }
                return nativeGainNode;
            }
            if (!nativePannerNodeIsOwnedByContext) {
                await renderAutomation(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX);
                await renderAutomation(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY);
                await renderAutomation(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ);
                await renderAutomation(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX);
                await renderAutomation(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY);
                await renderAutomation(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ);
            } else {
                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX);
                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY);
                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ);
                await connectAudioParam(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX);
                await connectAudioParam(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY);
                await connectAudioParam(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ);
            }
            if ((0, $77ab69d57b7e7a12$export$ac2aef07f705aa48)(nativePannerNode)) await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode.inputs[0]);
            else await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode);
            return nativePannerNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeGainNodeOrNativePannerNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeGainNodeOrNativePannerNode !== undefined) return Promise.resolve(renderedNativeGainNodeOrNativePannerNode);
                return createAudioNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};


const $6a9b3836ffa94976$var$DEFAULT_OPTIONS = {
    disableNormalization: false
};
const $6a9b3836ffa94976$export$10e47cfa48a5069d = (createNativePeriodicWave, getNativeContext, periodicWaveStore, sanitizePeriodicWaveOptions)=>{
    return class PeriodicWave {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = sanitizePeriodicWaveOptions({
                ...$6a9b3836ffa94976$var$DEFAULT_OPTIONS,
                ...options
            });
            const periodicWave = createNativePeriodicWave(nativeContext, mergedOptions);
            periodicWaveStore.add(periodicWave);
            // This does violate all good pratices but it is used here to simplify the handling of periodic waves.
            return periodicWave;
        }
        static [Symbol.hasInstance](instance) {
            return instance !== null && typeof instance === "object" && Object.getPrototypeOf(instance) === PeriodicWave.prototype || periodicWaveStore.has(instance);
        }
    };
};


const $ab31fa70408c9e61$export$889eef7d338963f6 = (getAudioParamRenderer, renderInputsOfAudioParam)=>{
    return (nativeOfflineAudioContext, audioParam, nativeAudioParam)=>{
        const audioParamRenderer = getAudioParamRenderer(audioParam);
        audioParamRenderer.replay(nativeAudioParam);
        return renderInputsOfAudioParam(audioParam, nativeOfflineAudioContext, nativeAudioParam);
    };
};


const $0a69be9a881260e4$export$cff0938ddf51f6f4 = (getAudioNodeConnections, getAudioNodeRenderer, isPartOfACycle)=>{
    return async (audioNode, nativeOfflineAudioContext, nativeAudioNode)=>{
        const audioNodeConnections = getAudioNodeConnections(audioNode);
        await Promise.all(audioNodeConnections.activeInputs.map((connections, input)=>Array.from(connections).map(async ([source, output])=>{
                const audioNodeRenderer = getAudioNodeRenderer(source);
                const renderedNativeAudioNode = await audioNodeRenderer.render(source, nativeOfflineAudioContext);
                const destination = audioNode.context.destination;
                if (!isPartOfACycle(source) && (audioNode !== destination || !isPartOfACycle(audioNode))) renderedNativeAudioNode.connect(nativeAudioNode, output, input);
            })).reduce((allRenderingPromises, renderingPromises)=>[
                ...allRenderingPromises,
                ...renderingPromises
            ], []));
    };
};


const $d5a853e48f4f5160$export$82cd58acb1062198 = (getAudioNodeRenderer, getAudioParamConnections, isPartOfACycle)=>{
    return async (audioParam, nativeOfflineAudioContext, nativeAudioParam)=>{
        const audioParamConnections = getAudioParamConnections(audioParam);
        await Promise.all(Array.from(audioParamConnections.activeInputs).map(async ([source, output])=>{
            const audioNodeRenderer = getAudioNodeRenderer(source);
            const renderedNativeAudioNode = await audioNodeRenderer.render(source, nativeOfflineAudioContext);
            if (!isPartOfACycle(source)) renderedNativeAudioNode.connect(nativeAudioParam, output);
        }));
    };
};



const $2485ca71b88aec2b$export$feb8d4a8e403af48 = (cacheTestResult, createNativeGainNode, createNativeScriptProcessorNode, testOfflineAudioContextCurrentTimeSupport)=>{
    return (nativeOfflineAudioContext)=>{
        // Bug #21: Safari does not support promises yet.
        if (cacheTestResult((0, $02e438f09c588964$export$9ec44223b1284cd4), ()=>(0, $02e438f09c588964$export$9ec44223b1284cd4)(nativeOfflineAudioContext))) // Bug #158: Chrome and Edge do not advance currentTime if it is not accessed while rendering the audio.
        return Promise.resolve(cacheTestResult(testOfflineAudioContextCurrentTimeSupport, testOfflineAudioContextCurrentTimeSupport)).then((isOfflineAudioContextCurrentTimeSupported)=>{
            if (!isOfflineAudioContextCurrentTimeSupported) {
                const scriptProcessorNode = createNativeScriptProcessorNode(nativeOfflineAudioContext, 512, 0, 1);
                nativeOfflineAudioContext.oncomplete = ()=>{
                    scriptProcessorNode.onaudioprocess = null; // tslint:disable-line:deprecation
                    scriptProcessorNode.disconnect();
                };
                scriptProcessorNode.onaudioprocess = ()=>nativeOfflineAudioContext.currentTime; // tslint:disable-line:deprecation
                scriptProcessorNode.connect(nativeOfflineAudioContext.destination);
            }
            return nativeOfflineAudioContext.startRendering();
        });
        return new Promise((resolve)=>{
            // Bug #48: Safari does not render an OfflineAudioContext without any connected node.
            const gainNode = createNativeGainNode(nativeOfflineAudioContext, {
                channelCount: 1,
                channelCountMode: "explicit",
                channelInterpretation: "discrete",
                gain: 0
            });
            nativeOfflineAudioContext.oncomplete = (event)=>{
                gainNode.disconnect();
                resolve(event.renderedBuffer);
            };
            gainNode.connect(nativeOfflineAudioContext.destination);
            nativeOfflineAudioContext.startRendering();
        });
    };
};


const $9da34cc622e4cda2$export$17328c9508de4388 = (activeAudioWorkletNodeInputsStore)=>{
    return (nativeAudioWorkletNode, activeInputs)=>{
        activeAudioWorkletNodeInputsStore.set(nativeAudioWorkletNode, activeInputs);
    };
};


const $df112b7b8d94bab8$export$c5e78cc8035d00aa = (audioNodeTailTimeStore)=>{
    return (audioNode, tailTime)=>audioNodeTailTimeStore.set(audioNode, tailTime);
};



const $5e42c82d70af5757$export$a04cd80dfb1b8309 = (audioBufferStore, cacheTestResult, getAudioNodeRenderer, getUnrenderedAudioWorkletNodes, renderNativeOfflineAudioContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds)=>{
    return (destination, nativeOfflineAudioContext)=>getAudioNodeRenderer(destination).render(destination, nativeOfflineAudioContext)/*
         * Bug #86 & #87: Invoking the renderer of an AudioWorkletNode might be necessary if it has no direct or indirect connection to the
         * destination.
         */ .then(()=>Promise.all(Array.from(getUnrenderedAudioWorkletNodes(nativeOfflineAudioContext)).map((audioWorkletNode)=>getAudioNodeRenderer(audioWorkletNode).render(audioWorkletNode, nativeOfflineAudioContext)))).then(()=>renderNativeOfflineAudioContext(nativeOfflineAudioContext)).then((audioBuffer)=>{
            // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
            // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.
            if (typeof audioBuffer.copyFromChannel !== "function") {
                wrapAudioBufferCopyChannelMethods(audioBuffer);
                (0, $2e77af801a4782d4$export$df65309cf6249598)(audioBuffer);
            // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.
            } else if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, ()=>testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer))) wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);
            audioBufferStore.add(audioBuffer);
            return audioBuffer;
        });
};


const $bae493c300dc0e65$var$DEFAULT_OPTIONS = {
    channelCount: 2,
    /*
     * Bug #105: The channelCountMode should be 'clamped-max' according to the spec but is set to 'explicit' to achieve consistent
     * behavior.
     */ channelCountMode: "explicit",
    channelInterpretation: "speakers",
    pan: 0
};
const $bae493c300dc0e65$export$9b005b0c35721c84 = (audioNodeConstructor, createAudioParam, createNativeStereoPannerNode, createStereoPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext)=>{
    return class StereoPannerNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...$bae493c300dc0e65$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeStereoPannerNode = createNativeStereoPannerNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const stereoPannerNodeRenderer = isOffline ? createStereoPannerNodeRenderer() : null;
            super(context, false, nativeStereoPannerNode, stereoPannerNodeRenderer);
            this._pan = createAudioParam(this, isOffline, nativeStereoPannerNode.pan);
        }
        get pan() {
            return this._pan;
        }
    };
};




const $5180ef9c3864dba3$export$3ba9002bd6b539cf = (connectAudioParam, createNativeStereoPannerNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeStereoPannerNodes = new WeakMap();
        const createStereoPannerNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeStereoPannerNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeStereoPannerNode was not constructed on the same OfflineAudioContext it needs to be created
             * again.
             */ const nativeStereoPannerNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeStereoPannerNode, nativeOfflineAudioContext);
            if (!nativeStereoPannerNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeStereoPannerNode.channelCount,
                    channelCountMode: nativeStereoPannerNode.channelCountMode,
                    channelInterpretation: nativeStereoPannerNode.channelInterpretation,
                    pan: nativeStereoPannerNode.pan.value
                };
                nativeStereoPannerNode = createNativeStereoPannerNode(nativeOfflineAudioContext, options);
            }
            renderedNativeStereoPannerNodes.set(nativeOfflineAudioContext, nativeStereoPannerNode);
            if (!nativeStereoPannerNodeIsOwnedByContext) await renderAutomation(nativeOfflineAudioContext, proxy.pan, nativeStereoPannerNode.pan);
            else await connectAudioParam(nativeOfflineAudioContext, proxy.pan, nativeStereoPannerNode.pan);
            if ((0, $77ab69d57b7e7a12$export$ac2aef07f705aa48)(nativeStereoPannerNode)) await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeStereoPannerNode.inputs[0]);
            else await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeStereoPannerNode);
            return nativeStereoPannerNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeStereoPannerNode = renderedNativeStereoPannerNodes.get(nativeOfflineAudioContext);
                if (renderedNativeStereoPannerNode !== undefined) return Promise.resolve(renderedNativeStereoPannerNode);
                return createStereoPannerNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};


const $288671eaa569fb33$export$5bddcff46df9c642 = (nativeAudioBufferConstructor)=>{
    return ()=>{
        if (nativeAudioBufferConstructor === null) return false;
        try {
            new nativeAudioBufferConstructor({
                length: 1,
                sampleRate: 44100
            }); // tslint:disable-line:no-unused-expression
        } catch  {
            return false;
        }
        return true;
    };
};


const $4a9a939c1d9c567b$export$1995b5466f5c2709 = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeAudioBuffer = nativeOfflineAudioContext.createBuffer(1, 1, 44100);
        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
        if (nativeAudioBuffer.copyToChannel === undefined) return true;
        const source = new Float32Array(2);
        try {
            nativeAudioBuffer.copyFromChannel(source, 0, 0);
        } catch  {
            return false;
        }
        return true;
    };
};


const $c4ab0dbb21ad8d31$export$34981ee6aafdf532 = (nativeAudioContextConstructor)=>{
    return ()=>{
        if (nativeAudioContextConstructor === null) return false;
        // Try to check the prototype before constructing the AudioContext.
        if (nativeAudioContextConstructor.prototype !== undefined && nativeAudioContextConstructor.prototype.close !== undefined) return true;
        const audioContext = new nativeAudioContextConstructor();
        const isAudioContextClosable = audioContext.close !== undefined;
        try {
            audioContext.close();
        } catch  {
        // Ignore errors.
        }
        return isAudioContextClosable;
    };
};


const $991718564e974f22$export$622ba23aa6b35822 = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return Promise.resolve(false);
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        // Bug #21: Safari does not support promises yet.
        return new Promise((resolve)=>{
            let isPending = true;
            const resolvePromise = (err)=>{
                if (isPending) {
                    isPending = false;
                    offlineAudioContext.startRendering();
                    resolve(err instanceof TypeError);
                }
            };
            let promise;
            // Bug #26: Safari throws a synchronous error.
            try {
                promise = offlineAudioContext// Bug #1: Safari requires a successCallback.
                .decodeAudioData(null, ()=>{
                // Ignore the success callback.
                }, resolvePromise);
            } catch (err) {
                resolvePromise(err);
            }
            // Bug #21: Safari does not support promises yet.
            if (promise !== undefined) // Bug #6: Chrome, Edge, Firefox and Opera do not call the errorCallback.
            promise.catch(resolvePromise);
        });
    };
};


const $b2770317539a3239$export$2f44088abd2df2e = (nativeAudioContextConstructor)=>{
    return ()=>{
        if (nativeAudioContextConstructor === null) return false;
        let audioContext;
        try {
            audioContext = new nativeAudioContextConstructor({
                latencyHint: "balanced"
            });
        } catch  {
            return false;
        }
        audioContext.close();
        return true;
    };
};


const $79b9931130d468d6$export$f77a3bce7e4efd81 = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeGainNode = nativeOfflineAudioContext.createGain();
        const isSupported = nativeGainNode.connect(nativeGainNode) === nativeGainNode;
        nativeGainNode.disconnect(nativeGainNode);
        return isSupported;
    };
};


const $c0d11c72041d312f$export$ce5ba80a98dc0ba7 = (nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor)=>{
    return async ()=>{
        // Bug #61: If there is no native AudioWorkletNode it gets faked and therefore it is no problem if the it doesn't exist.
        if (nativeAudioWorkletNodeConstructor === null) return true;
        if (nativeOfflineAudioContextConstructor === null) return false;
        const blob = new Blob([
            'let c,p;class A extends AudioWorkletProcessor{constructor(){super();this.port.onmessage=(e)=>{p=e.data;p.onmessage=()=>{p.postMessage(c);p.close()};this.port.postMessage(0)}}process(){c=1}}registerProcessor("a",A)'
        ], {
            type: "application/javascript; charset=utf-8"
        });
        const messageChannel = new MessageChannel();
        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 128, 44100);
        const url = URL.createObjectURL(blob);
        let isCallingProcess = false;
        try {
            await offlineAudioContext.audioWorklet.addModule(url);
            const audioWorkletNode = new nativeAudioWorkletNodeConstructor(offlineAudioContext, "a", {
                numberOfOutputs: 0
            });
            const oscillator = offlineAudioContext.createOscillator();
            await new Promise((resolve)=>{
                audioWorkletNode.port.onmessage = ()=>resolve();
                audioWorkletNode.port.postMessage(messageChannel.port2, [
                    messageChannel.port2
                ]);
            });
            audioWorkletNode.port.onmessage = ()=>isCallingProcess = true;
            oscillator.connect(audioWorkletNode);
            oscillator.start(0);
            await offlineAudioContext.startRendering();
            isCallingProcess = await new Promise((resolve)=>{
                messageChannel.port1.onmessage = ({ data: data  })=>resolve(data === 1);
                messageChannel.port1.postMessage(0);
            });
        } catch  {
        // Ignore errors.
        } finally{
            messageChannel.port1.close();
            URL.revokeObjectURL(url);
        }
        return isCallingProcess;
    };
};


const $5bb20e3ade2fe5eb$export$19b2cf184a7cfba8 = (nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor)=>{
    return async ()=>{
        // Bug #61: If there is no native AudioWorkletNode it gets faked and therefore it is no problem if the it doesn't exist.
        if (nativeAudioWorkletNodeConstructor === null) return true;
        if (nativeOfflineAudioContextConstructor === null) return false;
        const blob = new Blob([
            'class A extends AudioWorkletProcessor{process(i){this.port.postMessage(i,[i[0][0].buffer])}}registerProcessor("a",A)'
        ], {
            type: "application/javascript; charset=utf-8"
        });
        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 128, 44100);
        const url = URL.createObjectURL(blob);
        let isEmittingMessageEvents = false;
        let isEmittingProcessorErrorEvents = false;
        try {
            await offlineAudioContext.audioWorklet.addModule(url);
            const audioWorkletNode = new nativeAudioWorkletNodeConstructor(offlineAudioContext, "a", {
                numberOfOutputs: 0
            });
            const oscillator = offlineAudioContext.createOscillator();
            audioWorkletNode.port.onmessage = ()=>isEmittingMessageEvents = true;
            audioWorkletNode.onprocessorerror = ()=>isEmittingProcessorErrorEvents = true;
            oscillator.connect(audioWorkletNode);
            oscillator.start(0);
            await offlineAudioContext.startRendering();
        } catch  {
        // Ignore errors.
        } finally{
            URL.revokeObjectURL(url);
        }
        return isEmittingMessageEvents && !isEmittingProcessorErrorEvents;
    };
};


const $b06628055a1150da$export$a04037cfe0b977fa = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeChannelMergerNode = offlineAudioContext.createChannelMerger();
        /**
         * Bug #15: Safari does not return the default properties. It still needs to be patched. This test is supposed to test the support
         * in other browsers.
         */ if (nativeChannelMergerNode.channelCountMode === "max") return true;
        try {
            nativeChannelMergerNode.channelCount = 2;
        } catch  {
            return true;
        }
        return false;
    };
};


const $384e72ffdc0fd648$export$63ae3ec177f0ed66 = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        // Bug #62: Safari does not support ConstantSourceNodes.
        if (nativeOfflineAudioContext.createConstantSource === undefined) return true;
        const nativeConstantSourceNode = nativeOfflineAudioContext.createConstantSource();
        /*
         * @todo This is using bug #75 to detect bug #70. That works because both bugs were unique to
         * the implementation of Firefox right now, but it could probably be done in a better way.
         */ return nativeConstantSourceNode.offset.maxValue !== Number.POSITIVE_INFINITY;
    };
};


const $3eca900f24929922$export$b6f3c4027f959b95 = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeConvolverNode = offlineAudioContext.createConvolver();
        nativeConvolverNode.buffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);
        try {
            nativeConvolverNode.buffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);
        } catch  {
            return false;
        }
        return true;
    };
};


const $1dafc4ed43e766f7$export$d1bddb88e5c21d26 = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeConvolverNode = offlineAudioContext.createConvolver();
        try {
            nativeConvolverNode.channelCount = 1;
        } catch  {
            return false;
        }
        return true;
    };
};


const $7c947a2416b94687$export$41669e689e17d4f0 = (window)=>{
    return ()=>window !== null && window.hasOwnProperty("isSecureContext");
};


const $f0b6df9dd6a9c594$export$416bb3b14425e126 = (nativeAudioContextConstructor)=>{
    return ()=>{
        if (nativeAudioContextConstructor === null) return false;
        const audioContext = new nativeAudioContextConstructor();
        try {
            audioContext.createMediaStreamSource(new MediaStream());
            return false;
        } catch (err) {
            return true;
        } finally{
            audioContext.close();
        }
    };
};


const $1f9bfe39fc10c854$export$6db7e9dd49157213 = (createNativeGainNode, nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return Promise.resolve(false);
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        // Bug #48: Safari does not render an OfflineAudioContext without any connected node.
        const gainNode = createNativeGainNode(nativeOfflineAudioContext, {
            channelCount: 1,
            channelCountMode: "explicit",
            channelInterpretation: "discrete",
            gain: 0
        });
        // Bug #21: Safari does not support promises yet.
        return new Promise((resolve)=>{
            nativeOfflineAudioContext.oncomplete = ()=>{
                gainNode.disconnect();
                resolve(nativeOfflineAudioContext.currentTime !== 0);
            };
            nativeOfflineAudioContext.startRendering();
        });
    };
};


const $75aebf71b38e1e06$export$5ea70af76c7a03fc = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return Promise.resolve(false);
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        /*
         * Bug #105: Safari does not support the StereoPannerNode. Therefore the returned value should normally be false but the faker does
         * support the tested behaviour.
         */ if (nativeOfflineAudioContext.createStereoPanner === undefined) return Promise.resolve(true);
        // Bug #62: Safari does not support ConstantSourceNodes.
        if (nativeOfflineAudioContext.createConstantSource === undefined) return Promise.resolve(true);
        const constantSourceNode = nativeOfflineAudioContext.createConstantSource();
        const stereoPanner = nativeOfflineAudioContext.createStereoPanner();
        constantSourceNode.channelCount = 1;
        constantSourceNode.offset.value = 1;
        stereoPanner.channelCount = 1;
        constantSourceNode.start();
        constantSourceNode.connect(stereoPanner).connect(nativeOfflineAudioContext.destination);
        return nativeOfflineAudioContext.startRendering().then((buffer)=>buffer.getChannelData(0)[0] !== 1);
    };
};


const $03c74873b1e908cf$export$988fb803bae63f80 = ()=>new DOMException("", "UnknownError");


const $f3731b078b33221f$var$DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: "max",
    channelInterpretation: "speakers",
    curve: null,
    oversample: "none"
};
const $f3731b078b33221f$export$3a30e911e17b1cf5 = (audioNodeConstructor, createInvalidStateError, createNativeWaveShaperNode, createWaveShaperNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class WaveShaperNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...$f3731b078b33221f$var$DEFAULT_OPTIONS,
                ...options
            };
            const nativeWaveShaperNode = createNativeWaveShaperNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const waveShaperNodeRenderer = isOffline ? createWaveShaperNodeRenderer() : null;
            // @todo Add a mechanism to only switch a WaveShaperNode to active while it is connected.
            super(context, true, nativeWaveShaperNode, waveShaperNodeRenderer);
            this._isCurveNullified = false;
            this._nativeWaveShaperNode = nativeWaveShaperNode;
            // @todo Determine a meaningful tail-time instead of just using one second.
            setAudioNodeTailTime(this, 1);
        }
        get curve() {
            if (this._isCurveNullified) return null;
            return this._nativeWaveShaperNode.curve;
        }
        set curve(value) {
            // Bug #103: Safari does not allow to set the curve to null.
            if (value === null) {
                this._isCurveNullified = true;
                this._nativeWaveShaperNode.curve = new Float32Array([
                    0,
                    0
                ]);
            } else {
                // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.
                // Bug #104: Chrome, Edge and Opera will throw an InvalidAccessError when the curve has less than two samples.
                if (value.length < 2) throw createInvalidStateError();
                this._isCurveNullified = false;
                this._nativeWaveShaperNode.curve = value;
            }
        }
        get oversample() {
            return this._nativeWaveShaperNode.oversample;
        }
        set oversample(value) {
            this._nativeWaveShaperNode.oversample = value;
        }
    };
};




const $9a6b6ebbfdaceba8$export$9709a48a5037d121 = (createNativeWaveShaperNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeWaveShaperNodes = new WeakMap();
        const createWaveShaperNode = async (proxy, nativeOfflineAudioContext)=>{
            let nativeWaveShaperNode = getNativeAudioNode(proxy);
            // If the initially used nativeWaveShaperNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeWaveShaperNodeIsOwnedByContext = (0, $f95943e20b45689b$export$4bd7a4bf54ca80bc)(nativeWaveShaperNode, nativeOfflineAudioContext);
            if (!nativeWaveShaperNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeWaveShaperNode.channelCount,
                    channelCountMode: nativeWaveShaperNode.channelCountMode,
                    channelInterpretation: nativeWaveShaperNode.channelInterpretation,
                    curve: nativeWaveShaperNode.curve,
                    oversample: nativeWaveShaperNode.oversample
                };
                nativeWaveShaperNode = createNativeWaveShaperNode(nativeOfflineAudioContext, options);
            }
            renderedNativeWaveShaperNodes.set(nativeOfflineAudioContext, nativeWaveShaperNode);
            if ((0, $77ab69d57b7e7a12$export$ac2aef07f705aa48)(nativeWaveShaperNode)) await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeWaveShaperNode.inputs[0]);
            else await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeWaveShaperNode);
            return nativeWaveShaperNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext) {
                const renderedNativeWaveShaperNode = renderedNativeWaveShaperNodes.get(nativeOfflineAudioContext);
                if (renderedNativeWaveShaperNode !== undefined) return Promise.resolve(renderedNativeWaveShaperNode);
                return createWaveShaperNode(proxy, nativeOfflineAudioContext);
            }
        };
    };
};


const $ea199c19096f5acf$export$ba255020126e276e = ()=>typeof window === "undefined" ? null : window;


const $d2fcc46e44c75e24$export$dbf1ce6ba2b4bc6a = (convertNumberToUnsignedLong, createIndexSizeError)=>{
    return (audioBuffer)=>{
        audioBuffer.copyFromChannel = (destination, channelNumberAsNumber, bufferOffsetAsNumber = 0)=>{
            const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
            const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
            if (channelNumber >= audioBuffer.numberOfChannels) throw createIndexSizeError();
            const audioBufferLength = audioBuffer.length;
            const channelData = audioBuffer.getChannelData(channelNumber);
            const destinationLength = destination.length;
            for(let i = bufferOffset < 0 ? -bufferOffset : 0; i + bufferOffset < audioBufferLength && i < destinationLength; i += 1)destination[i] = channelData[i + bufferOffset];
        };
        audioBuffer.copyToChannel = (source, channelNumberAsNumber, bufferOffsetAsNumber = 0)=>{
            const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
            const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
            if (channelNumber >= audioBuffer.numberOfChannels) throw createIndexSizeError();
            const audioBufferLength = audioBuffer.length;
            const channelData = audioBuffer.getChannelData(channelNumber);
            const sourceLength = source.length;
            for(let i = bufferOffset < 0 ? -bufferOffset : 0; i + bufferOffset < audioBufferLength && i < sourceLength; i += 1)channelData[i + bufferOffset] = source[i];
        };
    };
};


const $bb24eb9b543511a5$export$bff9a41e76b37a6e = (convertNumberToUnsignedLong)=>{
    return (audioBuffer)=>{
        audioBuffer.copyFromChannel = ((copyFromChannel)=>{
            return (destination, channelNumberAsNumber, bufferOffsetAsNumber = 0)=>{
                const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
                const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
                if (bufferOffset < audioBuffer.length) return copyFromChannel.call(audioBuffer, destination, channelNumber, bufferOffset);
            };
        })(audioBuffer.copyFromChannel);
        audioBuffer.copyToChannel = ((copyToChannel)=>{
            return (source, channelNumberAsNumber, bufferOffsetAsNumber = 0)=>{
                const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
                const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
                if (bufferOffset < audioBuffer.length) return copyToChannel.call(audioBuffer, source, channelNumber, bufferOffset);
            };
        })(audioBuffer.copyToChannel);
    };
};


const $037a1db229398884$export$3c1722ed0f0ed532 = (overwriteAccessors)=>{
    return (nativeAudioBufferSourceNode, nativeContext)=>{
        const nullifiedBuffer = nativeContext.createBuffer(1, 1, 44100);
        if (nativeAudioBufferSourceNode.buffer === null) nativeAudioBufferSourceNode.buffer = nullifiedBuffer;
        overwriteAccessors(nativeAudioBufferSourceNode, "buffer", (get)=>()=>{
                const value = get.call(nativeAudioBufferSourceNode);
                return value === nullifiedBuffer ? null : value;
            }, (set)=>(value)=>{
                return set.call(nativeAudioBufferSourceNode, value === null ? nullifiedBuffer : value);
            });
    };
};


const $991b2a3fc9486ca0$export$162785cfa8a63221 = (createInvalidStateError, monitorConnections)=>{
    return (nativeContext, channelMergerNode)=>{
        // Bug #15: Safari does not return the default properties.
        channelMergerNode.channelCount = 1;
        channelMergerNode.channelCountMode = "explicit";
        // Bug #16: Safari does not throw an error when setting a different channelCount or channelCountMode.
        Object.defineProperty(channelMergerNode, "channelCount", {
            get: ()=>1,
            set: ()=>{
                throw createInvalidStateError();
            }
        });
        Object.defineProperty(channelMergerNode, "channelCountMode", {
            get: ()=>"explicit",
            set: ()=>{
                throw createInvalidStateError();
            }
        });
        // Bug #20: Safari requires a connection of any kind to treat the input signal correctly.
        const audioBufferSourceNode = nativeContext.createBufferSource();
        const whenConnected = ()=>{
            const length = channelMergerNode.numberOfInputs;
            for(let i = 0; i < length; i += 1)audioBufferSourceNode.connect(channelMergerNode, 0, i);
        };
        const whenDisconnected = ()=>audioBufferSourceNode.disconnect(channelMergerNode);
        monitorConnections(channelMergerNode, whenConnected, whenDisconnected);
    };
};








const $310b27ad9883fbff$export$4ec0c13c358eb2b5 = (audioBuffer, buffer, channelNumber)=>{
    // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
    if (audioBuffer.copyFromChannel === undefined) return audioBuffer.getChannelData(channelNumber)[0];
    audioBuffer.copyFromChannel(buffer, channelNumber);
    return buffer[0];
};







const $c10ae02b5c342862$export$b32eba1f356dc699 = (curve)=>{
    if (curve === null) return false;
    const length = curve.length;
    if (length % 2 !== 0) return curve[Math.floor(length / 2)] !== 0;
    return curve[length / 2 - 1] + curve[length / 2] !== 0;
};




const $5c1d1cb3e2507429$export$f25ed0e1b53c5d37 = (object, property, createGetter, createSetter)=>{
    let prototype = object;
    while(!prototype.hasOwnProperty(property))prototype = Object.getPrototypeOf(prototype);
    const { get: get , set: set  } = Object.getOwnPropertyDescriptor(prototype, property);
    Object.defineProperty(object, property, {
        get: createGetter(get),
        set: createSetter(set)
    });
};



const $b75e1a3ebb977a47$export$9a47aefcb4b02450 = (options)=>{
    return {
        ...options,
        outputChannelCount: options.outputChannelCount !== undefined ? options.outputChannelCount : options.numberOfInputs === 1 && options.numberOfOutputs === 1 ? /*
                   * Bug #61: This should be the computedNumberOfChannels, but unfortunately that is almost impossible to fake. That's why
                   * the channelCountMode is required to be 'explicit' as long as there is not a native implementation in every browser. That
                   * makes sure the computedNumberOfChannels is equivilant to the channelCount which makes it much easier to compute.
                   */ [
            options.channelCount
        ] : Array.from({
            length: options.numberOfOutputs
        }, ()=>1)
    };
};


const $4698955bbe7d9b3a$export$6edb0bde597f2c9a = (options)=>{
    return {
        ...options,
        channelCount: options.numberOfOutputs
    };
};


const $768ab8b80a1487b1$export$833c872c8eda5015 = (options)=>{
    const { imag: imag , real: real  } = options;
    if (imag === undefined) {
        if (real === undefined) return {
            ...options,
            imag: [
                0,
                0
            ],
            real: [
                0,
                0
            ]
        };
        return {
            ...options,
            imag: Array.from(real, ()=>0),
            real: real
        };
    }
    if (real === undefined) return {
        ...options,
        imag: imag,
        real: Array.from(imag, ()=>0)
    };
    return {
        ...options,
        imag: imag,
        real: real
    };
};


const $0db03483626f280b$export$652ab3e522965552 = (audioParam, value, startTime)=>{
    try {
        audioParam.setValueAtTime(value, startTime);
    } catch (err) {
        if (err.code !== 9) throw err;
        $0db03483626f280b$export$652ab3e522965552(audioParam, value, startTime + 1e-7);
    }
};



const $da96dc139d1d043d$export$3211ed65c5b8326b = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
    nativeAudioBufferSourceNode.start();
    try {
        nativeAudioBufferSourceNode.start();
    } catch  {
        return true;
    }
    return false;
};


const $494d3d48af2df6f3$export$74929efb99360b7a = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
    const nativeAudioBuffer = nativeContext.createBuffer(1, 1, 44100);
    nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;
    try {
        nativeAudioBufferSourceNode.start(0, 1);
    } catch  {
        return false;
    }
    return true;
};


const $acd740640f4a39b6$export$c29f4eec5460fc70 = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
    nativeAudioBufferSourceNode.start();
    try {
        nativeAudioBufferSourceNode.stop();
    } catch  {
        return false;
    }
    return true;
};


const $6e4098b3ea8ada29$export$9be334adb9176c59 = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createOscillator();
    try {
        nativeAudioBufferSourceNode.start(-1);
    } catch (err) {
        return err instanceof RangeError;
    }
    return false;
};


const $18f136752ba69d33$export$a7f1019c14a08879 = (nativeContext)=>{
    const nativeAudioBuffer = nativeContext.createBuffer(1, 1, 44100);
    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
    nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;
    nativeAudioBufferSourceNode.start();
    nativeAudioBufferSourceNode.stop();
    try {
        nativeAudioBufferSourceNode.stop();
        return true;
    } catch  {
        return false;
    }
};


const $cec3d2119afa7026$export$67a72517a9facc5 = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createOscillator();
    try {
        nativeAudioBufferSourceNode.stop(-1);
    } catch (err) {
        return err instanceof RangeError;
    }
    return false;
};


const $73083767f13a3af7$export$a40748749fc273c5 = (audioWorkletNodeOptions)=>{
    const { port1: port1 , port2: port2  } = new MessageChannel();
    try {
        // This will throw an error if the audioWorkletNodeOptions are not clonable.
        port1.postMessage(audioWorkletNodeOptions);
    } finally{
        port1.close();
        port2.close();
    }
};


const $59b776ff57894eb4$export$1310f0b96d9d8115 = ()=>{
    try {
        new DOMException(); // tslint:disable-line:no-unused-expression
    } catch  {
        return false;
    }
    return true;
};



const $9c33322f03b96319$export$4f6e0d4bb1ead9ce = ()=>new Promise((resolve)=>{
        const arrayBuffer = new ArrayBuffer(0);
        const { port1: port1 , port2: port2  } = new MessageChannel();
        port1.onmessage = ({ data: data  })=>resolve(data !== null);
        port2.postMessage(arrayBuffer, [
            arrayBuffer
        ]);
    });


const $dfff722a4bba2b07$export$c3eb87c85305df2 = (nativeAudioBufferSourceNode)=>{
    nativeAudioBufferSourceNode.start = ((start)=>{
        return (when = 0, offset = 0, duration)=>{
            const buffer = nativeAudioBufferSourceNode.buffer;
            // Bug #154: Safari does not clamp the offset if it is equal to or greater than the duration of the buffer.
            const clampedOffset = buffer === null ? offset : Math.min(buffer.duration, offset);
            // Bug #155: Safari does not handle the offset correctly if it would cause the buffer to be not be played at all.
            if (buffer !== null && clampedOffset > buffer.duration - 0.5 / nativeAudioBufferSourceNode.context.sampleRate) start.call(nativeAudioBufferSourceNode, when, 0, 0);
            else start.call(nativeAudioBufferSourceNode, when, clampedOffset, duration);
        };
    })(nativeAudioBufferSourceNode.start);
};



const $29a51da6a1953a8a$export$587074127be31245 = (nativeAudioScheduledSourceNode, nativeContext)=>{
    const nativeGainNode = nativeContext.createGain();
    nativeAudioScheduledSourceNode.connect(nativeGainNode);
    const disconnectGainNode = ((disconnect)=>{
        return ()=>{
            // @todo TypeScript cannot infer the overloaded signature with 1 argument yet.
            disconnect.call(nativeAudioScheduledSourceNode, nativeGainNode);
            nativeAudioScheduledSourceNode.removeEventListener("ended", disconnectGainNode);
        };
    })(nativeAudioScheduledSourceNode.disconnect);
    nativeAudioScheduledSourceNode.addEventListener("ended", disconnectGainNode);
    (0, $f50dfa358e381b90$export$19c8a106f82dff14)(nativeAudioScheduledSourceNode, nativeGainNode);
    nativeAudioScheduledSourceNode.stop = ((stop)=>{
        let isStopped = false;
        return (when = 0)=>{
            if (isStopped) try {
                stop.call(nativeAudioScheduledSourceNode, when);
            } catch  {
                nativeGainNode.gain.setValueAtTime(0, when);
            }
            else {
                stop.call(nativeAudioScheduledSourceNode, when);
                isStopped = true;
            }
        };
    })(nativeAudioScheduledSourceNode.stop);
};


const $2e02501193eee810$export$63f14ca2e716ed28 = (target, eventListener)=>{
    return (event)=>{
        const descriptor = {
            value: target
        };
        Object.defineProperties(event, {
            currentTarget: descriptor,
            target: descriptor
        });
        if (typeof eventListener === "function") return eventListener.call(target, event);
        return eventListener.handleEvent.call(target, event);
    };
};




































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































const $28970d85181d1a3a$var$addActiveInputConnectionToAudioNode = (0, $e1b9ef044571c7b2$export$43d20cccdc976834)((0, $2cb97ab8cc5662cd$export$64505511c8abc942));
const $28970d85181d1a3a$var$addPassiveInputConnectionToAudioNode = (0, $608abbe6ab6cc7e7$export$67aa4e90be3a506b)((0, $2cb97ab8cc5662cd$export$64505511c8abc942));
const $28970d85181d1a3a$var$deleteActiveInputConnectionToAudioNode = (0, $477fe5e73ad92df6$export$1f7c0152b9e322ae)((0, $115343c7346cd8e6$export$3f1b331b43a0e659));
const $28970d85181d1a3a$var$audioNodeTailTimeStore = new WeakMap();
const $28970d85181d1a3a$var$getAudioNodeTailTime = (0, $f379da479c52f5b2$export$4abc3abd061bc2cc)($28970d85181d1a3a$var$audioNodeTailTimeStore);
const $28970d85181d1a3a$var$cacheTestResult = (0, $7c87a57a3e4e78d1$export$e72d622686b5f6c7)(new Map(), new WeakMap());
const $28970d85181d1a3a$var$window = (0, $ea199c19096f5acf$export$ba255020126e276e)();
const $28970d85181d1a3a$var$createNativeAnalyserNode = (0, $2cb9b20e39baeef5$export$36e704ad7c903a26)($28970d85181d1a3a$var$cacheTestResult, (0, $5e22421cd58df859$export$926e4aa3eed6ec13));
const $28970d85181d1a3a$var$getAudioNodeRenderer = (0, $1c0990f0eabc339c$export$97bb1acefff8970e)((0, $82132aac47394666$export$6b29eee2af836dfc));
const $28970d85181d1a3a$var$renderInputsOfAudioNode = (0, $0a69be9a881260e4$export$cff0938ddf51f6f4)((0, $82132aac47394666$export$6b29eee2af836dfc), $28970d85181d1a3a$var$getAudioNodeRenderer, (0, $ff7fd1ee6b8a1725$export$8658a39a04a404d5));
const $28970d85181d1a3a$var$createAnalyserNodeRenderer = (0, $115369693fdf36f2$export$5fe3f5c2d995fe20)($28970d85181d1a3a$var$createNativeAnalyserNode, (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$renderInputsOfAudioNode);
const $28970d85181d1a3a$var$getNativeContext = (0, $6c2ddbefdfe0db9b$export$797a319a8065fb37)((0, $45092aa0415316c7$export$7d17302229276f06));
const $28970d85181d1a3a$var$nativeOfflineAudioContextConstructor = (0, $7ed72cbb8b4eb4b1$export$e628a2a5fd5b78b9)($28970d85181d1a3a$var$window);
const $28970d85181d1a3a$var$isNativeOfflineAudioContext = (0, $a21b7ebb07b6ed07$export$722bd4bab77df75a)($28970d85181d1a3a$var$nativeOfflineAudioContextConstructor);
const $28970d85181d1a3a$var$audioParamAudioNodeStore = new WeakMap();
const $28970d85181d1a3a$var$eventTargetConstructor = (0, $eb27148c76e60649$export$a512af3fc2ab91f2)((0, $2e02501193eee810$export$63f14ca2e716ed28));
const $28970d85181d1a3a$var$nativeAudioContextConstructor = (0, $792783d50bf09b55$export$3a22fc4046f7b4ec)($28970d85181d1a3a$var$window);
const $28970d85181d1a3a$var$isNativeAudioContext = (0, $e6dcf60ee968f7b7$export$5d44272df169092e)($28970d85181d1a3a$var$nativeAudioContextConstructor);
const $28970d85181d1a3a$var$isNativeAudioNode = (0, $deab5577981f9cf3$export$96f2bb6e8a5795ea)($28970d85181d1a3a$var$window);
const $28970d85181d1a3a$var$isNativeAudioParam = (0, $3bdb9cabcc884b13$export$7c3a44537acaf24e)($28970d85181d1a3a$var$window);
const $28970d85181d1a3a$var$nativeAudioWorkletNodeConstructor = (0, $bfe566b60cab0cea$export$b0ef4818c07d1453)($28970d85181d1a3a$var$window);
const $28970d85181d1a3a$var$audioNodeConstructor = (0, $45ba32bea7b08f76$export$20e3fa4f981cb01d)((0, $751bcb2732d93877$export$7ff07578cebde522)((0, $45092aa0415316c7$export$61ca80a8c8c6d728)), (0, $d20379ab3ffab405$export$1776cf0d295db1d7)($28970d85181d1a3a$var$addActiveInputConnectionToAudioNode, $28970d85181d1a3a$var$addPassiveInputConnectionToAudioNode, (0, $9561d33b242cedb0$export$b92162b3199b4461), $28970d85181d1a3a$var$deleteActiveInputConnectionToAudioNode, (0, $147c083052099f38$export$a19b495df4b88921), (0, $82132aac47394666$export$6b29eee2af836dfc), $28970d85181d1a3a$var$getAudioNodeTailTime, (0, $d6dd4c96535f9fa2$export$caac7ea54cb93b25), (0, $91004965fac1b491$export$e719c0d45ea16d08), (0, $2cb97ab8cc5662cd$export$64505511c8abc942), (0, $a52e8cf090f6ea8d$export$e44f0fc8e83fb084), (0, $ff7fd1ee6b8a1725$export$8658a39a04a404d5), (0, $2e47ed05befd6218$export$79a7cb9fa56970e)), $28970d85181d1a3a$var$cacheTestResult, (0, $4d0326c0f9d09f93$export$e306a463e9286bbd)((0, $45092aa0415316c7$export$cf686a6a3e402092), (0, $147c083052099f38$export$a19b495df4b88921), (0, $82132aac47394666$export$6b29eee2af836dfc), (0, $91004965fac1b491$export$e719c0d45ea16d08), (0, $172aa88b2fc4c949$export$fad3d843b2a56ffb), (0, $a52e8cf090f6ea8d$export$e44f0fc8e83fb084)), (0, $5e22421cd58df859$export$926e4aa3eed6ec13), (0, $365f5e3658bdb1fe$export$254c536c2ca9b917), (0, $724da61d5e6b149b$export$dbebdb13622d486c), (0, $3e58ea8f410c8370$export$93f58f9268fde9f6)((0, $9561d33b242cedb0$export$b92162b3199b4461), (0, $45092aa0415316c7$export$cf686a6a3e402092), (0, $82132aac47394666$export$6b29eee2af836dfc), (0, $91004965fac1b491$export$e719c0d45ea16d08), (0, $172aa88b2fc4c949$export$fad3d843b2a56ffb), $28970d85181d1a3a$var$getNativeContext, (0, $a52e8cf090f6ea8d$export$e44f0fc8e83fb084), $28970d85181d1a3a$var$isNativeOfflineAudioContext), (0, $40fa50096cb00484$export$b4f8d2824d9887dc)($28970d85181d1a3a$var$audioParamAudioNodeStore, (0, $82132aac47394666$export$6b29eee2af836dfc), (0, $838ea8ed33d27e81$export$520987e3ff3ffad3)), $28970d85181d1a3a$var$eventTargetConstructor, $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeAudioContext, $28970d85181d1a3a$var$isNativeAudioNode, $28970d85181d1a3a$var$isNativeAudioParam, $28970d85181d1a3a$var$isNativeOfflineAudioContext, $28970d85181d1a3a$var$nativeAudioWorkletNodeConstructor);
const $28970d85181d1a3a$export$ed204192bbbabcef = (0, $eae529b582453c5f$export$569b2da15d7fe153)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createAnalyserNodeRenderer, (0, $5e22421cd58df859$export$926e4aa3eed6ec13), $28970d85181d1a3a$var$createNativeAnalyserNode, $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext);
const $28970d85181d1a3a$var$audioBufferStore = new WeakSet();
const $28970d85181d1a3a$var$nativeAudioBufferConstructor = (0, $f92c7034c4236288$export$1ddb6a79e564be96)($28970d85181d1a3a$var$window);
const $28970d85181d1a3a$var$convertNumberToUnsignedLong = (0, $c5f519196ef2423e$export$540e228106d2c471)(new Uint32Array(1));
const $28970d85181d1a3a$var$wrapAudioBufferCopyChannelMethods = (0, $d2fcc46e44c75e24$export$dbf1ce6ba2b4bc6a)($28970d85181d1a3a$var$convertNumberToUnsignedLong, (0, $5e22421cd58df859$export$926e4aa3eed6ec13));
const $28970d85181d1a3a$var$wrapAudioBufferCopyChannelMethodsOutOfBounds = (0, $bb24eb9b543511a5$export$bff9a41e76b37a6e)($28970d85181d1a3a$var$convertNumberToUnsignedLong);
const $28970d85181d1a3a$export$2dbca7d91f7769d7 = (0, $d331f10434d18ebe$export$c8b88126795b7df2)($28970d85181d1a3a$var$audioBufferStore, $28970d85181d1a3a$var$cacheTestResult, (0, $724da61d5e6b149b$export$dbebdb13622d486c), $28970d85181d1a3a$var$nativeAudioBufferConstructor, $28970d85181d1a3a$var$nativeOfflineAudioContextConstructor, (0, $288671eaa569fb33$export$5bddcff46df9c642)($28970d85181d1a3a$var$nativeAudioBufferConstructor), $28970d85181d1a3a$var$wrapAudioBufferCopyChannelMethods, $28970d85181d1a3a$var$wrapAudioBufferCopyChannelMethodsOutOfBounds);
const $28970d85181d1a3a$var$addSilentConnection = (0, $9a2ab1599c9292df$export$c6991e18a29704b9)((0, $71f48eec1b56edf3$export$7cf909169b9c4d6f));
const $28970d85181d1a3a$var$renderInputsOfAudioParam = (0, $d5a853e48f4f5160$export$82cd58acb1062198)($28970d85181d1a3a$var$getAudioNodeRenderer, (0, $b3cb1d7500dafa25$export$1b11f454bf19657), (0, $ff7fd1ee6b8a1725$export$8658a39a04a404d5));
const $28970d85181d1a3a$var$connectAudioParam = (0, $8992e81c70c72605$export$1e69fdca2ad79f10)($28970d85181d1a3a$var$renderInputsOfAudioParam);
const $28970d85181d1a3a$var$createNativeAudioBufferSourceNode = (0, $307420c32fae1fc4$export$4f48c993f264b207)($28970d85181d1a3a$var$addSilentConnection, $28970d85181d1a3a$var$cacheTestResult, (0, $da96dc139d1d043d$export$3211ed65c5b8326b), (0, $494d3d48af2df6f3$export$74929efb99360b7a), (0, $acd740640f4a39b6$export$c29f4eec5460fc70), (0, $6e4098b3ea8ada29$export$9be334adb9176c59), (0, $18f136752ba69d33$export$a7f1019c14a08879), (0, $cec3d2119afa7026$export$67a72517a9facc5), (0, $dfff722a4bba2b07$export$c3eb87c85305df2), (0, $037a1db229398884$export$3c1722ed0f0ed532)((0, $5c1d1cb3e2507429$export$f25ed0e1b53c5d37)), (0, $29a51da6a1953a8a$export$587074127be31245));
const $28970d85181d1a3a$var$renderAutomation = (0, $ab31fa70408c9e61$export$889eef7d338963f6)((0, $d6767de90b841a3b$export$1653dd3e76bcb1b0)((0, $b3cb1d7500dafa25$export$1b11f454bf19657)), $28970d85181d1a3a$var$renderInputsOfAudioParam);
const $28970d85181d1a3a$var$createAudioBufferSourceNodeRenderer = (0, $a4495543677998f1$export$82721be5d1bb22c5)($28970d85181d1a3a$var$connectAudioParam, $28970d85181d1a3a$var$createNativeAudioBufferSourceNode, (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$renderAutomation, $28970d85181d1a3a$var$renderInputsOfAudioNode);
const $28970d85181d1a3a$var$createAudioParam = (0, $d0eac1364ca1b1f7$export$25d3edb077748cfc)((0, $db6875aab68aad9f$export$25226f7a087f88c3)((0, $45092aa0415316c7$export$c5d3ff1f46a0185a)), $28970d85181d1a3a$var$audioParamAudioNodeStore, (0, $45092aa0415316c7$export$55484e3055c7a9e2), (0, $ba5705d1c52da529$export$8858f507eb103ac6), (0, $4765696a62faea77$exports.createCancelAndHoldAutomationEvent), (0, $4765696a62faea77$exports.createCancelScheduledValuesAutomationEvent), (0, $4765696a62faea77$exports.createExponentialRampToValueAutomationEvent), (0, $4765696a62faea77$exports.createLinearRampToValueAutomationEvent), (0, $4765696a62faea77$exports.createSetTargetAutomationEvent), (0, $4765696a62faea77$exports.createSetValueAutomationEvent), (0, $4765696a62faea77$exports.createSetValueCurveAutomationEvent), $28970d85181d1a3a$var$nativeAudioContextConstructor, (0, $0db03483626f280b$export$652ab3e522965552));
const $28970d85181d1a3a$export$c1b1480edd16e065 = (0, $34eafaf1433ef6a8$export$6857b764b4428518)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createAudioBufferSourceNodeRenderer, $28970d85181d1a3a$var$createAudioParam, (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), $28970d85181d1a3a$var$createNativeAudioBufferSourceNode, $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext, (0, $2e02501193eee810$export$63f14ca2e716ed28));
const $28970d85181d1a3a$var$audioDestinationNodeConstructor = (0, $615d78d315d73e79$export$cbbb0c3ba3f5dd5b)($28970d85181d1a3a$var$audioNodeConstructor, (0, $83c842f9a51e64b0$export$d44f3f5d4e42ced2), (0, $5e22421cd58df859$export$926e4aa3eed6ec13), (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), (0, $b385ebedfeec267d$export$d3097038f258fce)((0, $71f48eec1b56edf3$export$7cf909169b9c4d6f), (0, $5c1d1cb3e2507429$export$f25ed0e1b53c5d37)), $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext, $28970d85181d1a3a$var$renderInputsOfAudioNode);
const $28970d85181d1a3a$var$createBiquadFilterNodeRenderer = (0, $648a49d61d66668f$export$1532cc6682032d84)($28970d85181d1a3a$var$connectAudioParam, (0, $8c4ffb908a10983f$export$97e69c8dbd260f85), (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$renderAutomation, $28970d85181d1a3a$var$renderInputsOfAudioNode);
const $28970d85181d1a3a$var$setAudioNodeTailTime = (0, $df112b7b8d94bab8$export$c5e78cc8035d00aa)($28970d85181d1a3a$var$audioNodeTailTimeStore);
const $28970d85181d1a3a$export$f068340fbfd684eb = (0, $5626cc38a66fbbf6$export$aa421daabad177b5)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createAudioParam, $28970d85181d1a3a$var$createBiquadFilterNodeRenderer, (0, $365f5e3658bdb1fe$export$254c536c2ca9b917), (0, $8c4ffb908a10983f$export$97e69c8dbd260f85), $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext, $28970d85181d1a3a$var$setAudioNodeTailTime);
const $28970d85181d1a3a$var$monitorConnections = (0, $2225d588bbca3bbc$export$9f33b5a0b80f2717)((0, $2cb97ab8cc5662cd$export$64505511c8abc942), $28970d85181d1a3a$var$isNativeAudioNode);
const $28970d85181d1a3a$var$wrapChannelMergerNode = (0, $991b2a3fc9486ca0$export$162785cfa8a63221)((0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), $28970d85181d1a3a$var$monitorConnections);
const $28970d85181d1a3a$var$createNativeChannelMergerNode = (0, $25fec0ffa6e9acb4$export$99fe194415d94151)($28970d85181d1a3a$var$nativeAudioContextConstructor, $28970d85181d1a3a$var$wrapChannelMergerNode);
const $28970d85181d1a3a$var$createChannelMergerNodeRenderer = (0, $9c62d9a5222cb634$export$79056cbe2b10cae5)($28970d85181d1a3a$var$createNativeChannelMergerNode, (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$renderInputsOfAudioNode);
const $28970d85181d1a3a$export$7488bfd772ec10fc = (0, $9914bd5698d6d720$export$a65a5a400135d27)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createChannelMergerNodeRenderer, $28970d85181d1a3a$var$createNativeChannelMergerNode, $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext);
const $28970d85181d1a3a$var$createChannelSplitterNodeRenderer = (0, $cfe1fc595bf80c45$export$d815cad16abde9c3)((0, $bc9026dcb0dcb567$export$17649533bf213707), (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$renderInputsOfAudioNode);
const $28970d85181d1a3a$export$6f860927b3cf75c1 = (0, $428734a9d6f3ff0b$export$ce9d996cafa605b)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createChannelSplitterNodeRenderer, (0, $bc9026dcb0dcb567$export$17649533bf213707), $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext, (0, $4698955bbe7d9b3a$export$6edb0bde597f2c9a));
const $28970d85181d1a3a$var$createNativeConstantSourceNodeFaker = (0, $1651ef53e16686cd$export$360749cf3d02285a)($28970d85181d1a3a$var$addSilentConnection, $28970d85181d1a3a$var$createNativeAudioBufferSourceNode, (0, $71f48eec1b56edf3$export$7cf909169b9c4d6f), $28970d85181d1a3a$var$monitorConnections);
const $28970d85181d1a3a$var$createNativeConstantSourceNode = (0, $a94975f5203cc134$export$2dd44f7bb3dd8089)($28970d85181d1a3a$var$addSilentConnection, $28970d85181d1a3a$var$cacheTestResult, $28970d85181d1a3a$var$createNativeConstantSourceNodeFaker, (0, $6e4098b3ea8ada29$export$9be334adb9176c59), (0, $cec3d2119afa7026$export$67a72517a9facc5));
const $28970d85181d1a3a$var$createConstantSourceNodeRenderer = (0, $8129e008e11233c4$export$bc541a3c87b45a7d)($28970d85181d1a3a$var$connectAudioParam, $28970d85181d1a3a$var$createNativeConstantSourceNode, (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$renderAutomation, $28970d85181d1a3a$var$renderInputsOfAudioNode);
const $28970d85181d1a3a$export$d394f3dc072b3480 = (0, $d86f7b3e69ec2393$export$a02a9a6200996500)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createAudioParam, $28970d85181d1a3a$var$createConstantSourceNodeRenderer, $28970d85181d1a3a$var$createNativeConstantSourceNode, $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext, (0, $2e02501193eee810$export$63f14ca2e716ed28));
const $28970d85181d1a3a$var$createNativeConvolverNode = (0, $ba518ad47f75b625$export$afdcf89d13ff62e)((0, $724da61d5e6b149b$export$dbebdb13622d486c), (0, $5c1d1cb3e2507429$export$f25ed0e1b53c5d37));
const $28970d85181d1a3a$var$createConvolverNodeRenderer = (0, $f3ffd1bf4bfdfd06$export$5b278ccdb1a6393)($28970d85181d1a3a$var$createNativeConvolverNode, (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$renderInputsOfAudioNode);
const $28970d85181d1a3a$export$20cfee6cb9c5d644 = (0, $391774b3d5d015d0$export$4894173a4b4ee485)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createConvolverNodeRenderer, $28970d85181d1a3a$var$createNativeConvolverNode, $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext, $28970d85181d1a3a$var$setAudioNodeTailTime);
const $28970d85181d1a3a$var$createDelayNodeRenderer = (0, $6968cde2bce7c88d$export$d03c2308083a28e5)($28970d85181d1a3a$var$connectAudioParam, (0, $823fb61947f30fc5$export$f7dd6d407a2109ef), (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$renderAutomation, $28970d85181d1a3a$var$renderInputsOfAudioNode);
const $28970d85181d1a3a$export$ce8664483cc583db = (0, $891c129c739fee1a$export$b89a0215c1c607e3)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createAudioParam, $28970d85181d1a3a$var$createDelayNodeRenderer, (0, $823fb61947f30fc5$export$f7dd6d407a2109ef), $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext, $28970d85181d1a3a$var$setAudioNodeTailTime);
const $28970d85181d1a3a$var$createNativeDynamicsCompressorNode = (0, $1634e82587ef6934$export$f19d90a0cd4a2ecc)((0, $724da61d5e6b149b$export$dbebdb13622d486c));
const $28970d85181d1a3a$var$createDynamicsCompressorNodeRenderer = (0, $ba58754860d16983$export$1b1e82cc3f0a2c8)($28970d85181d1a3a$var$connectAudioParam, $28970d85181d1a3a$var$createNativeDynamicsCompressorNode, (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$renderAutomation, $28970d85181d1a3a$var$renderInputsOfAudioNode);
const $28970d85181d1a3a$export$c74a663d797d02ba = (0, $bf0956ea33de903c$export$60ec6725c2d45fc8)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createAudioParam, $28970d85181d1a3a$var$createDynamicsCompressorNodeRenderer, $28970d85181d1a3a$var$createNativeDynamicsCompressorNode, (0, $724da61d5e6b149b$export$dbebdb13622d486c), $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext, $28970d85181d1a3a$var$setAudioNodeTailTime);
const $28970d85181d1a3a$var$createGainNodeRenderer = (0, $0521b0be5b77d36f$export$7312404e5bea9cd)($28970d85181d1a3a$var$connectAudioParam, (0, $71f48eec1b56edf3$export$7cf909169b9c4d6f), (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$renderAutomation, $28970d85181d1a3a$var$renderInputsOfAudioNode);
const $28970d85181d1a3a$export$db147ea22bd7e3ce = (0, $b09df3934a68d1ac$export$7b37b693b55bf5d7)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createAudioParam, $28970d85181d1a3a$var$createGainNodeRenderer, (0, $71f48eec1b56edf3$export$7cf909169b9c4d6f), $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext);
const $28970d85181d1a3a$var$createNativeIIRFilterNodeFaker = (0, $116fcdd65e044d11$export$49dca6a724f463b)((0, $365f5e3658bdb1fe$export$254c536c2ca9b917), (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), (0, $de474b62d5dbb70a$export$9f784f497a6d6acb), (0, $724da61d5e6b149b$export$dbebdb13622d486c));
const $28970d85181d1a3a$var$renderNativeOfflineAudioContext = (0, $2485ca71b88aec2b$export$feb8d4a8e403af48)($28970d85181d1a3a$var$cacheTestResult, (0, $71f48eec1b56edf3$export$7cf909169b9c4d6f), (0, $de474b62d5dbb70a$export$9f784f497a6d6acb), (0, $1f9bfe39fc10c854$export$6db7e9dd49157213)((0, $71f48eec1b56edf3$export$7cf909169b9c4d6f), $28970d85181d1a3a$var$nativeOfflineAudioContextConstructor));
const $28970d85181d1a3a$var$createIIRFilterNodeRenderer = (0, $9a90b3aeee504dd7$export$329316f0ca6cf17e)($28970d85181d1a3a$var$createNativeAudioBufferSourceNode, (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$nativeOfflineAudioContextConstructor, $28970d85181d1a3a$var$renderInputsOfAudioNode, $28970d85181d1a3a$var$renderNativeOfflineAudioContext);
const $28970d85181d1a3a$var$createNativeIIRFilterNode = (0, $28ba387b3ce04508$export$3c1aed24ed6efd9d)($28970d85181d1a3a$var$createNativeIIRFilterNodeFaker);
const $28970d85181d1a3a$export$81c00f34825a7708 = (0, $f187530af5fffe8c$export$a22f1eb785a05608)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createNativeIIRFilterNode, $28970d85181d1a3a$var$createIIRFilterNodeRenderer, $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext, $28970d85181d1a3a$var$setAudioNodeTailTime);
const $28970d85181d1a3a$var$createAudioListener = (0, $28f8df2bee08a6f8$export$3e70692c55bd5b52)($28970d85181d1a3a$var$createAudioParam, $28970d85181d1a3a$var$createNativeChannelMergerNode, $28970d85181d1a3a$var$createNativeConstantSourceNode, (0, $de474b62d5dbb70a$export$9f784f497a6d6acb), (0, $724da61d5e6b149b$export$dbebdb13622d486c), (0, $310b27ad9883fbff$export$4ec0c13c358eb2b5), $28970d85181d1a3a$var$isNativeOfflineAudioContext, (0, $5c1d1cb3e2507429$export$f25ed0e1b53c5d37));
const $28970d85181d1a3a$var$unrenderedAudioWorkletNodeStore = new WeakMap();
const $28970d85181d1a3a$var$minimalBaseAudioContextConstructor = (0, $8473550d2b626bca$export$3f49d9c870ba2692)($28970d85181d1a3a$var$audioDestinationNodeConstructor, $28970d85181d1a3a$var$createAudioListener, $28970d85181d1a3a$var$eventTargetConstructor, $28970d85181d1a3a$var$isNativeOfflineAudioContext, $28970d85181d1a3a$var$unrenderedAudioWorkletNodeStore, (0, $2e02501193eee810$export$63f14ca2e716ed28));
const $28970d85181d1a3a$var$createNativeOscillatorNode = (0, $1e109504cb557d07$export$a40e02c218ae01d3)($28970d85181d1a3a$var$addSilentConnection, $28970d85181d1a3a$var$cacheTestResult, (0, $6e4098b3ea8ada29$export$9be334adb9176c59), (0, $18f136752ba69d33$export$a7f1019c14a08879), (0, $cec3d2119afa7026$export$67a72517a9facc5), (0, $29a51da6a1953a8a$export$587074127be31245));
const $28970d85181d1a3a$var$createOscillatorNodeRenderer = (0, $6def87b551bd6da0$export$99143538b3590be5)($28970d85181d1a3a$var$connectAudioParam, $28970d85181d1a3a$var$createNativeOscillatorNode, (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$renderAutomation, $28970d85181d1a3a$var$renderInputsOfAudioNode);
const $28970d85181d1a3a$export$f44e83cdc55961f2 = (0, $a62880cbf04a4a17$export$c1c3584074b042b3)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createAudioParam, $28970d85181d1a3a$var$createNativeOscillatorNode, $28970d85181d1a3a$var$createOscillatorNodeRenderer, $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext, (0, $2e02501193eee810$export$63f14ca2e716ed28));
const $28970d85181d1a3a$var$createConnectedNativeAudioBufferSourceNode = (0, $5a894e221bf91800$export$e82b2b63ea82dc82)($28970d85181d1a3a$var$createNativeAudioBufferSourceNode);
const $28970d85181d1a3a$var$createNativeWaveShaperNodeFaker = (0, $0f28b6d4737c93a6$export$f5f0b26abc22907e)($28970d85181d1a3a$var$createConnectedNativeAudioBufferSourceNode, (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), (0, $71f48eec1b56edf3$export$7cf909169b9c4d6f), (0, $c10ae02b5c342862$export$b32eba1f356dc699), $28970d85181d1a3a$var$monitorConnections);
const $28970d85181d1a3a$var$createNativeWaveShaperNode = (0, $f3b47b1ee9b886b8$export$75168c4c8ce320c4)($28970d85181d1a3a$var$createConnectedNativeAudioBufferSourceNode, (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), $28970d85181d1a3a$var$createNativeWaveShaperNodeFaker, (0, $c10ae02b5c342862$export$b32eba1f356dc699), $28970d85181d1a3a$var$monitorConnections, $28970d85181d1a3a$var$nativeAudioContextConstructor, (0, $5c1d1cb3e2507429$export$f25ed0e1b53c5d37));
const $28970d85181d1a3a$var$createNativePannerNodeFaker = (0, $38050e19c37591ce$export$f04468477689c1b4)((0, $9561d33b242cedb0$export$b92162b3199b4461), (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), $28970d85181d1a3a$var$createNativeChannelMergerNode, (0, $71f48eec1b56edf3$export$7cf909169b9c4d6f), (0, $de474b62d5dbb70a$export$9f784f497a6d6acb), $28970d85181d1a3a$var$createNativeWaveShaperNode, (0, $724da61d5e6b149b$export$dbebdb13622d486c), (0, $147c083052099f38$export$a19b495df4b88921), (0, $310b27ad9883fbff$export$4ec0c13c358eb2b5), $28970d85181d1a3a$var$monitorConnections);
const $28970d85181d1a3a$var$createNativePannerNode = (0, $67e03e834ff263c9$export$8e3c89af72a58833)($28970d85181d1a3a$var$createNativePannerNodeFaker);
const $28970d85181d1a3a$var$createPannerNodeRenderer = (0, $e0ac4d195ddcf52f$export$ccd091498494025)($28970d85181d1a3a$var$connectAudioParam, $28970d85181d1a3a$var$createNativeChannelMergerNode, $28970d85181d1a3a$var$createNativeConstantSourceNode, (0, $71f48eec1b56edf3$export$7cf909169b9c4d6f), $28970d85181d1a3a$var$createNativePannerNode, (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$nativeOfflineAudioContextConstructor, $28970d85181d1a3a$var$renderAutomation, $28970d85181d1a3a$var$renderInputsOfAudioNode, $28970d85181d1a3a$var$renderNativeOfflineAudioContext);
const $28970d85181d1a3a$export$dafa2f26c98332af = (0, $eeaadc307a57ff75$export$91b046021cf98bac)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createAudioParam, $28970d85181d1a3a$var$createNativePannerNode, $28970d85181d1a3a$var$createPannerNodeRenderer, $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext, $28970d85181d1a3a$var$setAudioNodeTailTime);
const $28970d85181d1a3a$var$createNativePeriodicWave = (0, $5dddcd8afd51ba39$export$3f519524c23feca0)((0, $5e22421cd58df859$export$926e4aa3eed6ec13));
const $28970d85181d1a3a$export$6b71e63ac9d62aa3 = (0, $6a9b3836ffa94976$export$10e47cfa48a5069d)($28970d85181d1a3a$var$createNativePeriodicWave, $28970d85181d1a3a$var$getNativeContext, new WeakSet(), (0, $768ab8b80a1487b1$export$833c872c8eda5015));
const $28970d85181d1a3a$var$nativeStereoPannerNodeFakerFactory = (0, $8b47882dc0c94faf$export$5fe2a787c06b2d34)($28970d85181d1a3a$var$createNativeChannelMergerNode, (0, $bc9026dcb0dcb567$export$17649533bf213707), (0, $71f48eec1b56edf3$export$7cf909169b9c4d6f), $28970d85181d1a3a$var$createNativeWaveShaperNode, (0, $724da61d5e6b149b$export$dbebdb13622d486c), $28970d85181d1a3a$var$monitorConnections);
const $28970d85181d1a3a$var$createNativeStereoPannerNode = (0, $c9529036294e4e7d$export$247580dcf7d2f2c4)($28970d85181d1a3a$var$nativeStereoPannerNodeFakerFactory, (0, $724da61d5e6b149b$export$dbebdb13622d486c));
const $28970d85181d1a3a$var$createStereoPannerNodeRenderer = (0, $5180ef9c3864dba3$export$3ba9002bd6b539cf)($28970d85181d1a3a$var$connectAudioParam, $28970d85181d1a3a$var$createNativeStereoPannerNode, (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$renderAutomation, $28970d85181d1a3a$var$renderInputsOfAudioNode);
const $28970d85181d1a3a$export$4ee0e4c1628c69a6 = (0, $bae493c300dc0e65$export$9b005b0c35721c84)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createAudioParam, $28970d85181d1a3a$var$createNativeStereoPannerNode, $28970d85181d1a3a$var$createStereoPannerNodeRenderer, $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext);
const $28970d85181d1a3a$var$createWaveShaperNodeRenderer = (0, $9a6b6ebbfdaceba8$export$9709a48a5037d121)($28970d85181d1a3a$var$createNativeWaveShaperNode, (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$renderInputsOfAudioNode);
const $28970d85181d1a3a$export$400071720810ca26 = (0, $f3731b078b33221f$export$3a30e911e17b1cf5)($28970d85181d1a3a$var$audioNodeConstructor, (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), $28970d85181d1a3a$var$createNativeWaveShaperNode, $28970d85181d1a3a$var$createWaveShaperNodeRenderer, $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext, $28970d85181d1a3a$var$setAudioNodeTailTime);
const $28970d85181d1a3a$var$isSecureContext = (0, $846a59dfb4657901$export$2e9a7e6b17a9abae)($28970d85181d1a3a$var$window);
const $28970d85181d1a3a$var$exposeCurrentFrameAndCurrentTime = (0, $a049692fe9048d3a$export$c43b8ab5e8913cbb)($28970d85181d1a3a$var$window);
const $28970d85181d1a3a$var$backupOfflineAudioContextStore = new WeakMap();
const $28970d85181d1a3a$var$getOrCreateBackupOfflineAudioContext = (0, $e6d091ae8e3fe914$export$70df0ae42e1340c8)($28970d85181d1a3a$var$backupOfflineAudioContextStore, $28970d85181d1a3a$var$nativeOfflineAudioContextConstructor);
const $28970d85181d1a3a$export$f820757b6d3df312 = $28970d85181d1a3a$var$isSecureContext ? (0, $6cf8f231e9742452$export$16c6049a33c70efa)($28970d85181d1a3a$var$cacheTestResult, (0, $724da61d5e6b149b$export$dbebdb13622d486c), (0, $580f414c25754405$export$43b563d089dd1d8)($28970d85181d1a3a$var$window), $28970d85181d1a3a$var$exposeCurrentFrameAndCurrentTime, (0, $8f1fddea8d9746a6$export$c7282a393375a8ca)((0, $e20fccd48d473655$export$aff31bd5258e9fd4)), $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$getOrCreateBackupOfflineAudioContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext, $28970d85181d1a3a$var$nativeAudioWorkletNodeConstructor, new WeakMap(), new WeakMap(), (0, $5bb20e3ade2fe5eb$export$19b2cf184a7cfba8)($28970d85181d1a3a$var$nativeAudioWorkletNodeConstructor, $28970d85181d1a3a$var$nativeOfflineAudioContextConstructor), // @todo window is guaranteed to be defined because isSecureContext checks that as well.
$28970d85181d1a3a$var$window) : undefined;
const $28970d85181d1a3a$var$isNativeContext = (0, $5d79ae3733f1a816$export$a7c969701e5471d0)($28970d85181d1a3a$var$isNativeAudioContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext);
const $28970d85181d1a3a$export$1fbfb80f24dc90ea = (0, $3c9f526d1dcde320$export$d83e4a6039bccfb)($28970d85181d1a3a$var$audioBufferStore, $28970d85181d1a3a$var$cacheTestResult, (0, $90aaf2df262a09a1$export$fc1a599a84ca01a8), (0, $c6480c21a9b77362$export$6372d3d9069bc778), new WeakSet(), $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeContext, (0, $ab7234a0e06cc19b$export$54e424f510c54ced), (0, $02e438f09c588964$export$9ec44223b1284cd4), $28970d85181d1a3a$var$wrapAudioBufferCopyChannelMethods, $28970d85181d1a3a$var$wrapAudioBufferCopyChannelMethodsOutOfBounds);
const $28970d85181d1a3a$var$baseAudioContextConstructor = (0, $3b9761fb51dbb0f5$export$7824d6f4713e1e35)($28970d85181d1a3a$export$f820757b6d3df312, $28970d85181d1a3a$export$ed204192bbbabcef, $28970d85181d1a3a$export$2dbca7d91f7769d7, $28970d85181d1a3a$export$c1b1480edd16e065, $28970d85181d1a3a$export$f068340fbfd684eb, $28970d85181d1a3a$export$7488bfd772ec10fc, $28970d85181d1a3a$export$6f860927b3cf75c1, $28970d85181d1a3a$export$d394f3dc072b3480, $28970d85181d1a3a$export$20cfee6cb9c5d644, $28970d85181d1a3a$export$1fbfb80f24dc90ea, $28970d85181d1a3a$export$ce8664483cc583db, $28970d85181d1a3a$export$c74a663d797d02ba, $28970d85181d1a3a$export$db147ea22bd7e3ce, $28970d85181d1a3a$export$81c00f34825a7708, $28970d85181d1a3a$var$minimalBaseAudioContextConstructor, $28970d85181d1a3a$export$f44e83cdc55961f2, $28970d85181d1a3a$export$dafa2f26c98332af, $28970d85181d1a3a$export$6b71e63ac9d62aa3, $28970d85181d1a3a$export$4ee0e4c1628c69a6, $28970d85181d1a3a$export$400071720810ca26);
const $28970d85181d1a3a$export$cbdfd9619c90296e = (0, $7e54bbea88042f73$export$d24d3af0853fd021)($28970d85181d1a3a$var$audioNodeConstructor, (0, $ba0f7b60145e25d7$export$2b1682bf41b4d16b), $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext);
const $28970d85181d1a3a$export$3ebbc22363b821ba = (0, $8d43c0fa51667b8e$export$5d3ee2470cd2874)($28970d85181d1a3a$var$audioNodeConstructor, (0, $9410eeed5fd8d656$export$acb51039efa3405d), $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext);
const $28970d85181d1a3a$export$57f554392102e4c0 = (0, $3f763324265efb18$export$a42e10687df73a9d)($28970d85181d1a3a$var$audioNodeConstructor, (0, $7397b291c753f419$export$ad3e497ef44fc577), $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext);
const $28970d85181d1a3a$var$createNativeMediaStreamTrackAudioSourceNode = (0, $adf577b329eb4b9c$export$87e46bc6eb8ed6ac)((0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), $28970d85181d1a3a$var$isNativeOfflineAudioContext);
const $28970d85181d1a3a$export$b6c8ffccaed2d826 = (0, $7a9eb73582b65b9c$export$24f27d34fdf823bc)($28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createNativeMediaStreamTrackAudioSourceNode, $28970d85181d1a3a$var$getNativeContext);
const $28970d85181d1a3a$export$fcbc63750ec2a81f = (0, $d05f510371680fae$export$c6fe175def53ff71)($28970d85181d1a3a$var$baseAudioContextConstructor, (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), (0, $724da61d5e6b149b$export$dbebdb13622d486c), (0, $03c74873b1e908cf$export$988fb803bae63f80), $28970d85181d1a3a$export$cbdfd9619c90296e, $28970d85181d1a3a$export$3ebbc22363b821ba, $28970d85181d1a3a$export$57f554392102e4c0, $28970d85181d1a3a$export$b6c8ffccaed2d826, $28970d85181d1a3a$var$nativeAudioContextConstructor);
const $28970d85181d1a3a$var$getUnrenderedAudioWorkletNodes = (0, $1c2a4b9507caf1a4$export$43ef7eb1ae3d2f40)($28970d85181d1a3a$var$unrenderedAudioWorkletNodeStore);
const $28970d85181d1a3a$var$addUnrenderedAudioWorkletNode = (0, $f316e86eecb60d34$export$fd0136b1517d036f)($28970d85181d1a3a$var$getUnrenderedAudioWorkletNodes);
const $28970d85181d1a3a$var$connectMultipleOutputs = (0, $f29cfd6579875e35$export$5f708e50316bf1a)((0, $5e22421cd58df859$export$926e4aa3eed6ec13));
const $28970d85181d1a3a$var$deleteUnrenderedAudioWorkletNode = (0, $e9000ac5eec278e9$export$92df121abbf21dca)($28970d85181d1a3a$var$getUnrenderedAudioWorkletNodes);
const $28970d85181d1a3a$var$disconnectMultipleOutputs = (0, $0dde459ead155eae$export$78a992fad11cd00e)((0, $5e22421cd58df859$export$926e4aa3eed6ec13));
const $28970d85181d1a3a$var$activeAudioWorkletNodeInputsStore = new WeakMap();
const $28970d85181d1a3a$var$getActiveAudioWorkletNodeInputs = (0, $f563f21289bb8166$export$8b01844840684f8d)($28970d85181d1a3a$var$activeAudioWorkletNodeInputsStore, (0, $838ea8ed33d27e81$export$520987e3ff3ffad3));
const $28970d85181d1a3a$var$createNativeAudioWorkletNodeFaker = (0, $16898f3baaba3ba9$export$ea40f9f600f0adcb)($28970d85181d1a3a$var$connectMultipleOutputs, (0, $5e22421cd58df859$export$926e4aa3eed6ec13), (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), $28970d85181d1a3a$var$createNativeChannelMergerNode, (0, $bc9026dcb0dcb567$export$17649533bf213707), $28970d85181d1a3a$var$createNativeConstantSourceNode, (0, $71f48eec1b56edf3$export$7cf909169b9c4d6f), (0, $de474b62d5dbb70a$export$9f784f497a6d6acb), (0, $724da61d5e6b149b$export$dbebdb13622d486c), $28970d85181d1a3a$var$disconnectMultipleOutputs, $28970d85181d1a3a$var$exposeCurrentFrameAndCurrentTime, $28970d85181d1a3a$var$getActiveAudioWorkletNodeInputs, $28970d85181d1a3a$var$monitorConnections);
const $28970d85181d1a3a$var$createNativeAudioWorkletNode = (0, $05daef3b9aca3079$export$a6399b47836cd044)((0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), $28970d85181d1a3a$var$createNativeAudioWorkletNodeFaker, (0, $71f48eec1b56edf3$export$7cf909169b9c4d6f), (0, $724da61d5e6b149b$export$dbebdb13622d486c), $28970d85181d1a3a$var$monitorConnections);
const $28970d85181d1a3a$var$createAudioWorkletNodeRenderer = (0, $73e5f5f4a9d714e0$export$3a898af5d2b29a5b)($28970d85181d1a3a$var$connectAudioParam, $28970d85181d1a3a$var$connectMultipleOutputs, $28970d85181d1a3a$var$createNativeAudioBufferSourceNode, $28970d85181d1a3a$var$createNativeChannelMergerNode, (0, $bc9026dcb0dcb567$export$17649533bf213707), $28970d85181d1a3a$var$createNativeConstantSourceNode, (0, $71f48eec1b56edf3$export$7cf909169b9c4d6f), $28970d85181d1a3a$var$deleteUnrenderedAudioWorkletNode, $28970d85181d1a3a$var$disconnectMultipleOutputs, $28970d85181d1a3a$var$exposeCurrentFrameAndCurrentTime, (0, $91004965fac1b491$export$e719c0d45ea16d08), $28970d85181d1a3a$var$nativeAudioWorkletNodeConstructor, $28970d85181d1a3a$var$nativeOfflineAudioContextConstructor, $28970d85181d1a3a$var$renderAutomation, $28970d85181d1a3a$var$renderInputsOfAudioNode, $28970d85181d1a3a$var$renderNativeOfflineAudioContext);
const $28970d85181d1a3a$var$getBackupOfflineAudioContext = (0, $32c25768643dbcd8$export$afecf147821b5609)($28970d85181d1a3a$var$backupOfflineAudioContextStore);
const $28970d85181d1a3a$var$setActiveAudioWorkletNodeInputs = (0, $9da34cc622e4cda2$export$17328c9508de4388)($28970d85181d1a3a$var$activeAudioWorkletNodeInputsStore);
// The AudioWorkletNode constructor is only available in a SecureContext.
const $28970d85181d1a3a$export$bc6715221481535 = $28970d85181d1a3a$var$isSecureContext ? (0, $4887df8ecec6be4d$export$48302d37fa2cf062)($28970d85181d1a3a$var$addUnrenderedAudioWorkletNode, $28970d85181d1a3a$var$audioNodeConstructor, $28970d85181d1a3a$var$createAudioParam, $28970d85181d1a3a$var$createAudioWorkletNodeRenderer, $28970d85181d1a3a$var$createNativeAudioWorkletNode, (0, $82132aac47394666$export$6b29eee2af836dfc), $28970d85181d1a3a$var$getBackupOfflineAudioContext, $28970d85181d1a3a$var$getNativeContext, $28970d85181d1a3a$var$isNativeOfflineAudioContext, $28970d85181d1a3a$var$nativeAudioWorkletNodeConstructor, (0, $b75e1a3ebb977a47$export$9a47aefcb4b02450), $28970d85181d1a3a$var$setActiveAudioWorkletNodeInputs, (0, $73083767f13a3af7$export$a40748749fc273c5), (0, $2e02501193eee810$export$63f14ca2e716ed28)) : undefined;
const $28970d85181d1a3a$export$898a44341df73d6e = (0, $257e38a5716f492b$export$8a5e66f668b2e9e8)((0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), (0, $724da61d5e6b149b$export$dbebdb13622d486c), (0, $03c74873b1e908cf$export$988fb803bae63f80), $28970d85181d1a3a$var$minimalBaseAudioContextConstructor, $28970d85181d1a3a$var$nativeAudioContextConstructor);
const $28970d85181d1a3a$var$createNativeOfflineAudioContext = (0, $358421f0a53ddf49$export$ab44e304a31eb0ae)((0, $724da61d5e6b149b$export$dbebdb13622d486c), $28970d85181d1a3a$var$nativeOfflineAudioContextConstructor);
const $28970d85181d1a3a$var$startRendering = (0, $5e42c82d70af5757$export$a04cd80dfb1b8309)($28970d85181d1a3a$var$audioBufferStore, $28970d85181d1a3a$var$cacheTestResult, $28970d85181d1a3a$var$getAudioNodeRenderer, $28970d85181d1a3a$var$getUnrenderedAudioWorkletNodes, $28970d85181d1a3a$var$renderNativeOfflineAudioContext, (0, $ab7234a0e06cc19b$export$54e424f510c54ced), $28970d85181d1a3a$var$wrapAudioBufferCopyChannelMethods, $28970d85181d1a3a$var$wrapAudioBufferCopyChannelMethodsOutOfBounds);
const $28970d85181d1a3a$export$a6f995d32126fe2e = (0, $b2d360608fd94c64$export$3d487af37fe7f521)($28970d85181d1a3a$var$cacheTestResult, (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), $28970d85181d1a3a$var$createNativeOfflineAudioContext, $28970d85181d1a3a$var$minimalBaseAudioContextConstructor, $28970d85181d1a3a$var$startRendering);
const $28970d85181d1a3a$export$5ab5c649a10df7db = (0, $71cd54f99465e1c1$export$a9b5caf52b398870)($28970d85181d1a3a$var$baseAudioContextConstructor, $28970d85181d1a3a$var$cacheTestResult, (0, $12252263e7ea8a6f$export$5a1c4cd5830ea09b), $28970d85181d1a3a$var$createNativeOfflineAudioContext, $28970d85181d1a3a$var$startRendering);
const $28970d85181d1a3a$export$e55e427bf52f793d = (0, $04e2826196eab8ca$export$7030a6f3318876b)((0, $45092aa0415316c7$export$7d17302229276f06), $28970d85181d1a3a$var$isNativeAudioContext);
const $28970d85181d1a3a$export$61ea8ea4691b9a32 = (0, $3adf3251cc26ee23$export$150a35c855945f9d)((0, $45092aa0415316c7$export$864a3cfb55580d0c), $28970d85181d1a3a$var$isNativeAudioNode);
const $28970d85181d1a3a$export$254dcc24b342c8c2 = (0, $111a900d3117bb7d$export$41505fc8888255a0)((0, $45092aa0415316c7$export$55484e3055c7a9e2), $28970d85181d1a3a$var$isNativeAudioParam);
const $28970d85181d1a3a$export$e78994f7990ad5d3 = (0, $fa6a37efafacc48d$export$845691ce8ebc2907)((0, $45092aa0415316c7$export$7d17302229276f06), $28970d85181d1a3a$var$isNativeOfflineAudioContext);
const $28970d85181d1a3a$export$48c17662a6902497 = ()=>(0, $0a2afdc8e1fe81ef$export$a245ecb43f54c4de)($28970d85181d1a3a$var$cacheTestResult, (0, $4a9a939c1d9c567b$export$1995b5466f5c2709)($28970d85181d1a3a$var$nativeOfflineAudioContextConstructor), (0, $c4ab0dbb21ad8d31$export$34981ee6aafdf532)($28970d85181d1a3a$var$nativeAudioContextConstructor), (0, $991718564e974f22$export$622ba23aa6b35822)($28970d85181d1a3a$var$nativeOfflineAudioContextConstructor), (0, $b2770317539a3239$export$2f44088abd2df2e)($28970d85181d1a3a$var$nativeAudioContextConstructor), (0, $79b9931130d468d6$export$f77a3bce7e4efd81)($28970d85181d1a3a$var$nativeOfflineAudioContextConstructor), (0, $c0d11c72041d312f$export$ce5ba80a98dc0ba7)($28970d85181d1a3a$var$nativeAudioWorkletNodeConstructor, $28970d85181d1a3a$var$nativeOfflineAudioContextConstructor), (0, $b06628055a1150da$export$a04037cfe0b977fa)($28970d85181d1a3a$var$nativeOfflineAudioContextConstructor), (0, $384e72ffdc0fd648$export$63ae3ec177f0ed66)($28970d85181d1a3a$var$nativeOfflineAudioContextConstructor), (0, $3eca900f24929922$export$b6f3c4027f959b95)($28970d85181d1a3a$var$nativeOfflineAudioContextConstructor), (0, $1dafc4ed43e766f7$export$d1bddb88e5c21d26)($28970d85181d1a3a$var$nativeOfflineAudioContextConstructor), (0, $59b776ff57894eb4$export$1310f0b96d9d8115), (0, $7c947a2416b94687$export$41669e689e17d4f0)($28970d85181d1a3a$var$window), (0, $f0b6df9dd6a9c594$export$416bb3b14425e126)($28970d85181d1a3a$var$nativeAudioContextConstructor), (0, $75aebf71b38e1e06$export$5ea70af76c7a03fc)($28970d85181d1a3a$var$nativeOfflineAudioContextConstructor), (0, $9c33322f03b96319$export$4f6e0d4bb1ead9ce));


function $23cf54af36cc9441$export$a7a9523472993e97(statement, error) {
    if (!statement) throw new Error(error);
}
function $23cf54af36cc9441$export$6698b6d148bc9b0c(value, gte, lte = Infinity) {
    if (!(gte <= value && value <= lte)) throw new RangeError(`Value must be within [${gte}, ${lte}], got: ${value}`);
}
function $23cf54af36cc9441$export$8ef1ce44f93c2687(context) {
    // add a warning if the context is not started
    if (!context.isOffline && context.state !== "running") $23cf54af36cc9441$export$c106dd0671a0fc2d('The AudioContext is "suspended". Invoke Tone.start() from a user action to start the audio.');
}
/**
 * The default logger is the console
 */ let $23cf54af36cc9441$var$defaultLogger = console;
function $23cf54af36cc9441$export$3abbd92f765bee58(logger) {
    $23cf54af36cc9441$var$defaultLogger = logger;
}
function $23cf54af36cc9441$export$bef1f36f5486a6a3(...args) {
    $23cf54af36cc9441$var$defaultLogger.log(...args);
}
function $23cf54af36cc9441$export$c106dd0671a0fc2d(...args) {
    $23cf54af36cc9441$var$defaultLogger.warn(...args);
}


function $b63b9a75cba601b0$export$eb605f91c5895a5b(arg) {
    return typeof arg === "undefined";
}
function $b63b9a75cba601b0$export$4e62c701997796c1(arg) {
    return !$b63b9a75cba601b0$export$eb605f91c5895a5b(arg);
}
function $b63b9a75cba601b0$export$f6e2535fb5126e54(arg) {
    return typeof arg === "function";
}
function $b63b9a75cba601b0$export$7e4aa119212bc614(arg) {
    return typeof arg === "number";
}
function $b63b9a75cba601b0$export$a6cdc56e425d0d0a(arg) {
    return Object.prototype.toString.call(arg) === "[object Object]" && arg.constructor === Object;
}
function $b63b9a75cba601b0$export$f9ce7b637dfbe238(arg) {
    return typeof arg === "boolean";
}
function $b63b9a75cba601b0$export$43bee75e5e14138e(arg) {
    return Array.isArray(arg);
}
function $b63b9a75cba601b0$export$844ec244b1367d54(arg) {
    return typeof arg === "string";
}
function $b63b9a75cba601b0$export$4dcca4501f2037f9(arg) {
    return $b63b9a75cba601b0$export$844ec244b1367d54(arg) && /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i.test(arg);
}



function $4d32d9be36060d13$export$9e09b0a77eebe103(options) {
    return new (0, $28970d85181d1a3a$export$fcbc63750ec2a81f)(options);
}
function $4d32d9be36060d13$export$b7df220975ff4035(channels, length, sampleRate) {
    return new (0, $28970d85181d1a3a$export$5ab5c649a10df7db)(channels, length, sampleRate);
}
const $4d32d9be36060d13$export$a3ddad83b7a6ba2 = typeof self === "object" ? self : null;
const $4d32d9be36060d13$export$50898d6dff7e65a3 = $4d32d9be36060d13$export$a3ddad83b7a6ba2 && ($4d32d9be36060d13$export$a3ddad83b7a6ba2.hasOwnProperty("AudioContext") || $4d32d9be36060d13$export$a3ddad83b7a6ba2.hasOwnProperty("webkitAudioContext"));
function $4d32d9be36060d13$export$f2cca0e3f6d50e11(context, name, options) {
    (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $b63b9a75cba601b0$export$4e62c701997796c1)((0, $28970d85181d1a3a$export$bc6715221481535)), "This node only works in a secure context (https or localhost)");
    // @ts-ignore
    return new (0, $28970d85181d1a3a$export$bc6715221481535)(context, name, options);
}


/*! *****************************************************************************
Copyright (c) Microsoft Corporation.

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.
***************************************************************************** */ /* global Reflect, Promise */ var $a522a8f63c306c1c$var$extendStatics = function(d1, b1) {
    $a522a8f63c306c1c$var$extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d, b) {
        d.__proto__ = b;
    } || function(d, b) {
        for(var p in b)if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];
    };
    return $a522a8f63c306c1c$var$extendStatics(d1, b1);
};
function $a522a8f63c306c1c$export$a8ba968b8961cb8a(d, b) {
    if (typeof b !== "function" && b !== null) throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
    $a522a8f63c306c1c$var$extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
var $a522a8f63c306c1c$export$18ce0697a983be9b = function() {
    $a522a8f63c306c1c$export$18ce0697a983be9b = Object.assign || function __assign(t) {
        for(var s, i = 1, n = arguments.length; i < n; i++){
            s = arguments[i];
            for(var p in s)if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];
        }
        return t;
    };
    return $a522a8f63c306c1c$export$18ce0697a983be9b.apply(this, arguments);
};
function $a522a8f63c306c1c$export$3c9a16f847548506(s, e) {
    var t = {};
    for(var p in s)if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0) t[p] = s[p];
    if (s != null && typeof Object.getOwnPropertySymbols === "function") {
        for(var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++)if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i])) t[p[i]] = s[p[i]];
    }
    return t;
}
function $a522a8f63c306c1c$export$29e00dfd3077644b(decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for(var i = decorators.length - 1; i >= 0; i--)if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
}
function $a522a8f63c306c1c$export$d5ad3fd78186038f(paramIndex, decorator) {
    return function(target, key) {
        decorator(target, key, paramIndex);
    };
}
function $a522a8f63c306c1c$export$f1db080c865becb9(metadataKey, metadataValue) {
    if (typeof Reflect === "object" && typeof Reflect.metadata === "function") return Reflect.metadata(metadataKey, metadataValue);
}
function $a522a8f63c306c1c$export$1050f835b63b671e(thisArg, _arguments, P, generator) {
    function adopt(value) {
        return value instanceof P ? value : new P(function(resolve) {
            resolve(value);
        });
    }
    return new (P || (P = Promise))(function(resolve, reject) {
        function fulfilled(value) {
            try {
                step(generator.next(value));
            } catch (e) {
                reject(e);
            }
        }
        function rejected(value) {
            try {
                step(generator["throw"](value));
            } catch (e) {
                reject(e);
            }
        }
        function step(result) {
            result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
}
function $a522a8f63c306c1c$export$67ebef60e6f28a6(thisArg, body) {
    var _ = {
        label: 0,
        sent: function() {
            if (t[0] & 1) throw t[1];
            return t[1];
        },
        trys: [],
        ops: []
    }, f, y, t, g;
    return g = {
        next: verb(0),
        "throw": verb(1),
        "return": verb(2)
    }, typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
    }), g;
    function verb(n) {
        return function(v) {
            return step([
                n,
                v
            ]);
        };
    }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while(_)try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [
                op[0] & 2,
                t.value
            ];
            switch(op[0]){
                case 0:
                case 1:
                    t = op;
                    break;
                case 4:
                    _.label++;
                    return {
                        value: op[1],
                        done: false
                    };
                case 5:
                    _.label++;
                    y = op[1];
                    op = [
                        0
                    ];
                    continue;
                case 7:
                    op = _.ops.pop();
                    _.trys.pop();
                    continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {
                        _ = 0;
                        continue;
                    }
                    if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {
                        _.label = op[1];
                        break;
                    }
                    if (op[0] === 6 && _.label < t[1]) {
                        _.label = t[1];
                        t = op;
                        break;
                    }
                    if (t && _.label < t[2]) {
                        _.label = t[2];
                        _.ops.push(op);
                        break;
                    }
                    if (t[2]) _.ops.pop();
                    _.trys.pop();
                    continue;
            }
            op = body.call(thisArg, _);
        } catch (e) {
            op = [
                6,
                e
            ];
            y = 0;
        } finally{
            f = t = 0;
        }
        if (op[0] & 5) throw op[1];
        return {
            value: op[0] ? op[1] : void 0,
            done: true
        };
    }
}
var $a522a8f63c306c1c$export$45d3717a4c69092e = Object.create ? function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, {
        enumerable: true,
        get: function() {
            return m[k];
        }
    });
} : function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
};
function $a522a8f63c306c1c$export$f33643c0debef087(m, o) {
    for(var p in m)if (p !== "default" && !Object.prototype.hasOwnProperty.call(o, p)) $a522a8f63c306c1c$export$45d3717a4c69092e(o, m, p);
}
function $a522a8f63c306c1c$export$19a8beecd37a4c45(o) {
    var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
    if (m) return m.call(o);
    if (o && typeof o.length === "number") return {
        next: function() {
            if (o && i >= o.length) o = void 0;
            return {
                value: o && o[i++],
                done: !o
            };
        }
    };
    throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
}
function $a522a8f63c306c1c$export$8d051b38c9118094(o, n) {
    var m = typeof Symbol === "function" && o[Symbol.iterator];
    if (!m) return o;
    var i = m.call(o), r, ar = [], e;
    try {
        while((n === void 0 || n-- > 0) && !(r = i.next()).done)ar.push(r.value);
    } catch (error) {
        e = {
            error: error
        };
    } finally{
        try {
            if (r && !r.done && (m = i["return"])) m.call(i);
        } finally{
            if (e) throw e.error;
        }
    }
    return ar;
}
function $a522a8f63c306c1c$export$afc72e2116322959() {
    for(var ar = [], i = 0; i < arguments.length; i++)ar = ar.concat($a522a8f63c306c1c$export$8d051b38c9118094(arguments[i]));
    return ar;
}
function $a522a8f63c306c1c$export$6388937ca91ccae8() {
    for(var s = 0, i = 0, il = arguments.length; i < il; i++)s += arguments[i].length;
    for(var r = Array(s), k = 0, i = 0; i < il; i++)for(var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)r[k] = a[j];
    return r;
}
function $a522a8f63c306c1c$export$1216008129fb82ed(to, from, pack) {
    if (pack || arguments.length === 2) {
        for(var i = 0, l = from.length, ar; i < l; i++)if (ar || !(i in from)) {
            if (!ar) ar = Array.prototype.slice.call(from, 0, i);
            ar[i] = from[i];
        }
    }
    return to.concat(ar || Array.prototype.slice.call(from));
}
function $a522a8f63c306c1c$export$10c90e4f7922046c(v) {
    return this instanceof $a522a8f63c306c1c$export$10c90e4f7922046c ? (this.v = v, this) : new $a522a8f63c306c1c$export$10c90e4f7922046c(v);
}
function $a522a8f63c306c1c$export$e427f37a30a4de9b(thisArg, _arguments, generator) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var g = generator.apply(thisArg, _arguments || []), i, q = [];
    return i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function() {
        return this;
    }, i;
    function verb(n) {
        if (g[n]) i[n] = function(v) {
            return new Promise(function(a, b) {
                q.push([
                    n,
                    v,
                    a,
                    b
                ]) > 1 || resume(n, v);
            });
        };
    }
    function resume(n, v) {
        try {
            step(g[n](v));
        } catch (e) {
            settle(q[0][3], e);
        }
    }
    function step(r) {
        r.value instanceof $a522a8f63c306c1c$export$10c90e4f7922046c ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r);
    }
    function fulfill(value) {
        resume("next", value);
    }
    function reject(value) {
        resume("throw", value);
    }
    function settle(f, v) {
        if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]);
    }
}
function $a522a8f63c306c1c$export$bbd80228419bb833(o) {
    var i, p;
    return i = {}, verb("next"), verb("throw", function(e) {
        throw e;
    }), verb("return"), i[Symbol.iterator] = function() {
        return this;
    }, i;
    function verb(n, f) {
        i[n] = o[n] ? function(v) {
            return (p = !p) ? {
                value: $a522a8f63c306c1c$export$10c90e4f7922046c(o[n](v)),
                done: n === "return"
            } : f ? f(v) : v;
        } : f;
    }
}
function $a522a8f63c306c1c$export$e3b29a3d6162315f(o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator], i;
    return m ? m.call(o) : (o = typeof $a522a8f63c306c1c$export$19a8beecd37a4c45 === "function" ? $a522a8f63c306c1c$export$19a8beecd37a4c45(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function() {
        return this;
    }, i);
    function verb(n) {
        i[n] = o[n] && function(v) {
            return new Promise(function(resolve, reject) {
                v = o[n](v), settle(resolve, reject, v.done, v.value);
            });
        };
    }
    function settle(resolve, reject, d, v1) {
        Promise.resolve(v1).then(function(v) {
            resolve({
                value: v,
                done: d
            });
        }, reject);
    }
}
function $a522a8f63c306c1c$export$4fb47efe1390b86f(cooked, raw) {
    if (Object.defineProperty) Object.defineProperty(cooked, "raw", {
        value: raw
    });
    else cooked.raw = raw;
    return cooked;
}
var $a522a8f63c306c1c$var$__setModuleDefault = Object.create ? function(o, v) {
    Object.defineProperty(o, "default", {
        enumerable: true,
        value: v
    });
} : function(o, v) {
    o["default"] = v;
};
function $a522a8f63c306c1c$export$c21735bcef00d192(mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) {
        for(var k in mod)if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) $a522a8f63c306c1c$export$45d3717a4c69092e(result, mod, k);
    }
    $a522a8f63c306c1c$var$__setModuleDefault(result, mod);
    return result;
}
function $a522a8f63c306c1c$export$da59b14a69baef04(mod) {
    return mod && mod.__esModule ? mod : {
        default: mod
    };
}
function $a522a8f63c306c1c$export$d5dcaf168c640c35(receiver, state, kind, f) {
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
    return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
}
function $a522a8f63c306c1c$export$d40a35129aaff81f(receiver, state, value, kind, f) {
    if (kind === "m") throw new TypeError("Private method is not writable");
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a setter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot write private member to an object whose class did not declare it");
    return kind === "a" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value), value;
}


class $229eebcbdc37eb30$export$39c54bcc89dcee11 {
    constructor(callback, type, updateInterval){
        this._callback = callback;
        this._type = type;
        this._updateInterval = updateInterval;
        // create the clock source for the first time
        this._createClock();
    }
    /**
     * Generate a web worker
     */ _createWorker() {
        const blob = new Blob([
            /* javascript */ `
			// the initial timeout time
			let timeoutTime =  ${(this._updateInterval * 1000).toFixed(1)};
			// onmessage callback
			self.onmessage = function(msg){
				timeoutTime = parseInt(msg.data);
			};
			// the tick function which posts a message
			// and schedules a new tick
			function tick(){
				setTimeout(tick, timeoutTime);
				self.postMessage('tick');
			}
			// call tick initially
			tick();
			`
        ], {
            type: "text/javascript"
        });
        const blobUrl = URL.createObjectURL(blob);
        const worker = new Worker(blobUrl);
        worker.onmessage = this._callback.bind(this);
        this._worker = worker;
    }
    /**
     * Create a timeout loop
     */ _createTimeout() {
        this._timeout = setTimeout(()=>{
            this._createTimeout();
            this._callback();
        }, this._updateInterval * 1000);
    }
    /**
     * Create the clock source.
     */ _createClock() {
        if (this._type === "worker") try {
            this._createWorker();
        } catch (e) {
            // workers not supported, fallback to timeout
            this._type = "timeout";
            this._createClock();
        }
        else if (this._type === "timeout") this._createTimeout();
    }
    /**
     * Clean up the current clock source
     */ _disposeClock() {
        if (this._timeout) {
            clearTimeout(this._timeout);
            this._timeout = 0;
        }
        if (this._worker) {
            this._worker.terminate();
            this._worker.onmessage = null;
        }
    }
    /**
     * The rate in seconds the ticker will update
     */ get updateInterval() {
        return this._updateInterval;
    }
    set updateInterval(interval) {
        this._updateInterval = Math.max(interval, 128 / 44100);
        if (this._type === "worker") this._worker.postMessage(Math.max(interval * 1000, 1));
    }
    /**
     * The type of the ticker, either a worker or a timeout
     */ get type() {
        return this._type;
    }
    set type(type) {
        this._disposeClock();
        this._type = type;
        this._createClock();
    }
    /**
     * Clean up
     */ dispose() {
        this._disposeClock();
    }
}



function $ca1a79a064f4108f$export$1abe4e52803657f3(arg) {
    return (0, $28970d85181d1a3a$export$254dcc24b342c8c2)(arg);
}
function $ca1a79a064f4108f$export$85cd8e93eb858e81(arg) {
    return (0, $28970d85181d1a3a$export$61ea8ea4691b9a32)(arg);
}
function $ca1a79a064f4108f$export$539f87c8e5511243(arg) {
    return (0, $28970d85181d1a3a$export$e78994f7990ad5d3)(arg);
}
function $ca1a79a064f4108f$export$c46cbd835dc15c90(arg) {
    return (0, $28970d85181d1a3a$export$e55e427bf52f793d)(arg);
}
function $ca1a79a064f4108f$export$3cc2454c233bdc32(arg) {
    return arg instanceof AudioBuffer;
}




/**
 * Some objects should not be merged
 */ function $1e273b197c429402$var$noCopy(key, arg) {
    return key === "value" || (0, $ca1a79a064f4108f$export$1abe4e52803657f3)(arg) || (0, $ca1a79a064f4108f$export$85cd8e93eb858e81)(arg) || (0, $ca1a79a064f4108f$export$3cc2454c233bdc32)(arg);
}
function $1e273b197c429402$export$6969335ea1e4e77c(target, ...sources) {
    if (!sources.length) return target;
    const source = sources.shift();
    if ((0, $b63b9a75cba601b0$export$a6cdc56e425d0d0a)(target) && (0, $b63b9a75cba601b0$export$a6cdc56e425d0d0a)(source)) for(const key in source){
        if ($1e273b197c429402$var$noCopy(key, source[key])) target[key] = source[key];
        else if ((0, $b63b9a75cba601b0$export$a6cdc56e425d0d0a)(source[key])) {
            if (!target[key]) Object.assign(target, {
                [key]: {}
            });
            $1e273b197c429402$export$6969335ea1e4e77c(target[key], source[key]);
        } else Object.assign(target, {
            [key]: source[key]
        });
    }
    // @ts-ignore
    return $1e273b197c429402$export$6969335ea1e4e77c(target, ...sources);
}
function $1e273b197c429402$export$73ce4178444047a5(arrayA, arrayB) {
    return arrayA.length === arrayB.length && arrayA.every((element, index)=>arrayB[index] === element);
}
function $1e273b197c429402$export$71d3255081da70a3(defaults, argsArray, keys = [], objKey) {
    const opts = {};
    const args = Array.from(argsArray);
    // if the first argument is an object and has an object key
    if ((0, $b63b9a75cba601b0$export$a6cdc56e425d0d0a)(args[0]) && objKey && !Reflect.has(args[0], objKey)) {
        // if it's not part of the defaults
        const partOfDefaults = Object.keys(args[0]).some((key)=>Reflect.has(defaults, key));
        if (!partOfDefaults) {
            // merge that key
            $1e273b197c429402$export$6969335ea1e4e77c(opts, {
                [objKey]: args[0]
            });
            // remove the obj key from the keys
            keys.splice(keys.indexOf(objKey), 1);
            // shift the first argument off
            args.shift();
        }
    }
    if (args.length === 1 && (0, $b63b9a75cba601b0$export$a6cdc56e425d0d0a)(args[0])) $1e273b197c429402$export$6969335ea1e4e77c(opts, args[0]);
    else {
        for(let i = 0; i < keys.length; i++)if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(args[i])) opts[keys[i]] = args[i];
    }
    return $1e273b197c429402$export$6969335ea1e4e77c(defaults, opts);
}
function $1e273b197c429402$export$4b8c3341c9aef2b8(instance) {
    return instance.constructor.getDefaults();
}
function $1e273b197c429402$export$37721a79838ca038(given, fallback) {
    if ((0, $b63b9a75cba601b0$export$eb605f91c5895a5b)(given)) return fallback;
    else return given;
}
function $1e273b197c429402$export$e35a36a1f3b5e86b(obj, omit) {
    omit.forEach((prop)=>{
        if (Reflect.has(obj, prop)) delete obj[prop];
    });
    return obj;
}





class $0eb7340e2d092af9$export$12b11dc969d02fed {
    constructor(){
        //-------------------------------------
        // 	DEBUGGING
        //-------------------------------------
        /**
         * Set this debug flag to log all events that happen in this class.
         */ this.debug = false;
        //-------------------------------------
        // 	DISPOSING
        //-------------------------------------
        /**
         * Indicates if the instance was disposed
         */ this._wasDisposed = false;
    }
    /**
     * Returns all of the default options belonging to the class.
     */ static getDefaults() {
        return {};
    }
    /**
     * Prints the outputs to the console log for debugging purposes.
     * Prints the contents only if either the object has a property
     * called `debug` set to true, or a variable called TONE_DEBUG_CLASS
     * is set to the name of the class.
     * @example
     * const osc = new Tone.Oscillator();
     * // prints all logs originating from this oscillator
     * osc.debug = true;
     * // calls to start/stop will print in the console
     * osc.start();
     */ log(...args) {
        // if the object is either set to debug = true
        // or if there is a string on the Tone.global.with the class name
        if (this.debug || (0, $4d32d9be36060d13$export$a3ddad83b7a6ba2) && this.toString() === (0, $4d32d9be36060d13$export$a3ddad83b7a6ba2).TONE_DEBUG_CLASS) (0, $23cf54af36cc9441$export$bef1f36f5486a6a3)(this, ...args);
    }
    /**
     * disconnect and dispose.
     */ dispose() {
        this._wasDisposed = true;
        return this;
    }
    /**
     * Indicates if the instance was disposed. 'Disposing' an
     * instance means that all of the Web Audio nodes that were
     * created for the instance are disconnected and freed for garbage collection.
     */ get disposed() {
        return this._wasDisposed;
    }
    /**
     * Convert the class to a string
     * @example
     * const osc = new Tone.Oscillator();
     * console.log(osc.toString());
     */ toString() {
        return this.name;
    }
}
/**
 * The version number semver
 */ $0eb7340e2d092af9$export$12b11dc969d02fed.version = (0, $ffd1d50d2c55b871$export$83d89fbfd8236492);




/**
 * The threshold for correctness for operators. Less than one sample even
 * at very high sampling rates (e.g. `1e-6 < 1 / 192000`).
 */ const $e85238bb45fd87b7$var$EPSILON = 1e-6;
function $e85238bb45fd87b7$export$b023c82b48e70453(a, b) {
    return a > b + $e85238bb45fd87b7$var$EPSILON;
}
function $e85238bb45fd87b7$export$c846515610eb2c50(a, b) {
    return $e85238bb45fd87b7$export$b023c82b48e70453(a, b) || $e85238bb45fd87b7$export$1c0a5d05eb3f6e18(a, b);
}
function $e85238bb45fd87b7$export$7158f0ceb70f54c7(a, b) {
    return a + $e85238bb45fd87b7$var$EPSILON < b;
}
function $e85238bb45fd87b7$export$1c0a5d05eb3f6e18(a, b) {
    return Math.abs(a - b) < $e85238bb45fd87b7$var$EPSILON;
}
function $e85238bb45fd87b7$export$7d15b64cf5a3a4c4(value, min, max) {
    return Math.max(Math.min(value, max), min);
}


class $3684d29589a800b6$export$e6a97ba2cae5bb94 extends (0, $0eb7340e2d092af9$export$12b11dc969d02fed) {
    constructor(){
        super();
        this.name = "Timeline";
        /**
         * The array of scheduled timeline events
         */ this._timeline = [];
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($3684d29589a800b6$export$e6a97ba2cae5bb94.getDefaults(), arguments, [
            "memory"
        ]);
        this.memory = options.memory;
        this.increasing = options.increasing;
    }
    static getDefaults() {
        return {
            memory: Infinity,
            increasing: false
        };
    }
    /**
     * The number of items in the timeline.
     */ get length() {
        return this._timeline.length;
    }
    /**
     * Insert an event object onto the timeline. Events must have a "time" attribute.
     * @param event  The event object to insert into the timeline.
     */ add(event) {
        // the event needs to have a time attribute
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(Reflect.has(event, "time"), "Timeline: events must have a time attribute");
        event.time = event.time.valueOf();
        if (this.increasing && this.length) {
            const lastValue = this._timeline[this.length - 1];
            (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $e85238bb45fd87b7$export$c846515610eb2c50)(event.time, lastValue.time), "The time must be greater than or equal to the last scheduled time");
            this._timeline.push(event);
        } else {
            const index = this._search(event.time);
            this._timeline.splice(index + 1, 0, event);
        }
        // if the length is more than the memory, remove the previous ones
        if (this.length > this.memory) {
            const diff = this.length - this.memory;
            this._timeline.splice(0, diff);
        }
        return this;
    }
    /**
     * Remove an event from the timeline.
     * @param  {Object}  event  The event object to remove from the list.
     * @returns {Timeline} this
     */ remove(event) {
        const index = this._timeline.indexOf(event);
        if (index !== -1) this._timeline.splice(index, 1);
        return this;
    }
    /**
     * Get the nearest event whose time is less than or equal to the given time.
     * @param  time  The time to query.
     */ get(time, param = "time") {
        const index = this._search(time, param);
        if (index !== -1) return this._timeline[index];
        else return null;
    }
    /**
     * Return the first event in the timeline without removing it
     * @returns {Object} The first event object
     */ peek() {
        return this._timeline[0];
    }
    /**
     * Return the first event in the timeline and remove it
     */ shift() {
        return this._timeline.shift();
    }
    /**
     * Get the event which is scheduled after the given time.
     * @param  time  The time to query.
     */ getAfter(time, param = "time") {
        const index = this._search(time, param);
        if (index + 1 < this._timeline.length) return this._timeline[index + 1];
        else return null;
    }
    /**
     * Get the event before the event at the given time.
     * @param  time  The time to query.
     */ getBefore(time) {
        const len = this._timeline.length;
        // if it's after the last item, return the last item
        if (len > 0 && this._timeline[len - 1].time < time) return this._timeline[len - 1];
        const index = this._search(time);
        if (index - 1 >= 0) return this._timeline[index - 1];
        else return null;
    }
    /**
     * Cancel events at and after the given time
     * @param  after  The time to query.
     */ cancel(after) {
        if (this._timeline.length > 1) {
            let index = this._search(after);
            if (index >= 0) {
                if ((0, $e85238bb45fd87b7$export$1c0a5d05eb3f6e18)(this._timeline[index].time, after)) {
                    // get the first item with that time
                    for(let i = index; i >= 0; i--){
                        if ((0, $e85238bb45fd87b7$export$1c0a5d05eb3f6e18)(this._timeline[i].time, after)) index = i;
                        else break;
                    }
                    this._timeline = this._timeline.slice(0, index);
                } else this._timeline = this._timeline.slice(0, index + 1);
            } else this._timeline = [];
        } else if (this._timeline.length === 1) // the first item's time
        {
            if ((0, $e85238bb45fd87b7$export$c846515610eb2c50)(this._timeline[0].time, after)) this._timeline = [];
        }
        return this;
    }
    /**
     * Cancel events before or equal to the given time.
     * @param  time  The time to cancel before.
     */ cancelBefore(time) {
        const index = this._search(time);
        if (index >= 0) this._timeline = this._timeline.slice(index + 1);
        return this;
    }
    /**
     * Returns the previous event if there is one. null otherwise
     * @param  event The event to find the previous one of
     * @return The event right before the given event
     */ previousEvent(event) {
        const index = this._timeline.indexOf(event);
        if (index > 0) return this._timeline[index - 1];
        else return null;
    }
    /**
     * Does a binary search on the timeline array and returns the
     * nearest event index whose time is after or equal to the given time.
     * If a time is searched before the first index in the timeline, -1 is returned.
     * If the time is after the end, the index of the last item is returned.
     */ _search(time, param = "time") {
        if (this._timeline.length === 0) return -1;
        let beginning = 0;
        const len = this._timeline.length;
        let end = len;
        if (len > 0 && this._timeline[len - 1][param] <= time) return len - 1;
        while(beginning < end){
            // calculate the midpoint for roughly equal partition
            let midPoint = Math.floor(beginning + (end - beginning) / 2);
            const event = this._timeline[midPoint];
            const nextEvent = this._timeline[midPoint + 1];
            if ((0, $e85238bb45fd87b7$export$1c0a5d05eb3f6e18)(event[param], time)) {
                // choose the last one that has the same time
                for(let i = midPoint; i < this._timeline.length; i++){
                    const testEvent = this._timeline[i];
                    if ((0, $e85238bb45fd87b7$export$1c0a5d05eb3f6e18)(testEvent[param], time)) midPoint = i;
                    else break;
                }
                return midPoint;
            } else if ((0, $e85238bb45fd87b7$export$7158f0ceb70f54c7)(event[param], time) && (0, $e85238bb45fd87b7$export$b023c82b48e70453)(nextEvent[param], time)) return midPoint;
            else if ((0, $e85238bb45fd87b7$export$b023c82b48e70453)(event[param], time)) // search lower
            end = midPoint;
            else // search upper
            beginning = midPoint + 1;
        }
        return -1;
    }
    /**
     * Internal iterator. Applies extra safety checks for
     * removing items from the array.
     */ _iterate(callback, lowerBound = 0, upperBound = this._timeline.length - 1) {
        this._timeline.slice(lowerBound, upperBound + 1).forEach(callback);
    }
    /**
     * Iterate over everything in the array
     * @param  callback The callback to invoke with every item
     */ forEach(callback) {
        this._iterate(callback);
        return this;
    }
    /**
     * Iterate over everything in the array at or before the given time.
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachBefore(time, callback) {
        // iterate over the items in reverse so that removing an item doesn't break things
        const upperBound = this._search(time);
        if (upperBound !== -1) this._iterate(callback, 0, upperBound);
        return this;
    }
    /**
     * Iterate over everything in the array after the given time.
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachAfter(time, callback) {
        // iterate over the items in reverse so that removing an item doesn't break things
        const lowerBound = this._search(time);
        this._iterate(callback, lowerBound + 1);
        return this;
    }
    /**
     * Iterate over everything in the array between the startTime and endTime.
     * The timerange is inclusive of the startTime, but exclusive of the endTime.
     * range = [startTime, endTime).
     * @param  startTime The time to check if items are before
     * @param  endTime The end of the test interval.
     * @param  callback The callback to invoke with every item
     */ forEachBetween(startTime, endTime, callback) {
        let lowerBound = this._search(startTime);
        let upperBound = this._search(endTime);
        if (lowerBound !== -1 && upperBound !== -1) {
            if (this._timeline[lowerBound].time !== startTime) lowerBound += 1;
            // exclusive of the end time
            if (this._timeline[upperBound].time === endTime) upperBound -= 1;
            this._iterate(callback, lowerBound, upperBound);
        } else if (lowerBound === -1) this._iterate(callback, 0, upperBound);
        return this;
    }
    /**
     * Iterate over everything in the array at or after the given time. Similar to
     * forEachAfter, but includes the item(s) at the given time.
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachFrom(time, callback) {
        // iterate over the items in reverse so that removing an item doesn't break things
        let lowerBound = this._search(time);
        // work backwards until the event time is less than time
        while(lowerBound >= 0 && this._timeline[lowerBound].time >= time)lowerBound--;
        this._iterate(callback, lowerBound + 1);
        return this;
    }
    /**
     * Iterate over everything in the array at the given time
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachAtTime(time, callback) {
        // iterate over the items in reverse so that removing an item doesn't break things
        const upperBound = this._search(time);
        if (upperBound !== -1 && (0, $e85238bb45fd87b7$export$1c0a5d05eb3f6e18)(this._timeline[upperBound].time, time)) {
            let lowerBound = upperBound;
            for(let i = upperBound; i >= 0; i--){
                if ((0, $e85238bb45fd87b7$export$1c0a5d05eb3f6e18)(this._timeline[i].time, time)) lowerBound = i;
                else break;
            }
            this._iterate((event)=>{
                callback(event);
            }, lowerBound, upperBound);
        }
        return this;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._timeline = [];
        return this;
    }
}




//-------------------------------------
// INITIALIZING NEW CONTEXT
//-------------------------------------
/**
 * Array of callbacks to invoke when a new context is created
 */ const $5845e19ca4e07c3f$var$notifyNewContext = [];
function $5845e19ca4e07c3f$export$cdd816203a02e74e(cb) {
    $5845e19ca4e07c3f$var$notifyNewContext.push(cb);
}
function $5845e19ca4e07c3f$export$881f7fb71351b304(ctx) {
    // add any additional modules
    $5845e19ca4e07c3f$var$notifyNewContext.forEach((cb)=>cb(ctx));
}
/**
 * Array of callbacks to invoke when a new context is created
 */ const $5845e19ca4e07c3f$var$notifyCloseContext = [];
function $5845e19ca4e07c3f$export$7e1ecadd06ae8222(cb) {
    $5845e19ca4e07c3f$var$notifyCloseContext.push(cb);
}
function $5845e19ca4e07c3f$export$c7e36f690049420f(ctx) {
    // add any additional modules
    $5845e19ca4e07c3f$var$notifyCloseContext.forEach((cb)=>cb(ctx));
}




class $a281f9e80bc9e8f9$export$4293555f241ae35a extends (0, $0eb7340e2d092af9$export$12b11dc969d02fed) {
    constructor(){
        super(...arguments);
        this.name = "Emitter";
    }
    /**
     * Bind a callback to a specific event.
     * @param  event     The name of the event to listen for.
     * @param  callback  The callback to invoke when the event is emitted
     */ on(event, callback) {
        // split the event
        const events = event.split(/\W+/);
        events.forEach((eventName)=>{
            if ((0, $b63b9a75cba601b0$export$eb605f91c5895a5b)(this._events)) this._events = {};
            if (!this._events.hasOwnProperty(eventName)) this._events[eventName] = [];
            this._events[eventName].push(callback);
        });
        return this;
    }
    /**
     * Bind a callback which is only invoked once
     * @param  event     The name of the event to listen for.
     * @param  callback  The callback to invoke when the event is emitted
     */ once(event, callback) {
        const boundCallback = (...args)=>{
            // invoke the callback
            callback(...args);
            // remove the event
            this.off(event, boundCallback);
        };
        this.on(event, boundCallback);
        return this;
    }
    /**
     * Remove the event listener.
     * @param  event     The event to stop listening to.
     * @param  callback  The callback which was bound to the event with Emitter.on.
     *                   If no callback is given, all callbacks events are removed.
     */ off(event, callback) {
        const events = event.split(/\W+/);
        events.forEach((eventName)=>{
            if ((0, $b63b9a75cba601b0$export$eb605f91c5895a5b)(this._events)) this._events = {};
            if (this._events.hasOwnProperty(event)) {
                if ((0, $b63b9a75cba601b0$export$eb605f91c5895a5b)(callback)) this._events[event] = [];
                else {
                    const eventList = this._events[event];
                    for(let i = eventList.length - 1; i >= 0; i--)if (eventList[i] === callback) eventList.splice(i, 1);
                }
            }
        });
        return this;
    }
    /**
     * Invoke all of the callbacks bound to the event
     * with any arguments passed in.
     * @param  event  The name of the event.
     * @param args The arguments to pass to the functions listening.
     */ emit(event, ...args) {
        if (this._events) {
            if (this._events.hasOwnProperty(event)) {
                const eventList = this._events[event].slice(0);
                for(let i = 0, len = eventList.length; i < len; i++)eventList[i].apply(this, args);
            }
        }
        return this;
    }
    /**
     * Add Emitter functions (on/off/emit) to the object
     */ static mixin(constr) {
        // instance._events = {};
        [
            "on",
            "once",
            "off",
            "emit"
        ].forEach((name)=>{
            const property = Object.getOwnPropertyDescriptor($a281f9e80bc9e8f9$export$4293555f241ae35a.prototype, name);
            Object.defineProperty(constr.prototype, name, property);
        });
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._events = undefined;
        return this;
    }
}


class $e0d083d7a5ffe1c3$export$8138604c41bf2253 extends (0, $a281f9e80bc9e8f9$export$4293555f241ae35a) {
    constructor(){
        super(...arguments);
        this.isOffline = false;
    }
    /*
     * This is a placeholder so that JSON.stringify does not throw an error
     * This matches what JSON.stringify(audioContext) returns on a native
     * audioContext instance.
     */ toJSON() {
        return {};
    }
}



class $3d1074565f871f5d$export$841858b892ce1f4c extends (0, $e0d083d7a5ffe1c3$export$8138604c41bf2253) {
    constructor(){
        super();
        this.name = "Context";
        /**
         * An object containing all of the constants AudioBufferSourceNodes
         */ this._constants = new Map();
        /**
         * All of the setTimeout events.
         */ this._timeouts = new (0, $3684d29589a800b6$export$e6a97ba2cae5bb94)();
        /**
         * The timeout id counter
         */ this._timeoutIds = 0;
        /**
         * Private indicator if the context has been initialized
         */ this._initialized = false;
        /**
         * Indicates if the context is an OfflineAudioContext or an AudioContext
         */ this.isOffline = false;
        //--------------------------------------------
        // AUDIO WORKLET
        //--------------------------------------------
        /**
         * Maps a module name to promise of the addModule method
         */ this._workletModules = new Map();
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($3d1074565f871f5d$export$841858b892ce1f4c.getDefaults(), arguments, [
            "context", 
        ]);
        if (options.context) this._context = options.context;
        else this._context = (0, $4d32d9be36060d13$export$9e09b0a77eebe103)({
            latencyHint: options.latencyHint
        });
        this._ticker = new (0, $229eebcbdc37eb30$export$39c54bcc89dcee11)(this.emit.bind(this, "tick"), options.clockSource, options.updateInterval);
        this.on("tick", this._timeoutLoop.bind(this));
        // fwd events from the context
        this._context.onstatechange = ()=>{
            this.emit("statechange", this.state);
        };
        this._setLatencyHint(options.latencyHint);
        this.lookAhead = options.lookAhead;
    }
    static getDefaults() {
        return {
            clockSource: "worker",
            latencyHint: "interactive",
            lookAhead: 0.1,
            updateInterval: 0.05
        };
    }
    /**
     * Finish setting up the context. **You usually do not need to do this manually.**
     */ initialize() {
        if (!this._initialized) {
            // add any additional modules
            (0, $5845e19ca4e07c3f$export$881f7fb71351b304)(this);
            this._initialized = true;
        }
        return this;
    }
    //---------------------------
    // BASE AUDIO CONTEXT METHODS
    //---------------------------
    createAnalyser() {
        return this._context.createAnalyser();
    }
    createOscillator() {
        return this._context.createOscillator();
    }
    createBufferSource() {
        return this._context.createBufferSource();
    }
    createBiquadFilter() {
        return this._context.createBiquadFilter();
    }
    createBuffer(numberOfChannels, length, sampleRate) {
        return this._context.createBuffer(numberOfChannels, length, sampleRate);
    }
    createChannelMerger(numberOfInputs) {
        return this._context.createChannelMerger(numberOfInputs);
    }
    createChannelSplitter(numberOfOutputs) {
        return this._context.createChannelSplitter(numberOfOutputs);
    }
    createConstantSource() {
        return this._context.createConstantSource();
    }
    createConvolver() {
        return this._context.createConvolver();
    }
    createDelay(maxDelayTime) {
        return this._context.createDelay(maxDelayTime);
    }
    createDynamicsCompressor() {
        return this._context.createDynamicsCompressor();
    }
    createGain() {
        return this._context.createGain();
    }
    createIIRFilter(feedForward, feedback) {
        // @ts-ignore
        return this._context.createIIRFilter(feedForward, feedback);
    }
    createPanner() {
        return this._context.createPanner();
    }
    createPeriodicWave(real, imag, constraints) {
        return this._context.createPeriodicWave(real, imag, constraints);
    }
    createStereoPanner() {
        return this._context.createStereoPanner();
    }
    createWaveShaper() {
        return this._context.createWaveShaper();
    }
    createMediaStreamSource(stream) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $ca1a79a064f4108f$export$c46cbd835dc15c90)(this._context), "Not available if OfflineAudioContext");
        const context = this._context;
        return context.createMediaStreamSource(stream);
    }
    createMediaElementSource(element) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $ca1a79a064f4108f$export$c46cbd835dc15c90)(this._context), "Not available if OfflineAudioContext");
        const context = this._context;
        return context.createMediaElementSource(element);
    }
    createMediaStreamDestination() {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $ca1a79a064f4108f$export$c46cbd835dc15c90)(this._context), "Not available if OfflineAudioContext");
        const context = this._context;
        return context.createMediaStreamDestination();
    }
    decodeAudioData(audioData) {
        return this._context.decodeAudioData(audioData);
    }
    /**
     * The current time in seconds of the AudioContext.
     */ get currentTime() {
        return this._context.currentTime;
    }
    /**
     * The current time in seconds of the AudioContext.
     */ get state() {
        return this._context.state;
    }
    /**
     * The current time in seconds of the AudioContext.
     */ get sampleRate() {
        return this._context.sampleRate;
    }
    /**
     * The listener
     */ get listener() {
        this.initialize();
        return this._listener;
    }
    set listener(l) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(!this._initialized, "The listener cannot be set after initialization.");
        this._listener = l;
    }
    /**
     * There is only one Transport per Context. It is created on initialization.
     */ get transport() {
        this.initialize();
        return this._transport;
    }
    set transport(t) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(!this._initialized, "The transport cannot be set after initialization.");
        this._transport = t;
    }
    /**
     * This is the Draw object for the context which is useful for synchronizing the draw frame with the Tone.js clock.
     */ get draw() {
        this.initialize();
        return this._draw;
    }
    set draw(d) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(!this._initialized, "Draw cannot be set after initialization.");
        this._draw = d;
    }
    /**
     * A reference to the Context's destination node.
     */ get destination() {
        this.initialize();
        return this._destination;
    }
    set destination(d) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(!this._initialized, "The destination cannot be set after initialization.");
        this._destination = d;
    }
    /**
     * Create an audio worklet node from a name and options. The module
     * must first be loaded using [[addAudioWorkletModule]].
     */ createAudioWorkletNode(name, options) {
        return (0, $4d32d9be36060d13$export$f2cca0e3f6d50e11)(this.rawContext, name, options);
    }
    /**
     * Add an AudioWorkletProcessor module
     * @param url The url of the module
     * @param name The name of the module
     */ addAudioWorkletModule(url, name) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $b63b9a75cba601b0$export$4e62c701997796c1)(this.rawContext.audioWorklet), "AudioWorkletNode is only available in a secure context (https or localhost)");
            if (!this._workletModules.has(name)) this._workletModules.set(name, this.rawContext.audioWorklet.addModule(url));
            yield this._workletModules.get(name);
        });
    }
    /**
     * Returns a promise which resolves when all of the worklets have been loaded on this context
     */ workletsAreReady() {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            const promises = [];
            this._workletModules.forEach((promise)=>promises.push(promise));
            yield Promise.all(promises);
        });
    }
    //---------------------------
    // TICKER
    //---------------------------
    /**
     * How often the interval callback is invoked.
     * This number corresponds to how responsive the scheduling
     * can be. context.updateInterval + context.lookAhead gives you the
     * total latency between scheduling an event and hearing it.
     */ get updateInterval() {
        return this._ticker.updateInterval;
    }
    set updateInterval(interval) {
        this._ticker.updateInterval = interval;
    }
    /**
     * What the source of the clock is, either "worker" (default),
     * "timeout", or "offline" (none).
     */ get clockSource() {
        return this._ticker.type;
    }
    set clockSource(type) {
        this._ticker.type = type;
    }
    /**
     * The type of playback, which affects tradeoffs between audio
     * output latency and responsiveness.
     * In addition to setting the value in seconds, the latencyHint also
     * accepts the strings "interactive" (prioritizes low latency),
     * "playback" (prioritizes sustained playback), "balanced" (balances
     * latency and performance).
     * @example
     * // prioritize sustained playback
     * const context = new Tone.Context({ latencyHint: "playback" });
     * // set this context as the global Context
     * Tone.setContext(context);
     * // the global context is gettable with Tone.getContext()
     * console.log(Tone.getContext().latencyHint);
     */ get latencyHint() {
        return this._latencyHint;
    }
    /**
     * Update the lookAhead and updateInterval based on the latencyHint
     */ _setLatencyHint(hint) {
        let lookAheadValue = 0;
        this._latencyHint = hint;
        if ((0, $b63b9a75cba601b0$export$844ec244b1367d54)(hint)) switch(hint){
            case "interactive":
                lookAheadValue = 0.1;
                break;
            case "playback":
                lookAheadValue = 0.5;
                break;
            case "balanced":
                lookAheadValue = 0.25;
                break;
        }
        this.lookAhead = lookAheadValue;
        this.updateInterval = lookAheadValue / 2;
    }
    /**
     * The unwrapped AudioContext or OfflineAudioContext
     */ get rawContext() {
        return this._context;
    }
    /**
     * The current audio context time plus a short [[lookAhead]].
     */ now() {
        return this._context.currentTime + this.lookAhead;
    }
    /**
     * The current audio context time without the [[lookAhead]].
     * In most cases it is better to use [[now]] instead of [[immediate]] since
     * with [[now]] the [[lookAhead]] is applied equally to _all_ components including internal components,
     * to making sure that everything is scheduled in sync. Mixing [[now]] and [[immediate]]
     * can cause some timing issues. If no lookAhead is desired, you can set the [[lookAhead]] to `0`.
     */ immediate() {
        return this._context.currentTime;
    }
    /**
     * Starts the audio context from a suspended state. This is required
     * to initially start the AudioContext. See [[Tone.start]]
     */ resume() {
        if ((0, $ca1a79a064f4108f$export$c46cbd835dc15c90)(this._context)) return this._context.resume();
        else return Promise.resolve();
    }
    /**
     * Close the context. Once closed, the context can no longer be used and
     * any AudioNodes created from the context will be silent.
     */ close() {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            if ((0, $ca1a79a064f4108f$export$c46cbd835dc15c90)(this._context)) yield this._context.close();
            if (this._initialized) (0, $5845e19ca4e07c3f$export$c7e36f690049420f)(this);
        });
    }
    /**
     * **Internal** Generate a looped buffer at some constant value.
     */ getConstant(val) {
        if (this._constants.has(val)) return this._constants.get(val);
        else {
            const buffer = this._context.createBuffer(1, 128, this._context.sampleRate);
            const arr = buffer.getChannelData(0);
            for(let i = 0; i < arr.length; i++)arr[i] = val;
            const constant = this._context.createBufferSource();
            constant.channelCount = 1;
            constant.channelCountMode = "explicit";
            constant.buffer = buffer;
            constant.loop = true;
            constant.start(0);
            this._constants.set(val, constant);
            return constant;
        }
    }
    /**
     * Clean up. Also closes the audio context.
     */ dispose() {
        super.dispose();
        this._ticker.dispose();
        this._timeouts.dispose();
        Object.keys(this._constants).map((val)=>this._constants[val].disconnect());
        return this;
    }
    //---------------------------
    // TIMEOUTS
    //---------------------------
    /**
     * The private loop which keeps track of the context scheduled timeouts
     * Is invoked from the clock source
     */ _timeoutLoop() {
        const now = this.now();
        let firstEvent = this._timeouts.peek();
        while(this._timeouts.length && firstEvent && firstEvent.time <= now){
            // invoke the callback
            firstEvent.callback();
            // shift the first event off
            this._timeouts.shift();
            // get the next one
            firstEvent = this._timeouts.peek();
        }
    }
    /**
     * A setTimeout which is guaranteed by the clock source.
     * Also runs in the offline context.
     * @param  fn       The callback to invoke
     * @param  timeout  The timeout in seconds
     * @returns ID to use when invoking Context.clearTimeout
     */ setTimeout(fn, timeout) {
        this._timeoutIds++;
        const now = this.now();
        this._timeouts.add({
            callback: fn,
            id: this._timeoutIds,
            time: now + timeout
        });
        return this._timeoutIds;
    }
    /**
     * Clears a previously scheduled timeout with Tone.context.setTimeout
     * @param  id  The ID returned from setTimeout
     */ clearTimeout(id) {
        this._timeouts.forEach((event)=>{
            if (event.id === id) this._timeouts.remove(event);
        });
        return this;
    }
    /**
     * Clear the function scheduled by [[setInterval]]
     */ clearInterval(id) {
        return this.clearTimeout(id);
    }
    /**
     * Adds a repeating event to the context's callback clock
     */ setInterval(fn, interval) {
        const id = ++this._timeoutIds;
        const intervalFn = ()=>{
            const now = this.now();
            this._timeouts.add({
                callback: ()=>{
                    // invoke the callback
                    fn();
                    // invoke the event to repeat it
                    intervalFn();
                },
                id: id,
                time: now + interval
            });
        };
        // kick it off
        intervalFn();
        return id;
    }
}




class $d128c5664d557cc0$export$bc5f2fd86e1bc223 extends (0, $e0d083d7a5ffe1c3$export$8138604c41bf2253) {
    constructor(){
        super(...arguments);
        this.lookAhead = 0;
        this.latencyHint = 0;
        this.isOffline = false;
    }
    //---------------------------
    // BASE AUDIO CONTEXT METHODS
    //---------------------------
    createAnalyser() {
        return {};
    }
    createOscillator() {
        return {};
    }
    createBufferSource() {
        return {};
    }
    createBiquadFilter() {
        return {};
    }
    createBuffer(_numberOfChannels, _length, _sampleRate) {
        return {};
    }
    createChannelMerger(_numberOfInputs) {
        return {};
    }
    createChannelSplitter(_numberOfOutputs) {
        return {};
    }
    createConstantSource() {
        return {};
    }
    createConvolver() {
        return {};
    }
    createDelay(_maxDelayTime) {
        return {};
    }
    createDynamicsCompressor() {
        return {};
    }
    createGain() {
        return {};
    }
    createIIRFilter(_feedForward, _feedback) {
        return {};
    }
    createPanner() {
        return {};
    }
    createPeriodicWave(_real, _imag, _constraints) {
        return {};
    }
    createStereoPanner() {
        return {};
    }
    createWaveShaper() {
        return {};
    }
    createMediaStreamSource(_stream) {
        return {};
    }
    createMediaElementSource(_element) {
        return {};
    }
    createMediaStreamDestination() {
        return {};
    }
    decodeAudioData(_audioData) {
        return Promise.resolve({});
    }
    //---------------------------
    // TONE AUDIO CONTEXT METHODS
    //---------------------------
    createAudioWorkletNode(_name, _options) {
        return {};
    }
    get rawContext() {
        return {};
    }
    addAudioWorkletModule(_url, _name) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            return Promise.resolve();
        });
    }
    resume() {
        return Promise.resolve();
    }
    setTimeout(_fn, _timeout) {
        return 0;
    }
    clearTimeout(_id) {
        return this;
    }
    setInterval(_fn, _interval) {
        return 0;
    }
    clearInterval(_id) {
        return this;
    }
    getConstant(_val) {
        return {};
    }
    get currentTime() {
        return 0;
    }
    get state() {
        return {};
    }
    get sampleRate() {
        return 0;
    }
    get listener() {
        return {};
    }
    get transport() {
        return {};
    }
    get draw() {
        return {};
    }
    set draw(_d) {}
    get destination() {
        return {};
    }
    set destination(_d) {}
    now() {
        return 0;
    }
    immediate() {
        return 0;
    }
}












function $c0a1ee726091e30a$export$b2cbc93d4da94977(target, property) {
    if ((0, $b63b9a75cba601b0$export$43bee75e5e14138e)(property)) property.forEach((str)=>$c0a1ee726091e30a$export$b2cbc93d4da94977(target, str));
    else Object.defineProperty(target, property, {
        enumerable: true,
        writable: false
    });
}
function $c0a1ee726091e30a$export$e6d3eada50a007b1(target, property) {
    if ((0, $b63b9a75cba601b0$export$43bee75e5e14138e)(property)) property.forEach((str)=>$c0a1ee726091e30a$export$e6d3eada50a007b1(target, str));
    else Object.defineProperty(target, property, {
        writable: true
    });
}
const $c0a1ee726091e30a$export$b50b6e108474309b = ()=>{
// no operation here!
};




class $f8b2c4c1413d235f$export$424a335715b38178 extends (0, $0eb7340e2d092af9$export$12b11dc969d02fed) {
    constructor(){
        super();
        this.name = "ToneAudioBuffer";
        /**
         * Callback when the buffer is loaded.
         */ this.onload = (0, $c0a1ee726091e30a$export$b50b6e108474309b);
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($f8b2c4c1413d235f$export$424a335715b38178.getDefaults(), arguments, [
            "url",
            "onload",
            "onerror"
        ]);
        this.reverse = options.reverse;
        this.onload = options.onload;
        if (options.url && (0, $ca1a79a064f4108f$export$3cc2454c233bdc32)(options.url) || options.url instanceof $f8b2c4c1413d235f$export$424a335715b38178) this.set(options.url);
        else if ((0, $b63b9a75cba601b0$export$844ec244b1367d54)(options.url)) // initiate the download
        this.load(options.url).catch(options.onerror);
    }
    static getDefaults() {
        return {
            onerror: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            onload: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            reverse: false
        };
    }
    /**
     * The sample rate of the AudioBuffer
     */ get sampleRate() {
        if (this._buffer) return this._buffer.sampleRate;
        else return (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().sampleRate;
    }
    /**
     * Pass in an AudioBuffer or ToneAudioBuffer to set the value of this buffer.
     */ set(buffer) {
        if (buffer instanceof $f8b2c4c1413d235f$export$424a335715b38178) {
            // if it's loaded, set it
            if (buffer.loaded) this._buffer = buffer.get();
            else // otherwise when it's loaded, invoke it's callback
            buffer.onload = ()=>{
                this.set(buffer);
                this.onload(this);
            };
        } else this._buffer = buffer;
        // reverse it initially
        if (this._reversed) this._reverse();
        return this;
    }
    /**
     * The audio buffer stored in the object.
     */ get() {
        return this._buffer;
    }
    /**
     * Makes an fetch request for the selected url then decodes the file as an audio buffer.
     * Invokes the callback once the audio buffer loads.
     * @param url The url of the buffer to load. filetype support depends on the browser.
     * @returns A Promise which resolves with this ToneAudioBuffer
     */ load(url) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            const doneLoading = $f8b2c4c1413d235f$export$424a335715b38178.load(url).then((audioBuffer)=>{
                this.set(audioBuffer);
                // invoke the onload method
                this.onload(this);
            });
            $f8b2c4c1413d235f$export$424a335715b38178.downloads.push(doneLoading);
            try {
                yield doneLoading;
            } finally{
                // remove the downloaded file
                const index = $f8b2c4c1413d235f$export$424a335715b38178.downloads.indexOf(doneLoading);
                $f8b2c4c1413d235f$export$424a335715b38178.downloads.splice(index, 1);
            }
            return this;
        });
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this._buffer = undefined;
        return this;
    }
    /**
     * Set the audio buffer from the array.
     * To create a multichannel AudioBuffer, pass in a multidimensional array.
     * @param array The array to fill the audio buffer
     */ fromArray(array) {
        const isMultidimensional = (0, $b63b9a75cba601b0$export$43bee75e5e14138e)(array) && array[0].length > 0;
        const channels = isMultidimensional ? array.length : 1;
        const len = isMultidimensional ? array[0].length : array.length;
        const context = (0, $3d00f6854e3cc34b$export$31553aaa555c1514)();
        const buffer = context.createBuffer(channels, len, context.sampleRate);
        const multiChannelArray = !isMultidimensional && channels === 1 ? [
            array
        ] : array;
        for(let c = 0; c < channels; c++)buffer.copyToChannel(multiChannelArray[c], c);
        this._buffer = buffer;
        return this;
    }
    /**
     * Sums multiple channels into 1 channel
     * @param chanNum Optionally only copy a single channel from the array.
     */ toMono(chanNum) {
        if ((0, $b63b9a75cba601b0$export$7e4aa119212bc614)(chanNum)) this.fromArray(this.toArray(chanNum));
        else {
            let outputArray = new Float32Array(this.length);
            const numChannels = this.numberOfChannels;
            for(let channel = 0; channel < numChannels; channel++){
                const channelArray = this.toArray(channel);
                for(let i = 0; i < channelArray.length; i++)outputArray[i] += channelArray[i];
            }
            // divide by the number of channels
            outputArray = outputArray.map((sample)=>sample / numChannels);
            this.fromArray(outputArray);
        }
        return this;
    }
    /**
     * Get the buffer as an array. Single channel buffers will return a 1-dimensional
     * Float32Array, and multichannel buffers will return multidimensional arrays.
     * @param channel Optionally only copy a single channel from the array.
     */ toArray(channel) {
        if ((0, $b63b9a75cba601b0$export$7e4aa119212bc614)(channel)) return this.getChannelData(channel);
        else if (this.numberOfChannels === 1) return this.toArray(0);
        else {
            const ret = [];
            for(let c = 0; c < this.numberOfChannels; c++)ret[c] = this.getChannelData(c);
            return ret;
        }
    }
    /**
     * Returns the Float32Array representing the PCM audio data for the specific channel.
     * @param  channel  The channel number to return
     * @return The audio as a TypedArray
     */ getChannelData(channel) {
        if (this._buffer) return this._buffer.getChannelData(channel);
        else return new Float32Array(0);
    }
    /**
     * Cut a subsection of the array and return a buffer of the
     * subsection. Does not modify the original buffer
     * @param start The time to start the slice
     * @param end The end time to slice. If none is given will default to the end of the buffer
     */ slice(start, end = this.duration) {
        const startSamples = Math.floor(start * this.sampleRate);
        const endSamples = Math.floor(end * this.sampleRate);
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(startSamples < endSamples, "The start time must be less than the end time");
        const length = endSamples - startSamples;
        const retBuffer = (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().createBuffer(this.numberOfChannels, length, this.sampleRate);
        for(let channel = 0; channel < this.numberOfChannels; channel++)retBuffer.copyToChannel(this.getChannelData(channel).subarray(startSamples, endSamples), channel);
        return new $f8b2c4c1413d235f$export$424a335715b38178(retBuffer);
    }
    /**
     * Reverse the buffer.
     */ _reverse() {
        if (this.loaded) for(let i = 0; i < this.numberOfChannels; i++)this.getChannelData(i).reverse();
        return this;
    }
    /**
     * If the buffer is loaded or not
     */ get loaded() {
        return this.length > 0;
    }
    /**
     * The duration of the buffer in seconds.
     */ get duration() {
        if (this._buffer) return this._buffer.duration;
        else return 0;
    }
    /**
     * The length of the buffer in samples
     */ get length() {
        if (this._buffer) return this._buffer.length;
        else return 0;
    }
    /**
     * The number of discrete audio channels. Returns 0 if no buffer is loaded.
     */ get numberOfChannels() {
        if (this._buffer) return this._buffer.numberOfChannels;
        else return 0;
    }
    /**
     * Reverse the buffer.
     */ get reverse() {
        return this._reversed;
    }
    set reverse(rev) {
        if (this._reversed !== rev) {
            this._reversed = rev;
            this._reverse();
        }
    }
    /**
     * Create a ToneAudioBuffer from the array. To create a multichannel AudioBuffer,
     * pass in a multidimensional array.
     * @param array The array to fill the audio buffer
     * @return A ToneAudioBuffer created from the array
     */ static fromArray(array) {
        return new $f8b2c4c1413d235f$export$424a335715b38178().fromArray(array);
    }
    /**
     * Creates a ToneAudioBuffer from a URL, returns a promise which resolves to a ToneAudioBuffer
     * @param  url The url to load.
     * @return A promise which resolves to a ToneAudioBuffer
     */ static fromUrl(url) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            const buffer = new $f8b2c4c1413d235f$export$424a335715b38178();
            return yield buffer.load(url);
        });
    }
    /**
     * Loads a url using fetch and returns the AudioBuffer.
     */ static load(url) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            // test if the url contains multiple extensions
            const matches = url.match(/\[([^\]\[]+\|.+)\]$/);
            if (matches) {
                const extensions = matches[1].split("|");
                let extension = extensions[0];
                for (const ext of extensions)if ($f8b2c4c1413d235f$export$424a335715b38178.supportsType(ext)) {
                    extension = ext;
                    break;
                }
                url = url.replace(matches[0], extension);
            }
            // make sure there is a slash between the baseUrl and the url
            const baseUrl = $f8b2c4c1413d235f$export$424a335715b38178.baseUrl === "" || $f8b2c4c1413d235f$export$424a335715b38178.baseUrl.endsWith("/") ? $f8b2c4c1413d235f$export$424a335715b38178.baseUrl : $f8b2c4c1413d235f$export$424a335715b38178.baseUrl + "/";
            const response = yield fetch(baseUrl + url);
            if (!response.ok) throw new Error(`could not load url: ${url}`);
            const arrayBuffer = yield response.arrayBuffer();
            const audioBuffer = yield (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().decodeAudioData(arrayBuffer);
            return audioBuffer;
        });
    }
    /**
     * Checks a url's extension to see if the current browser can play that file type.
     * @param url The url/extension to test
     * @return If the file extension can be played
     * @static
     * @example
     * Tone.ToneAudioBuffer.supportsType("wav"); // returns true
     * Tone.ToneAudioBuffer.supportsType("path/to/file.wav"); // returns true
     */ static supportsType(url) {
        const extensions = url.split(".");
        const extension = extensions[extensions.length - 1];
        const response = document.createElement("audio").canPlayType("audio/" + extension);
        return response !== "";
    }
    /**
     * Returns a Promise which resolves when all of the buffers have loaded
     */ static loaded() {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            // this makes sure that the function is always async
            yield Promise.resolve();
            while($f8b2c4c1413d235f$export$424a335715b38178.downloads.length)yield $f8b2c4c1413d235f$export$424a335715b38178.downloads[0];
        });
    }
}
//-------------------------------------
// STATIC METHODS
//-------------------------------------
/**
 * A path which is prefixed before every url.
 */ $f8b2c4c1413d235f$export$424a335715b38178.baseUrl = "";
/**
 * All of the downloads
 */ $f8b2c4c1413d235f$export$424a335715b38178.downloads = [];


class $d73ede3d936d3e15$export$46814dd5412c611c extends (0, $3d1074565f871f5d$export$841858b892ce1f4c) {
    constructor(){
        super({
            clockSource: "offline",
            context: (0, $ca1a79a064f4108f$export$539f87c8e5511243)(arguments[0]) ? arguments[0] : (0, $4d32d9be36060d13$export$b7df220975ff4035)(arguments[0], arguments[1] * arguments[2], arguments[2]),
            lookAhead: 0,
            updateInterval: (0, $ca1a79a064f4108f$export$539f87c8e5511243)(arguments[0]) ? 128 / arguments[0].sampleRate : 128 / arguments[2]
        });
        this.name = "OfflineContext";
        /**
         * An artificial clock source
         */ this._currentTime = 0;
        this.isOffline = true;
        this._duration = (0, $ca1a79a064f4108f$export$539f87c8e5511243)(arguments[0]) ? arguments[0].length / arguments[0].sampleRate : arguments[1];
    }
    /**
     * Override the now method to point to the internal clock time
     */ now() {
        return this._currentTime;
    }
    /**
     * Same as this.now()
     */ get currentTime() {
        return this._currentTime;
    }
    /**
     * Render just the clock portion of the audio context.
     */ _renderClock(asynchronous) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            let index = 0;
            while(this._duration - this._currentTime >= 0){
                // invoke all the callbacks on that time
                this.emit("tick");
                // increment the clock in block-sized chunks
                this._currentTime += 128 / this.sampleRate;
                // yield once a second of audio
                index++;
                const yieldEvery = Math.floor(this.sampleRate / 128);
                if (asynchronous && index % yieldEvery === 0) yield new Promise((done)=>setTimeout(done, 1));
            }
        });
    }
    /**
     * Render the output of the OfflineContext
     * @param asynchronous If the clock should be rendered asynchronously, which will not block the main thread, but be slightly slower.
     */ render(asynchronous = true) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            yield this.workletsAreReady();
            yield this._renderClock(asynchronous);
            const buffer = yield this._context.startRendering();
            return new (0, $f8b2c4c1413d235f$export$424a335715b38178)(buffer);
        });
    }
    /**
     * Close the context
     */ close() {
        return Promise.resolve();
    }
}



/**
 * This dummy context is used to avoid throwing immediate errors when importing in Node.js
 */ const $3d00f6854e3cc34b$var$dummyContext = new (0, $d128c5664d557cc0$export$bc5f2fd86e1bc223)();
/**
 * The global audio context which is getable and assignable through
 * getContext and setContext
 */ let $3d00f6854e3cc34b$var$globalContext = $3d00f6854e3cc34b$var$dummyContext;
function $3d00f6854e3cc34b$export$31553aaa555c1514() {
    if ($3d00f6854e3cc34b$var$globalContext === $3d00f6854e3cc34b$var$dummyContext && (0, $4d32d9be36060d13$export$50898d6dff7e65a3)) $3d00f6854e3cc34b$export$2f04de43fe27971a(new (0, $3d1074565f871f5d$export$841858b892ce1f4c)());
    return $3d00f6854e3cc34b$var$globalContext;
}
function $3d00f6854e3cc34b$export$2f04de43fe27971a(context) {
    if ((0, $ca1a79a064f4108f$export$c46cbd835dc15c90)(context)) $3d00f6854e3cc34b$var$globalContext = new (0, $3d1074565f871f5d$export$841858b892ce1f4c)(context);
    else if ((0, $ca1a79a064f4108f$export$539f87c8e5511243)(context)) $3d00f6854e3cc34b$var$globalContext = new (0, $d73ede3d936d3e15$export$46814dd5412c611c)(context);
    else $3d00f6854e3cc34b$var$globalContext = context;
}
function $3d00f6854e3cc34b$export$b3571188c770cc5a() {
    return $3d00f6854e3cc34b$var$globalContext.resume();
}
/**
 * Log Tone.js + version in the console.
 */ if ((0, $4d32d9be36060d13$export$a3ddad83b7a6ba2) && !(0, $4d32d9be36060d13$export$a3ddad83b7a6ba2).TONE_SILENCE_LOGGING) {
    let prefix = "v";
    if ((0, $ffd1d50d2c55b871$export$83d89fbfd8236492) === "dev") prefix = "";
    const printString = ` * Tone.js ${prefix}${(0, $ffd1d50d2c55b871$export$83d89fbfd8236492)} * `;
    // eslint-disable-next-line no-console
    console.log(`%c${printString}`, "background: #000; color: #fff");
}









class $11a3577f34f45a1d$export$7232b969b571e570 extends (0, $0eb7340e2d092af9$export$12b11dc969d02fed) {
    constructor(){
        super();
        this.name = "ToneAudioBuffers";
        /**
         * All of the buffers
         */ this._buffers = new Map();
        /**
         * Keep track of the number of loaded buffers
         */ this._loadingCount = 0;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($11a3577f34f45a1d$export$7232b969b571e570.getDefaults(), arguments, [
            "urls",
            "onload",
            "baseUrl"
        ], "urls");
        this.baseUrl = options.baseUrl;
        // add each one
        Object.keys(options.urls).forEach((name)=>{
            this._loadingCount++;
            const url = options.urls[name];
            this.add(name, url, this._bufferLoaded.bind(this, options.onload), options.onerror);
        });
    }
    static getDefaults() {
        return {
            baseUrl: "",
            onerror: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            onload: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            urls: {}
        };
    }
    /**
     * True if the buffers object has a buffer by that name.
     * @param  name  The key or index of the buffer.
     */ has(name) {
        return this._buffers.has(name.toString());
    }
    /**
     * Get a buffer by name. If an array was loaded,
     * then use the array index.
     * @param  name  The key or index of the buffer.
     */ get(name) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(this.has(name), `ToneAudioBuffers has no buffer named: ${name}`);
        return this._buffers.get(name.toString());
    }
    /**
     * A buffer was loaded. decrement the counter.
     */ _bufferLoaded(callback) {
        this._loadingCount--;
        if (this._loadingCount === 0 && callback) callback();
    }
    /**
     * If the buffers are loaded or not
     */ get loaded() {
        return Array.from(this._buffers).every(([_, buffer])=>buffer.loaded);
    }
    /**
     * Add a buffer by name and url to the Buffers
     * @param  name      A unique name to give the buffer
     * @param  url  Either the url of the bufer, or a buffer which will be added with the given name.
     * @param  callback  The callback to invoke when the url is loaded.
     * @param  onerror  Invoked if the buffer can't be loaded
     */ add(name, url, callback = (0, $c0a1ee726091e30a$export$b50b6e108474309b), onerror = (0, $c0a1ee726091e30a$export$b50b6e108474309b)) {
        if ((0, $b63b9a75cba601b0$export$844ec244b1367d54)(url)) this._buffers.set(name.toString(), new (0, $f8b2c4c1413d235f$export$424a335715b38178)(this.baseUrl + url, callback, onerror));
        else this._buffers.set(name.toString(), new (0, $f8b2c4c1413d235f$export$424a335715b38178)(url, callback, onerror));
        return this;
    }
    dispose() {
        super.dispose();
        this._buffers.forEach((buffer)=>buffer.dispose());
        this._buffers.clear();
        return this;
    }
}




function $73949b14fe57a99a$export$bfc35d599238ec59(percent) {
    const piFactor = 0.5 * Math.PI;
    return Math.sin(percent * piFactor);
}
function $73949b14fe57a99a$export$33ed28de027e9482(db) {
    return Math.pow(10, db / 20);
}
function $73949b14fe57a99a$export$6af3969727ca2a60(gain) {
    return 20 * (Math.log(gain) / Math.LN10);
}
function $73949b14fe57a99a$export$5d18fe46719f6008(interval) {
    return Math.pow(2, interval / 12);
}
/**
 * The Global [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used
 * to generate all the other pitch values from notes. A4's values in Hertz.
 */ let $73949b14fe57a99a$var$A4 = 440;
function $73949b14fe57a99a$export$9f4826388a169ebd() {
    return $73949b14fe57a99a$var$A4;
}
function $73949b14fe57a99a$export$2a0f2ad6a5f8e4fe(freq) {
    $73949b14fe57a99a$var$A4 = freq;
}
function $73949b14fe57a99a$export$5cf9d9f9506eec5(frequency) {
    return Math.round($73949b14fe57a99a$export$12513e46625518e4(frequency));
}
function $73949b14fe57a99a$export$12513e46625518e4(frequency) {
    return 69 + 12 * Math.log2(frequency / $73949b14fe57a99a$var$A4);
}
function $73949b14fe57a99a$export$45a6434f7c391dc(midi) {
    return $73949b14fe57a99a$var$A4 * Math.pow(2, (midi - 69) / 12);
}















class $aef073e4341f6769$export$23b5656976f56273 extends (0, $0eb7340e2d092af9$export$12b11dc969d02fed) {
    /**
     * @param context The context associated with the time value. Used to compute
     * Transport and context-relative timing.
     * @param  value  The time value as a number, string or object
     * @param  units  Unit values
     */ constructor(context, value, units){
        super();
        /**
         * The default units
         */ this.defaultUnits = "s";
        this._val = value;
        this._units = units;
        this.context = context;
        this._expressions = this._getExpressions();
    }
    /**
     * All of the time encoding expressions
     */ _getExpressions() {
        return {
            hz: {
                method: (value)=>{
                    return this._frequencyToUnits(parseFloat(value));
                },
                regexp: /^(\d+(?:\.\d+)?)hz$/i
            },
            i: {
                method: (value)=>{
                    return this._ticksToUnits(parseInt(value, 10));
                },
                regexp: /^(\d+)i$/i
            },
            m: {
                method: (value)=>{
                    return this._beatsToUnits(parseInt(value, 10) * this._getTimeSignature());
                },
                regexp: /^(\d+)m$/i
            },
            n: {
                method: (value, dot)=>{
                    const numericValue = parseInt(value, 10);
                    const scalar = dot === "." ? 1.5 : 1;
                    if (numericValue === 1) return this._beatsToUnits(this._getTimeSignature()) * scalar;
                    else return this._beatsToUnits(4 / numericValue) * scalar;
                },
                regexp: /^(\d+)n(\.?)$/i
            },
            number: {
                method: (value)=>{
                    return this._expressions[this.defaultUnits].method.call(this, value);
                },
                regexp: /^(\d+(?:\.\d+)?)$/
            },
            s: {
                method: (value)=>{
                    return this._secondsToUnits(parseFloat(value));
                },
                regexp: /^(\d+(?:\.\d+)?)s$/
            },
            samples: {
                method: (value)=>{
                    return parseInt(value, 10) / this.context.sampleRate;
                },
                regexp: /^(\d+)samples$/
            },
            t: {
                method: (value)=>{
                    const numericValue = parseInt(value, 10);
                    return this._beatsToUnits(8 / (Math.floor(numericValue) * 3));
                },
                regexp: /^(\d+)t$/i
            },
            tr: {
                method: (m, q, s)=>{
                    let total = 0;
                    if (m && m !== "0") total += this._beatsToUnits(this._getTimeSignature() * parseFloat(m));
                    if (q && q !== "0") total += this._beatsToUnits(parseFloat(q));
                    if (s && s !== "0") total += this._beatsToUnits(parseFloat(s) / 4);
                    return total;
                },
                regexp: /^(\d+(?:\.\d+)?):(\d+(?:\.\d+)?):?(\d+(?:\.\d+)?)?$/
            }
        };
    }
    //-------------------------------------
    // 	VALUE OF
    //-------------------------------------
    /**
     * Evaluate the time value. Returns the time in seconds.
     */ valueOf() {
        if (this._val instanceof $aef073e4341f6769$export$23b5656976f56273) this.fromType(this._val);
        if ((0, $b63b9a75cba601b0$export$eb605f91c5895a5b)(this._val)) return this._noArg();
        else if ((0, $b63b9a75cba601b0$export$844ec244b1367d54)(this._val) && (0, $b63b9a75cba601b0$export$eb605f91c5895a5b)(this._units)) {
            for(const units in this._expressions)if (this._expressions[units].regexp.test(this._val.trim())) {
                this._units = units;
                break;
            }
        } else if ((0, $b63b9a75cba601b0$export$a6cdc56e425d0d0a)(this._val)) {
            let total = 0;
            for(const typeName in this._val)if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(this._val[typeName])) {
                const quantity = this._val[typeName];
                // @ts-ignore
                const time = new this.constructor(this.context, typeName).valueOf() * quantity;
                total += time;
            }
            return total;
        }
        if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(this._units)) {
            const expr = this._expressions[this._units];
            const matching = this._val.toString().trim().match(expr.regexp);
            if (matching) return expr.method.apply(this, matching.slice(1));
            else return expr.method.call(this, this._val);
        } else if ((0, $b63b9a75cba601b0$export$844ec244b1367d54)(this._val)) return parseFloat(this._val);
        else return this._val;
    }
    //-------------------------------------
    // 	UNIT CONVERSIONS
    //-------------------------------------
    /**
     * Returns the value of a frequency in the current units
     */ _frequencyToUnits(freq) {
        return 1 / freq;
    }
    /**
     * Return the value of the beats in the current units
     */ _beatsToUnits(beats) {
        return 60 / this._getBpm() * beats;
    }
    /**
     * Returns the value of a second in the current units
     */ _secondsToUnits(seconds) {
        return seconds;
    }
    /**
     * Returns the value of a tick in the current time units
     */ _ticksToUnits(ticks) {
        return ticks * this._beatsToUnits(1) / this._getPPQ();
    }
    /**
     * With no arguments, return 'now'
     */ _noArg() {
        return this._now();
    }
    //-------------------------------------
    // 	TEMPO CONVERSIONS
    //-------------------------------------
    /**
     * Return the bpm
     */ _getBpm() {
        return this.context.transport.bpm.value;
    }
    /**
     * Return the timeSignature
     */ _getTimeSignature() {
        return this.context.transport.timeSignature;
    }
    /**
     * Return the PPQ or 192 if Transport is not available
     */ _getPPQ() {
        return this.context.transport.PPQ;
    }
    //-------------------------------------
    // 	CONVERSION INTERFACE
    //-------------------------------------
    /**
     * Coerce a time type into this units type.
     * @param type Any time type units
     */ fromType(type) {
        this._units = undefined;
        switch(this.defaultUnits){
            case "s":
                this._val = type.toSeconds();
                break;
            case "i":
                this._val = type.toTicks();
                break;
            case "hz":
                this._val = type.toFrequency();
                break;
            case "midi":
                this._val = type.toMidi();
                break;
        }
        return this;
    }
    /**
     * Return the value in hertz
     */ toFrequency() {
        return 1 / this.toSeconds();
    }
    /**
     * Return the time in samples
     */ toSamples() {
        return this.toSeconds() * this.context.sampleRate;
    }
    /**
     * Return the time in milliseconds.
     */ toMilliseconds() {
        return this.toSeconds() * 1000;
    }
}


class $7eeede37354a7671$export$52b3039dca93a306 extends (0, $aef073e4341f6769$export$23b5656976f56273) {
    constructor(){
        super(...arguments);
        this.name = "TimeClass";
    }
    _getExpressions() {
        return Object.assign(super._getExpressions(), {
            now: {
                method: (capture)=>{
                    return this._now() + new this.constructor(this.context, capture).valueOf();
                },
                regexp: /^\+(.+)/
            },
            quantize: {
                method: (capture)=>{
                    const quantTo = new $7eeede37354a7671$export$52b3039dca93a306(this.context, capture).valueOf();
                    return this._secondsToUnits(this.context.transport.nextSubdivision(quantTo));
                },
                regexp: /^@(.+)/
            }
        });
    }
    /**
     * Quantize the time by the given subdivision. Optionally add a
     * percentage which will move the time value towards the ideal
     * quantized value by that percentage.
     * @param  subdiv    The subdivision to quantize to
     * @param  percent  Move the time value towards the quantized value by a percentage.
     * @example
     * Tone.Time(21).quantize(2); // returns 22
     * Tone.Time(0.6).quantize("4n", 0.5); // returns 0.55
     */ quantize(subdiv, percent = 1) {
        const subdivision = new this.constructor(this.context, subdiv).valueOf();
        const value = this.valueOf();
        const multiple = Math.round(value / subdivision);
        const ideal = multiple * subdivision;
        const diff = ideal - value;
        return value + diff * percent;
    }
    //-------------------------------------
    // CONVERSIONS
    //-------------------------------------
    /**
     * Convert a Time to Notation. The notation values are will be the
     * closest representation between 1m to 128th note.
     * @return {Notation}
     * @example
     * // if the Transport is at 120bpm:
     * Tone.Time(2).toNotation(); // returns "1m"
     */ toNotation() {
        const time = this.toSeconds();
        const testNotations = [
            "1m"
        ];
        for(let power = 1; power < 9; power++){
            const subdiv = Math.pow(2, power);
            testNotations.push(subdiv + "n.");
            testNotations.push(subdiv + "n");
            testNotations.push(subdiv + "t");
        }
        testNotations.push("0");
        // find the closets notation representation
        let closest = testNotations[0];
        let closestSeconds = new $7eeede37354a7671$export$52b3039dca93a306(this.context, testNotations[0]).toSeconds();
        testNotations.forEach((notation)=>{
            const notationSeconds = new $7eeede37354a7671$export$52b3039dca93a306(this.context, notation).toSeconds();
            if (Math.abs(notationSeconds - time) < Math.abs(closestSeconds - time)) {
                closest = notation;
                closestSeconds = notationSeconds;
            }
        });
        return closest;
    }
    /**
     * Return the time encoded as Bars:Beats:Sixteenths.
     */ toBarsBeatsSixteenths() {
        const quarterTime = this._beatsToUnits(1);
        let quarters = this.valueOf() / quarterTime;
        quarters = parseFloat(quarters.toFixed(4));
        const measures = Math.floor(quarters / this._getTimeSignature());
        let sixteenths = quarters % 1 * 4;
        quarters = Math.floor(quarters) % this._getTimeSignature();
        const sixteenthString = sixteenths.toString();
        if (sixteenthString.length > 3) // the additional parseFloat removes insignificant trailing zeroes
        sixteenths = parseFloat(parseFloat(sixteenthString).toFixed(3));
        const progress = [
            measures,
            quarters,
            sixteenths
        ];
        return progress.join(":");
    }
    /**
     * Return the time in ticks.
     */ toTicks() {
        const quarterTime = this._beatsToUnits(1);
        const quarters = this.valueOf() / quarterTime;
        return Math.round(quarters * this._getPPQ());
    }
    /**
     * Return the time in seconds.
     */ toSeconds() {
        return this.valueOf();
    }
    /**
     * Return the value as a midi note.
     */ toMidi() {
        return (0, $73949b14fe57a99a$export$5cf9d9f9506eec5)(this.toFrequency());
    }
    _now() {
        return this.context.now();
    }
}
function $7eeede37354a7671$export$680ea196effce5f(value, units) {
    return new $7eeede37354a7671$export$52b3039dca93a306((0, $3d00f6854e3cc34b$export$31553aaa555c1514)(), value, units);
}


class $5b410fbffb0274be$export$38b56155c8552868 extends (0, $7eeede37354a7671$export$52b3039dca93a306) {
    constructor(){
        super(...arguments);
        this.name = "Frequency";
        this.defaultUnits = "hz";
    }
    /**
     * The [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used
     * to generate all the other pitch values from notes. A4's values in Hertz.
     */ static get A4() {
        return (0, $73949b14fe57a99a$export$9f4826388a169ebd)();
    }
    static set A4(freq) {
        (0, $73949b14fe57a99a$export$2a0f2ad6a5f8e4fe)(freq);
    }
    //-------------------------------------
    // 	AUGMENT BASE EXPRESSIONS
    //-------------------------------------
    _getExpressions() {
        return Object.assign({}, super._getExpressions(), {
            midi: {
                regexp: /^(\d+(?:\.\d+)?midi)/,
                method (value) {
                    if (this.defaultUnits === "midi") return value;
                    else return $5b410fbffb0274be$export$38b56155c8552868.mtof(value);
                }
            },
            note: {
                regexp: /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i,
                method (pitch, octave) {
                    const index = $5b410fbffb0274be$var$noteToScaleIndex[pitch.toLowerCase()];
                    const noteNumber = index + (parseInt(octave, 10) + 1) * 12;
                    if (this.defaultUnits === "midi") return noteNumber;
                    else return $5b410fbffb0274be$export$38b56155c8552868.mtof(noteNumber);
                }
            },
            tr: {
                regexp: /^(\d+(?:\.\d+)?):(\d+(?:\.\d+)?):?(\d+(?:\.\d+)?)?/,
                method (m, q, s) {
                    let total = 1;
                    if (m && m !== "0") total *= this._beatsToUnits(this._getTimeSignature() * parseFloat(m));
                    if (q && q !== "0") total *= this._beatsToUnits(parseFloat(q));
                    if (s && s !== "0") total *= this._beatsToUnits(parseFloat(s) / 4);
                    return total;
                }
            }
        });
    }
    //-------------------------------------
    // 	EXPRESSIONS
    //-------------------------------------
    /**
     * Transposes the frequency by the given number of semitones.
     * @return  A new transposed frequency
     * @example
     * Tone.Frequency("A4").transpose(3); // "C5"
     */ transpose(interval) {
        return new $5b410fbffb0274be$export$38b56155c8552868(this.context, this.valueOf() * (0, $73949b14fe57a99a$export$5d18fe46719f6008)(interval));
    }
    /**
     * Takes an array of semitone intervals and returns
     * an array of frequencies transposed by those intervals.
     * @return  Returns an array of Frequencies
     * @example
     * Tone.Frequency("A4").harmonize([0, 3, 7]); // ["A4", "C5", "E5"]
     */ harmonize(intervals) {
        return intervals.map((interval)=>{
            return this.transpose(interval);
        });
    }
    //-------------------------------------
    // 	UNIT CONVERSIONS
    //-------------------------------------
    /**
     * Return the value of the frequency as a MIDI note
     * @example
     * Tone.Frequency("C4").toMidi(); // 60
     */ toMidi() {
        return (0, $73949b14fe57a99a$export$5cf9d9f9506eec5)(this.valueOf());
    }
    /**
     * Return the value of the frequency in Scientific Pitch Notation
     * @example
     * Tone.Frequency(69, "midi").toNote(); // "A4"
     */ toNote() {
        const freq = this.toFrequency();
        const log = Math.log2(freq / $5b410fbffb0274be$export$38b56155c8552868.A4);
        let noteNumber = Math.round(12 * log) + 57;
        const octave = Math.floor(noteNumber / 12);
        if (octave < 0) noteNumber += -12 * octave;
        const noteName = $5b410fbffb0274be$var$scaleIndexToNote[noteNumber % 12];
        return noteName + octave.toString();
    }
    /**
     * Return the duration of one cycle in seconds.
     */ toSeconds() {
        return 1 / super.toSeconds();
    }
    /**
     * Return the duration of one cycle in ticks
     */ toTicks() {
        const quarterTime = this._beatsToUnits(1);
        const quarters = this.valueOf() / quarterTime;
        return Math.floor(quarters * this._getPPQ());
    }
    //-------------------------------------
    // 	UNIT CONVERSIONS HELPERS
    //-------------------------------------
    /**
     * With no arguments, return 0
     */ _noArg() {
        return 0;
    }
    /**
     * Returns the value of a frequency in the current units
     */ _frequencyToUnits(freq) {
        return freq;
    }
    /**
     * Returns the value of a tick in the current time units
     */ _ticksToUnits(ticks) {
        return 1 / (ticks * 60 / (this._getBpm() * this._getPPQ()));
    }
    /**
     * Return the value of the beats in the current units
     */ _beatsToUnits(beats) {
        return 1 / super._beatsToUnits(beats);
    }
    /**
     * Returns the value of a second in the current units
     */ _secondsToUnits(seconds) {
        return 1 / seconds;
    }
    /**
     * Convert a MIDI note to frequency value.
     * @param  midi The midi number to convert.
     * @return The corresponding frequency value
     */ static mtof(midi) {
        return (0, $73949b14fe57a99a$export$45a6434f7c391dc)(midi);
    }
    /**
     * Convert a frequency value to a MIDI note.
     * @param frequency The value to frequency value to convert.
     */ static ftom(frequency) {
        return (0, $73949b14fe57a99a$export$5cf9d9f9506eec5)(frequency);
    }
}
//-------------------------------------
// 	FREQUENCY CONVERSIONS
//-------------------------------------
/**
 * Note to scale index.
 * @hidden
 */ const $5b410fbffb0274be$var$noteToScaleIndex = {
    cbb: -2,
    cb: -1,
    c: 0,
    "c#": 1,
    cx: 2,
    dbb: 0,
    db: 1,
    d: 2,
    "d#": 3,
    dx: 4,
    ebb: 2,
    eb: 3,
    e: 4,
    "e#": 5,
    ex: 6,
    fbb: 3,
    fb: 4,
    f: 5,
    "f#": 6,
    fx: 7,
    gbb: 5,
    gb: 6,
    g: 7,
    "g#": 8,
    gx: 9,
    abb: 7,
    ab: 8,
    a: 9,
    "a#": 10,
    ax: 11,
    bbb: 9,
    bb: 10,
    b: 11,
    "b#": 12,
    bx: 13
};
/**
 * scale index to note (sharps)
 * @hidden
 */ const $5b410fbffb0274be$var$scaleIndexToNote = [
    "C",
    "C#",
    "D",
    "D#",
    "E",
    "F",
    "F#",
    "G",
    "G#",
    "A",
    "A#",
    "B"
];
function $5b410fbffb0274be$export$44c95d3770756ed2(value, units) {
    return new $5b410fbffb0274be$export$38b56155c8552868((0, $3d00f6854e3cc34b$export$31553aaa555c1514)(), value, units);
}





class $16edc52e2d0df4ee$export$c824041178a9697 extends (0, $7eeede37354a7671$export$52b3039dca93a306) {
    constructor(){
        super(...arguments);
        this.name = "TransportTime";
    }
    /**
     * Return the current time in whichever context is relevant
     */ _now() {
        return this.context.transport.seconds;
    }
}
function $16edc52e2d0df4ee$export$c5a05eab537a3f95(value, units) {
    return new $16edc52e2d0df4ee$export$c824041178a9697((0, $3d00f6854e3cc34b$export$31553aaa555c1514)(), value, units);
}




class $60e11f0590acfc0d$export$4eb0ca57400aa172 extends (0, $0eb7340e2d092af9$export$12b11dc969d02fed) {
    constructor(){
        super();
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($60e11f0590acfc0d$export$4eb0ca57400aa172.getDefaults(), arguments, [
            "context"
        ]);
        if (this.defaultContext) this.context = this.defaultContext;
        else this.context = options.context;
    }
    static getDefaults() {
        return {
            context: (0, $3d00f6854e3cc34b$export$31553aaa555c1514)()
        };
    }
    /**
     * Return the current time of the Context clock plus the lookAhead.
     * @example
     * setInterval(() => {
     * 	console.log(Tone.now());
     * }, 100);
     */ now() {
        return this.context.currentTime + this.context.lookAhead;
    }
    /**
     * Return the current time of the Context clock without any lookAhead.
     * @example
     * setInterval(() => {
     * 	console.log(Tone.immediate());
     * }, 100);
     */ immediate() {
        return this.context.currentTime;
    }
    /**
     * The duration in seconds of one sample.
     * @example
     * console.log(Tone.Transport.sampleTime);
     */ get sampleTime() {
        return 1 / this.context.sampleRate;
    }
    /**
     * The number of seconds of 1 processing block (128 samples)
     * @example
     * console.log(Tone.Destination.blockTime);
     */ get blockTime() {
        return 128 / this.context.sampleRate;
    }
    /**
     * Convert the incoming time to seconds.
     * This is calculated against the current [[Tone.Transport]] bpm
     * @example
     * const gain = new Tone.Gain();
     * setInterval(() => console.log(gain.toSeconds("4n")), 100);
     * // ramp the tempo to 60 bpm over 30 seconds
     * Tone.getTransport().bpm.rampTo(60, 30);
     */ toSeconds(time) {
        return new (0, $7eeede37354a7671$export$52b3039dca93a306)(this.context, time).toSeconds();
    }
    /**
     * Convert the input to a frequency number
     * @example
     * const gain = new Tone.Gain();
     * console.log(gain.toFrequency("4n"));
     */ toFrequency(freq) {
        return new (0, $5b410fbffb0274be$export$38b56155c8552868)(this.context, freq).toFrequency();
    }
    /**
     * Convert the input time into ticks
     * @example
     * const gain = new Tone.Gain();
     * console.log(gain.toTicks("4n"));
     */ toTicks(time) {
        return new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, time).toTicks();
    }
    //-------------------------------------
    // 	GET/SET
    //-------------------------------------
    /**
     * Get a subset of the properties which are in the partial props
     */ _getPartialProperties(props) {
        const options = this.get();
        // remove attributes from the prop that are not in the partial
        Object.keys(options).forEach((name)=>{
            if ((0, $b63b9a75cba601b0$export$eb605f91c5895a5b)(props[name])) delete options[name];
        });
        return options;
    }
    /**
     * Get the object's attributes.
     * @example
     * const osc = new Tone.Oscillator();
     * console.log(osc.get());
     */ get() {
        const defaults = (0, $1e273b197c429402$export$4b8c3341c9aef2b8)(this);
        Object.keys(defaults).forEach((attribute)=>{
            if (Reflect.has(this, attribute)) {
                const member = this[attribute];
                if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(member) && (0, $b63b9a75cba601b0$export$4e62c701997796c1)(member.value) && (0, $b63b9a75cba601b0$export$4e62c701997796c1)(member.setValueAtTime)) defaults[attribute] = member.value;
                else if (member instanceof $60e11f0590acfc0d$export$4eb0ca57400aa172) defaults[attribute] = member._getPartialProperties(defaults[attribute]);
                else if ((0, $b63b9a75cba601b0$export$43bee75e5e14138e)(member) || (0, $b63b9a75cba601b0$export$7e4aa119212bc614)(member) || (0, $b63b9a75cba601b0$export$844ec244b1367d54)(member) || (0, $b63b9a75cba601b0$export$f9ce7b637dfbe238)(member)) defaults[attribute] = member;
                else // remove all undefined and unserializable attributes
                delete defaults[attribute];
            }
        });
        return defaults;
    }
    /**
     * Set multiple properties at once with an object.
     * @example
     * const filter = new Tone.Filter().toDestination();
     * // set values using an object
     * filter.set({
     * 	frequency: "C6",
     * 	type: "highpass"
     * });
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/Analogsynth_octaves_highmid.mp3").connect(filter);
     * player.autostart = true;
     */ set(props) {
        Object.keys(props).forEach((attribute)=>{
            if (Reflect.has(this, attribute) && (0, $b63b9a75cba601b0$export$4e62c701997796c1)(this[attribute])) {
                if (this[attribute] && (0, $b63b9a75cba601b0$export$4e62c701997796c1)(this[attribute].value) && (0, $b63b9a75cba601b0$export$4e62c701997796c1)(this[attribute].setValueAtTime)) // small optimization
                {
                    if (this[attribute].value !== props[attribute]) this[attribute].value = props[attribute];
                } else if (this[attribute] instanceof $60e11f0590acfc0d$export$4eb0ca57400aa172) this[attribute].set(props[attribute]);
                else this[attribute] = props[attribute];
            }
        });
        return this;
    }
}




class $139d674b4982de8e$export$1ca45c9a47aec42c extends (0, $60e11f0590acfc0d$export$4eb0ca57400aa172) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($139d674b4982de8e$export$1ca45c9a47aec42c.getDefaults(), arguments, [
            "param",
            "units",
            "convert"
        ]));
        this.name = "Param";
        this.overridden = false;
        /**
         * The minimum output value
         */ this._minOutput = 1e-7;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($139d674b4982de8e$export$1ca45c9a47aec42c.getDefaults(), arguments, [
            "param",
            "units",
            "convert"
        ]);
        (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $b63b9a75cba601b0$export$4e62c701997796c1)(options.param) && ((0, $ca1a79a064f4108f$export$1abe4e52803657f3)(options.param) || options.param instanceof $139d674b4982de8e$export$1ca45c9a47aec42c), "param must be an AudioParam");
        while(!(0, $ca1a79a064f4108f$export$1abe4e52803657f3)(options.param))options.param = options.param._param;
        this._swappable = (0, $b63b9a75cba601b0$export$4e62c701997796c1)(options.swappable) ? options.swappable : false;
        if (this._swappable) {
            this.input = this.context.createGain();
            // initialize
            this._param = options.param;
            this.input.connect(this._param);
        } else this._param = this.input = options.param;
        this._events = new (0, $3684d29589a800b6$export$e6a97ba2cae5bb94)(1000);
        this._initialValue = this._param.defaultValue;
        this.units = options.units;
        this.convert = options.convert;
        this._minValue = options.minValue;
        this._maxValue = options.maxValue;
        // if the value is defined, set it immediately
        if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(options.value) && options.value !== this._toType(this._initialValue)) this.setValueAtTime(options.value, 0);
    }
    static getDefaults() {
        return Object.assign((0, $60e11f0590acfc0d$export$4eb0ca57400aa172).getDefaults(), {
            convert: true,
            units: "number"
        });
    }
    get value() {
        const now = this.now();
        return this.getValueAtTime(now);
    }
    set value(value) {
        this.cancelScheduledValues(this.now());
        this.setValueAtTime(value, this.now());
    }
    get minValue() {
        // if it's not the default minValue, return it
        if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(this._minValue)) return this._minValue;
        else if (this.units === "time" || this.units === "frequency" || this.units === "normalRange" || this.units === "positive" || this.units === "transportTime" || this.units === "ticks" || this.units === "bpm" || this.units === "hertz" || this.units === "samples") return 0;
        else if (this.units === "audioRange") return -1;
        else if (this.units === "decibels") return -Infinity;
        else return this._param.minValue;
    }
    get maxValue() {
        if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(this._maxValue)) return this._maxValue;
        else if (this.units === "normalRange" || this.units === "audioRange") return 1;
        else return this._param.maxValue;
    }
    /**
     * Type guard based on the unit name
     */ _is(arg, type) {
        return this.units === type;
    }
    /**
     * Make sure the value is always in the defined range
     */ _assertRange(value) {
        if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(this.maxValue) && (0, $b63b9a75cba601b0$export$4e62c701997796c1)(this.minValue)) (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(value, this._fromType(this.minValue), this._fromType(this.maxValue));
        return value;
    }
    /**
     * Convert the given value from the type specified by Param.units
     * into the destination value (such as Gain or Frequency).
     */ _fromType(val) {
        if (this.convert && !this.overridden) {
            if (this._is(val, "time")) return this.toSeconds(val);
            else if (this._is(val, "decibels")) return (0, $73949b14fe57a99a$export$33ed28de027e9482)(val);
            else if (this._is(val, "frequency")) return this.toFrequency(val);
            else return val;
        } else if (this.overridden) // if it's overridden, should only schedule 0s
        return 0;
        else return val;
    }
    /**
     * Convert the parameters value into the units specified by Param.units.
     */ _toType(val) {
        if (this.convert && this.units === "decibels") return (0, $73949b14fe57a99a$export$6af3969727ca2a60)(val);
        else return val;
    }
    //-------------------------------------
    // ABSTRACT PARAM INTERFACE
    // all docs are generated from ParamInterface.ts
    //-------------------------------------
    setValueAtTime(value, time) {
        const computedTime = this.toSeconds(time);
        const numericValue = this._fromType(value);
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to setValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(time)}`);
        this._assertRange(numericValue);
        this.log(this.units, "setValueAtTime", value, computedTime);
        this._events.add({
            time: computedTime,
            type: "setValueAtTime",
            value: numericValue
        });
        this._param.setValueAtTime(numericValue, computedTime);
        return this;
    }
    getValueAtTime(time) {
        const computedTime = Math.max(this.toSeconds(time), 0);
        const after = this._events.getAfter(computedTime);
        const before = this._events.get(computedTime);
        let value = this._initialValue;
        // if it was set by
        if (before === null) value = this._initialValue;
        else if (before.type === "setTargetAtTime" && (after === null || after.type === "setValueAtTime")) {
            const previous = this._events.getBefore(before.time);
            let previousVal;
            if (previous === null) previousVal = this._initialValue;
            else previousVal = previous.value;
            if (before.type === "setTargetAtTime") value = this._exponentialApproach(before.time, previousVal, before.value, before.constant, computedTime);
        } else if (after === null) value = before.value;
        else if (after.type === "linearRampToValueAtTime" || after.type === "exponentialRampToValueAtTime") {
            let beforeValue = before.value;
            if (before.type === "setTargetAtTime") {
                const previous = this._events.getBefore(before.time);
                if (previous === null) beforeValue = this._initialValue;
                else beforeValue = previous.value;
            }
            if (after.type === "linearRampToValueAtTime") value = this._linearInterpolate(before.time, beforeValue, after.time, after.value, computedTime);
            else value = this._exponentialInterpolate(before.time, beforeValue, after.time, after.value, computedTime);
        } else value = before.value;
        return this._toType(value);
    }
    setRampPoint(time) {
        time = this.toSeconds(time);
        let currentVal = this.getValueAtTime(time);
        this.cancelAndHoldAtTime(time);
        if (this._fromType(currentVal) === 0) currentVal = this._toType(this._minOutput);
        this.setValueAtTime(currentVal, time);
        return this;
    }
    linearRampToValueAtTime(value, endTime) {
        const numericValue = this._fromType(value);
        const computedTime = this.toSeconds(endTime);
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to linearRampToValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(endTime)}`);
        this._assertRange(numericValue);
        this._events.add({
            time: computedTime,
            type: "linearRampToValueAtTime",
            value: numericValue
        });
        this.log(this.units, "linearRampToValueAtTime", value, computedTime);
        this._param.linearRampToValueAtTime(numericValue, computedTime);
        return this;
    }
    exponentialRampToValueAtTime(value, endTime) {
        let numericValue = this._fromType(value);
        // the value can't be 0
        numericValue = (0, $e85238bb45fd87b7$export$1c0a5d05eb3f6e18)(numericValue, 0) ? this._minOutput : numericValue;
        this._assertRange(numericValue);
        const computedTime = this.toSeconds(endTime);
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to exponentialRampToValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(endTime)}`);
        // store the event
        this._events.add({
            time: computedTime,
            type: "exponentialRampToValueAtTime",
            value: numericValue
        });
        this.log(this.units, "exponentialRampToValueAtTime", value, computedTime);
        this._param.exponentialRampToValueAtTime(numericValue, computedTime);
        return this;
    }
    exponentialRampTo(value, rampTime, startTime) {
        startTime = this.toSeconds(startTime);
        this.setRampPoint(startTime);
        this.exponentialRampToValueAtTime(value, startTime + this.toSeconds(rampTime));
        return this;
    }
    linearRampTo(value, rampTime, startTime) {
        startTime = this.toSeconds(startTime);
        this.setRampPoint(startTime);
        this.linearRampToValueAtTime(value, startTime + this.toSeconds(rampTime));
        return this;
    }
    targetRampTo(value, rampTime, startTime) {
        startTime = this.toSeconds(startTime);
        this.setRampPoint(startTime);
        this.exponentialApproachValueAtTime(value, startTime, rampTime);
        return this;
    }
    exponentialApproachValueAtTime(value, time, rampTime) {
        time = this.toSeconds(time);
        rampTime = this.toSeconds(rampTime);
        const timeConstant = Math.log(rampTime + 1) / Math.log(200);
        this.setTargetAtTime(value, time, timeConstant);
        // at 90% start a linear ramp to the final value
        this.cancelAndHoldAtTime(time + rampTime * 0.9);
        this.linearRampToValueAtTime(value, time + rampTime);
        return this;
    }
    setTargetAtTime(value, startTime, timeConstant) {
        const numericValue = this._fromType(value);
        // The value will never be able to approach without timeConstant > 0.
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(isFinite(timeConstant) && timeConstant > 0, "timeConstant must be a number greater than 0");
        const computedTime = this.toSeconds(startTime);
        this._assertRange(numericValue);
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to setTargetAtTime: ${JSON.stringify(value)}, ${JSON.stringify(startTime)}`);
        this._events.add({
            constant: timeConstant,
            time: computedTime,
            type: "setTargetAtTime",
            value: numericValue
        });
        this.log(this.units, "setTargetAtTime", value, computedTime, timeConstant);
        this._param.setTargetAtTime(numericValue, computedTime, timeConstant);
        return this;
    }
    setValueCurveAtTime(values, startTime, duration, scaling = 1) {
        duration = this.toSeconds(duration);
        startTime = this.toSeconds(startTime);
        const startingValue = this._fromType(values[0]) * scaling;
        this.setValueAtTime(this._toType(startingValue), startTime);
        const segTime = duration / (values.length - 1);
        for(let i = 1; i < values.length; i++){
            const numericValue = this._fromType(values[i]) * scaling;
            this.linearRampToValueAtTime(this._toType(numericValue), startTime + i * segTime);
        }
        return this;
    }
    cancelScheduledValues(time) {
        const computedTime = this.toSeconds(time);
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(isFinite(computedTime), `Invalid argument to cancelScheduledValues: ${JSON.stringify(time)}`);
        this._events.cancel(computedTime);
        this._param.cancelScheduledValues(computedTime);
        this.log(this.units, "cancelScheduledValues", computedTime);
        return this;
    }
    cancelAndHoldAtTime(time) {
        const computedTime = this.toSeconds(time);
        const valueAtTime = this._fromType(this.getValueAtTime(computedTime));
        // remove the schedule events
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(isFinite(computedTime), `Invalid argument to cancelAndHoldAtTime: ${JSON.stringify(time)}`);
        this.log(this.units, "cancelAndHoldAtTime", computedTime, "value=" + valueAtTime);
        // if there is an event at the given computedTime
        // and that even is not a "set"
        const before = this._events.get(computedTime);
        const after = this._events.getAfter(computedTime);
        if (before && (0, $e85238bb45fd87b7$export$1c0a5d05eb3f6e18)(before.time, computedTime)) {
            // remove everything after
            if (after) {
                this._param.cancelScheduledValues(after.time);
                this._events.cancel(after.time);
            } else {
                this._param.cancelAndHoldAtTime(computedTime);
                this._events.cancel(computedTime + this.sampleTime);
            }
        } else if (after) {
            this._param.cancelScheduledValues(after.time);
            // cancel the next event(s)
            this._events.cancel(after.time);
            if (after.type === "linearRampToValueAtTime") this.linearRampToValueAtTime(this._toType(valueAtTime), computedTime);
            else if (after.type === "exponentialRampToValueAtTime") this.exponentialRampToValueAtTime(this._toType(valueAtTime), computedTime);
        }
        // set the value at the given time
        this._events.add({
            time: computedTime,
            type: "setValueAtTime",
            value: valueAtTime
        });
        this._param.setValueAtTime(valueAtTime, computedTime);
        return this;
    }
    rampTo(value, rampTime = 0.1, startTime) {
        if (this.units === "frequency" || this.units === "bpm" || this.units === "decibels") this.exponentialRampTo(value, rampTime, startTime);
        else this.linearRampTo(value, rampTime, startTime);
        return this;
    }
    /**
     * Apply all of the previously scheduled events to the passed in Param or AudioParam.
     * The applied values will start at the context's current time and schedule
     * all of the events which are scheduled on this Param onto the passed in param.
     */ apply(param) {
        const now = this.context.currentTime;
        // set the param's value at the current time and schedule everything else
        param.setValueAtTime(this.getValueAtTime(now), now);
        // if the previous event was a curve, then set the rest of it
        const previousEvent = this._events.get(now);
        if (previousEvent && previousEvent.type === "setTargetAtTime") {
            // approx it until the next event with linear ramps
            const nextEvent = this._events.getAfter(previousEvent.time);
            // or for 2 seconds if there is no event
            const endTime = nextEvent ? nextEvent.time : now + 2;
            const subdivisions = (endTime - now) / 10;
            for(let i = now; i < endTime; i += subdivisions)param.linearRampToValueAtTime(this.getValueAtTime(i), i);
        }
        this._events.forEachAfter(this.context.currentTime, (event)=>{
            if (event.type === "cancelScheduledValues") param.cancelScheduledValues(event.time);
            else if (event.type === "setTargetAtTime") param.setTargetAtTime(event.value, event.time, event.constant);
            else param[event.type](event.value, event.time);
        });
        return this;
    }
    /**
     * Replace the Param's internal AudioParam. Will apply scheduled curves
     * onto the parameter and replace the connections.
     */ setParam(param) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(this._swappable, "The Param must be assigned as 'swappable' in the constructor");
        const input = this.input;
        input.disconnect(this._param);
        this.apply(param);
        this._param = param;
        input.connect(this._param);
        return this;
    }
    dispose() {
        super.dispose();
        this._events.dispose();
        return this;
    }
    get defaultValue() {
        return this._toType(this._param.defaultValue);
    }
    //-------------------------------------
    // 	AUTOMATION CURVE CALCULATIONS
    // 	MIT License, copyright (c) 2014 Jordan Santell
    //-------------------------------------
    // Calculates the the value along the curve produced by setTargetAtTime
    _exponentialApproach(t0, v0, v1, timeConstant, t) {
        return v1 + (v0 - v1) * Math.exp(-(t - t0) / timeConstant);
    }
    // Calculates the the value along the curve produced by linearRampToValueAtTime
    _linearInterpolate(t0, v0, t1, v1, t) {
        return v0 + (v1 - v0) * ((t - t0) / (t1 - t0));
    }
    // Calculates the the value along the curve produced by exponentialRampToValueAtTime
    _exponentialInterpolate(t0, v0, t1, v1, t) {
        return v0 * Math.pow(v1 / v0, (t - t0) / (t1 - t0));
    }
}




class $5ffbb5654e49c399$export$14a6d069f26d1d33 extends (0, $60e11f0590acfc0d$export$4eb0ca57400aa172) {
    constructor(){
        super(...arguments);
        /**
         * The name of the class
         */ this.name = "ToneAudioNode";
        /**
         * List all of the node that must be set to match the ChannelProperties
         */ this._internalChannels = [];
    }
    /**
     * The number of inputs feeding into the AudioNode.
     * For source nodes, this will be 0.
     * @example
     * const node = new Tone.Gain();
     * console.log(node.numberOfInputs);
     */ get numberOfInputs() {
        if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(this.input)) {
            if ((0, $ca1a79a064f4108f$export$1abe4e52803657f3)(this.input) || this.input instanceof (0, $139d674b4982de8e$export$1ca45c9a47aec42c)) return 1;
            else return this.input.numberOfInputs;
        } else return 0;
    }
    /**
     * The number of outputs of the AudioNode.
     * @example
     * const node = new Tone.Gain();
     * console.log(node.numberOfOutputs);
     */ get numberOfOutputs() {
        if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(this.output)) return this.output.numberOfOutputs;
        else return 0;
    }
    //-------------------------------------
    // AUDIO PROPERTIES
    //-------------------------------------
    /**
     * Used to decide which nodes to get/set properties on
     */ _isAudioNode(node) {
        return (0, $b63b9a75cba601b0$export$4e62c701997796c1)(node) && (node instanceof $5ffbb5654e49c399$export$14a6d069f26d1d33 || (0, $ca1a79a064f4108f$export$85cd8e93eb858e81)(node));
    }
    /**
     * Get all of the audio nodes (either internal or input/output) which together
     * make up how the class node responds to channel input/output
     */ _getInternalNodes() {
        const nodeList = this._internalChannels.slice(0);
        if (this._isAudioNode(this.input)) nodeList.push(this.input);
        if (this._isAudioNode(this.output)) {
            if (this.input !== this.output) nodeList.push(this.output);
        }
        return nodeList;
    }
    /**
     * Set the audio options for this node such as channelInterpretation
     * channelCount, etc.
     * @param options
     */ _setChannelProperties(options) {
        const nodeList = this._getInternalNodes();
        nodeList.forEach((node)=>{
            node.channelCount = options.channelCount;
            node.channelCountMode = options.channelCountMode;
            node.channelInterpretation = options.channelInterpretation;
        });
    }
    /**
     * Get the current audio options for this node such as channelInterpretation
     * channelCount, etc.
     */ _getChannelProperties() {
        const nodeList = this._getInternalNodes();
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(nodeList.length > 0, "ToneAudioNode does not have any internal nodes");
        // use the first node to get properties
        // they should all be the same
        const node = nodeList[0];
        return {
            channelCount: node.channelCount,
            channelCountMode: node.channelCountMode,
            channelInterpretation: node.channelInterpretation
        };
    }
    /**
     * channelCount is the number of channels used when up-mixing and down-mixing
     * connections to any inputs to the node. The default value is 2 except for
     * specific nodes where its value is specially determined.
     */ get channelCount() {
        return this._getChannelProperties().channelCount;
    }
    set channelCount(channelCount) {
        const props = this._getChannelProperties();
        // merge it with the other properties
        this._setChannelProperties(Object.assign(props, {
            channelCount: channelCount
        }));
    }
    /**
     * channelCountMode determines how channels will be counted when up-mixing and
     * down-mixing connections to any inputs to the node.
     * The default value is "max". This attribute has no effect for nodes with no inputs.
     * * "max" - computedNumberOfChannels is the maximum of the number of channels of all connections to an input. In this mode channelCount is ignored.
     * * "clamped-max" - computedNumberOfChannels is determined as for "max" and then clamped to a maximum value of the given channelCount.
     * * "explicit" - computedNumberOfChannels is the exact value as specified by the channelCount.
     */ get channelCountMode() {
        return this._getChannelProperties().channelCountMode;
    }
    set channelCountMode(channelCountMode) {
        const props = this._getChannelProperties();
        // merge it with the other properties
        this._setChannelProperties(Object.assign(props, {
            channelCountMode: channelCountMode
        }));
    }
    /**
     * channelInterpretation determines how individual channels will be treated
     * when up-mixing and down-mixing connections to any inputs to the node.
     * The default value is "speakers".
     */ get channelInterpretation() {
        return this._getChannelProperties().channelInterpretation;
    }
    set channelInterpretation(channelInterpretation) {
        const props = this._getChannelProperties();
        // merge it with the other properties
        this._setChannelProperties(Object.assign(props, {
            channelInterpretation: channelInterpretation
        }));
    }
    //-------------------------------------
    // CONNECTIONS
    //-------------------------------------
    /**
     * connect the output of a ToneAudioNode to an AudioParam, AudioNode, or ToneAudioNode
     * @param destination The output to connect to
     * @param outputNum The output to connect from
     * @param inputNum The input to connect to
     */ connect(destination, outputNum = 0, inputNum = 0) {
        $5ffbb5654e49c399$export$64605811ab45167f(this, destination, outputNum, inputNum);
        return this;
    }
    /**
     * Connect the output to the context's destination node.
     * @example
     * const osc = new Tone.Oscillator("C2").start();
     * osc.toDestination();
     */ toDestination() {
        this.connect(this.context.destination);
        return this;
    }
    /**
     * Connect the output to the context's destination node.
     * See [[toDestination]]
     * @deprecated
     */ toMaster() {
        (0, $23cf54af36cc9441$export$c106dd0671a0fc2d)("toMaster() has been renamed toDestination()");
        return this.toDestination();
    }
    /**
     * disconnect the output
     */ disconnect(destination, outputNum = 0, inputNum = 0) {
        $5ffbb5654e49c399$export$37dfea93db2e14ed(this, destination, outputNum, inputNum);
        return this;
    }
    /**
     * Connect the output of this node to the rest of the nodes in series.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/handdrum-loop.mp3");
     * player.autostart = true;
     * const filter = new Tone.AutoFilter(4).start();
     * const distortion = new Tone.Distortion(0.5);
     * // connect the player to the filter, distortion and then to the master output
     * player.chain(filter, distortion, Tone.Destination);
     */ chain(...nodes) {
        $5ffbb5654e49c399$export$933c3b67552fb559(this, ...nodes);
        return this;
    }
    /**
     * connect the output of this node to the rest of the nodes in parallel.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/conga-rhythm.mp3");
     * player.autostart = true;
     * const pitchShift = new Tone.PitchShift(4).toDestination();
     * const filter = new Tone.Filter("G5").toDestination();
     * // connect a node to the pitch shift and filter in parallel
     * player.fan(pitchShift, filter);
     */ fan(...nodes) {
        nodes.forEach((node)=>this.connect(node));
        return this;
    }
    /**
     * Dispose and disconnect
     */ dispose() {
        super.dispose();
        if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(this.input)) {
            if (this.input instanceof $5ffbb5654e49c399$export$14a6d069f26d1d33) this.input.dispose();
            else if ((0, $ca1a79a064f4108f$export$85cd8e93eb858e81)(this.input)) this.input.disconnect();
        }
        if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(this.output)) {
            if (this.output instanceof $5ffbb5654e49c399$export$14a6d069f26d1d33) this.output.dispose();
            else if ((0, $ca1a79a064f4108f$export$85cd8e93eb858e81)(this.output)) this.output.disconnect();
        }
        this._internalChannels = [];
        return this;
    }
}
function $5ffbb5654e49c399$export$933c3b67552fb559(...nodes) {
    const first = nodes.shift();
    nodes.reduce((prev, current)=>{
        if (prev instanceof $5ffbb5654e49c399$export$14a6d069f26d1d33) prev.connect(current);
        else if ((0, $ca1a79a064f4108f$export$85cd8e93eb858e81)(prev)) $5ffbb5654e49c399$export$64605811ab45167f(prev, current);
        return current;
    }, first);
}
function $5ffbb5654e49c399$export$64605811ab45167f(srcNode, dstNode, outputNumber = 0, inputNumber = 0) {
    (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $b63b9a75cba601b0$export$4e62c701997796c1)(srcNode), "Cannot connect from undefined node");
    (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $b63b9a75cba601b0$export$4e62c701997796c1)(dstNode), "Cannot connect to undefined node");
    if (dstNode instanceof $5ffbb5654e49c399$export$14a6d069f26d1d33 || (0, $ca1a79a064f4108f$export$85cd8e93eb858e81)(dstNode)) (0, $23cf54af36cc9441$export$a7a9523472993e97)(dstNode.numberOfInputs > 0, "Cannot connect to node with no inputs");
    (0, $23cf54af36cc9441$export$a7a9523472993e97)(srcNode.numberOfOutputs > 0, "Cannot connect from node with no outputs");
    // resolve the input of the dstNode
    while(dstNode instanceof $5ffbb5654e49c399$export$14a6d069f26d1d33 || dstNode instanceof (0, $139d674b4982de8e$export$1ca45c9a47aec42c))if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(dstNode.input)) dstNode = dstNode.input;
    while(srcNode instanceof $5ffbb5654e49c399$export$14a6d069f26d1d33)if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(srcNode.output)) srcNode = srcNode.output;
    // make the connection
    if ((0, $ca1a79a064f4108f$export$1abe4e52803657f3)(dstNode)) srcNode.connect(dstNode, outputNumber);
    else srcNode.connect(dstNode, outputNumber, inputNumber);
}
function $5ffbb5654e49c399$export$37dfea93db2e14ed(srcNode, dstNode, outputNumber = 0, inputNumber = 0) {
    // resolve the destination node
    if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(dstNode)) while(dstNode instanceof $5ffbb5654e49c399$export$14a6d069f26d1d33)dstNode = dstNode.input;
    // resolve the src node
    while(!(0, $ca1a79a064f4108f$export$85cd8e93eb858e81)(srcNode))if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(srcNode.output)) srcNode = srcNode.output;
    if ((0, $ca1a79a064f4108f$export$1abe4e52803657f3)(dstNode)) srcNode.disconnect(dstNode, outputNumber);
    else if ((0, $ca1a79a064f4108f$export$85cd8e93eb858e81)(dstNode)) srcNode.disconnect(dstNode, outputNumber, inputNumber);
    else srcNode.disconnect();
}












class $200a6bd89d4579f9$export$acd19d919666900d extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($200a6bd89d4579f9$export$acd19d919666900d.getDefaults(), arguments, [
            "gain",
            "units"
        ]));
        this.name = "Gain";
        /**
         * The wrapped GainNode.
         */ this._gainNode = this.context.createGain();
        // input = output
        this.input = this._gainNode;
        this.output = this._gainNode;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($200a6bd89d4579f9$export$acd19d919666900d.getDefaults(), arguments, [
            "gain",
            "units"
        ]);
        this.gain = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            convert: options.convert,
            param: this._gainNode.gain,
            units: options.units,
            value: options.gain,
            minValue: options.minValue,
            maxValue: options.maxValue
        });
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "gain");
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            convert: true,
            gain: 1,
            units: "gain"
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._gainNode.disconnect();
        this.gain.dispose();
        return this;
    }
}





class $f93c69dcced4086a$export$27749f88ede4d2a3 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(options){
        super(options);
        /**
         * The callback to invoke after the
         * source is done playing.
         */ this.onended = (0, $c0a1ee726091e30a$export$b50b6e108474309b);
        /**
         * The start time
         */ this._startTime = -1;
        /**
         * The stop time
         */ this._stopTime = -1;
        /**
         * The id of the timeout
         */ this._timeout = -1;
        /**
         * The public output node
         */ this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            gain: 0
        });
        /**
         * The output gain node.
         */ this._gainNode = this.output;
        /**
         * Get the playback state at the given time
         */ this.getStateAtTime = function(time) {
            const computedTime = this.toSeconds(time);
            if (this._startTime !== -1 && computedTime >= this._startTime && (this._stopTime === -1 || computedTime <= this._stopTime)) return "started";
            else return "stopped";
        };
        this._fadeIn = options.fadeIn;
        this._fadeOut = options.fadeOut;
        this._curve = options.curve;
        this.onended = options.onended;
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            curve: "linear",
            fadeIn: 0,
            fadeOut: 0,
            onended: (0, $c0a1ee726091e30a$export$b50b6e108474309b)
        });
    }
    /**
     * Start the source at the given time
     * @param  time When to start the source
     */ _startGain(time, gain = 1) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(this._startTime === -1, "Source cannot be started more than once");
        // apply a fade in envelope
        const fadeInTime = this.toSeconds(this._fadeIn);
        // record the start time
        this._startTime = time + fadeInTime;
        this._startTime = Math.max(this._startTime, this.context.currentTime);
        // schedule the envelope
        if (fadeInTime > 0) {
            this._gainNode.gain.setValueAtTime(0, time);
            if (this._curve === "linear") this._gainNode.gain.linearRampToValueAtTime(gain, time + fadeInTime);
            else this._gainNode.gain.exponentialApproachValueAtTime(gain, time, fadeInTime);
        } else this._gainNode.gain.setValueAtTime(gain, time);
        return this;
    }
    /**
     * Stop the source node at the given time.
     * @param time When to stop the source
     */ stop(time) {
        this.log("stop", time);
        this._stopGain(this.toSeconds(time));
        return this;
    }
    /**
     * Stop the source at the given time
     * @param  time When to stop the source
     */ _stopGain(time) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(this._startTime !== -1, "'start' must be called before 'stop'");
        // cancel the previous stop
        this.cancelStop();
        // the fadeOut time
        const fadeOutTime = this.toSeconds(this._fadeOut);
        // schedule the stop callback
        this._stopTime = this.toSeconds(time) + fadeOutTime;
        this._stopTime = Math.max(this._stopTime, this.context.currentTime);
        if (fadeOutTime > 0) {
            // start the fade out curve at the given time
            if (this._curve === "linear") this._gainNode.gain.linearRampTo(0, fadeOutTime, time);
            else this._gainNode.gain.targetRampTo(0, fadeOutTime, time);
        } else {
            // stop any ongoing ramps, and set the value to 0
            this._gainNode.gain.cancelAndHoldAtTime(time);
            this._gainNode.gain.setValueAtTime(0, time);
        }
        this.context.clearTimeout(this._timeout);
        this._timeout = this.context.setTimeout(()=>{
            // allow additional time for the exponential curve to fully decay
            const additionalTail = this._curve === "exponential" ? fadeOutTime * 2 : 0;
            this._stopSource(this.now() + additionalTail);
            this._onended();
        }, this._stopTime - this.context.currentTime);
        return this;
    }
    /**
     * Invoke the onended callback
     */ _onended() {
        if (this.onended !== (0, $c0a1ee726091e30a$export$b50b6e108474309b)) {
            this.onended(this);
            // overwrite onended to make sure it only is called once
            this.onended = (0, $c0a1ee726091e30a$export$b50b6e108474309b);
            // dispose when it's ended to free up for garbage collection only in the online context
            if (!this.context.isOffline) {
                const disposeCallback = ()=>this.dispose();
                // @ts-ignore
                if (typeof window.requestIdleCallback !== "undefined") // @ts-ignore
                window.requestIdleCallback(disposeCallback);
                else setTimeout(disposeCallback, 1000);
            }
        }
    }
    /**
     * Get the playback state at the current time
     */ get state() {
        return this.getStateAtTime(this.now());
    }
    /**
     * Cancel a scheduled stop event
     */ cancelStop() {
        this.log("cancelStop");
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(this._startTime !== -1, "Source is not started");
        // cancel the stop envelope
        this._gainNode.gain.cancelScheduledValues(this._startTime + this.sampleTime);
        this.context.clearTimeout(this._timeout);
        this._stopTime = -1;
        return this;
    }
    dispose() {
        super.dispose();
        this._gainNode.disconnect();
        return this;
    }
}



class $ab1da665fc34fe83$export$30cbf4ba14db4fdd extends (0, $f93c69dcced4086a$export$27749f88ede4d2a3) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($ab1da665fc34fe83$export$30cbf4ba14db4fdd.getDefaults(), arguments, [
            "url",
            "onload"
        ]));
        this.name = "ToneBufferSource";
        /**
         * The oscillator
         */ this._source = this.context.createBufferSource();
        this._internalChannels = [
            this._source
        ];
        /**
         * indicators if the source has started/stopped
         */ this._sourceStarted = false;
        this._sourceStopped = false;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($ab1da665fc34fe83$export$30cbf4ba14db4fdd.getDefaults(), arguments, [
            "url",
            "onload"
        ]);
        (0, $5ffbb5654e49c399$export$64605811ab45167f)(this._source, this._gainNode);
        this._source.onended = ()=>this._stopSource();
        /**
         * The playbackRate of the buffer
         */ this.playbackRate = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this._source.playbackRate,
            units: "positive",
            value: options.playbackRate
        });
        // set some values initially
        this.loop = options.loop;
        this.loopStart = options.loopStart;
        this.loopEnd = options.loopEnd;
        this._buffer = new (0, $f8b2c4c1413d235f$export$424a335715b38178)(options.url, options.onload, options.onerror);
        this._internalChannels.push(this._source);
    }
    static getDefaults() {
        return Object.assign((0, $f93c69dcced4086a$export$27749f88ede4d2a3).getDefaults(), {
            url: new (0, $f8b2c4c1413d235f$export$424a335715b38178)(),
            loop: false,
            loopEnd: 0,
            loopStart: 0,
            onload: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            onerror: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            playbackRate: 1
        });
    }
    /**
     * The fadeIn time of the amplitude envelope.
     */ get fadeIn() {
        return this._fadeIn;
    }
    set fadeIn(t) {
        this._fadeIn = t;
    }
    /**
     * The fadeOut time of the amplitude envelope.
     */ get fadeOut() {
        return this._fadeOut;
    }
    set fadeOut(t) {
        this._fadeOut = t;
    }
    /**
     * The curve applied to the fades, either "linear" or "exponential"
     */ get curve() {
        return this._curve;
    }
    set curve(t) {
        this._curve = t;
    }
    /**
     * Start the buffer
     * @param  time When the player should start.
     * @param  offset The offset from the beginning of the sample to start at.
     * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)
     * @param  gain  The gain to play the buffer back at.
     */ start(time, offset, duration, gain = 1) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(this.buffer.loaded, "buffer is either not set or not loaded");
        const computedTime = this.toSeconds(time);
        // apply the gain envelope
        this._startGain(computedTime, gain);
        // if it's a loop the default offset is the loopstart point
        if (this.loop) offset = (0, $1e273b197c429402$export$37721a79838ca038)(offset, this.loopStart);
        else // otherwise the default offset is 0
        offset = (0, $1e273b197c429402$export$37721a79838ca038)(offset, 0);
        // make sure the offset is not less than 0
        let computedOffset = Math.max(this.toSeconds(offset), 0);
        // start the buffer source
        if (this.loop) {
            // modify the offset if it's greater than the loop time
            const loopEnd = this.toSeconds(this.loopEnd) || this.buffer.duration;
            const loopStart = this.toSeconds(this.loopStart);
            const loopDuration = loopEnd - loopStart;
            // move the offset back
            if ((0, $e85238bb45fd87b7$export$c846515610eb2c50)(computedOffset, loopEnd)) computedOffset = (computedOffset - loopStart) % loopDuration + loopStart;
            // when the offset is very close to the duration, set it to 0
            if ((0, $e85238bb45fd87b7$export$1c0a5d05eb3f6e18)(computedOffset, this.buffer.duration)) computedOffset = 0;
        }
        // this.buffer.loaded would have return false if the AudioBuffer was undefined
        this._source.buffer = this.buffer.get();
        this._source.loopEnd = this.toSeconds(this.loopEnd) || this.buffer.duration;
        if ((0, $e85238bb45fd87b7$export$7158f0ceb70f54c7)(computedOffset, this.buffer.duration)) {
            this._sourceStarted = true;
            this._source.start(computedTime, computedOffset);
        }
        // if a duration is given, schedule a stop
        if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(duration)) {
            let computedDur = this.toSeconds(duration);
            // make sure it's never negative
            computedDur = Math.max(computedDur, 0);
            this.stop(computedTime + computedDur);
        }
        return this;
    }
    _stopSource(time) {
        if (!this._sourceStopped && this._sourceStarted) {
            this._sourceStopped = true;
            this._source.stop(this.toSeconds(time));
            this._onended();
        }
    }
    /**
     * If loop is true, the loop will start at this position.
     */ get loopStart() {
        return this._source.loopStart;
    }
    set loopStart(loopStart) {
        this._source.loopStart = this.toSeconds(loopStart);
    }
    /**
     * If loop is true, the loop will end at this position.
     */ get loopEnd() {
        return this._source.loopEnd;
    }
    set loopEnd(loopEnd) {
        this._source.loopEnd = this.toSeconds(loopEnd);
    }
    /**
     * The audio buffer belonging to the player.
     */ get buffer() {
        return this._buffer;
    }
    set buffer(buffer) {
        this._buffer.set(buffer);
    }
    /**
     * If the buffer should loop once it's over.
     */ get loop() {
        return this._source.loop;
    }
    set loop(loop) {
        this._source.loop = loop;
        if (this._sourceStarted) this.cancelStop();
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._source.onended = null;
        this._source.disconnect();
        this._buffer.dispose();
        this.playbackRate.dispose();
        return this;
    }
}






class $eaa581548eb3754c$export$dca20402ebea5ece extends (0, $60e11f0590acfc0d$export$4eb0ca57400aa172) {
    constructor(){
        super(...arguments);
        this.name = "Draw";
        /**
         * The duration after which events are not invoked.
         */ this.expiration = 0.25;
        /**
         * The amount of time before the scheduled time
         * that the callback can be invoked. Default is
         * half the time of an animation frame (0.008 seconds).
         */ this.anticipation = 0.008;
        /**
         * All of the events.
         */ this._events = new (0, $3684d29589a800b6$export$e6a97ba2cae5bb94)();
        /**
         * The draw loop
         */ this._boundDrawLoop = this._drawLoop.bind(this);
        /**
         * The animation frame id
         */ this._animationFrame = -1;
    }
    /**
     * Schedule a function at the given time to be invoked
     * on the nearest animation frame.
     * @param  callback  Callback is invoked at the given time.
     * @param  time      The time relative to the AudioContext time to invoke the callback.
     * @example
     * Tone.Transport.scheduleRepeat(time => {
     * 	Tone.Draw.schedule(() => console.log(time), time);
     * }, 1);
     * Tone.Transport.start();
     */ schedule(callback, time) {
        this._events.add({
            callback: callback,
            time: this.toSeconds(time)
        });
        // start the draw loop on the first event
        if (this._events.length === 1) this._animationFrame = requestAnimationFrame(this._boundDrawLoop);
        return this;
    }
    /**
     * Cancel events scheduled after the given time
     * @param  after  Time after which scheduled events will be removed from the scheduling timeline.
     */ cancel(after) {
        this._events.cancel(this.toSeconds(after));
        return this;
    }
    /**
     * The draw loop
     */ _drawLoop() {
        const now = this.context.currentTime;
        while(this._events.length && this._events.peek().time - this.anticipation <= now){
            const event = this._events.shift();
            if (event && now - event.time <= this.expiration) event.callback();
        }
        if (this._events.length > 0) this._animationFrame = requestAnimationFrame(this._boundDrawLoop);
    }
    dispose() {
        super.dispose();
        this._events.dispose();
        cancelAnimationFrame(this._animationFrame);
        return this;
    }
}
//-------------------------------------
// 	INITIALIZATION
//-------------------------------------
(0, $5845e19ca4e07c3f$export$cdd816203a02e74e)((context)=>{
    context.draw = new $eaa581548eb3754c$export$dca20402ebea5ece({
        context: context
    });
});
(0, $5845e19ca4e07c3f$export$7e1ecadd06ae8222)((context)=>{
    context.draw.dispose();
});













class $e9f51dc63c33b8a5$export$89221a927ffadcaf extends (0, $3684d29589a800b6$export$e6a97ba2cae5bb94) {
    constructor(initial = "stopped"){
        super();
        this.name = "StateTimeline";
        this._initial = initial;
        this.setStateAtTime(this._initial, 0);
    }
    /**
     * Returns the scheduled state scheduled before or at
     * the given time.
     * @param  time  The time to query.
     * @return  The name of the state input in setStateAtTime.
     */ getValueAtTime(time) {
        const event = this.get(time);
        if (event !== null) return event.state;
        else return this._initial;
    }
    /**
     * Add a state to the timeline.
     * @param  state The name of the state to set.
     * @param  time  The time to query.
     * @param options Any additional options that are needed in the timeline.
     */ setStateAtTime(state, time, options) {
        (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(time, 0);
        this.add(Object.assign({}, options, {
            state: state,
            time: time
        }));
        return this;
    }
    /**
     * Return the event before the time with the given state
     * @param  state The state to look for
     * @param  time  When to check before
     * @return  The event with the given state before the time
     */ getLastState(state, time) {
        // time = this.toSeconds(time);
        const index = this._search(time);
        for(let i = index; i >= 0; i--){
            const event = this._timeline[i];
            if (event.state === state) return event;
        }
    }
    /**
     * Return the event after the time with the given state
     * @param  state The state to look for
     * @param  time  When to check from
     * @return  The event with the given state after the time
     */ getNextState(state, time) {
        // time = this.toSeconds(time);
        const index = this._search(time);
        if (index !== -1) for(let i = index; i < this._timeline.length; i++){
            const event = this._timeline[i];
            if (event.state === state) return event;
        }
    }
}

















class $ef1d4c7c24882f1b$export$717f1ef4ba8fd295 extends (0, $f93c69dcced4086a$export$27749f88ede4d2a3) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($ef1d4c7c24882f1b$export$717f1ef4ba8fd295.getDefaults(), arguments, [
            "offset"
        ]));
        this.name = "ToneConstantSource";
        /**
         * The signal generator
         */ this._source = this.context.createConstantSource();
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($ef1d4c7c24882f1b$export$717f1ef4ba8fd295.getDefaults(), arguments, [
            "offset"
        ]);
        (0, $5ffbb5654e49c399$export$64605811ab45167f)(this._source, this._gainNode);
        this.offset = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            convert: options.convert,
            param: this._source.offset,
            units: options.units,
            value: options.offset,
            minValue: options.minValue,
            maxValue: options.maxValue
        });
    }
    static getDefaults() {
        return Object.assign((0, $f93c69dcced4086a$export$27749f88ede4d2a3).getDefaults(), {
            convert: true,
            offset: 1,
            units: "number"
        });
    }
    /**
     * Start the source node at the given time
     * @param  time When to start the source
     */ start(time) {
        const computedTime = this.toSeconds(time);
        this.log("start", computedTime);
        this._startGain(computedTime);
        this._source.start(computedTime);
        return this;
    }
    _stopSource(time) {
        this._source.stop(time);
    }
    dispose() {
        super.dispose();
        if (this.state === "started") this.stop();
        this._source.disconnect();
        this.offset.dispose();
        return this;
    }
}


class $293163363e9daa43$export$8210dfe1863c478 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($293163363e9daa43$export$8210dfe1863c478.getDefaults(), arguments, [
            "value",
            "units"
        ]));
        this.name = "Signal";
        /**
         * Indicates if the value should be overridden on connection.
         */ this.override = true;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($293163363e9daa43$export$8210dfe1863c478.getDefaults(), arguments, [
            "value",
            "units"
        ]);
        this.output = this._constantSource = new (0, $ef1d4c7c24882f1b$export$717f1ef4ba8fd295)({
            context: this.context,
            convert: options.convert,
            offset: options.value,
            units: options.units,
            minValue: options.minValue,
            maxValue: options.maxValue
        });
        this._constantSource.start(0);
        this.input = this._param = this._constantSource.offset;
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            convert: true,
            units: "number",
            value: 0
        });
    }
    connect(destination, outputNum = 0, inputNum = 0) {
        // start it only when connected to something
        $293163363e9daa43$export$c8174dc07173cff0(this, destination, outputNum, inputNum);
        return this;
    }
    dispose() {
        super.dispose();
        this._param.dispose();
        this._constantSource.dispose();
        return this;
    }
    //-------------------------------------
    // ABSTRACT PARAM INTERFACE
    // just a proxy for the ConstantSourceNode's offset AudioParam
    // all docs are generated from AbstractParam.ts
    //-------------------------------------
    setValueAtTime(value, time) {
        this._param.setValueAtTime(value, time);
        return this;
    }
    getValueAtTime(time) {
        return this._param.getValueAtTime(time);
    }
    setRampPoint(time) {
        this._param.setRampPoint(time);
        return this;
    }
    linearRampToValueAtTime(value, time) {
        this._param.linearRampToValueAtTime(value, time);
        return this;
    }
    exponentialRampToValueAtTime(value, time) {
        this._param.exponentialRampToValueAtTime(value, time);
        return this;
    }
    exponentialRampTo(value, rampTime, startTime) {
        this._param.exponentialRampTo(value, rampTime, startTime);
        return this;
    }
    linearRampTo(value, rampTime, startTime) {
        this._param.linearRampTo(value, rampTime, startTime);
        return this;
    }
    targetRampTo(value, rampTime, startTime) {
        this._param.targetRampTo(value, rampTime, startTime);
        return this;
    }
    exponentialApproachValueAtTime(value, time, rampTime) {
        this._param.exponentialApproachValueAtTime(value, time, rampTime);
        return this;
    }
    setTargetAtTime(value, startTime, timeConstant) {
        this._param.setTargetAtTime(value, startTime, timeConstant);
        return this;
    }
    setValueCurveAtTime(values, startTime, duration, scaling) {
        this._param.setValueCurveAtTime(values, startTime, duration, scaling);
        return this;
    }
    cancelScheduledValues(time) {
        this._param.cancelScheduledValues(time);
        return this;
    }
    cancelAndHoldAtTime(time) {
        this._param.cancelAndHoldAtTime(time);
        return this;
    }
    rampTo(value, rampTime, startTime) {
        this._param.rampTo(value, rampTime, startTime);
        return this;
    }
    get value() {
        return this._param.value;
    }
    set value(value) {
        this._param.value = value;
    }
    get convert() {
        return this._param.convert;
    }
    set convert(convert) {
        this._param.convert = convert;
    }
    get units() {
        return this._param.units;
    }
    get overridden() {
        return this._param.overridden;
    }
    set overridden(overridden) {
        this._param.overridden = overridden;
    }
    get maxValue() {
        return this._param.maxValue;
    }
    get minValue() {
        return this._param.minValue;
    }
    /**
     * See [[Param.apply]].
     */ apply(param) {
        this._param.apply(param);
        return this;
    }
}
function $293163363e9daa43$export$c8174dc07173cff0(signal, destination, outputNum, inputNum) {
    if (destination instanceof (0, $139d674b4982de8e$export$1ca45c9a47aec42c) || (0, $ca1a79a064f4108f$export$1abe4e52803657f3)(destination) || destination instanceof $293163363e9daa43$export$8210dfe1863c478 && destination.override) {
        // cancel changes
        destination.cancelScheduledValues(0);
        // reset the value
        destination.setValueAtTime(0, 0);
        // mark the value as overridden
        if (destination instanceof $293163363e9daa43$export$8210dfe1863c478) destination.overridden = true;
    }
    (0, $5ffbb5654e49c399$export$64605811ab45167f)(signal, destination, outputNum, inputNum);
}







class $db7cdf3f7e47c65a$export$7d6cb743a95f18af extends (0, $139d674b4982de8e$export$1ca45c9a47aec42c) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($db7cdf3f7e47c65a$export$7d6cb743a95f18af.getDefaults(), arguments, [
            "value"
        ]));
        this.name = "TickParam";
        /**
         * The timeline which tracks all of the automations.
         */ this._events = new (0, $3684d29589a800b6$export$e6a97ba2cae5bb94)(Infinity);
        /**
         * The internal holder for the multiplier value
         */ this._multiplier = 1;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($db7cdf3f7e47c65a$export$7d6cb743a95f18af.getDefaults(), arguments, [
            "value"
        ]);
        // set the multiplier
        this._multiplier = options.multiplier;
        // clear the ticks from the beginning
        this._events.cancel(0);
        // set an initial event
        this._events.add({
            ticks: 0,
            time: 0,
            type: "setValueAtTime",
            value: this._fromType(options.value)
        });
        this.setValueAtTime(options.value, 0);
    }
    static getDefaults() {
        return Object.assign((0, $139d674b4982de8e$export$1ca45c9a47aec42c).getDefaults(), {
            multiplier: 1,
            units: "hertz",
            value: 1
        });
    }
    setTargetAtTime(value, time, constant) {
        // approximate it with multiple linear ramps
        time = this.toSeconds(time);
        this.setRampPoint(time);
        const computedValue = this._fromType(value);
        // start from previously scheduled value
        const prevEvent = this._events.get(time);
        const segments = Math.round(Math.max(1 / constant, 1));
        for(let i = 0; i <= segments; i++){
            const segTime = constant * i + time;
            const rampVal = this._exponentialApproach(prevEvent.time, prevEvent.value, computedValue, constant, segTime);
            this.linearRampToValueAtTime(this._toType(rampVal), segTime);
        }
        return this;
    }
    setValueAtTime(value, time) {
        const computedTime = this.toSeconds(time);
        super.setValueAtTime(value, time);
        const event = this._events.get(computedTime);
        const previousEvent = this._events.previousEvent(event);
        const ticksUntilTime = this._getTicksUntilEvent(previousEvent, computedTime);
        event.ticks = Math.max(ticksUntilTime, 0);
        return this;
    }
    linearRampToValueAtTime(value, time) {
        const computedTime = this.toSeconds(time);
        super.linearRampToValueAtTime(value, time);
        const event = this._events.get(computedTime);
        const previousEvent = this._events.previousEvent(event);
        const ticksUntilTime = this._getTicksUntilEvent(previousEvent, computedTime);
        event.ticks = Math.max(ticksUntilTime, 0);
        return this;
    }
    exponentialRampToValueAtTime(value, time) {
        // aproximate it with multiple linear ramps
        time = this.toSeconds(time);
        const computedVal = this._fromType(value);
        // start from previously scheduled value
        const prevEvent = this._events.get(time);
        // approx 10 segments per second
        const segments = Math.round(Math.max((time - prevEvent.time) * 10, 1));
        const segmentDur = (time - prevEvent.time) / segments;
        for(let i = 0; i <= segments; i++){
            const segTime = segmentDur * i + prevEvent.time;
            const rampVal = this._exponentialInterpolate(prevEvent.time, prevEvent.value, time, computedVal, segTime);
            this.linearRampToValueAtTime(this._toType(rampVal), segTime);
        }
        return this;
    }
    /**
     * Returns the tick value at the time. Takes into account
     * any automation curves scheduled on the signal.
     * @param  event The time to get the tick count at
     * @return The number of ticks which have elapsed at the time given any automations.
     */ _getTicksUntilEvent(event, time) {
        if (event === null) event = {
            ticks: 0,
            time: 0,
            type: "setValueAtTime",
            value: 0
        };
        else if ((0, $b63b9a75cba601b0$export$eb605f91c5895a5b)(event.ticks)) {
            const previousEvent = this._events.previousEvent(event);
            event.ticks = this._getTicksUntilEvent(previousEvent, event.time);
        }
        const val0 = this._fromType(this.getValueAtTime(event.time));
        let val1 = this._fromType(this.getValueAtTime(time));
        // if it's right on the line, take the previous value
        const onTheLineEvent = this._events.get(time);
        if (onTheLineEvent && onTheLineEvent.time === time && onTheLineEvent.type === "setValueAtTime") val1 = this._fromType(this.getValueAtTime(time - this.sampleTime));
        return 0.5 * (time - event.time) * (val0 + val1) + event.ticks;
    }
    /**
     * Returns the tick value at the time. Takes into account
     * any automation curves scheduled on the signal.
     * @param  time The time to get the tick count at
     * @return The number of ticks which have elapsed at the time given any automations.
     */ getTicksAtTime(time) {
        const computedTime = this.toSeconds(time);
        const event = this._events.get(computedTime);
        return Math.max(this._getTicksUntilEvent(event, computedTime), 0);
    }
    /**
     * Return the elapsed time of the number of ticks from the given time
     * @param ticks The number of ticks to calculate
     * @param  time The time to get the next tick from
     * @return The duration of the number of ticks from the given time in seconds
     */ getDurationOfTicks(ticks, time) {
        const computedTime = this.toSeconds(time);
        const currentTick = this.getTicksAtTime(time);
        return this.getTimeOfTick(currentTick + ticks) - computedTime;
    }
    /**
     * Given a tick, returns the time that tick occurs at.
     * @return The time that the tick occurs.
     */ getTimeOfTick(tick) {
        const before = this._events.get(tick, "ticks");
        const after = this._events.getAfter(tick, "ticks");
        if (before && before.ticks === tick) return before.time;
        else if (before && after && after.type === "linearRampToValueAtTime" && before.value !== after.value) {
            const val0 = this._fromType(this.getValueAtTime(before.time));
            const val1 = this._fromType(this.getValueAtTime(after.time));
            const delta = (val1 - val0) / (after.time - before.time);
            const k = Math.sqrt(Math.pow(val0, 2) - 2 * delta * (before.ticks - tick));
            const sol1 = (-val0 + k) / delta;
            const sol2 = (-val0 - k) / delta;
            return (sol1 > 0 ? sol1 : sol2) + before.time;
        } else if (before) {
            if (before.value === 0) return Infinity;
            else return before.time + (tick - before.ticks) / before.value;
        } else return tick / this._initialValue;
    }
    /**
     * Convert some number of ticks their the duration in seconds accounting
     * for any automation curves starting at the given time.
     * @param  ticks The number of ticks to convert to seconds.
     * @param  when  When along the automation timeline to convert the ticks.
     * @return The duration in seconds of the ticks.
     */ ticksToTime(ticks, when) {
        return this.getDurationOfTicks(ticks, when);
    }
    /**
     * The inverse of [[ticksToTime]]. Convert a duration in
     * seconds to the corresponding number of ticks accounting for any
     * automation curves starting at the given time.
     * @param  duration The time interval to convert to ticks.
     * @param  when When along the automation timeline to convert the ticks.
     * @return The duration in ticks.
     */ timeToTicks(duration, when) {
        const computedTime = this.toSeconds(when);
        const computedDuration = this.toSeconds(duration);
        const startTicks = this.getTicksAtTime(computedTime);
        const endTicks = this.getTicksAtTime(computedTime + computedDuration);
        return endTicks - startTicks;
    }
    /**
     * Convert from the type when the unit value is BPM
     */ _fromType(val) {
        if (this.units === "bpm" && this.multiplier) return 1 / (60 / val / this.multiplier);
        else return super._fromType(val);
    }
    /**
     * Special case of type conversion where the units === "bpm"
     */ _toType(val) {
        if (this.units === "bpm" && this.multiplier) return val / this.multiplier * 60;
        else return super._toType(val);
    }
    /**
     * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.
     */ get multiplier() {
        return this._multiplier;
    }
    set multiplier(m) {
        // get and reset the current value with the new multiplier
        // might be necessary to clear all the previous values
        const currentVal = this.value;
        this._multiplier = m;
        this.cancelScheduledValues(0);
        this.setValueAtTime(currentVal, 0);
    }
}


class $ea7f204e9288afb9$export$f1be63c3ef84bc34 extends (0, $293163363e9daa43$export$8210dfe1863c478) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($ea7f204e9288afb9$export$f1be63c3ef84bc34.getDefaults(), arguments, [
            "value"
        ]));
        this.name = "TickSignal";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($ea7f204e9288afb9$export$f1be63c3ef84bc34.getDefaults(), arguments, [
            "value"
        ]);
        this.input = this._param = new (0, $db7cdf3f7e47c65a$export$7d6cb743a95f18af)({
            context: this.context,
            convert: options.convert,
            multiplier: options.multiplier,
            param: this._constantSource.offset,
            units: options.units,
            value: options.value
        });
    }
    static getDefaults() {
        return Object.assign((0, $293163363e9daa43$export$8210dfe1863c478).getDefaults(), {
            multiplier: 1,
            units: "hertz",
            value: 1
        });
    }
    ticksToTime(ticks, when) {
        return this._param.ticksToTime(ticks, when);
    }
    timeToTicks(duration, when) {
        return this._param.timeToTicks(duration, when);
    }
    getTimeOfTick(tick) {
        return this._param.getTimeOfTick(tick);
    }
    getDurationOfTicks(ticks, time) {
        return this._param.getDurationOfTicks(ticks, time);
    }
    getTicksAtTime(time) {
        return this._param.getTicksAtTime(time);
    }
    /**
     * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.
     */ get multiplier() {
        return this._param.multiplier;
    }
    set multiplier(m) {
        this._param.multiplier = m;
    }
    dispose() {
        super.dispose();
        this._param.dispose();
        return this;
    }
}



class $ecc2ab7d28a50f1e$export$617abaa845df50f1 extends (0, $60e11f0590acfc0d$export$4eb0ca57400aa172) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($ecc2ab7d28a50f1e$export$617abaa845df50f1.getDefaults(), arguments, [
            "frequency"
        ]));
        this.name = "TickSource";
        /**
         * The state timeline
         */ this._state = new (0, $e9f51dc63c33b8a5$export$89221a927ffadcaf)();
        /**
         * The offset values of the ticks
         */ this._tickOffset = new (0, $3684d29589a800b6$export$e6a97ba2cae5bb94)();
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($ecc2ab7d28a50f1e$export$617abaa845df50f1.getDefaults(), arguments, [
            "frequency"
        ]);
        this.frequency = new (0, $ea7f204e9288afb9$export$f1be63c3ef84bc34)({
            context: this.context,
            units: options.units,
            value: options.frequency
        });
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "frequency");
        // set the initial state
        this._state.setStateAtTime("stopped", 0);
        // add the first event
        this.setTicksAtTime(0, 0);
    }
    static getDefaults() {
        return Object.assign({
            frequency: 1,
            units: "hertz"
        }, (0, $60e11f0590acfc0d$export$4eb0ca57400aa172).getDefaults());
    }
    /**
     * Returns the playback state of the source, either "started", "stopped" or "paused".
     */ get state() {
        return this.getStateAtTime(this.now());
    }
    /**
     * Start the clock at the given time. Optionally pass in an offset
     * of where to start the tick counter from.
     * @param  time    The time the clock should start
     * @param offset The number of ticks to start the source at
     */ start(time, offset) {
        const computedTime = this.toSeconds(time);
        if (this._state.getValueAtTime(computedTime) !== "started") {
            this._state.setStateAtTime("started", computedTime);
            if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(offset)) this.setTicksAtTime(offset, computedTime);
        }
        return this;
    }
    /**
     * Stop the clock. Stopping the clock resets the tick counter to 0.
     * @param time The time when the clock should stop.
     */ stop(time) {
        const computedTime = this.toSeconds(time);
        // cancel the previous stop
        if (this._state.getValueAtTime(computedTime) === "stopped") {
            const event = this._state.get(computedTime);
            if (event && event.time > 0) {
                this._tickOffset.cancel(event.time);
                this._state.cancel(event.time);
            }
        }
        this._state.cancel(computedTime);
        this._state.setStateAtTime("stopped", computedTime);
        this.setTicksAtTime(0, computedTime);
        return this;
    }
    /**
     * Pause the clock. Pausing does not reset the tick counter.
     * @param time The time when the clock should stop.
     */ pause(time) {
        const computedTime = this.toSeconds(time);
        if (this._state.getValueAtTime(computedTime) === "started") this._state.setStateAtTime("paused", computedTime);
        return this;
    }
    /**
     * Cancel start/stop/pause and setTickAtTime events scheduled after the given time.
     * @param time When to clear the events after
     */ cancel(time) {
        time = this.toSeconds(time);
        this._state.cancel(time);
        this._tickOffset.cancel(time);
        return this;
    }
    /**
     * Get the elapsed ticks at the given time
     * @param  time  When to get the tick value
     * @return The number of ticks
     */ getTicksAtTime(time) {
        const computedTime = this.toSeconds(time);
        const stopEvent = this._state.getLastState("stopped", computedTime);
        // this event allows forEachBetween to iterate until the current time
        const tmpEvent = {
            state: "paused",
            time: computedTime
        };
        this._state.add(tmpEvent);
        // keep track of the previous offset event
        let lastState = stopEvent;
        let elapsedTicks = 0;
        // iterate through all the events since the last stop
        this._state.forEachBetween(stopEvent.time, computedTime + this.sampleTime, (e)=>{
            let periodStartTime = lastState.time;
            // if there is an offset event in this period use that
            const offsetEvent = this._tickOffset.get(e.time);
            if (offsetEvent && offsetEvent.time >= lastState.time) {
                elapsedTicks = offsetEvent.ticks;
                periodStartTime = offsetEvent.time;
            }
            if (lastState.state === "started" && e.state !== "started") elapsedTicks += this.frequency.getTicksAtTime(e.time) - this.frequency.getTicksAtTime(periodStartTime);
            lastState = e;
        });
        // remove the temporary event
        this._state.remove(tmpEvent);
        // return the ticks
        return elapsedTicks;
    }
    /**
     * The number of times the callback was invoked. Starts counting at 0
     * and increments after the callback was invoked. Returns -1 when stopped.
     */ get ticks() {
        return this.getTicksAtTime(this.now());
    }
    set ticks(t) {
        this.setTicksAtTime(t, this.now());
    }
    /**
     * The time since ticks=0 that the TickSource has been running. Accounts
     * for tempo curves
     */ get seconds() {
        return this.getSecondsAtTime(this.now());
    }
    set seconds(s) {
        const now = this.now();
        const ticks = this.frequency.timeToTicks(s, now);
        this.setTicksAtTime(ticks, now);
    }
    /**
     * Return the elapsed seconds at the given time.
     * @param  time  When to get the elapsed seconds
     * @return  The number of elapsed seconds
     */ getSecondsAtTime(time) {
        time = this.toSeconds(time);
        const stopEvent = this._state.getLastState("stopped", time);
        // this event allows forEachBetween to iterate until the current time
        const tmpEvent = {
            state: "paused",
            time: time
        };
        this._state.add(tmpEvent);
        // keep track of the previous offset event
        let lastState = stopEvent;
        let elapsedSeconds = 0;
        // iterate through all the events since the last stop
        this._state.forEachBetween(stopEvent.time, time + this.sampleTime, (e)=>{
            let periodStartTime = lastState.time;
            // if there is an offset event in this period use that
            const offsetEvent = this._tickOffset.get(e.time);
            if (offsetEvent && offsetEvent.time >= lastState.time) {
                elapsedSeconds = offsetEvent.seconds;
                periodStartTime = offsetEvent.time;
            }
            if (lastState.state === "started" && e.state !== "started") elapsedSeconds += e.time - periodStartTime;
            lastState = e;
        });
        // remove the temporary event
        this._state.remove(tmpEvent);
        // return the ticks
        return elapsedSeconds;
    }
    /**
     * Set the clock's ticks at the given time.
     * @param  ticks The tick value to set
     * @param  time  When to set the tick value
     */ setTicksAtTime(ticks, time) {
        time = this.toSeconds(time);
        this._tickOffset.cancel(time);
        this._tickOffset.add({
            seconds: this.frequency.getDurationOfTicks(ticks, time),
            ticks: ticks,
            time: time
        });
        return this;
    }
    /**
     * Returns the scheduled state at the given time.
     * @param  time  The time to query.
     */ getStateAtTime(time) {
        time = this.toSeconds(time);
        return this._state.getValueAtTime(time);
    }
    /**
     * Get the time of the given tick. The second argument
     * is when to test before. Since ticks can be set (with setTicksAtTime)
     * there may be multiple times for a given tick value.
     * @param  tick The tick number.
     * @param  before When to measure the tick value from.
     * @return The time of the tick
     */ getTimeOfTick(tick, before = this.now()) {
        const offset = this._tickOffset.get(before);
        const event = this._state.get(before);
        const startTime = Math.max(offset.time, event.time);
        const absoluteTicks = this.frequency.getTicksAtTime(startTime) + tick - offset.ticks;
        return this.frequency.getTimeOfTick(absoluteTicks);
    }
    /**
     * Invoke the callback event at all scheduled ticks between the
     * start time and the end time
     * @param  startTime  The beginning of the search range
     * @param  endTime    The end of the search range
     * @param  callback   The callback to invoke with each tick
     */ forEachTickBetween(startTime, endTime, callback) {
        // only iterate through the sections where it is "started"
        let lastStateEvent = this._state.get(startTime);
        this._state.forEachBetween(startTime, endTime, (event)=>{
            if (lastStateEvent && lastStateEvent.state === "started" && event.state !== "started") this.forEachTickBetween(Math.max(lastStateEvent.time, startTime), event.time - this.sampleTime, callback);
            lastStateEvent = event;
        });
        let error = null;
        if (lastStateEvent && lastStateEvent.state === "started") {
            const maxStartTime = Math.max(lastStateEvent.time, startTime);
            // figure out the difference between the frequency ticks and the
            const startTicks = this.frequency.getTicksAtTime(maxStartTime);
            const ticksAtStart = this.frequency.getTicksAtTime(lastStateEvent.time);
            const diff = startTicks - ticksAtStart;
            let offset = Math.ceil(diff) - diff;
            // guard against floating point issues
            offset = (0, $e85238bb45fd87b7$export$1c0a5d05eb3f6e18)(offset, 1) ? 0 : offset;
            let nextTickTime = this.frequency.getTimeOfTick(startTicks + offset);
            while(nextTickTime < endTime){
                try {
                    callback(nextTickTime, Math.round(this.getTicksAtTime(nextTickTime)));
                } catch (e) {
                    error = e;
                    break;
                }
                nextTickTime += this.frequency.getDurationOfTicks(1, nextTickTime);
            }
        }
        if (error) throw error;
        return this;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._state.dispose();
        this._tickOffset.dispose();
        this.frequency.dispose();
        return this;
    }
}



class $4303602842dc7b38$export$9735c82c4bae3302 extends (0, $60e11f0590acfc0d$export$4eb0ca57400aa172) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($4303602842dc7b38$export$9735c82c4bae3302.getDefaults(), arguments, [
            "callback",
            "frequency"
        ]));
        this.name = "Clock";
        /**
         * The callback function to invoke at the scheduled tick.
         */ this.callback = (0, $c0a1ee726091e30a$export$b50b6e108474309b);
        /**
         * The last time the loop callback was invoked
         */ this._lastUpdate = 0;
        /**
         * Keep track of the playback state
         */ this._state = new (0, $e9f51dc63c33b8a5$export$89221a927ffadcaf)("stopped");
        /**
         * Context bound reference to the _loop method
         * This is necessary to remove the event in the end.
         */ this._boundLoop = this._loop.bind(this);
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($4303602842dc7b38$export$9735c82c4bae3302.getDefaults(), arguments, [
            "callback",
            "frequency"
        ]);
        this.callback = options.callback;
        this._tickSource = new (0, $ecc2ab7d28a50f1e$export$617abaa845df50f1)({
            context: this.context,
            frequency: options.frequency,
            units: options.units
        });
        this._lastUpdate = 0;
        this.frequency = this._tickSource.frequency;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "frequency");
        // add an initial state
        this._state.setStateAtTime("stopped", 0);
        // bind a callback to the worker thread
        this.context.on("tick", this._boundLoop);
    }
    static getDefaults() {
        return Object.assign((0, $60e11f0590acfc0d$export$4eb0ca57400aa172).getDefaults(), {
            callback: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            frequency: 1,
            units: "hertz"
        });
    }
    /**
     * Returns the playback state of the source, either "started", "stopped" or "paused".
     */ get state() {
        return this._state.getValueAtTime(this.now());
    }
    /**
     * Start the clock at the given time. Optionally pass in an offset
     * of where to start the tick counter from.
     * @param  time    The time the clock should start
     * @param offset  Where the tick counter starts counting from.
     */ start(time, offset) {
        // make sure the context is running
        (0, $23cf54af36cc9441$export$8ef1ce44f93c2687)(this.context);
        // start the loop
        const computedTime = this.toSeconds(time);
        this.log("start", computedTime);
        if (this._state.getValueAtTime(computedTime) !== "started") {
            this._state.setStateAtTime("started", computedTime);
            this._tickSource.start(computedTime, offset);
            if (computedTime < this._lastUpdate) this.emit("start", computedTime, offset);
        }
        return this;
    }
    /**
     * Stop the clock. Stopping the clock resets the tick counter to 0.
     * @param time The time when the clock should stop.
     * @example
     * const clock = new Tone.Clock(time => {
     * 	console.log(time);
     * }, 1);
     * clock.start();
     * // stop the clock after 10 seconds
     * clock.stop("+10");
     */ stop(time) {
        const computedTime = this.toSeconds(time);
        this.log("stop", computedTime);
        this._state.cancel(computedTime);
        this._state.setStateAtTime("stopped", computedTime);
        this._tickSource.stop(computedTime);
        if (computedTime < this._lastUpdate) this.emit("stop", computedTime);
        return this;
    }
    /**
     * Pause the clock. Pausing does not reset the tick counter.
     * @param time The time when the clock should stop.
     */ pause(time) {
        const computedTime = this.toSeconds(time);
        if (this._state.getValueAtTime(computedTime) === "started") {
            this._state.setStateAtTime("paused", computedTime);
            this._tickSource.pause(computedTime);
            if (computedTime < this._lastUpdate) this.emit("pause", computedTime);
        }
        return this;
    }
    /**
     * The number of times the callback was invoked. Starts counting at 0
     * and increments after the callback was invoked.
     */ get ticks() {
        return Math.ceil(this.getTicksAtTime(this.now()));
    }
    set ticks(t) {
        this._tickSource.ticks = t;
    }
    /**
     * The time since ticks=0 that the Clock has been running. Accounts for tempo curves
     */ get seconds() {
        return this._tickSource.seconds;
    }
    set seconds(s) {
        this._tickSource.seconds = s;
    }
    /**
     * Return the elapsed seconds at the given time.
     * @param  time  When to get the elapsed seconds
     * @return  The number of elapsed seconds
     */ getSecondsAtTime(time) {
        return this._tickSource.getSecondsAtTime(time);
    }
    /**
     * Set the clock's ticks at the given time.
     * @param  ticks The tick value to set
     * @param  time  When to set the tick value
     */ setTicksAtTime(ticks, time) {
        this._tickSource.setTicksAtTime(ticks, time);
        return this;
    }
    /**
     * Get the time of the given tick. The second argument
     * is when to test before. Since ticks can be set (with setTicksAtTime)
     * there may be multiple times for a given tick value.
     * @param  tick The tick number.
     * @param  before When to measure the tick value from.
     * @return The time of the tick
     */ getTimeOfTick(tick, before = this.now()) {
        return this._tickSource.getTimeOfTick(tick, before);
    }
    /**
     * Get the clock's ticks at the given time.
     * @param  time  When to get the tick value
     * @return The tick value at the given time.
     */ getTicksAtTime(time) {
        return this._tickSource.getTicksAtTime(time);
    }
    /**
     * Get the time of the next tick
     * @param  offset The tick number.
     */ nextTickTime(offset, when) {
        const computedTime = this.toSeconds(when);
        const currentTick = this.getTicksAtTime(computedTime);
        return this._tickSource.getTimeOfTick(currentTick + offset, computedTime);
    }
    /**
     * The scheduling loop.
     */ _loop() {
        const startTime = this._lastUpdate;
        const endTime = this.now();
        this._lastUpdate = endTime;
        this.log("loop", startTime, endTime);
        if (startTime !== endTime) {
            // the state change events
            this._state.forEachBetween(startTime, endTime, (e)=>{
                switch(e.state){
                    case "started":
                        const offset = this._tickSource.getTicksAtTime(e.time);
                        this.emit("start", e.time, offset);
                        break;
                    case "stopped":
                        if (e.time !== 0) this.emit("stop", e.time);
                        break;
                    case "paused":
                        this.emit("pause", e.time);
                        break;
                }
            });
            // the tick callbacks
            this._tickSource.forEachTickBetween(startTime, endTime, (time, ticks)=>{
                this.callback(time, ticks);
            });
        }
    }
    /**
     * Returns the scheduled state at the given time.
     * @param  time  The time to query.
     * @return  The name of the state input in setStateAtTime.
     * @example
     * const clock = new Tone.Clock();
     * clock.start("+0.1");
     * clock.getStateAtTime("+0.1"); // returns "started"
     */ getStateAtTime(time) {
        const computedTime = this.toSeconds(time);
        return this._state.getValueAtTime(computedTime);
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this.context.off("tick", this._boundLoop);
        this._tickSource.dispose();
        this._state.dispose();
        return this;
    }
}
(0, $a281f9e80bc9e8f9$export$4293555f241ae35a).mixin($4303602842dc7b38$export$9735c82c4bae3302);








class $56c02e4cadfbd835$export$7419ff430885d61c extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($56c02e4cadfbd835$export$7419ff430885d61c.getDefaults(), arguments, [
            "delayTime",
            "maxDelay"
        ]));
        this.name = "Delay";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($56c02e4cadfbd835$export$7419ff430885d61c.getDefaults(), arguments, [
            "delayTime",
            "maxDelay"
        ]);
        const maxDelayInSeconds = this.toSeconds(options.maxDelay);
        this._maxDelay = Math.max(maxDelayInSeconds, this.toSeconds(options.delayTime));
        this._delayNode = this.input = this.output = this.context.createDelay(maxDelayInSeconds);
        this.delayTime = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this._delayNode.delayTime,
            units: "time",
            value: options.delayTime,
            minValue: 0,
            maxValue: this.maxDelay
        });
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "delayTime");
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            delayTime: 0,
            maxDelay: 1
        });
    }
    /**
     * The maximum delay time. This cannot be changed after
     * the value is passed into the constructor.
     */ get maxDelay() {
        return this._maxDelay;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._delayNode.disconnect();
        this.delayTime.dispose();
        return this;
    }
}







function $2bc9ffd0557ed046$export$a273407dc53e3f0a(callback, duration, channels = 2, sampleRate = (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().sampleRate) {
    return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
        // set the OfflineAudioContext based on the current context
        const originalContext = (0, $3d00f6854e3cc34b$export$31553aaa555c1514)();
        const context = new (0, $d73ede3d936d3e15$export$46814dd5412c611c)(channels, duration, sampleRate);
        (0, $3d00f6854e3cc34b$export$2f04de43fe27971a)(context);
        // invoke the callback/scheduling
        yield callback(context);
        // then render the audio
        const bufferPromise = context.render();
        // return the original AudioContext
        (0, $3d00f6854e3cc34b$export$2f04de43fe27971a)(originalContext);
        // await the rendering
        const buffer = yield bufferPromise;
        // return the audio
        return new (0, $f8b2c4c1413d235f$export$424a335715b38178)(buffer);
    });
}











class $28d90c8ab77bc1a1$export$266cef4b055bf7de extends (0, $5b410fbffb0274be$export$38b56155c8552868) {
    constructor(){
        super(...arguments);
        this.name = "MidiClass";
        this.defaultUnits = "midi";
    }
    /**
     * Returns the value of a frequency in the current units
     */ _frequencyToUnits(freq) {
        return (0, $73949b14fe57a99a$export$5cf9d9f9506eec5)(super._frequencyToUnits(freq));
    }
    /**
     * Returns the value of a tick in the current time units
     */ _ticksToUnits(ticks) {
        return (0, $73949b14fe57a99a$export$5cf9d9f9506eec5)(super._ticksToUnits(ticks));
    }
    /**
     * Return the value of the beats in the current units
     */ _beatsToUnits(beats) {
        return (0, $73949b14fe57a99a$export$5cf9d9f9506eec5)(super._beatsToUnits(beats));
    }
    /**
     * Returns the value of a second in the current units
     */ _secondsToUnits(seconds) {
        return (0, $73949b14fe57a99a$export$5cf9d9f9506eec5)(super._secondsToUnits(seconds));
    }
    /**
     * Return the value of the frequency as a MIDI note
     * @example
     * Tone.Midi(60).toMidi(); // 60
     */ toMidi() {
        return this.valueOf();
    }
    /**
     * Return the value of the frequency as a MIDI note
     * @example
     * Tone.Midi(60).toFrequency(); // 261.6255653005986
     */ toFrequency() {
        return (0, $73949b14fe57a99a$export$45a6434f7c391dc)(this.toMidi());
    }
    /**
     * Transposes the frequency by the given number of semitones.
     * @return A new transposed MidiClass
     * @example
     * Tone.Midi("A4").transpose(3); // "C5"
     */ transpose(interval) {
        return new $28d90c8ab77bc1a1$export$266cef4b055bf7de(this.context, this.toMidi() + interval);
    }
}
function $28d90c8ab77bc1a1$export$ed87582254f87fd5(value, units) {
    return new $28d90c8ab77bc1a1$export$266cef4b055bf7de((0, $3d00f6854e3cc34b$export$31553aaa555c1514)(), value, units);
}





class $5a2725674ec35741$export$fe3569694b9f5728 extends (0, $16edc52e2d0df4ee$export$c824041178a9697) {
    constructor(){
        super(...arguments);
        this.name = "Ticks";
        this.defaultUnits = "i";
    }
    /**
     * Get the current time in the given units
     */ _now() {
        return this.context.transport.ticks;
    }
    /**
     * Return the value of the beats in the current units
     */ _beatsToUnits(beats) {
        return this._getPPQ() * beats;
    }
    /**
     * Returns the value of a second in the current units
     */ _secondsToUnits(seconds) {
        return Math.floor(seconds / (60 / this._getBpm()) * this._getPPQ());
    }
    /**
     * Returns the value of a tick in the current time units
     */ _ticksToUnits(ticks) {
        return ticks;
    }
    /**
     * Return the time in ticks
     */ toTicks() {
        return this.valueOf();
    }
    /**
     * Return the time in seconds
     */ toSeconds() {
        return this.valueOf() / this._getPPQ() * (60 / this._getBpm());
    }
}
function $5a2725674ec35741$export$27c7467594ef87bd(value, units) {
    return new $5a2725674ec35741$export$fe3569694b9f5728((0, $3d00f6854e3cc34b$export$31553aaa555c1514)(), value, units);
}







class $e3e68012a1ffdf1d$export$5a615b1a895bd9ec extends (0, $0eb7340e2d092af9$export$12b11dc969d02fed) {
    constructor(){
        super(...arguments);
        this.name = "IntervalTimeline";
        /**
         * The root node of the inteval tree
         */ this._root = null;
        /**
         * Keep track of the length of the timeline.
         */ this._length = 0;
    }
    /**
     * The event to add to the timeline. All events must
     * have a time and duration value
     * @param  event  The event to add to the timeline
     */ add(event) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $b63b9a75cba601b0$export$4e62c701997796c1)(event.time), "Events must have a time property");
        (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $b63b9a75cba601b0$export$4e62c701997796c1)(event.duration), "Events must have a duration parameter");
        event.time = event.time.valueOf();
        let node = new $e3e68012a1ffdf1d$var$IntervalNode(event.time, event.time + event.duration, event);
        if (this._root === null) this._root = node;
        else this._root.insert(node);
        this._length++;
        // Restructure tree to be balanced
        while(node !== null){
            node.updateHeight();
            node.updateMax();
            this._rebalance(node);
            node = node.parent;
        }
        return this;
    }
    /**
     * Remove an event from the timeline.
     * @param  event  The event to remove from the timeline
     */ remove(event) {
        if (this._root !== null) {
            const results = [];
            this._root.search(event.time, results);
            for (const node of results)if (node.event === event) {
                this._removeNode(node);
                this._length--;
                break;
            }
        }
        return this;
    }
    /**
     * The number of items in the timeline.
     * @readOnly
     */ get length() {
        return this._length;
    }
    /**
     * Remove events whose time time is after the given time
     * @param  after  The time to query.
     */ cancel(after) {
        this.forEachFrom(after, (event)=>this.remove(event));
        return this;
    }
    /**
     * Set the root node as the given node
     */ _setRoot(node) {
        this._root = node;
        if (this._root !== null) this._root.parent = null;
    }
    /**
     * Replace the references to the node in the node's parent
     * with the replacement node.
     */ _replaceNodeInParent(node, replacement) {
        if (node.parent !== null) {
            if (node.isLeftChild()) node.parent.left = replacement;
            else node.parent.right = replacement;
            this._rebalance(node.parent);
        } else this._setRoot(replacement);
    }
    /**
     * Remove the node from the tree and replace it with
     * a successor which follows the schema.
     */ _removeNode(node) {
        if (node.left === null && node.right === null) this._replaceNodeInParent(node, null);
        else if (node.right === null) this._replaceNodeInParent(node, node.left);
        else if (node.left === null) this._replaceNodeInParent(node, node.right);
        else {
            const balance = node.getBalance();
            let replacement;
            let temp = null;
            if (balance > 0) {
                if (node.left.right === null) {
                    replacement = node.left;
                    replacement.right = node.right;
                    temp = replacement;
                } else {
                    replacement = node.left.right;
                    while(replacement.right !== null)replacement = replacement.right;
                    if (replacement.parent) {
                        replacement.parent.right = replacement.left;
                        temp = replacement.parent;
                        replacement.left = node.left;
                        replacement.right = node.right;
                    }
                }
            } else if (node.right.left === null) {
                replacement = node.right;
                replacement.left = node.left;
                temp = replacement;
            } else {
                replacement = node.right.left;
                while(replacement.left !== null)replacement = replacement.left;
                if (replacement.parent) {
                    replacement.parent.left = replacement.right;
                    temp = replacement.parent;
                    replacement.left = node.left;
                    replacement.right = node.right;
                }
            }
            if (node.parent !== null) {
                if (node.isLeftChild()) node.parent.left = replacement;
                else node.parent.right = replacement;
            } else this._setRoot(replacement);
            if (temp) this._rebalance(temp);
        }
        node.dispose();
    }
    /**
     * Rotate the tree to the left
     */ _rotateLeft(node) {
        const parent = node.parent;
        const isLeftChild = node.isLeftChild();
        // Make node.right the new root of this sub tree (instead of node)
        const pivotNode = node.right;
        if (pivotNode) {
            node.right = pivotNode.left;
            pivotNode.left = node;
        }
        if (parent !== null) {
            if (isLeftChild) parent.left = pivotNode;
            else parent.right = pivotNode;
        } else this._setRoot(pivotNode);
    }
    /**
     * Rotate the tree to the right
     */ _rotateRight(node) {
        const parent = node.parent;
        const isLeftChild = node.isLeftChild();
        // Make node.left the new root of this sub tree (instead of node)
        const pivotNode = node.left;
        if (pivotNode) {
            node.left = pivotNode.right;
            pivotNode.right = node;
        }
        if (parent !== null) {
            if (isLeftChild) parent.left = pivotNode;
            else parent.right = pivotNode;
        } else this._setRoot(pivotNode);
    }
    /**
     * Balance the BST
     */ _rebalance(node) {
        const balance = node.getBalance();
        if (balance > 1 && node.left) {
            if (node.left.getBalance() < 0) this._rotateLeft(node.left);
            else this._rotateRight(node);
        } else if (balance < -1 && node.right) {
            if (node.right.getBalance() > 0) this._rotateRight(node.right);
            else this._rotateLeft(node);
        }
    }
    /**
     * Get an event whose time and duration span the give time. Will
     * return the match whose "time" value is closest to the given time.
     * @return  The event which spans the desired time
     */ get(time) {
        if (this._root !== null) {
            const results = [];
            this._root.search(time, results);
            if (results.length > 0) {
                let max = results[0];
                for(let i = 1; i < results.length; i++)if (results[i].low > max.low) max = results[i];
                return max.event;
            }
        }
        return null;
    }
    /**
     * Iterate over everything in the timeline.
     * @param  callback The callback to invoke with every item
     */ forEach(callback) {
        if (this._root !== null) {
            const allNodes = [];
            this._root.traverse((node)=>allNodes.push(node));
            allNodes.forEach((node)=>{
                if (node.event) callback(node.event);
            });
        }
        return this;
    }
    /**
     * Iterate over everything in the array in which the given time
     * overlaps with the time and duration time of the event.
     * @param  time The time to check if items are overlapping
     * @param  callback The callback to invoke with every item
     */ forEachAtTime(time, callback) {
        if (this._root !== null) {
            const results = [];
            this._root.search(time, results);
            results.forEach((node)=>{
                if (node.event) callback(node.event);
            });
        }
        return this;
    }
    /**
     * Iterate over everything in the array in which the time is greater
     * than or equal to the given time.
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachFrom(time, callback) {
        if (this._root !== null) {
            const results = [];
            this._root.searchAfter(time, results);
            results.forEach((node)=>{
                if (node.event) callback(node.event);
            });
        }
        return this;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        if (this._root !== null) this._root.traverse((node)=>node.dispose());
        this._root = null;
        return this;
    }
}
//-------------------------------------
// 	INTERVAL NODE HELPER
//-------------------------------------
/**
 * Represents a node in the binary search tree, with the addition
 * of a "high" value which keeps track of the highest value of
 * its children.
 * References:
 * https://brooknovak.wordpress.com/2013/12/07/augmented-interval-tree-in-c/
 * http://www.mif.vu.lt/~valdas/ALGORITMAI/LITERATURA/Cormen/Cormen.pdf
 * @param low
 * @param high
 */ class $e3e68012a1ffdf1d$var$IntervalNode {
    constructor(low, high, event){
        // the nodes to the left
        this._left = null;
        // the nodes to the right
        this._right = null;
        // the parent node
        this.parent = null;
        // the number of child nodes
        this.height = 0;
        this.event = event;
        // the low value
        this.low = low;
        // the high value
        this.high = high;
        // the high value for this and all child nodes
        this.max = this.high;
    }
    /**
     * Insert a node into the correct spot in the tree
     */ insert(node) {
        if (node.low <= this.low) {
            if (this.left === null) this.left = node;
            else this.left.insert(node);
        } else if (this.right === null) this.right = node;
        else this.right.insert(node);
    }
    /**
     * Search the tree for nodes which overlap
     * with the given point
     * @param  point  The point to query
     * @param  results  The array to put the results
     */ search(point, results) {
        // If p is to the right of the rightmost point of any interval
        // in this node and all children, there won't be any matches.
        if (point > this.max) return;
        // Search left children
        if (this.left !== null) this.left.search(point, results);
        // Check this node
        if (this.low <= point && this.high > point) results.push(this);
        // If p is to the left of the time of this interval,
        // then it can't be in any child to the right.
        if (this.low > point) return;
        // Search right children
        if (this.right !== null) this.right.search(point, results);
    }
    /**
     * Search the tree for nodes which are less
     * than the given point
     * @param  point  The point to query
     * @param  results  The array to put the results
     */ searchAfter(point, results) {
        // Check this node
        if (this.low >= point) {
            results.push(this);
            if (this.left !== null) this.left.searchAfter(point, results);
        }
        // search the right side
        if (this.right !== null) this.right.searchAfter(point, results);
    }
    /**
     * Invoke the callback on this element and both it's branches
     * @param  {Function}  callback
     */ traverse(callback) {
        callback(this);
        if (this.left !== null) this.left.traverse(callback);
        if (this.right !== null) this.right.traverse(callback);
    }
    /**
     * Update the height of the node
     */ updateHeight() {
        if (this.left !== null && this.right !== null) this.height = Math.max(this.left.height, this.right.height) + 1;
        else if (this.right !== null) this.height = this.right.height + 1;
        else if (this.left !== null) this.height = this.left.height + 1;
        else this.height = 0;
    }
    /**
     * Update the height of the node
     */ updateMax() {
        this.max = this.high;
        if (this.left !== null) this.max = Math.max(this.max, this.left.max);
        if (this.right !== null) this.max = Math.max(this.max, this.right.max);
    }
    /**
     * The balance is how the leafs are distributed on the node
     * @return  Negative numbers are balanced to the right
     */ getBalance() {
        let balance = 0;
        if (this.left !== null && this.right !== null) balance = this.left.height - this.right.height;
        else if (this.left !== null) balance = this.left.height + 1;
        else if (this.right !== null) balance = -(this.right.height + 1);
        return balance;
    }
    /**
     * @returns true if this node is the left child of its parent
     */ isLeftChild() {
        return this.parent !== null && this.parent.left === this;
    }
    /**
     * get/set the left node
     */ get left() {
        return this._left;
    }
    set left(node) {
        this._left = node;
        if (node !== null) node.parent = this;
        this.updateHeight();
        this.updateMax();
    }
    /**
     * get/set the right node
     */ get right() {
        return this._right;
    }
    set right(node) {
        this._right = node;
        if (node !== null) node.parent = this;
        this.updateHeight();
        this.updateMax();
    }
    /**
     * null out references.
     */ dispose() {
        this.parent = null;
        this._left = null;
        this._right = null;
        this.event = null;
    }
}
















class $7d48f9af04226b93$export$dde279e52d625429 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($7d48f9af04226b93$export$dde279e52d625429.getDefaults(), arguments, [
            "volume"
        ]));
        this.name = "Volume";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($7d48f9af04226b93$export$dde279e52d625429.getDefaults(), arguments, [
            "volume"
        ]);
        this.input = this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            gain: options.volume,
            units: "decibels"
        });
        this.volume = this.output.gain;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "volume");
        this._unmutedVolume = options.volume;
        // set the mute initially
        this.mute = options.mute;
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            mute: false,
            volume: 0
        });
    }
    /**
     * Mute the output.
     * @example
     * const vol = new Tone.Volume(-12).toDestination();
     * const osc = new Tone.Oscillator().connect(vol).start();
     * // mute the output
     * vol.mute = true;
     */ get mute() {
        return this.volume.value === -Infinity;
    }
    set mute(mute) {
        if (!this.mute && mute) {
            this._unmutedVolume = this.volume.value;
            // maybe it should ramp here?
            this.volume.value = -Infinity;
        } else if (this.mute && !mute) this.volume.value = this._unmutedVolume;
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this.input.dispose();
        this.volume.dispose();
        return this;
    }
}







class $93f47b369d6c1ce4$export$5c4bdf44e1e9cea1 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($93f47b369d6c1ce4$export$5c4bdf44e1e9cea1.getDefaults(), arguments));
        this.name = "Destination";
        this.input = new (0, $7d48f9af04226b93$export$dde279e52d625429)({
            context: this.context
        });
        this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        /**
         * The volume of the master output in decibels. -Infinity is silent, and 0 is no change.
         * @example
         * const osc = new Tone.Oscillator().toDestination();
         * osc.start();
         * // ramp the volume down to silent over 10 seconds
         * Tone.getDestination().volume.rampTo(-Infinity, 10);
         */ this.volume = this.input.volume;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($93f47b369d6c1ce4$export$5c4bdf44e1e9cea1.getDefaults(), arguments);
        (0, $5ffbb5654e49c399$export$933c3b67552fb559)(this.input, this.output, this.context.rawContext.destination);
        this.mute = options.mute;
        this._internalChannels = [
            this.input,
            this.context.rawContext.destination,
            this.output
        ];
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            mute: false,
            volume: 0
        });
    }
    /**
     * Mute the output.
     * @example
     * const oscillator = new Tone.Oscillator().start().toDestination();
     * setTimeout(() => {
     * 	// mute the output
     * 	Tone.Destination.mute = true;
     * }, 1000);
     */ get mute() {
        return this.input.mute;
    }
    set mute(mute) {
        this.input.mute = mute;
    }
    /**
     * Add a master effects chain. NOTE: this will disconnect any nodes which were previously
     * chained in the master effects chain.
     * @param args All arguments will be connected in a row and the Master will be routed through it.
     * @example
     * // route all audio through a filter and compressor
     * const lowpass = new Tone.Filter(800, "lowpass");
     * const compressor = new Tone.Compressor(-18);
     * Tone.Destination.chain(lowpass, compressor);
     */ chain(...args) {
        this.input.disconnect();
        args.unshift(this.input);
        args.push(this.output);
        (0, $5ffbb5654e49c399$export$933c3b67552fb559)(...args);
        return this;
    }
    /**
     * The maximum number of channels the system can output
     * @example
     * console.log(Tone.Destination.maxChannelCount);
     */ get maxChannelCount() {
        return this.context.rawContext.destination.maxChannelCount;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this.volume.dispose();
        return this;
    }
}
//-------------------------------------
// 	INITIALIZATION
//-------------------------------------
(0, $5845e19ca4e07c3f$export$cdd816203a02e74e)((context)=>{
    context.destination = new $93f47b369d6c1ce4$export$5c4bdf44e1e9cea1({
        context: context
    });
});
(0, $5845e19ca4e07c3f$export$7e1ecadd06ae8222)((context)=>{
    context.destination.dispose();
});





class $80b8f6ea9ad35822$export$562790db7cca758d extends (0, $0eb7340e2d092af9$export$12b11dc969d02fed) {
    /**
     * @param initialValue The value to return if there is no scheduled values
     */ constructor(initialValue){
        super();
        this.name = "TimelineValue";
        /**
         * The timeline which stores the values
         */ this._timeline = new (0, $3684d29589a800b6$export$e6a97ba2cae5bb94)({
            memory: 10
        });
        this._initialValue = initialValue;
    }
    /**
     * Set the value at the given time
     */ set(value, time) {
        this._timeline.add({
            value: value,
            time: time
        });
        return this;
    }
    /**
     * Get the value at the given time
     */ get(time) {
        const event = this._timeline.get(time);
        if (event) return event.value;
        else return this._initialValue;
    }
}















class $860d7330cf63911e$export$bbddcd8b4881600f {
    /**
     * @param transport The transport object which the event belongs to
     */ constructor(transport, opts){
        /**
         * The unique id of the event
         */ this.id = $860d7330cf63911e$export$bbddcd8b4881600f._eventId++;
        const options = Object.assign($860d7330cf63911e$export$bbddcd8b4881600f.getDefaults(), opts);
        this.transport = transport;
        this.callback = options.callback;
        this._once = options.once;
        this.time = options.time;
    }
    static getDefaults() {
        return {
            callback: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            once: false,
            time: 0
        };
    }
    /**
     * Invoke the event callback.
     * @param  time  The AudioContext time in seconds of the event
     */ invoke(time) {
        if (this.callback) {
            this.callback(time);
            if (this._once) this.transport.clear(this.id);
        }
    }
    /**
     * Clean up
     */ dispose() {
        this.callback = undefined;
        return this;
    }
}
/**
 * Current ID counter
 */ $860d7330cf63911e$export$bbddcd8b4881600f._eventId = 0;




class $e2be38b384ecc10e$export$8473d2e877b20cae extends (0, $860d7330cf63911e$export$bbddcd8b4881600f) {
    /**
     * @param transport The transport object which the event belongs to
     */ constructor(transport, opts){
        super(transport, opts);
        /**
         * The ID of the current timeline event
         */ this._currentId = -1;
        /**
         * The ID of the next timeline event
         */ this._nextId = -1;
        /**
         * The time of the next event
         */ this._nextTick = this.time;
        /**
         * a reference to the bound start method
         */ this._boundRestart = this._restart.bind(this);
        const options = Object.assign($e2be38b384ecc10e$export$8473d2e877b20cae.getDefaults(), opts);
        this.duration = new (0, $5a2725674ec35741$export$fe3569694b9f5728)(transport.context, options.duration).valueOf();
        this._interval = new (0, $5a2725674ec35741$export$fe3569694b9f5728)(transport.context, options.interval).valueOf();
        this._nextTick = options.time;
        this.transport.on("start", this._boundRestart);
        this.transport.on("loopStart", this._boundRestart);
        this.context = this.transport.context;
        this._restart();
    }
    static getDefaults() {
        return Object.assign({}, (0, $860d7330cf63911e$export$bbddcd8b4881600f).getDefaults(), {
            duration: Infinity,
            interval: 1,
            once: false
        });
    }
    /**
     * Invoke the callback. Returns the tick time which
     * the next event should be scheduled at.
     * @param  time  The AudioContext time in seconds of the event
     */ invoke(time) {
        // create more events if necessary
        this._createEvents(time);
        // call the super class
        super.invoke(time);
    }
    /**
     * Push more events onto the timeline to keep up with the position of the timeline
     */ _createEvents(time) {
        // schedule the next event
        const ticks = this.transport.getTicksAtTime(time);
        if (ticks >= this.time && ticks >= this._nextTick && this._nextTick + this._interval < this.time + this.duration) {
            this._nextTick += this._interval;
            this._currentId = this._nextId;
            this._nextId = this.transport.scheduleOnce(this.invoke.bind(this), new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, this._nextTick).toSeconds());
        }
    }
    /**
     * Push more events onto the timeline to keep up with the position of the timeline
     */ _restart(time) {
        this.transport.clear(this._currentId);
        this.transport.clear(this._nextId);
        this._nextTick = this.time;
        const ticks = this.transport.getTicksAtTime(time);
        if (ticks > this.time) this._nextTick = this.time + Math.ceil((ticks - this.time) / this._interval) * this._interval;
        this._currentId = this.transport.scheduleOnce(this.invoke.bind(this), new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, this._nextTick).toSeconds());
        this._nextTick += this._interval;
        this._nextId = this.transport.scheduleOnce(this.invoke.bind(this), new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, this._nextTick).toSeconds());
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this.transport.clear(this._currentId);
        this.transport.clear(this._nextId);
        this.transport.off("start", this._boundRestart);
        this.transport.off("loopStart", this._boundRestart);
        return this;
    }
}


class $5b895e0d9fed9a8c$export$86495b081fef8e52 extends (0, $60e11f0590acfc0d$export$4eb0ca57400aa172) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($5b895e0d9fed9a8c$export$86495b081fef8e52.getDefaults(), arguments));
        this.name = "Transport";
        //-------------------------------------
        // 	LOOPING
        //-------------------------------------
        /**
         * If the transport loops or not.
         */ this._loop = new (0, $80b8f6ea9ad35822$export$562790db7cca758d)(false);
        /**
         * The loop start position in ticks
         */ this._loopStart = 0;
        /**
         * The loop end position in ticks
         */ this._loopEnd = 0;
        //-------------------------------------
        // 	TIMELINE EVENTS
        //-------------------------------------
        /**
         * All the events in an object to keep track by ID
         */ this._scheduledEvents = {};
        /**
         * The scheduled events.
         */ this._timeline = new (0, $3684d29589a800b6$export$e6a97ba2cae5bb94)();
        /**
         * Repeated events
         */ this._repeatedEvents = new (0, $e3e68012a1ffdf1d$export$5a615b1a895bd9ec)();
        /**
         * All of the synced Signals
         */ this._syncedSignals = [];
        /**
         * The swing amount
         */ this._swingAmount = 0;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($5b895e0d9fed9a8c$export$86495b081fef8e52.getDefaults(), arguments);
        // CLOCK/TEMPO
        this._ppq = options.ppq;
        this._clock = new (0, $4303602842dc7b38$export$9735c82c4bae3302)({
            callback: this._processTick.bind(this),
            context: this.context,
            frequency: 0,
            units: "bpm"
        });
        this._bindClockEvents();
        this.bpm = this._clock.frequency;
        this._clock.frequency.multiplier = options.ppq;
        this.bpm.setValueAtTime(options.bpm, 0);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "bpm");
        this._timeSignature = options.timeSignature;
        // SWING
        this._swingTicks = options.ppq / 2; // 8n
    }
    static getDefaults() {
        return Object.assign((0, $60e11f0590acfc0d$export$4eb0ca57400aa172).getDefaults(), {
            bpm: 120,
            loopEnd: "4m",
            loopStart: 0,
            ppq: 192,
            swing: 0,
            swingSubdivision: "8n",
            timeSignature: 4
        });
    }
    //-------------------------------------
    // 	TICKS
    //-------------------------------------
    /**
     * called on every tick
     * @param  tickTime clock relative tick time
     */ _processTick(tickTime, ticks) {
        // do the loop test
        if (this._loop.get(tickTime)) {
            if (ticks >= this._loopEnd) {
                this.emit("loopEnd", tickTime);
                this._clock.setTicksAtTime(this._loopStart, tickTime);
                ticks = this._loopStart;
                this.emit("loopStart", tickTime, this._clock.getSecondsAtTime(tickTime));
                this.emit("loop", tickTime);
            }
        }
        // handle swing
        if (this._swingAmount > 0 && ticks % this._ppq !== 0 && ticks % (this._swingTicks * 2) !== 0) {
            // add some swing
            const progress = ticks % (this._swingTicks * 2) / (this._swingTicks * 2);
            const amount = Math.sin(progress * Math.PI) * this._swingAmount;
            tickTime += new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, this._swingTicks * 2 / 3).toSeconds() * amount;
        }
        // invoke the timeline events scheduled on this tick
        this._timeline.forEachAtTime(ticks, (event)=>event.invoke(tickTime));
    }
    //-------------------------------------
    // 	SCHEDULABLE EVENTS
    //-------------------------------------
    /**
     * Schedule an event along the timeline.
     * @param callback The callback to be invoked at the time.
     * @param time The time to invoke the callback at.
     * @return The id of the event which can be used for canceling the event.
     * @example
     * // schedule an event on the 16th measure
     * Tone.Transport.schedule((time) => {
     * 	// invoked on measure 16
     * 	console.log("measure 16!");
     * }, "16:0:0");
     */ schedule(callback, time) {
        const event = new (0, $860d7330cf63911e$export$bbddcd8b4881600f)(this, {
            callback: callback,
            time: new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, time).toTicks()
        });
        return this._addEvent(event, this._timeline);
    }
    /**
     * Schedule a repeated event along the timeline. The event will fire
     * at the `interval` starting at the `startTime` and for the specified
     * `duration`.
     * @param  callback   The callback to invoke.
     * @param  interval   The duration between successive callbacks. Must be a positive number.
     * @param  startTime  When along the timeline the events should start being invoked.
     * @param  duration How long the event should repeat.
     * @return  The ID of the scheduled event. Use this to cancel the event.
     * @example
     * const osc = new Tone.Oscillator().toDestination().start();
     * // a callback invoked every eighth note after the first measure
     * Tone.Transport.scheduleRepeat((time) => {
     * 	osc.start(time).stop(time + 0.1);
     * }, "8n", "1m");
     */ scheduleRepeat(callback, interval, startTime, duration = Infinity) {
        const event = new (0, $e2be38b384ecc10e$export$8473d2e877b20cae)(this, {
            callback: callback,
            duration: new (0, $7eeede37354a7671$export$52b3039dca93a306)(this.context, duration).toTicks(),
            interval: new (0, $7eeede37354a7671$export$52b3039dca93a306)(this.context, interval).toTicks(),
            time: new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, startTime).toTicks()
        });
        // kick it off if the Transport is started
        // @ts-ignore
        return this._addEvent(event, this._repeatedEvents);
    }
    /**
     * Schedule an event that will be removed after it is invoked.
     * @param callback The callback to invoke once.
     * @param time The time the callback should be invoked.
     * @returns The ID of the scheduled event.
     */ scheduleOnce(callback, time) {
        const event = new (0, $860d7330cf63911e$export$bbddcd8b4881600f)(this, {
            callback: callback,
            once: true,
            time: new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, time).toTicks()
        });
        return this._addEvent(event, this._timeline);
    }
    /**
     * Clear the passed in event id from the timeline
     * @param eventId The id of the event.
     */ clear(eventId) {
        if (this._scheduledEvents.hasOwnProperty(eventId)) {
            const item = this._scheduledEvents[eventId.toString()];
            item.timeline.remove(item.event);
            item.event.dispose();
            delete this._scheduledEvents[eventId.toString()];
        }
        return this;
    }
    /**
     * Add an event to the correct timeline. Keep track of the
     * timeline it was added to.
     * @returns the event id which was just added
     */ _addEvent(event, timeline) {
        this._scheduledEvents[event.id.toString()] = {
            event: event,
            timeline: timeline
        };
        timeline.add(event);
        return event.id;
    }
    /**
     * Remove scheduled events from the timeline after
     * the given time. Repeated events will be removed
     * if their startTime is after the given time
     * @param after Clear all events after this time.
     */ cancel(after = 0) {
        const computedAfter = this.toTicks(after);
        this._timeline.forEachFrom(computedAfter, (event)=>this.clear(event.id));
        this._repeatedEvents.forEachFrom(computedAfter, (event)=>this.clear(event.id));
        return this;
    }
    //-------------------------------------
    // 	START/STOP/PAUSE
    //-------------------------------------
    /**
     * Bind start/stop/pause events from the clock and emit them.
     */ _bindClockEvents() {
        this._clock.on("start", (time, offset)=>{
            offset = new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, offset).toSeconds();
            this.emit("start", time, offset);
        });
        this._clock.on("stop", (time)=>{
            this.emit("stop", time);
        });
        this._clock.on("pause", (time)=>{
            this.emit("pause", time);
        });
    }
    /**
     * Returns the playback state of the source, either "started", "stopped", or "paused"
     */ get state() {
        return this._clock.getStateAtTime(this.now());
    }
    /**
     * Start the transport and all sources synced to the transport.
     * @param  time The time when the transport should start.
     * @param  offset The timeline offset to start the transport.
     * @example
     * // start the transport in one second starting at beginning of the 5th measure.
     * Tone.Transport.start("+1", "4:0:0");
     */ start(time, offset) {
        let offsetTicks;
        if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(offset)) offsetTicks = this.toTicks(offset);
        // start the clock
        this._clock.start(time, offsetTicks);
        return this;
    }
    /**
     * Stop the transport and all sources synced to the transport.
     * @param time The time when the transport should stop.
     * @example
     * Tone.Transport.stop();
     */ stop(time) {
        this._clock.stop(time);
        return this;
    }
    /**
     * Pause the transport and all sources synced to the transport.
     */ pause(time) {
        this._clock.pause(time);
        return this;
    }
    /**
     * Toggle the current state of the transport. If it is
     * started, it will stop it, otherwise it will start the Transport.
     * @param  time The time of the event
     */ toggle(time) {
        time = this.toSeconds(time);
        if (this._clock.getStateAtTime(time) !== "started") this.start(time);
        else this.stop(time);
        return this;
    }
    //-------------------------------------
    // 	SETTERS/GETTERS
    //-------------------------------------
    /**
     * The time signature as just the numerator over 4.
     * For example 4/4 would be just 4 and 6/8 would be 3.
     * @example
     * // common time
     * Tone.Transport.timeSignature = 4;
     * // 7/8
     * Tone.Transport.timeSignature = [7, 8];
     * // this will be reduced to a single number
     * Tone.Transport.timeSignature; // returns 3.5
     */ get timeSignature() {
        return this._timeSignature;
    }
    set timeSignature(timeSig) {
        if ((0, $b63b9a75cba601b0$export$43bee75e5e14138e)(timeSig)) timeSig = timeSig[0] / timeSig[1] * 4;
        this._timeSignature = timeSig;
    }
    /**
     * When the Transport.loop = true, this is the starting position of the loop.
     */ get loopStart() {
        return new (0, $7eeede37354a7671$export$52b3039dca93a306)(this.context, this._loopStart, "i").toSeconds();
    }
    set loopStart(startPosition) {
        this._loopStart = this.toTicks(startPosition);
    }
    /**
     * When the Transport.loop = true, this is the ending position of the loop.
     */ get loopEnd() {
        return new (0, $7eeede37354a7671$export$52b3039dca93a306)(this.context, this._loopEnd, "i").toSeconds();
    }
    set loopEnd(endPosition) {
        this._loopEnd = this.toTicks(endPosition);
    }
    /**
     * If the transport loops or not.
     */ get loop() {
        return this._loop.get(this.now());
    }
    set loop(loop) {
        this._loop.set(loop, this.now());
    }
    /**
     * Set the loop start and stop at the same time.
     * @example
     * // loop over the first measure
     * Tone.Transport.setLoopPoints(0, "1m");
     * Tone.Transport.loop = true;
     */ setLoopPoints(startPosition, endPosition) {
        this.loopStart = startPosition;
        this.loopEnd = endPosition;
        return this;
    }
    /**
     * The swing value. Between 0-1 where 1 equal to the note + half the subdivision.
     */ get swing() {
        return this._swingAmount;
    }
    set swing(amount) {
        // scale the values to a normal range
        this._swingAmount = amount;
    }
    /**
     * Set the subdivision which the swing will be applied to.
     * The default value is an 8th note. Value must be less
     * than a quarter note.
     */ get swingSubdivision() {
        return new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, this._swingTicks).toNotation();
    }
    set swingSubdivision(subdivision) {
        this._swingTicks = this.toTicks(subdivision);
    }
    /**
     * The Transport's position in Bars:Beats:Sixteenths.
     * Setting the value will jump to that position right away.
     */ get position() {
        const now = this.now();
        const ticks = this._clock.getTicksAtTime(now);
        return new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, ticks).toBarsBeatsSixteenths();
    }
    set position(progress) {
        const ticks = this.toTicks(progress);
        this.ticks = ticks;
    }
    /**
     * The Transport's position in seconds
     * Setting the value will jump to that position right away.
     */ get seconds() {
        return this._clock.seconds;
    }
    set seconds(s) {
        const now = this.now();
        const ticks = this._clock.frequency.timeToTicks(s, now);
        this.ticks = ticks;
    }
    /**
     * The Transport's loop position as a normalized value. Always
     * returns 0 if the transport if loop is not true.
     */ get progress() {
        if (this.loop) {
            const now = this.now();
            const ticks = this._clock.getTicksAtTime(now);
            return (ticks - this._loopStart) / (this._loopEnd - this._loopStart);
        } else return 0;
    }
    /**
     * The transports current tick position.
     */ get ticks() {
        return this._clock.ticks;
    }
    set ticks(t) {
        if (this._clock.ticks !== t) {
            const now = this.now();
            // stop everything synced to the transport
            if (this.state === "started") {
                const ticks = this._clock.getTicksAtTime(now);
                // schedule to start on the next tick, #573
                const remainingTick = this._clock.frequency.getDurationOfTicks(Math.ceil(ticks) - ticks, now);
                const time = now + remainingTick;
                this.emit("stop", time);
                this._clock.setTicksAtTime(t, time);
                // restart it with the new time
                this.emit("start", time, this._clock.getSecondsAtTime(time));
            } else this._clock.setTicksAtTime(t, now);
        }
    }
    /**
     * Get the clock's ticks at the given time.
     * @param  time  When to get the tick value
     * @return The tick value at the given time.
     */ getTicksAtTime(time) {
        return Math.round(this._clock.getTicksAtTime(time));
    }
    /**
     * Return the elapsed seconds at the given time.
     * @param  time  When to get the elapsed seconds
     * @return  The number of elapsed seconds
     */ getSecondsAtTime(time) {
        return this._clock.getSecondsAtTime(time);
    }
    /**
     * Pulses Per Quarter note. This is the smallest resolution
     * the Transport timing supports. This should be set once
     * on initialization and not set again. Changing this value
     * after other objects have been created can cause problems.
     */ get PPQ() {
        return this._clock.frequency.multiplier;
    }
    set PPQ(ppq) {
        this._clock.frequency.multiplier = ppq;
    }
    //-------------------------------------
    // 	SYNCING
    //-------------------------------------
    /**
     * Returns the time aligned to the next subdivision
     * of the Transport. If the Transport is not started,
     * it will return 0.
     * Note: this will not work precisely during tempo ramps.
     * @param  subdivision  The subdivision to quantize to
     * @return  The context time of the next subdivision.
     * @example
     * // the transport must be started, otherwise returns 0
     * Tone.Transport.start();
     * Tone.Transport.nextSubdivision("4n");
     */ nextSubdivision(subdivision) {
        subdivision = this.toTicks(subdivision);
        if (this.state !== "started") // if the transport's not started, return 0
        return 0;
        else {
            const now = this.now();
            // the remainder of the current ticks and the subdivision
            const transportPos = this.getTicksAtTime(now);
            const remainingTicks = subdivision - transportPos % subdivision;
            return this._clock.nextTickTime(remainingTicks, now);
        }
    }
    /**
     * Attaches the signal to the tempo control signal so that
     * any changes in the tempo will change the signal in the same
     * ratio.
     *
     * @param signal
     * @param ratio Optionally pass in the ratio between the two signals.
     * 			Otherwise it will be computed based on their current values.
     */ syncSignal(signal, ratio) {
        if (!ratio) {
            // get the sync ratio
            const now = this.now();
            if (signal.getValueAtTime(now) !== 0) {
                const bpm = this.bpm.getValueAtTime(now);
                const computedFreq = 1 / (60 / bpm / this.PPQ);
                ratio = signal.getValueAtTime(now) / computedFreq;
            } else ratio = 0;
        }
        const ratioSignal = new (0, $200a6bd89d4579f9$export$acd19d919666900d)(ratio);
        // @ts-ignore
        this.bpm.connect(ratioSignal);
        // @ts-ignore
        ratioSignal.connect(signal._param);
        this._syncedSignals.push({
            initial: signal.value,
            ratio: ratioSignal,
            signal: signal
        });
        signal.value = 0;
        return this;
    }
    /**
     * Unsyncs a previously synced signal from the transport's control.
     * See Transport.syncSignal.
     */ unsyncSignal(signal) {
        for(let i = this._syncedSignals.length - 1; i >= 0; i--){
            const syncedSignal = this._syncedSignals[i];
            if (syncedSignal.signal === signal) {
                syncedSignal.ratio.dispose();
                syncedSignal.signal.value = syncedSignal.initial;
                this._syncedSignals.splice(i, 1);
            }
        }
        return this;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._clock.dispose();
        (0, $c0a1ee726091e30a$export$e6d3eada50a007b1)(this, "bpm");
        this._timeline.dispose();
        this._repeatedEvents.dispose();
        return this;
    }
}
(0, $a281f9e80bc9e8f9$export$4293555f241ae35a).mixin($5b895e0d9fed9a8c$export$86495b081fef8e52);
//-------------------------------------
// 	INITIALIZATION
//-------------------------------------
(0, $5845e19ca4e07c3f$export$cdd816203a02e74e)((context)=>{
    context.transport = new $5b895e0d9fed9a8c$export$86495b081fef8e52({
        context: context
    });
});
(0, $5845e19ca4e07c3f$export$7e1ecadd06ae8222)((context)=>{
    context.transport.dispose();
});









class $fc0255c9fa8d003e$export$1d2df86270c81ecb extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(options){
        super(options);
        /**
         * Sources have no inputs
         */ this.input = undefined;
        /**
         * Keep track of the scheduled state.
         */ this._state = new (0, $e9f51dc63c33b8a5$export$89221a927ffadcaf)("stopped");
        /**
         * The synced `start` callback function from the transport
         */ this._synced = false;
        /**
         * Keep track of all of the scheduled event ids
         */ this._scheduled = [];
        /**
         * Placeholder functions for syncing/unsyncing to transport
         */ this._syncedStart = (0, $c0a1ee726091e30a$export$b50b6e108474309b);
        this._syncedStop = (0, $c0a1ee726091e30a$export$b50b6e108474309b);
        this._state.memory = 100;
        this._state.increasing = true;
        this._volume = this.output = new (0, $7d48f9af04226b93$export$dde279e52d625429)({
            context: this.context,
            mute: options.mute,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "volume");
        this.onstop = options.onstop;
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            mute: false,
            onstop: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            volume: 0
        });
    }
    /**
     * Returns the playback state of the source, either "started" or "stopped".
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/ahntone_c3.mp3", () => {
     * 	player.start();
     * 	console.log(player.state);
     * }).toDestination();
     */ get state() {
        if (this._synced) {
            if (this.context.transport.state === "started") return this._state.getValueAtTime(this.context.transport.seconds);
            else return "stopped";
        } else return this._state.getValueAtTime(this.now());
    }
    /**
     * Mute the output.
     * @example
     * const osc = new Tone.Oscillator().toDestination().start();
     * // mute the output
     * osc.mute = true;
     */ get mute() {
        return this._volume.mute;
    }
    set mute(mute) {
        this._volume.mute = mute;
    }
    /**
     * Ensure that the scheduled time is not before the current time.
     * Should only be used when scheduled unsynced.
     */ _clampToCurrentTime(time) {
        if (this._synced) return time;
        else return Math.max(time, this.context.currentTime);
    }
    /**
     * Start the source at the specified time. If no time is given,
     * start the source now.
     * @param  time When the source should be started.
     * @example
     * const source = new Tone.Oscillator().toDestination();
     * source.start("+0.5"); // starts the source 0.5 seconds from now
     */ start(time, offset, duration) {
        let computedTime = (0, $b63b9a75cba601b0$export$eb605f91c5895a5b)(time) && this._synced ? this.context.transport.seconds : this.toSeconds(time);
        computedTime = this._clampToCurrentTime(computedTime);
        // if it's started, stop it and restart it
        if (!this._synced && this._state.getValueAtTime(computedTime) === "started") {
            // time should be strictly greater than the previous start time
            (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $e85238bb45fd87b7$export$b023c82b48e70453)(computedTime, this._state.get(computedTime).time), "Start time must be strictly greater than previous start time");
            this._state.cancel(computedTime);
            this._state.setStateAtTime("started", computedTime);
            this.log("restart", computedTime);
            this.restart(computedTime, offset, duration);
        } else {
            this.log("start", computedTime);
            this._state.setStateAtTime("started", computedTime);
            if (this._synced) {
                // add the offset time to the event
                const event = this._state.get(computedTime);
                if (event) {
                    event.offset = this.toSeconds((0, $1e273b197c429402$export$37721a79838ca038)(offset, 0));
                    event.duration = duration ? this.toSeconds(duration) : undefined;
                }
                const sched = this.context.transport.schedule((t)=>{
                    this._start(t, offset, duration);
                }, computedTime);
                this._scheduled.push(sched);
                // if the transport is already started
                // and the time is greater than where the transport is
                if (this.context.transport.state === "started" && this.context.transport.getSecondsAtTime(this.immediate()) > computedTime) this._syncedStart(this.now(), this.context.transport.seconds);
            } else {
                (0, $23cf54af36cc9441$export$8ef1ce44f93c2687)(this.context);
                this._start(computedTime, offset, duration);
            }
        }
        return this;
    }
    /**
     * Stop the source at the specified time. If no time is given,
     * stop the source now.
     * @param  time When the source should be stopped.
     * @example
     * const source = new Tone.Oscillator().toDestination();
     * source.start();
     * source.stop("+0.5"); // stops the source 0.5 seconds from now
     */ stop(time) {
        let computedTime = (0, $b63b9a75cba601b0$export$eb605f91c5895a5b)(time) && this._synced ? this.context.transport.seconds : this.toSeconds(time);
        computedTime = this._clampToCurrentTime(computedTime);
        if (this._state.getValueAtTime(computedTime) === "started" || (0, $b63b9a75cba601b0$export$4e62c701997796c1)(this._state.getNextState("started", computedTime))) {
            this.log("stop", computedTime);
            if (!this._synced) this._stop(computedTime);
            else {
                const sched = this.context.transport.schedule(this._stop.bind(this), computedTime);
                this._scheduled.push(sched);
            }
            this._state.cancel(computedTime);
            this._state.setStateAtTime("stopped", computedTime);
        }
        return this;
    }
    /**
     * Restart the source.
     */ restart(time, offset, duration) {
        time = this.toSeconds(time);
        if (this._state.getValueAtTime(time) === "started") {
            this._state.cancel(time);
            this._restart(time, offset, duration);
        }
        return this;
    }
    /**
     * Sync the source to the Transport so that all subsequent
     * calls to `start` and `stop` are synced to the TransportTime
     * instead of the AudioContext time.
     *
     * @example
     * const osc = new Tone.Oscillator().toDestination();
     * // sync the source so that it plays between 0 and 0.3 on the Transport's timeline
     * osc.sync().start(0).stop(0.3);
     * // start the transport.
     * Tone.Transport.start();
     * // set it to loop once a second
     * Tone.Transport.loop = true;
     * Tone.Transport.loopEnd = 1;
     */ sync() {
        if (!this._synced) {
            this._synced = true;
            this._syncedStart = (time, offset)=>{
                if (offset > 0) {
                    // get the playback state at that time
                    const stateEvent = this._state.get(offset);
                    // listen for start events which may occur in the middle of the sync'ed time
                    if (stateEvent && stateEvent.state === "started" && stateEvent.time !== offset) {
                        // get the offset
                        const startOffset = offset - this.toSeconds(stateEvent.time);
                        let duration;
                        if (stateEvent.duration) duration = this.toSeconds(stateEvent.duration) - startOffset;
                        this._start(time, this.toSeconds(stateEvent.offset) + startOffset, duration);
                    }
                }
            };
            this._syncedStop = (time)=>{
                const seconds = this.context.transport.getSecondsAtTime(Math.max(time - this.sampleTime, 0));
                if (this._state.getValueAtTime(seconds) === "started") this._stop(time);
            };
            this.context.transport.on("start", this._syncedStart);
            this.context.transport.on("loopStart", this._syncedStart);
            this.context.transport.on("stop", this._syncedStop);
            this.context.transport.on("pause", this._syncedStop);
            this.context.transport.on("loopEnd", this._syncedStop);
        }
        return this;
    }
    /**
     * Unsync the source to the Transport. See Source.sync
     */ unsync() {
        if (this._synced) {
            this.context.transport.off("stop", this._syncedStop);
            this.context.transport.off("pause", this._syncedStop);
            this.context.transport.off("loopEnd", this._syncedStop);
            this.context.transport.off("start", this._syncedStart);
            this.context.transport.off("loopStart", this._syncedStart);
        }
        this._synced = false;
        // clear all of the scheduled ids
        this._scheduled.forEach((id)=>this.context.transport.clear(id));
        this._scheduled = [];
        this._state.cancel(0);
        // stop it also
        this._stop(0);
        return this;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this.onstop = (0, $c0a1ee726091e30a$export$b50b6e108474309b);
        this.unsync();
        this._volume.dispose();
        this._state.dispose();
        return this;
    }
}



class $76955c76dcac2d3e$export$484d33a0500a4ce1 extends (0, $fc0255c9fa8d003e$export$1d2df86270c81ecb) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($76955c76dcac2d3e$export$484d33a0500a4ce1.getDefaults(), arguments, [
            "type"
        ]));
        this.name = "Noise";
        /**
         * Private reference to the source
         */ this._source = null;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($76955c76dcac2d3e$export$484d33a0500a4ce1.getDefaults(), arguments, [
            "type"
        ]);
        this._playbackRate = options.playbackRate;
        this.type = options.type;
        this._fadeIn = options.fadeIn;
        this._fadeOut = options.fadeOut;
    }
    static getDefaults() {
        return Object.assign((0, $fc0255c9fa8d003e$export$1d2df86270c81ecb).getDefaults(), {
            fadeIn: 0,
            fadeOut: 0,
            playbackRate: 1,
            type: "white"
        });
    }
    /**
     * The type of the noise. Can be "white", "brown", or "pink".
     * @example
     * const noise = new Tone.Noise().toDestination().start();
     * noise.type = "brown";
     */ get type() {
        return this._type;
    }
    set type(type) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(type in $76955c76dcac2d3e$var$_noiseBuffers, "Noise: invalid type: " + type);
        if (this._type !== type) {
            this._type = type;
            // if it's playing, stop and restart it
            if (this.state === "started") {
                const now = this.now();
                this._stop(now);
                this._start(now);
            }
        }
    }
    /**
     * The playback rate of the noise. Affects
     * the "frequency" of the noise.
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        this._playbackRate = rate;
        if (this._source) this._source.playbackRate.value = rate;
    }
    /**
     * internal start method
     */ _start(time) {
        const buffer = $76955c76dcac2d3e$var$_noiseBuffers[this._type];
        this._source = new (0, $ab1da665fc34fe83$export$30cbf4ba14db4fdd)({
            url: buffer,
            context: this.context,
            fadeIn: this._fadeIn,
            fadeOut: this._fadeOut,
            loop: true,
            onended: ()=>this.onstop(this),
            playbackRate: this._playbackRate
        }).connect(this.output);
        this._source.start(this.toSeconds(time), Math.random() * (buffer.duration - 0.001));
    }
    /**
     * internal stop method
     */ _stop(time) {
        if (this._source) {
            this._source.stop(this.toSeconds(time));
            this._source = null;
        }
    }
    /**
     * The fadeIn time of the amplitude envelope.
     */ get fadeIn() {
        return this._fadeIn;
    }
    set fadeIn(time) {
        this._fadeIn = time;
        if (this._source) this._source.fadeIn = this._fadeIn;
    }
    /**
     * The fadeOut time of the amplitude envelope.
     */ get fadeOut() {
        return this._fadeOut;
    }
    set fadeOut(time) {
        this._fadeOut = time;
        if (this._source) this._source.fadeOut = this._fadeOut;
    }
    _restart(time) {
        // TODO could be optimized by cancelling the buffer source 'stop'
        this._stop(time);
        this._start(time);
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        if (this._source) this._source.disconnect();
        return this;
    }
}
//--------------------
// THE NOISE BUFFERS
//--------------------
// Noise buffer stats
const $76955c76dcac2d3e$var$BUFFER_LENGTH = 220500;
const $76955c76dcac2d3e$var$NUM_CHANNELS = 2;
/**
 * Cache the noise buffers
 */ const $76955c76dcac2d3e$var$_noiseCache = {
    brown: null,
    pink: null,
    white: null
};
/**
 * The noise arrays. Generated on initialization.
 * borrowed heavily from https://github.com/zacharydenton/noise.js
 * (c) 2013 Zach Denton (MIT)
 */ const $76955c76dcac2d3e$var$_noiseBuffers = {
    get brown () {
        if (!$76955c76dcac2d3e$var$_noiseCache.brown) {
            const buffer = [];
            for(let channelNum = 0; channelNum < $76955c76dcac2d3e$var$NUM_CHANNELS; channelNum++){
                const channel = new Float32Array($76955c76dcac2d3e$var$BUFFER_LENGTH);
                buffer[channelNum] = channel;
                let lastOut = 0.0;
                for(let i = 0; i < $76955c76dcac2d3e$var$BUFFER_LENGTH; i++){
                    const white = Math.random() * 2 - 1;
                    channel[i] = (lastOut + 0.02 * white) / 1.02;
                    lastOut = channel[i];
                    channel[i] *= 3.5; // (roughly) compensate for gain
                }
            }
            $76955c76dcac2d3e$var$_noiseCache.brown = new (0, $f8b2c4c1413d235f$export$424a335715b38178)().fromArray(buffer);
        }
        return $76955c76dcac2d3e$var$_noiseCache.brown;
    },
    get pink () {
        if (!$76955c76dcac2d3e$var$_noiseCache.pink) {
            const buffer = [];
            for(let channelNum = 0; channelNum < $76955c76dcac2d3e$var$NUM_CHANNELS; channelNum++){
                const channel = new Float32Array($76955c76dcac2d3e$var$BUFFER_LENGTH);
                buffer[channelNum] = channel;
                let b0, b1, b2, b3, b4, b5, b6;
                b0 = b1 = b2 = b3 = b4 = b5 = b6 = 0.0;
                for(let i = 0; i < $76955c76dcac2d3e$var$BUFFER_LENGTH; i++){
                    const white = Math.random() * 2 - 1;
                    b0 = 0.99886 * b0 + white * 0.0555179;
                    b1 = 0.99332 * b1 + white * 0.0750759;
                    b2 = 0.96900 * b2 + white * 0.1538520;
                    b3 = 0.86650 * b3 + white * 0.3104856;
                    b4 = 0.55000 * b4 + white * 0.5329522;
                    b5 = -0.7616 * b5 - white * 0.0168980;
                    channel[i] = b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362;
                    channel[i] *= 0.11; // (roughly) compensate for gain
                    b6 = white * 0.115926;
                }
            }
            $76955c76dcac2d3e$var$_noiseCache.pink = new (0, $f8b2c4c1413d235f$export$424a335715b38178)().fromArray(buffer);
        }
        return $76955c76dcac2d3e$var$_noiseCache.pink;
    },
    get white () {
        if (!$76955c76dcac2d3e$var$_noiseCache.white) {
            const buffer = [];
            for(let channelNum = 0; channelNum < $76955c76dcac2d3e$var$NUM_CHANNELS; channelNum++){
                const channel = new Float32Array($76955c76dcac2d3e$var$BUFFER_LENGTH);
                buffer[channelNum] = channel;
                for(let i = 0; i < $76955c76dcac2d3e$var$BUFFER_LENGTH; i++)channel[i] = Math.random() * 2 - 1;
            }
            $76955c76dcac2d3e$var$_noiseCache.white = new (0, $f8b2c4c1413d235f$export$424a335715b38178)().fromArray(buffer);
        }
        return $76955c76dcac2d3e$var$_noiseCache.white;
    }
};









class $c3fe8ac3fb2b1684$export$187d60d76727d102 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($c3fe8ac3fb2b1684$export$187d60d76727d102.getDefaults(), arguments, [
            "volume"
        ]));
        this.name = "UserMedia";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($c3fe8ac3fb2b1684$export$187d60d76727d102.getDefaults(), arguments, [
            "volume"
        ]);
        this._volume = this.output = new (0, $7d48f9af04226b93$export$dde279e52d625429)({
            context: this.context,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "volume");
        this.mute = options.mute;
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            mute: false,
            volume: 0
        });
    }
    /**
     * Open the media stream. If a string is passed in, it is assumed
     * to be the label or id of the stream, if a number is passed in,
     * it is the input number of the stream.
     * @param  labelOrId The label or id of the audio input media device.
     *                   With no argument, the default stream is opened.
     * @return The promise is resolved when the stream is open.
     */ open(labelOrId) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            (0, $23cf54af36cc9441$export$a7a9523472993e97)($c3fe8ac3fb2b1684$export$187d60d76727d102.supported, "UserMedia is not supported");
            // close the previous stream
            if (this.state === "started") this.close();
            const devices = yield $c3fe8ac3fb2b1684$export$187d60d76727d102.enumerateDevices();
            if ((0, $b63b9a75cba601b0$export$7e4aa119212bc614)(labelOrId)) this._device = devices[labelOrId];
            else {
                this._device = devices.find((device)=>{
                    return device.label === labelOrId || device.deviceId === labelOrId;
                });
                // didn't find a matching device
                if (!this._device && devices.length > 0) this._device = devices[0];
                (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $b63b9a75cba601b0$export$4e62c701997796c1)(this._device), `No matching device ${labelOrId}`);
            }
            // do getUserMedia
            const constraints = {
                audio: {
                    echoCancellation: false,
                    sampleRate: this.context.sampleRate,
                    noiseSuppression: false,
                    mozNoiseSuppression: false
                }
            };
            if (this._device) // @ts-ignore
            constraints.audio.deviceId = this._device.deviceId;
            const stream = yield navigator.mediaDevices.getUserMedia(constraints);
            // start a new source only if the previous one is closed
            if (!this._stream) {
                this._stream = stream;
                // Wrap a MediaStreamSourceNode around the live input stream.
                const mediaStreamNode = this.context.createMediaStreamSource(stream);
                // Connect the MediaStreamSourceNode to a gate gain node
                (0, $5ffbb5654e49c399$export$64605811ab45167f)(mediaStreamNode, this.output);
                this._mediaStream = mediaStreamNode;
            }
            return this;
        });
    }
    /**
     * Close the media stream
     */ close() {
        if (this._stream && this._mediaStream) {
            this._stream.getAudioTracks().forEach((track)=>{
                track.stop();
            });
            this._stream = undefined;
            // remove the old media stream
            this._mediaStream.disconnect();
            this._mediaStream = undefined;
        }
        this._device = undefined;
        return this;
    }
    /**
     * Returns a promise which resolves with the list of audio input devices available.
     * @return The promise that is resolved with the devices
     * @example
     * Tone.UserMedia.enumerateDevices().then((devices) => {
     * 	// print the device labels
     * 	console.log(devices.map(device => device.label));
     * });
     */ static enumerateDevices() {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            const allDevices = yield navigator.mediaDevices.enumerateDevices();
            return allDevices.filter((device)=>{
                return device.kind === "audioinput";
            });
        });
    }
    /**
     * Returns the playback state of the source, "started" when the microphone is open
     * and "stopped" when the mic is closed.
     */ get state() {
        return this._stream && this._stream.active ? "started" : "stopped";
    }
    /**
     * Returns an identifier for the represented device that is
     * persisted across sessions. It is un-guessable by other applications and
     * unique to the origin of the calling application. It is reset when the
     * user clears cookies (for Private Browsing, a different identifier is
     * used that is not persisted across sessions). Returns undefined when the
     * device is not open.
     */ get deviceId() {
        if (this._device) return this._device.deviceId;
        else return undefined;
    }
    /**
     * Returns a group identifier. Two devices have the
     * same group identifier if they belong to the same physical device.
     * Returns null  when the device is not open.
     */ get groupId() {
        if (this._device) return this._device.groupId;
        else return undefined;
    }
    /**
     * Returns a label describing this device (for example "Built-in Microphone").
     * Returns undefined when the device is not open or label is not available
     * because of permissions.
     */ get label() {
        if (this._device) return this._device.label;
        else return undefined;
    }
    /**
     * Mute the output.
     * @example
     * const mic = new Tone.UserMedia();
     * mic.open().then(() => {
     * 	// promise resolves when input is available
     * });
     * // mute the output
     * mic.mute = true;
     */ get mute() {
        return this._volume.mute;
    }
    set mute(mute) {
        this._volume.mute = mute;
    }
    dispose() {
        super.dispose();
        this.close();
        this._volume.dispose();
        this.volume.dispose();
        return this;
    }
    /**
     * If getUserMedia is supported by the browser.
     */ static get supported() {
        return (0, $b63b9a75cba601b0$export$4e62c701997796c1)(navigator.mediaDevices) && (0, $b63b9a75cba601b0$export$4e62c701997796c1)(navigator.mediaDevices.getUserMedia);
    }
}










function $4b331862aba07b54$export$c5486db94e413392(instance, length) {
    return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
        const duration = length / instance.context.sampleRate;
        const context = new (0, $d73ede3d936d3e15$export$46814dd5412c611c)(1, duration, instance.context.sampleRate);
        const clone = new instance.constructor(Object.assign(instance.get(), {
            // should do 2 iterations
            frequency: 2 / duration,
            // zero out the detune
            detune: 0,
            context: context
        })).toDestination();
        clone.start(0);
        const buffer = yield context.render();
        return buffer.getChannelData(0);
    });
}







class $6cdf93678f18ee88$export$284532b021137a4a extends (0, $f93c69dcced4086a$export$27749f88ede4d2a3) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($6cdf93678f18ee88$export$284532b021137a4a.getDefaults(), arguments, [
            "frequency",
            "type"
        ]));
        this.name = "ToneOscillatorNode";
        /**
         * The oscillator
         */ this._oscillator = this.context.createOscillator();
        this._internalChannels = [
            this._oscillator
        ];
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($6cdf93678f18ee88$export$284532b021137a4a.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        (0, $5ffbb5654e49c399$export$64605811ab45167f)(this._oscillator, this._gainNode);
        this.type = options.type;
        this.frequency = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this._oscillator.frequency,
            units: "frequency",
            value: options.frequency
        });
        this.detune = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this._oscillator.detune,
            units: "cents",
            value: options.detune
        });
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "frequency",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $f93c69dcced4086a$export$27749f88ede4d2a3).getDefaults(), {
            detune: 0,
            frequency: 440,
            type: "sine"
        });
    }
    /**
     * Start the oscillator node at the given time
     * @param  time When to start the oscillator
     */ start(time) {
        const computedTime = this.toSeconds(time);
        this.log("start", computedTime);
        this._startGain(computedTime);
        this._oscillator.start(computedTime);
        return this;
    }
    _stopSource(time) {
        this._oscillator.stop(time);
    }
    /**
     * Sets an arbitrary custom periodic waveform given a PeriodicWave.
     * @param  periodicWave PeriodicWave should be created with context.createPeriodicWave
     */ setPeriodicWave(periodicWave) {
        this._oscillator.setPeriodicWave(periodicWave);
        return this;
    }
    /**
     * The oscillator type. Either 'sine', 'sawtooth', 'square', or 'triangle'
     */ get type() {
        return this._oscillator.type;
    }
    set type(type) {
        this._oscillator.type = type;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        if (this.state === "started") this.stop();
        this._oscillator.disconnect();
        this.frequency.dispose();
        this.detune.dispose();
        return this;
    }
}




class $72f1219056ac35e7$export$c01c5c7b81696d70 extends (0, $fc0255c9fa8d003e$export$1d2df86270c81ecb) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($72f1219056ac35e7$export$c01c5c7b81696d70.getDefaults(), arguments, [
            "frequency",
            "type"
        ]));
        this.name = "Oscillator";
        /**
         * the main oscillator
         */ this._oscillator = null;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($72f1219056ac35e7$export$c01c5c7b81696d70.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        this.frequency = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "frequency");
        this.detune = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "detune");
        this._partials = options.partials;
        this._partialCount = options.partialCount;
        this._type = options.type;
        if (options.partialCount && options.type !== "custom") this._type = this.baseType + options.partialCount.toString();
        this.phase = options.phase;
    }
    static getDefaults() {
        return Object.assign((0, $fc0255c9fa8d003e$export$1d2df86270c81ecb).getDefaults(), {
            detune: 0,
            frequency: 440,
            partialCount: 0,
            partials: [],
            phase: 0,
            type: "sine"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        const computedTime = this.toSeconds(time);
        // new oscillator with previous values
        const oscillator = new (0, $6cdf93678f18ee88$export$284532b021137a4a)({
            context: this.context,
            onended: ()=>this.onstop(this)
        });
        this._oscillator = oscillator;
        if (this._wave) this._oscillator.setPeriodicWave(this._wave);
        else this._oscillator.type = this._type;
        // connect the control signal to the oscillator frequency & detune
        this._oscillator.connect(this.output);
        this.frequency.connect(this._oscillator.frequency);
        this.detune.connect(this._oscillator.detune);
        // start the oscillator
        this._oscillator.start(computedTime);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        const computedTime = this.toSeconds(time);
        if (this._oscillator) this._oscillator.stop(computedTime);
    }
    /**
     * Restart the oscillator. Does not stop the oscillator, but instead
     * just cancels any scheduled 'stop' from being invoked.
     */ _restart(time) {
        const computedTime = this.toSeconds(time);
        this.log("restart", computedTime);
        if (this._oscillator) this._oscillator.cancelStop();
        this._state.cancel(computedTime);
        return this;
    }
    /**
     * Sync the signal to the Transport's bpm. Any changes to the transports bpm,
     * will also affect the oscillators frequency.
     * @example
     * const osc = new Tone.Oscillator().toDestination().start();
     * osc.frequency.value = 440;
     * // the ratio between the bpm and the frequency will be maintained
     * osc.syncFrequency();
     * // double the tempo
     * Tone.Transport.bpm.value *= 2;
     * // the frequency of the oscillator is doubled to 880
     */ syncFrequency() {
        this.context.transport.syncSignal(this.frequency);
        return this;
    }
    /**
     * Unsync the oscillator's frequency from the Transport.
     * See Oscillator.syncFrequency
     */ unsyncFrequency() {
        this.context.transport.unsyncSignal(this.frequency);
        return this;
    }
    /**
     * Get a cached periodic wave. Avoids having to recompute
     * the oscillator values when they have already been computed
     * with the same values.
     */ _getCachedPeriodicWave() {
        if (this._type === "custom") {
            const oscProps = $72f1219056ac35e7$export$c01c5c7b81696d70._periodicWaveCache.find((description)=>{
                return description.phase === this._phase && (0, $1e273b197c429402$export$73ce4178444047a5)(description.partials, this._partials);
            });
            return oscProps;
        } else {
            const oscProps = $72f1219056ac35e7$export$c01c5c7b81696d70._periodicWaveCache.find((description)=>{
                return description.type === this._type && description.phase === this._phase;
            });
            this._partialCount = oscProps ? oscProps.partialCount : this._partialCount;
            return oscProps;
        }
    }
    get type() {
        return this._type;
    }
    set type(type) {
        this._type = type;
        const isBasicType = [
            "sine",
            "square",
            "sawtooth",
            "triangle"
        ].indexOf(type) !== -1;
        if (this._phase === 0 && isBasicType) {
            this._wave = undefined;
            this._partialCount = 0;
            // just go with the basic approach
            if (this._oscillator !== null) // already tested that it's a basic type
            this._oscillator.type = type;
        } else {
            // first check if the value is cached
            const cache = this._getCachedPeriodicWave();
            if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(cache)) {
                const { partials: partials , wave: wave  } = cache;
                this._wave = wave;
                this._partials = partials;
                if (this._oscillator !== null) this._oscillator.setPeriodicWave(this._wave);
            } else {
                const [real, imag] = this._getRealImaginary(type, this._phase);
                const periodicWave = this.context.createPeriodicWave(real, imag);
                this._wave = periodicWave;
                if (this._oscillator !== null) this._oscillator.setPeriodicWave(this._wave);
                // set the cache
                $72f1219056ac35e7$export$c01c5c7b81696d70._periodicWaveCache.push({
                    imag: imag,
                    partialCount: this._partialCount,
                    partials: this._partials,
                    phase: this._phase,
                    real: real,
                    type: this._type,
                    wave: this._wave
                });
                if ($72f1219056ac35e7$export$c01c5c7b81696d70._periodicWaveCache.length > 100) $72f1219056ac35e7$export$c01c5c7b81696d70._periodicWaveCache.shift();
            }
        }
    }
    get baseType() {
        return this._type.replace(this.partialCount.toString(), "");
    }
    set baseType(baseType) {
        if (this.partialCount && this._type !== "custom" && baseType !== "custom") this.type = baseType + this.partialCount;
        else this.type = baseType;
    }
    get partialCount() {
        return this._partialCount;
    }
    set partialCount(p) {
        (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(p, 0);
        let type = this._type;
        const partial = /^(sine|triangle|square|sawtooth)(\d+)$/.exec(this._type);
        if (partial) type = partial[1];
        if (this._type !== "custom") {
            if (p === 0) this.type = type;
            else this.type = type + p.toString();
        } else {
            // extend or shorten the partials array
            const fullPartials = new Float32Array(p);
            // copy over the partials array
            this._partials.forEach((v, i)=>fullPartials[i] = v);
            this._partials = Array.from(fullPartials);
            this.type = this._type;
        }
    }
    /**
     * Returns the real and imaginary components based
     * on the oscillator type.
     * @returns [real: Float32Array, imaginary: Float32Array]
     */ _getRealImaginary(type, phase) {
        const fftSize = 4096;
        let periodicWaveSize = fftSize / 2;
        const real = new Float32Array(periodicWaveSize);
        const imag = new Float32Array(periodicWaveSize);
        let partialCount = 1;
        if (type === "custom") {
            partialCount = this._partials.length + 1;
            this._partialCount = this._partials.length;
            periodicWaveSize = partialCount;
            // if the partial count is 0, don't bother doing any computation
            if (this._partials.length === 0) return [
                real,
                imag
            ];
        } else {
            const partial = /^(sine|triangle|square|sawtooth)(\d+)$/.exec(type);
            if (partial) {
                partialCount = parseInt(partial[2], 10) + 1;
                this._partialCount = parseInt(partial[2], 10);
                type = partial[1];
                partialCount = Math.max(partialCount, 2);
                periodicWaveSize = partialCount;
            } else this._partialCount = 0;
            this._partials = [];
        }
        for(let n = 1; n < periodicWaveSize; ++n){
            const piFactor = 2 / (n * Math.PI);
            let b;
            switch(type){
                case "sine":
                    b = n <= partialCount ? 1 : 0;
                    this._partials[n - 1] = b;
                    break;
                case "square":
                    b = n & 1 ? 2 * piFactor : 0;
                    this._partials[n - 1] = b;
                    break;
                case "sawtooth":
                    b = piFactor * (n & 1 ? 1 : -1);
                    this._partials[n - 1] = b;
                    break;
                case "triangle":
                    if (n & 1) b = 2 * (piFactor * piFactor) * (n - 1 >> 1 & 1 ? -1 : 1);
                    else b = 0;
                    this._partials[n - 1] = b;
                    break;
                case "custom":
                    b = this._partials[n - 1];
                    break;
                default:
                    throw new TypeError("Oscillator: invalid type: " + type);
            }
            if (b !== 0) {
                real[n] = -b * Math.sin(phase * n);
                imag[n] = b * Math.cos(phase * n);
            } else {
                real[n] = 0;
                imag[n] = 0;
            }
        }
        return [
            real,
            imag
        ];
    }
    /**
     * Compute the inverse FFT for a given phase.
     */ _inverseFFT(real, imag, phase) {
        let sum = 0;
        const len = real.length;
        for(let i = 0; i < len; i++)sum += real[i] * Math.cos(i * phase) + imag[i] * Math.sin(i * phase);
        return sum;
    }
    /**
     * Returns the initial value of the oscillator when stopped.
     * E.g. a "sine" oscillator with phase = 90 would return an initial value of -1.
     */ getInitialValue() {
        const [real, imag] = this._getRealImaginary(this._type, 0);
        let maxValue = 0;
        const twoPi = Math.PI * 2;
        const testPositions = 32;
        // check for peaks in 16 places
        for(let i = 0; i < testPositions; i++)maxValue = Math.max(this._inverseFFT(real, imag, i / testPositions * twoPi), maxValue);
        return (0, $e85238bb45fd87b7$export$7d15b64cf5a3a4c4)(-this._inverseFFT(real, imag, this._phase) / maxValue, -1, 1);
    }
    get partials() {
        return this._partials.slice(0, this.partialCount);
    }
    set partials(partials) {
        this._partials = partials;
        this._partialCount = this._partials.length;
        if (partials.length) this.type = "custom";
    }
    get phase() {
        return this._phase * (180 / Math.PI);
    }
    set phase(phase) {
        this._phase = phase * Math.PI / 180;
        // reset the type
        this.type = this._type;
    }
    asArray(length = 1024) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            return (0, $4b331862aba07b54$export$c5486db94e413392)(this, length);
        });
    }
    dispose() {
        super.dispose();
        if (this._oscillator !== null) this._oscillator.dispose();
        this._wave = undefined;
        this.frequency.dispose();
        this.detune.dispose();
        return this;
    }
}
/**
 * Cache the periodic waves to avoid having to redo computations
 */ $72f1219056ac35e7$export$c01c5c7b81696d70._periodicWaveCache = [];









class $19ab555af422f940$export$5d271ddbaaaa6dbe extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($19ab555af422f940$export$5d271ddbaaaa6dbe.getDefaults(), arguments, [
            "context"
        ])));
    }
    connect(destination, outputNum = 0, inputNum = 0) {
        (0, $293163363e9daa43$export$c8174dc07173cff0)(this, destination, outputNum, inputNum);
        return this;
    }
}







class $c802ebb611a7b944$export$4d933d013693e78 extends (0, $19ab555af422f940$export$5d271ddbaaaa6dbe) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($c802ebb611a7b944$export$4d933d013693e78.getDefaults(), arguments, [
            "mapping",
            "length"
        ])));
        this.name = "WaveShaper";
        /**
         * the waveshaper node
         */ this._shaper = this.context.createWaveShaper();
        /**
         * The input to the waveshaper node.
         */ this.input = this._shaper;
        /**
         * The output from the waveshaper node
         */ this.output = this._shaper;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($c802ebb611a7b944$export$4d933d013693e78.getDefaults(), arguments, [
            "mapping",
            "length"
        ]);
        if ((0, $b63b9a75cba601b0$export$43bee75e5e14138e)(options.mapping) || options.mapping instanceof Float32Array) this.curve = Float32Array.from(options.mapping);
        else if ((0, $b63b9a75cba601b0$export$f6e2535fb5126e54)(options.mapping)) this.setMap(options.mapping, options.length);
    }
    static getDefaults() {
        return Object.assign((0, $293163363e9daa43$export$8210dfe1863c478).getDefaults(), {
            length: 1024
        });
    }
    /**
     * Uses a mapping function to set the value of the curve.
     * @param mapping The function used to define the values.
     *                The mapping function take two arguments:
     *                the first is the value at the current position
     *                which goes from -1 to 1 over the number of elements
     *                in the curve array. The second argument is the array position.
     * @example
     * const shaper = new Tone.WaveShaper();
     * // map the input signal from [-1, 1] to [0, 10]
     * shaper.setMap((val, index) => (val + 1) * 5);
     */ setMap(mapping, length = 1024) {
        const array = new Float32Array(length);
        for(let i = 0, len = length; i < len; i++){
            const normalized = i / (len - 1) * 2 - 1;
            array[i] = mapping(normalized, i);
        }
        this.curve = array;
        return this;
    }
    /**
     * The array to set as the waveshaper curve. For linear curves
     * array length does not make much difference, but for complex curves
     * longer arrays will provide smoother interpolation.
     */ get curve() {
        return this._shaper.curve;
    }
    set curve(mapping) {
        this._shaper.curve = mapping;
    }
    /**
     * Specifies what type of oversampling (if any) should be used when
     * applying the shaping curve. Can either be "none", "2x" or "4x".
     */ get oversample() {
        return this._shaper.oversample;
    }
    set oversample(oversampling) {
        const isOverSampleType = [
            "none",
            "2x",
            "4x"
        ].some((str)=>str.includes(oversampling));
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(isOverSampleType, "oversampling must be either 'none', '2x', or '4x'");
        this._shaper.oversample = oversampling;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._shaper.disconnect();
        return this;
    }
}


class $17f3df4bd5004033$export$2e6ea0941c39f845 extends (0, $19ab555af422f940$export$5d271ddbaaaa6dbe) {
    constructor(){
        super(...arguments);
        this.name = "AudioToGain";
        /**
         * The node which converts the audio ranges
         */ this._norm = new (0, $c802ebb611a7b944$export$4d933d013693e78)({
            context: this.context,
            mapping: (x)=>(x + 1) / 2
        });
        /**
         * The AudioRange input [-1, 1]
         */ this.input = this._norm;
        /**
         * The GainRange output [0, 1]
         */ this.output = this._norm;
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this._norm.dispose();
        return this;
    }
}





class $cc8144811f713d56$export$f14f83b3b531d498 extends (0, $293163363e9daa43$export$8210dfe1863c478) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($cc8144811f713d56$export$f14f83b3b531d498.getDefaults(), arguments, [
            "value"
        ])));
        this.name = "Multiply";
        /**
         * Indicates if the value should be overridden on connection
         */ this.override = false;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($cc8144811f713d56$export$f14f83b3b531d498.getDefaults(), arguments, [
            "value"
        ]);
        this._mult = this.input = this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            minValue: options.minValue,
            maxValue: options.maxValue
        });
        this.factor = this._param = this._mult.gain;
        this.factor.setValueAtTime(options.value, 0);
    }
    static getDefaults() {
        return Object.assign((0, $293163363e9daa43$export$8210dfe1863c478).getDefaults(), {
            value: 0
        });
    }
    dispose() {
        super.dispose();
        this._mult.dispose();
        return this;
    }
}





class $6f2e46c465d3c15f$export$782fe1d3ba34f8d6 extends (0, $fc0255c9fa8d003e$export$1d2df86270c81ecb) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($6f2e46c465d3c15f$export$782fe1d3ba34f8d6.getDefaults(), arguments, [
            "frequency",
            "type",
            "modulationType"
        ]));
        this.name = "AMOscillator";
        /**
         * convert the -1,1 output to 0,1
         */ this._modulationScale = new (0, $17f3df4bd5004033$export$2e6ea0941c39f845)({
            context: this.context
        });
        /**
         * the node where the modulation happens
         */ this._modulationNode = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($6f2e46c465d3c15f$export$782fe1d3ba34f8d6.getDefaults(), arguments, [
            "frequency",
            "type",
            "modulationType"
        ]);
        this._carrier = new (0, $72f1219056ac35e7$export$c01c5c7b81696d70)({
            context: this.context,
            detune: options.detune,
            frequency: options.frequency,
            onstop: ()=>this.onstop(this),
            phase: options.phase,
            type: options.type
        });
        this.frequency = this._carrier.frequency, this.detune = this._carrier.detune;
        this._modulator = new (0, $72f1219056ac35e7$export$c01c5c7b81696d70)({
            context: this.context,
            phase: options.phase,
            type: options.modulationType
        });
        this.harmonicity = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            units: "positive",
            value: options.harmonicity
        });
        // connections
        this.frequency.chain(this.harmonicity, this._modulator.frequency);
        this._modulator.chain(this._modulationScale, this._modulationNode.gain);
        this._carrier.chain(this._modulationNode, this.output);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "frequency",
            "detune",
            "harmonicity"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $72f1219056ac35e7$export$c01c5c7b81696d70).getDefaults(), {
            harmonicity: 1,
            modulationType: "square"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        this._modulator.start(time);
        this._carrier.start(time);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        this._modulator.stop(time);
        this._carrier.stop(time);
    }
    _restart(time) {
        this._modulator.restart(time);
        this._carrier.restart(time);
    }
    /**
     * The type of the carrier oscillator
     */ get type() {
        return this._carrier.type;
    }
    set type(type) {
        this._carrier.type = type;
    }
    get baseType() {
        return this._carrier.baseType;
    }
    set baseType(baseType) {
        this._carrier.baseType = baseType;
    }
    get partialCount() {
        return this._carrier.partialCount;
    }
    set partialCount(partialCount) {
        this._carrier.partialCount = partialCount;
    }
    /**
     * The type of the modulator oscillator
     */ get modulationType() {
        return this._modulator.type;
    }
    set modulationType(type) {
        this._modulator.type = type;
    }
    get phase() {
        return this._carrier.phase;
    }
    set phase(phase) {
        this._carrier.phase = phase;
        this._modulator.phase = phase;
    }
    get partials() {
        return this._carrier.partials;
    }
    set partials(partials) {
        this._carrier.partials = partials;
    }
    asArray(length = 1024) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            return (0, $4b331862aba07b54$export$c5486db94e413392)(this, length);
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this.frequency.dispose();
        this.detune.dispose();
        this.harmonicity.dispose();
        this._carrier.dispose();
        this._modulator.dispose();
        this._modulationNode.dispose();
        this._modulationScale.dispose();
        return this;
    }
}











class $e0bc8dc1fcdfdb02$export$3055866937a7451d extends (0, $fc0255c9fa8d003e$export$1d2df86270c81ecb) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($e0bc8dc1fcdfdb02$export$3055866937a7451d.getDefaults(), arguments, [
            "frequency",
            "type",
            "modulationType"
        ]));
        this.name = "FMOscillator";
        /**
         * the node where the modulation happens
         */ this._modulationNode = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            gain: 0
        });
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($e0bc8dc1fcdfdb02$export$3055866937a7451d.getDefaults(), arguments, [
            "frequency",
            "type",
            "modulationType"
        ]);
        this._carrier = new (0, $72f1219056ac35e7$export$c01c5c7b81696d70)({
            context: this.context,
            detune: options.detune,
            frequency: 0,
            onstop: ()=>this.onstop(this),
            phase: options.phase,
            type: options.type
        });
        this.detune = this._carrier.detune;
        this.frequency = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        this._modulator = new (0, $72f1219056ac35e7$export$c01c5c7b81696d70)({
            context: this.context,
            phase: options.phase,
            type: options.modulationType
        });
        this.harmonicity = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            units: "positive",
            value: options.harmonicity
        });
        this.modulationIndex = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            units: "positive",
            value: options.modulationIndex
        });
        // connections
        this.frequency.connect(this._carrier.frequency);
        this.frequency.chain(this.harmonicity, this._modulator.frequency);
        this.frequency.chain(this.modulationIndex, this._modulationNode);
        this._modulator.connect(this._modulationNode.gain);
        this._modulationNode.connect(this._carrier.frequency);
        this._carrier.connect(this.output);
        this.detune.connect(this._modulator.detune);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "modulationIndex",
            "frequency",
            "detune",
            "harmonicity"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $72f1219056ac35e7$export$c01c5c7b81696d70).getDefaults(), {
            harmonicity: 1,
            modulationIndex: 2,
            modulationType: "square"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        this._modulator.start(time);
        this._carrier.start(time);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        this._modulator.stop(time);
        this._carrier.stop(time);
    }
    _restart(time) {
        this._modulator.restart(time);
        this._carrier.restart(time);
        return this;
    }
    get type() {
        return this._carrier.type;
    }
    set type(type) {
        this._carrier.type = type;
    }
    get baseType() {
        return this._carrier.baseType;
    }
    set baseType(baseType) {
        this._carrier.baseType = baseType;
    }
    get partialCount() {
        return this._carrier.partialCount;
    }
    set partialCount(partialCount) {
        this._carrier.partialCount = partialCount;
    }
    /**
     * The type of the modulator oscillator
     */ get modulationType() {
        return this._modulator.type;
    }
    set modulationType(type) {
        this._modulator.type = type;
    }
    get phase() {
        return this._carrier.phase;
    }
    set phase(phase) {
        this._carrier.phase = phase;
        this._modulator.phase = phase;
    }
    get partials() {
        return this._carrier.partials;
    }
    set partials(partials) {
        this._carrier.partials = partials;
    }
    asArray(length = 1024) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            return (0, $4b331862aba07b54$export$c5486db94e413392)(this, length);
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this.frequency.dispose();
        this.harmonicity.dispose();
        this._carrier.dispose();
        this._modulator.dispose();
        this._modulationNode.dispose();
        this.modulationIndex.dispose();
        return this;
    }
}











class $60463ac72cb75f44$export$f134e81916b1e032 extends (0, $fc0255c9fa8d003e$export$1d2df86270c81ecb) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($60463ac72cb75f44$export$f134e81916b1e032.getDefaults(), arguments, [
            "frequency",
            "width"
        ]));
        this.name = "PulseOscillator";
        /**
         * gate the width amount
         */ this._widthGate = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            gain: 0
        });
        /**
         * Threshold the signal to turn it into a square
         */ this._thresh = new (0, $c802ebb611a7b944$export$4d933d013693e78)({
            context: this.context,
            mapping: (val)=>val <= 0 ? -1 : 1
        });
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($60463ac72cb75f44$export$f134e81916b1e032.getDefaults(), arguments, [
            "frequency",
            "width"
        ]);
        this.width = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "audioRange",
            value: options.width
        });
        this._triangle = new (0, $72f1219056ac35e7$export$c01c5c7b81696d70)({
            context: this.context,
            detune: options.detune,
            frequency: options.frequency,
            onstop: ()=>this.onstop(this),
            phase: options.phase,
            type: "triangle"
        });
        this.frequency = this._triangle.frequency;
        this.detune = this._triangle.detune;
        // connections
        this._triangle.chain(this._thresh, this.output);
        this.width.chain(this._widthGate, this._thresh);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "width",
            "frequency",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $fc0255c9fa8d003e$export$1d2df86270c81ecb).getDefaults(), {
            detune: 0,
            frequency: 440,
            phase: 0,
            type: "pulse",
            width: 0.2
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        time = this.toSeconds(time);
        this._triangle.start(time);
        this._widthGate.gain.setValueAtTime(1, time);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        time = this.toSeconds(time);
        this._triangle.stop(time);
        // the width is still connected to the output.
        // that needs to be stopped also
        this._widthGate.gain.cancelScheduledValues(time);
        this._widthGate.gain.setValueAtTime(0, time);
    }
    _restart(time) {
        this._triangle.restart(time);
        this._widthGate.gain.cancelScheduledValues(time);
        this._widthGate.gain.setValueAtTime(1, time);
    }
    /**
     * The phase of the oscillator in degrees.
     */ get phase() {
        return this._triangle.phase;
    }
    set phase(phase) {
        this._triangle.phase = phase;
    }
    /**
     * The type of the oscillator. Always returns "pulse".
     */ get type() {
        return "pulse";
    }
    /**
     * The baseType of the oscillator. Always returns "pulse".
     */ get baseType() {
        return "pulse";
    }
    /**
     * The partials of the waveform. Cannot set partials for this waveform type
     */ get partials() {
        return [];
    }
    /**
     * No partials for this waveform type.
     */ get partialCount() {
        return 0;
    }
    /**
     * *Internal use* The carrier oscillator type is fed through the
     * waveshaper node to create the pulse. Using different carrier oscillators
     * changes oscillator's behavior.
     */ set carrierType(type) {
        this._triangle.type = type;
    }
    asArray(length = 1024) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            return (0, $4b331862aba07b54$export$c5486db94e413392)(this, length);
        });
    }
    /**
     * Clean up method.
     */ dispose() {
        super.dispose();
        this._triangle.dispose();
        this.width.dispose();
        this._widthGate.dispose();
        this._thresh.dispose();
        return this;
    }
}










class $58f6e9f1c8af5079$export$a7d0bd116bda6b00 extends (0, $fc0255c9fa8d003e$export$1d2df86270c81ecb) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($58f6e9f1c8af5079$export$a7d0bd116bda6b00.getDefaults(), arguments, [
            "frequency",
            "type",
            "spread"
        ]));
        this.name = "FatOscillator";
        /**
         * The array of oscillators
         */ this._oscillators = [];
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($58f6e9f1c8af5079$export$a7d0bd116bda6b00.getDefaults(), arguments, [
            "frequency",
            "type",
            "spread"
        ]);
        this.frequency = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        this.detune = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        this._spread = options.spread;
        this._type = options.type;
        this._phase = options.phase;
        this._partials = options.partials;
        this._partialCount = options.partialCount;
        // set the count initially
        this.count = options.count;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "frequency",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $72f1219056ac35e7$export$c01c5c7b81696d70).getDefaults(), {
            count: 3,
            spread: 20,
            type: "sawtooth"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        time = this.toSeconds(time);
        this._forEach((osc)=>osc.start(time));
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        time = this.toSeconds(time);
        this._forEach((osc)=>osc.stop(time));
    }
    _restart(time) {
        this._forEach((osc)=>osc.restart(time));
    }
    /**
     * Iterate over all of the oscillators
     */ _forEach(iterator) {
        for(let i = 0; i < this._oscillators.length; i++)iterator(this._oscillators[i], i);
    }
    /**
     * The type of the oscillator
     */ get type() {
        return this._type;
    }
    set type(type) {
        this._type = type;
        this._forEach((osc)=>osc.type = type);
    }
    /**
     * The detune spread between the oscillators. If "count" is
     * set to 3 oscillators and the "spread" is set to 40,
     * the three oscillators would be detuned like this: [-20, 0, 20]
     * for a total detune spread of 40 cents.
     * @example
     * const fatOsc = new Tone.FatOscillator().toDestination().start();
     * fatOsc.spread = 70;
     */ get spread() {
        return this._spread;
    }
    set spread(spread) {
        this._spread = spread;
        if (this._oscillators.length > 1) {
            const start = -spread / 2;
            const step = spread / (this._oscillators.length - 1);
            this._forEach((osc, i)=>osc.detune.value = start + step * i);
        }
    }
    /**
     * The number of detuned oscillators. Must be an integer greater than 1.
     * @example
     * const fatOsc = new Tone.FatOscillator("C#3", "sawtooth").toDestination().start();
     * // use 4 sawtooth oscillators
     * fatOsc.count = 4;
     */ get count() {
        return this._oscillators.length;
    }
    set count(count) {
        (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(count, 1);
        if (this._oscillators.length !== count) {
            // dispose the previous oscillators
            this._forEach((osc)=>osc.dispose());
            this._oscillators = [];
            for(let i = 0; i < count; i++){
                const osc = new (0, $72f1219056ac35e7$export$c01c5c7b81696d70)({
                    context: this.context,
                    volume: -6 - count * 1.1,
                    type: this._type,
                    phase: this._phase + i / count * 360,
                    partialCount: this._partialCount,
                    onstop: i === 0 ? ()=>this.onstop(this) : (0, $c0a1ee726091e30a$export$b50b6e108474309b)
                });
                if (this.type === "custom") osc.partials = this._partials;
                this.frequency.connect(osc.frequency);
                this.detune.connect(osc.detune);
                osc.detune.overridden = false;
                osc.connect(this.output);
                this._oscillators[i] = osc;
            }
            // set the spread
            this.spread = this._spread;
            if (this.state === "started") this._forEach((osc)=>osc.start());
        }
    }
    get phase() {
        return this._phase;
    }
    set phase(phase) {
        this._phase = phase;
        this._forEach((osc, i)=>osc.phase = this._phase + i / this.count * 360);
    }
    get baseType() {
        return this._oscillators[0].baseType;
    }
    set baseType(baseType) {
        this._forEach((osc)=>osc.baseType = baseType);
        this._type = this._oscillators[0].type;
    }
    get partials() {
        return this._oscillators[0].partials;
    }
    set partials(partials) {
        this._partials = partials;
        this._partialCount = this._partials.length;
        if (partials.length) {
            this._type = "custom";
            this._forEach((osc)=>osc.partials = partials);
        }
    }
    get partialCount() {
        return this._oscillators[0].partialCount;
    }
    set partialCount(partialCount) {
        this._partialCount = partialCount;
        this._forEach((osc)=>osc.partialCount = partialCount);
        this._type = this._oscillators[0].type;
    }
    asArray(length = 1024) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            return (0, $4b331862aba07b54$export$c5486db94e413392)(this, length);
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this.frequency.dispose();
        this.detune.dispose();
        this._forEach((osc)=>osc.dispose());
        return this;
    }
}










class $35a6d09635f18110$export$baa28c9ecd0db52 extends (0, $fc0255c9fa8d003e$export$1d2df86270c81ecb) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($35a6d09635f18110$export$baa28c9ecd0db52.getDefaults(), arguments, [
            "frequency",
            "modulationFrequency"
        ]));
        this.name = "PWMOscillator";
        this.sourceType = "pwm";
        /**
         * Scale the oscillator so it doesn't go silent
         * at the extreme values.
         */ this._scale = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            value: 2
        });
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($35a6d09635f18110$export$baa28c9ecd0db52.getDefaults(), arguments, [
            "frequency",
            "modulationFrequency"
        ]);
        this._pulse = new (0, $60463ac72cb75f44$export$f134e81916b1e032)({
            context: this.context,
            frequency: options.modulationFrequency
        });
        // change the pulse oscillator type
        this._pulse.carrierType = "sine";
        this.modulationFrequency = this._pulse.frequency;
        this._modulator = new (0, $72f1219056ac35e7$export$c01c5c7b81696d70)({
            context: this.context,
            detune: options.detune,
            frequency: options.frequency,
            onstop: ()=>this.onstop(this),
            phase: options.phase
        });
        this.frequency = this._modulator.frequency;
        this.detune = this._modulator.detune;
        // connections
        this._modulator.chain(this._scale, this._pulse.width);
        this._pulse.connect(this.output);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "modulationFrequency",
            "frequency",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $fc0255c9fa8d003e$export$1d2df86270c81ecb).getDefaults(), {
            detune: 0,
            frequency: 440,
            modulationFrequency: 0.4,
            phase: 0,
            type: "pwm"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        time = this.toSeconds(time);
        this._modulator.start(time);
        this._pulse.start(time);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        time = this.toSeconds(time);
        this._modulator.stop(time);
        this._pulse.stop(time);
    }
    /**
     * restart the oscillator
     */ _restart(time) {
        this._modulator.restart(time);
        this._pulse.restart(time);
    }
    /**
     * The type of the oscillator. Always returns "pwm".
     */ get type() {
        return "pwm";
    }
    /**
     * The baseType of the oscillator. Always returns "pwm".
     */ get baseType() {
        return "pwm";
    }
    /**
     * The partials of the waveform. Cannot set partials for this waveform type
     */ get partials() {
        return [];
    }
    /**
     * No partials for this waveform type.
     */ get partialCount() {
        return 0;
    }
    /**
     * The phase of the oscillator in degrees.
     */ get phase() {
        return this._modulator.phase;
    }
    set phase(phase) {
        this._modulator.phase = phase;
    }
    asArray(length = 1024) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            return (0, $4b331862aba07b54$export$c5486db94e413392)(this, length);
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._pulse.dispose();
        this._scale.dispose();
        this._modulator.dispose();
        return this;
    }
}















const $579972729410c095$var$OmniOscillatorSourceMap = {
    am: (0, $6f2e46c465d3c15f$export$782fe1d3ba34f8d6),
    fat: (0, $58f6e9f1c8af5079$export$a7d0bd116bda6b00),
    fm: (0, $e0bc8dc1fcdfdb02$export$3055866937a7451d),
    oscillator: (0, $72f1219056ac35e7$export$c01c5c7b81696d70),
    pulse: (0, $60463ac72cb75f44$export$f134e81916b1e032),
    pwm: (0, $35a6d09635f18110$export$baa28c9ecd0db52)
};
class $579972729410c095$export$46c9f562e6d6ca6d extends (0, $fc0255c9fa8d003e$export$1d2df86270c81ecb) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($579972729410c095$export$46c9f562e6d6ca6d.getDefaults(), arguments, [
            "frequency",
            "type"
        ]));
        this.name = "OmniOscillator";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($579972729410c095$export$46c9f562e6d6ca6d.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        this.frequency = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        this.detune = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "frequency",
            "detune"
        ]);
        // set the options
        this.set(options);
    }
    static getDefaults() {
        return Object.assign((0, $72f1219056ac35e7$export$c01c5c7b81696d70).getDefaults(), (0, $e0bc8dc1fcdfdb02$export$3055866937a7451d).getDefaults(), (0, $6f2e46c465d3c15f$export$782fe1d3ba34f8d6).getDefaults(), (0, $58f6e9f1c8af5079$export$a7d0bd116bda6b00).getDefaults(), (0, $60463ac72cb75f44$export$f134e81916b1e032).getDefaults(), (0, $35a6d09635f18110$export$baa28c9ecd0db52).getDefaults());
    }
    /**
     * start the oscillator
     */ _start(time) {
        this._oscillator.start(time);
    }
    /**
     * start the oscillator
     */ _stop(time) {
        this._oscillator.stop(time);
    }
    _restart(time) {
        this._oscillator.restart(time);
        return this;
    }
    /**
     * The type of the oscillator. Can be any of the basic types: sine, square, triangle, sawtooth. Or
     * prefix the basic types with "fm", "am", or "fat" to use the FMOscillator, AMOscillator or FatOscillator
     * types. The oscillator could also be set to "pwm" or "pulse". All of the parameters of the
     * oscillator's class are accessible when the oscillator is set to that type, but throws an error
     * when it's not.
     * @example
     * const omniOsc = new Tone.OmniOscillator().toDestination().start();
     * omniOsc.type = "pwm";
     * // modulationFrequency is parameter which is available
     * // only when the type is "pwm".
     * omniOsc.modulationFrequency.value = 0.5;
     */ get type() {
        let prefix = "";
        if ([
            "am",
            "fm",
            "fat"
        ].some((p)=>this._sourceType === p)) prefix = this._sourceType;
        return prefix + this._oscillator.type;
    }
    set type(type) {
        if (type.substr(0, 2) === "fm") {
            this._createNewOscillator("fm");
            this._oscillator = this._oscillator;
            this._oscillator.type = type.substr(2);
        } else if (type.substr(0, 2) === "am") {
            this._createNewOscillator("am");
            this._oscillator = this._oscillator;
            this._oscillator.type = type.substr(2);
        } else if (type.substr(0, 3) === "fat") {
            this._createNewOscillator("fat");
            this._oscillator = this._oscillator;
            this._oscillator.type = type.substr(3);
        } else if (type === "pwm") {
            this._createNewOscillator("pwm");
            this._oscillator = this._oscillator;
        } else if (type === "pulse") this._createNewOscillator("pulse");
        else {
            this._createNewOscillator("oscillator");
            this._oscillator = this._oscillator;
            this._oscillator.type = type;
        }
    }
    /**
     * The value is an empty array when the type is not "custom".
     * This is not available on "pwm" and "pulse" oscillator types.
     * See [[Oscillator.partials]]
     */ get partials() {
        return this._oscillator.partials;
    }
    set partials(partials) {
        if (!this._getOscType(this._oscillator, "pulse") && !this._getOscType(this._oscillator, "pwm")) this._oscillator.partials = partials;
    }
    get partialCount() {
        return this._oscillator.partialCount;
    }
    set partialCount(partialCount) {
        if (!this._getOscType(this._oscillator, "pulse") && !this._getOscType(this._oscillator, "pwm")) this._oscillator.partialCount = partialCount;
    }
    set(props) {
        // make sure the type is set first
        if (Reflect.has(props, "type") && props.type) this.type = props.type;
        // then set the rest
        super.set(props);
        return this;
    }
    /**
     * connect the oscillator to the frequency and detune signals
     */ _createNewOscillator(oscType) {
        if (oscType !== this._sourceType) {
            this._sourceType = oscType;
            const OscConstructor = $579972729410c095$var$OmniOscillatorSourceMap[oscType];
            // short delay to avoid clicks on the change
            const now = this.now();
            if (this._oscillator) {
                const oldOsc = this._oscillator;
                oldOsc.stop(now);
                // dispose the old one
                this.context.setTimeout(()=>oldOsc.dispose(), this.blockTime);
            }
            this._oscillator = new OscConstructor({
                context: this.context
            });
            this.frequency.connect(this._oscillator.frequency);
            this.detune.connect(this._oscillator.detune);
            this._oscillator.connect(this.output);
            this._oscillator.onstop = ()=>this.onstop(this);
            if (this.state === "started") this._oscillator.start(now);
        }
    }
    get phase() {
        return this._oscillator.phase;
    }
    set phase(phase) {
        this._oscillator.phase = phase;
    }
    /**
     * The source type of the oscillator.
     * @example
     * const omniOsc = new Tone.OmniOscillator(440, "fmsquare");
     * console.log(omniOsc.sourceType); // 'fm'
     */ get sourceType() {
        return this._sourceType;
    }
    set sourceType(sType) {
        // the basetype defaults to sine
        let baseType = "sine";
        if (this._oscillator.type !== "pwm" && this._oscillator.type !== "pulse") baseType = this._oscillator.type;
        // set the type
        if (sType === "fm") this.type = "fm" + baseType;
        else if (sType === "am") this.type = "am" + baseType;
        else if (sType === "fat") this.type = "fat" + baseType;
        else if (sType === "oscillator") this.type = baseType;
        else if (sType === "pulse") this.type = "pulse";
        else if (sType === "pwm") this.type = "pwm";
    }
    _getOscType(osc, sourceType) {
        return osc instanceof $579972729410c095$var$OmniOscillatorSourceMap[sourceType];
    }
    /**
     * The base type of the oscillator. See [[Oscillator.baseType]]
     * @example
     * const omniOsc = new Tone.OmniOscillator(440, "fmsquare4");
     * console.log(omniOsc.sourceType, omniOsc.baseType, omniOsc.partialCount);
     */ get baseType() {
        return this._oscillator.baseType;
    }
    set baseType(baseType) {
        if (!this._getOscType(this._oscillator, "pulse") && !this._getOscType(this._oscillator, "pwm") && baseType !== "pulse" && baseType !== "pwm") this._oscillator.baseType = baseType;
    }
    /**
     * The width of the oscillator when sourceType === "pulse".
     * See [[PWMOscillator.width]]
     */ get width() {
        if (this._getOscType(this._oscillator, "pulse")) return this._oscillator.width;
        else return undefined;
    }
    /**
     * The number of detuned oscillators when sourceType === "fat".
     * See [[FatOscillator.count]]
     */ get count() {
        if (this._getOscType(this._oscillator, "fat")) return this._oscillator.count;
        else return undefined;
    }
    set count(count) {
        if (this._getOscType(this._oscillator, "fat") && (0, $b63b9a75cba601b0$export$7e4aa119212bc614)(count)) this._oscillator.count = count;
    }
    /**
     * The detune spread between the oscillators when sourceType === "fat".
     * See [[FatOscillator.count]]
     */ get spread() {
        if (this._getOscType(this._oscillator, "fat")) return this._oscillator.spread;
        else return undefined;
    }
    set spread(spread) {
        if (this._getOscType(this._oscillator, "fat") && (0, $b63b9a75cba601b0$export$7e4aa119212bc614)(spread)) this._oscillator.spread = spread;
    }
    /**
     * The type of the modulator oscillator. Only if the oscillator is set to "am" or "fm" types.
     * See [[AMOscillator]] or [[FMOscillator]]
     */ get modulationType() {
        if (this._getOscType(this._oscillator, "fm") || this._getOscType(this._oscillator, "am")) return this._oscillator.modulationType;
        else return undefined;
    }
    set modulationType(mType) {
        if ((this._getOscType(this._oscillator, "fm") || this._getOscType(this._oscillator, "am")) && (0, $b63b9a75cba601b0$export$844ec244b1367d54)(mType)) this._oscillator.modulationType = mType;
    }
    /**
     * The modulation index when the sourceType === "fm"
     * See [[FMOscillator]].
     */ get modulationIndex() {
        if (this._getOscType(this._oscillator, "fm")) return this._oscillator.modulationIndex;
        else return undefined;
    }
    /**
     * Harmonicity is the frequency ratio between the carrier and the modulator oscillators.
     * See [[AMOscillator]] or [[FMOscillator]]
     */ get harmonicity() {
        if (this._getOscType(this._oscillator, "fm") || this._getOscType(this._oscillator, "am")) return this._oscillator.harmonicity;
        else return undefined;
    }
    /**
     * The modulationFrequency Signal of the oscillator when sourceType === "pwm"
     * see [[PWMOscillator]]
     * @min 0.1
     * @max 5
     */ get modulationFrequency() {
        if (this._getOscType(this._oscillator, "pwm")) return this._oscillator.modulationFrequency;
        else return undefined;
    }
    asArray(length = 1024) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            return (0, $4b331862aba07b54$export$c5486db94e413392)(this, length);
        });
    }
    dispose() {
        super.dispose();
        this.detune.dispose();
        this.frequency.dispose();
        this._oscillator.dispose();
        return this;
    }
}














class $8af016fb6845f5f0$export$d0265b2c425512d6 extends (0, $293163363e9daa43$export$8210dfe1863c478) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($8af016fb6845f5f0$export$d0265b2c425512d6.getDefaults(), arguments, [
            "value"
        ])));
        this.override = false;
        this.name = "Add";
        /**
         * the summing node
         */ this._sum = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this.input = this._sum;
        this.output = this._sum;
        /**
         * The value which is added to the input signal
         */ this.addend = this._param;
        (0, $5ffbb5654e49c399$export$933c3b67552fb559)(this._constantSource, this._sum);
    }
    static getDefaults() {
        return Object.assign((0, $293163363e9daa43$export$8210dfe1863c478).getDefaults(), {
            value: 0
        });
    }
    dispose() {
        super.dispose();
        this._sum.dispose();
        return this;
    }
}




class $768d8baaf984bb1a$export$d60cfc58d3c358b6 extends (0, $19ab555af422f940$export$5d271ddbaaaa6dbe) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($768d8baaf984bb1a$export$d60cfc58d3c358b6.getDefaults(), arguments, [
            "min",
            "max"
        ])));
        this.name = "Scale";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($768d8baaf984bb1a$export$d60cfc58d3c358b6.getDefaults(), arguments, [
            "min",
            "max"
        ]);
        this._mult = this.input = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            value: options.max - options.min
        });
        this._add = this.output = new (0, $8af016fb6845f5f0$export$d0265b2c425512d6)({
            context: this.context,
            value: options.min
        });
        this._min = options.min;
        this._max = options.max;
        this.input.connect(this.output);
    }
    static getDefaults() {
        return Object.assign((0, $19ab555af422f940$export$5d271ddbaaaa6dbe).getDefaults(), {
            max: 1,
            min: 0
        });
    }
    /**
     * The minimum output value. This number is output when the value input value is 0.
     */ get min() {
        return this._min;
    }
    set min(min) {
        this._min = min;
        this._setRange();
    }
    /**
     * The maximum output value. This number is output when the value input value is 1.
     */ get max() {
        return this._max;
    }
    set max(max) {
        this._max = max;
        this._setRange();
    }
    /**
     * set the values
     */ _setRange() {
        this._add.value = this._min;
        this._mult.value = this._max - this._min;
    }
    dispose() {
        super.dispose();
        this._add.dispose();
        this._mult.dispose();
        return this;
    }
}







class $8357d6ad1e97c334$export$aaef8a3eae948f03 extends (0, $19ab555af422f940$export$5d271ddbaaaa6dbe) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($8357d6ad1e97c334$export$aaef8a3eae948f03.getDefaults(), arguments)));
        this.name = "Zero";
        /**
         * The gain node which connects the constant source to the output
         */ this._gain = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        /**
         * Only outputs 0
         */ this.output = this._gain;
        /**
         * no input node
         */ this.input = undefined;
        (0, $5ffbb5654e49c399$export$64605811ab45167f)(this.context.getConstant(0), this._gain);
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        (0, $5ffbb5654e49c399$export$37dfea93db2e14ed)(this.context.getConstant(0), this._gain);
        return this;
    }
}



class $4a4529bace75b797$export$603054d5ec296d77 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($4a4529bace75b797$export$603054d5ec296d77.getDefaults(), arguments, [
            "frequency",
            "min",
            "max"
        ]));
        this.name = "LFO";
        /**
         * The value that the LFO outputs when it's stopped
         */ this._stoppedValue = 0;
        /**
         * A private placeholder for the units
         */ this._units = "number";
        /**
         * If the input value is converted using the [[units]]
         */ this.convert = true;
        /**
         * Private methods borrowed from Param
         */ // @ts-ignore
        this._fromType = (0, $139d674b4982de8e$export$1ca45c9a47aec42c).prototype._fromType;
        // @ts-ignore
        this._toType = (0, $139d674b4982de8e$export$1ca45c9a47aec42c).prototype._toType;
        // @ts-ignore
        this._is = (0, $139d674b4982de8e$export$1ca45c9a47aec42c).prototype._is;
        // @ts-ignore
        this._clampValue = (0, $139d674b4982de8e$export$1ca45c9a47aec42c).prototype._clampValue;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($4a4529bace75b797$export$603054d5ec296d77.getDefaults(), arguments, [
            "frequency",
            "min",
            "max"
        ]);
        this._oscillator = new (0, $72f1219056ac35e7$export$c01c5c7b81696d70)(options);
        this.frequency = this._oscillator.frequency;
        this._amplitudeGain = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            gain: options.amplitude,
            units: "normalRange"
        });
        this.amplitude = this._amplitudeGain.gain;
        this._stoppedSignal = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "audioRange",
            value: 0
        });
        this._zeros = new (0, $8357d6ad1e97c334$export$aaef8a3eae948f03)({
            context: this.context
        });
        this._a2g = new (0, $17f3df4bd5004033$export$2e6ea0941c39f845)({
            context: this.context
        });
        this._scaler = this.output = new (0, $768d8baaf984bb1a$export$d60cfc58d3c358b6)({
            context: this.context,
            max: options.max,
            min: options.min
        });
        this.units = options.units;
        this.min = options.min;
        this.max = options.max;
        // connect it up
        this._oscillator.chain(this._amplitudeGain, this._a2g, this._scaler);
        this._zeros.connect(this._a2g);
        this._stoppedSignal.connect(this._a2g);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "amplitude",
            "frequency"
        ]);
        this.phase = options.phase;
    }
    static getDefaults() {
        return Object.assign((0, $72f1219056ac35e7$export$c01c5c7b81696d70).getDefaults(), {
            amplitude: 1,
            frequency: "4n",
            max: 1,
            min: 0,
            type: "sine",
            units: "number"
        });
    }
    /**
     * Start the LFO.
     * @param time The time the LFO will start
     */ start(time) {
        time = this.toSeconds(time);
        this._stoppedSignal.setValueAtTime(0, time);
        this._oscillator.start(time);
        return this;
    }
    /**
     * Stop the LFO.
     * @param  time The time the LFO will stop
     */ stop(time) {
        time = this.toSeconds(time);
        this._stoppedSignal.setValueAtTime(this._stoppedValue, time);
        this._oscillator.stop(time);
        return this;
    }
    /**
     * Sync the start/stop/pause to the transport
     * and the frequency to the bpm of the transport
     * @example
     * const lfo = new Tone.LFO("8n");
     * lfo.sync().start(0);
     * // the rate of the LFO will always be an eighth note, even as the tempo changes
     */ sync() {
        this._oscillator.sync();
        this._oscillator.syncFrequency();
        return this;
    }
    /**
     * unsync the LFO from transport control
     */ unsync() {
        this._oscillator.unsync();
        this._oscillator.unsyncFrequency();
        return this;
    }
    /**
     * After the oscillator waveform is updated, reset the `_stoppedSignal` value to match the updated waveform
     */ _setStoppedValue() {
        this._stoppedValue = this._oscillator.getInitialValue();
        this._stoppedSignal.value = this._stoppedValue;
    }
    /**
     * The minimum output of the LFO.
     */ get min() {
        return this._toType(this._scaler.min);
    }
    set min(min) {
        min = this._fromType(min);
        this._scaler.min = min;
    }
    /**
     * The maximum output of the LFO.
     */ get max() {
        return this._toType(this._scaler.max);
    }
    set max(max) {
        max = this._fromType(max);
        this._scaler.max = max;
    }
    /**
     * The type of the oscillator: See [[Oscillator.type]]
     */ get type() {
        return this._oscillator.type;
    }
    set type(type) {
        this._oscillator.type = type;
        this._setStoppedValue();
    }
    /**
     * The oscillator's partials array: See [[Oscillator.partials]]
     */ get partials() {
        return this._oscillator.partials;
    }
    set partials(partials) {
        this._oscillator.partials = partials;
        this._setStoppedValue();
    }
    /**
     * The phase of the LFO.
     */ get phase() {
        return this._oscillator.phase;
    }
    set phase(phase) {
        this._oscillator.phase = phase;
        this._setStoppedValue();
    }
    /**
     * The output units of the LFO.
     */ get units() {
        return this._units;
    }
    set units(val) {
        const currentMin = this.min;
        const currentMax = this.max;
        // convert the min and the max
        this._units = val;
        this.min = currentMin;
        this.max = currentMax;
    }
    /**
     * Returns the playback state of the source, either "started" or "stopped".
     */ get state() {
        return this._oscillator.state;
    }
    /**
     * @param node the destination to connect to
     * @param outputNum the optional output number
     * @param inputNum the input number
     */ connect(node, outputNum, inputNum) {
        if (node instanceof (0, $139d674b4982de8e$export$1ca45c9a47aec42c) || node instanceof (0, $293163363e9daa43$export$8210dfe1863c478)) {
            this.convert = node.convert;
            this.units = node.units;
        }
        (0, $293163363e9daa43$export$c8174dc07173cff0)(this, node, outputNum, inputNum);
        return this;
    }
    dispose() {
        super.dispose();
        this._oscillator.dispose();
        this._stoppedSignal.dispose();
        this._zeros.dispose();
        this._scaler.dispose();
        this._a2g.dispose();
        this._amplitudeGain.dispose();
        this.amplitude.dispose();
        return this;
    }
}












function $cfc784831c74bf36$export$d02631cccf789723(min, max = Infinity) {
    const valueMap = new WeakMap();
    return function(target, propertyKey) {
        Reflect.defineProperty(target, propertyKey, {
            configurable: true,
            enumerable: true,
            get: function() {
                return valueMap.get(this);
            },
            set: function(newValue) {
                (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(newValue, min, max);
                valueMap.set(this, newValue);
            }
        });
    };
}
function $cfc784831c74bf36$export$4748a2e3a6d34ca5(min, max = Infinity) {
    const valueMap = new WeakMap();
    return function(target, propertyKey) {
        Reflect.defineProperty(target, propertyKey, {
            configurable: true,
            enumerable: true,
            get: function() {
                return valueMap.get(this);
            },
            set: function(newValue) {
                (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(this.toSeconds(newValue), min, max);
                valueMap.set(this, newValue);
            }
        });
    };
}


class $e0e97fa89782754a$export$2616165974278734 extends (0, $fc0255c9fa8d003e$export$1d2df86270c81ecb) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($e0e97fa89782754a$export$2616165974278734.getDefaults(), arguments, [
            "url",
            "onload"
        ]));
        this.name = "Player";
        /**
         * All of the active buffer source nodes
         */ this._activeSources = new Set();
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($e0e97fa89782754a$export$2616165974278734.getDefaults(), arguments, [
            "url",
            "onload"
        ]);
        this._buffer = new (0, $f8b2c4c1413d235f$export$424a335715b38178)({
            onload: this._onload.bind(this, options.onload),
            onerror: options.onerror,
            reverse: options.reverse,
            url: options.url
        });
        this.autostart = options.autostart;
        this._loop = options.loop;
        this._loopStart = options.loopStart;
        this._loopEnd = options.loopEnd;
        this._playbackRate = options.playbackRate;
        this.fadeIn = options.fadeIn;
        this.fadeOut = options.fadeOut;
    }
    static getDefaults() {
        return Object.assign((0, $fc0255c9fa8d003e$export$1d2df86270c81ecb).getDefaults(), {
            autostart: false,
            fadeIn: 0,
            fadeOut: 0,
            loop: false,
            loopEnd: 0,
            loopStart: 0,
            onload: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            onerror: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            playbackRate: 1,
            reverse: false
        });
    }
    /**
     * Load the audio file as an audio buffer.
     * Decodes the audio asynchronously and invokes
     * the callback once the audio buffer loads.
     * Note: this does not need to be called if a url
     * was passed in to the constructor. Only use this
     * if you want to manually load a new url.
     * @param url The url of the buffer to load. Filetype support depends on the browser.
     */ load(url) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            yield this._buffer.load(url);
            this._onload();
            return this;
        });
    }
    /**
     * Internal callback when the buffer is loaded.
     */ _onload(callback = (0, $c0a1ee726091e30a$export$b50b6e108474309b)) {
        callback();
        if (this.autostart) this.start();
    }
    /**
     * Internal callback when the buffer is done playing.
     */ _onSourceEnd(source) {
        // invoke the onstop function
        this.onstop(this);
        // delete the source from the active sources
        this._activeSources.delete(source);
        if (this._activeSources.size === 0 && !this._synced && this._state.getValueAtTime(this.now()) === "started") {
            // remove the 'implicitEnd' event and replace with an explicit end
            this._state.cancel(this.now());
            this._state.setStateAtTime("stopped", this.now());
        }
    }
    /**
     * Play the buffer at the given startTime. Optionally add an offset
     * and/or duration which will play the buffer from a position
     * within the buffer for the given duration.
     *
     * @param  time When the player should start.
     * @param  offset The offset from the beginning of the sample to start at.
     * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)
     */ start(time, offset, duration) {
        super.start(time, offset, duration);
        return this;
    }
    /**
     * Internal start method
     */ _start(startTime, offset, duration) {
        // if it's a loop the default offset is the loopStart point
        if (this._loop) offset = (0, $1e273b197c429402$export$37721a79838ca038)(offset, this._loopStart);
        else // otherwise the default offset is 0
        offset = (0, $1e273b197c429402$export$37721a79838ca038)(offset, 0);
        // compute the values in seconds
        const computedOffset = this.toSeconds(offset);
        // compute the duration which is either the passed in duration of the buffer.duration - offset
        const origDuration = duration;
        duration = (0, $1e273b197c429402$export$37721a79838ca038)(duration, Math.max(this._buffer.duration - computedOffset, 0));
        let computedDuration = this.toSeconds(duration);
        // scale it by the playback rate
        computedDuration = computedDuration / this._playbackRate;
        // get the start time
        startTime = this.toSeconds(startTime);
        // make the source
        const source = new (0, $ab1da665fc34fe83$export$30cbf4ba14db4fdd)({
            url: this._buffer,
            context: this.context,
            fadeIn: this.fadeIn,
            fadeOut: this.fadeOut,
            loop: this._loop,
            loopEnd: this._loopEnd,
            loopStart: this._loopStart,
            onended: this._onSourceEnd.bind(this),
            playbackRate: this._playbackRate
        }).connect(this.output);
        // set the looping properties
        if (!this._loop && !this._synced) {
            // cancel the previous stop
            this._state.cancel(startTime + computedDuration);
            // if it's not looping, set the state change at the end of the sample
            this._state.setStateAtTime("stopped", startTime + computedDuration, {
                implicitEnd: true
            });
        }
        // add it to the array of active sources
        this._activeSources.add(source);
        // start it
        if (this._loop && (0, $b63b9a75cba601b0$export$eb605f91c5895a5b)(origDuration)) source.start(startTime, computedOffset);
        else // subtract the fade out time
        source.start(startTime, computedOffset, computedDuration - this.toSeconds(this.fadeOut));
    }
    /**
     * Stop playback.
     */ _stop(time) {
        const computedTime = this.toSeconds(time);
        this._activeSources.forEach((source)=>source.stop(computedTime));
    }
    /**
     * Stop and then restart the player from the beginning (or offset)
     * @param  time When the player should start.
     * @param  offset The offset from the beginning of the sample to start at.
     * @param  duration How long the sample should play. If no duration is given,
     * 					it will default to the full length of the sample (minus any offset)
     */ restart(time, offset, duration) {
        super.restart(time, offset, duration);
        return this;
    }
    _restart(time, offset, duration) {
        this._stop(time);
        this._start(time, offset, duration);
    }
    /**
     * Seek to a specific time in the player's buffer. If the
     * source is no longer playing at that time, it will stop.
     * @param offset The time to seek to.
     * @param when The time for the seek event to occur.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/gurgling_theremin_1.mp3", () => {
     * 	player.start();
     * 	// seek to the offset in 1 second from now
     * 	player.seek(0.4, "+1");
     * }).toDestination();
     */ seek(offset, when) {
        const computedTime = this.toSeconds(when);
        if (this._state.getValueAtTime(computedTime) === "started") {
            const computedOffset = this.toSeconds(offset);
            // if it's currently playing, stop it
            this._stop(computedTime);
            // restart it at the given time
            this._start(computedTime, computedOffset);
        }
        return this;
    }
    /**
     * Set the loop start and end. Will only loop if loop is set to true.
     * @param loopStart The loop start time
     * @param loopEnd The loop end time
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/malevoices_aa2_F3.mp3").toDestination();
     * // loop between the given points
     * player.setLoopPoints(0.2, 0.3);
     * player.loop = true;
     * player.autostart = true;
     */ setLoopPoints(loopStart, loopEnd) {
        this.loopStart = loopStart;
        this.loopEnd = loopEnd;
        return this;
    }
    /**
     * If loop is true, the loop will start at this position.
     */ get loopStart() {
        return this._loopStart;
    }
    set loopStart(loopStart) {
        this._loopStart = loopStart;
        if (this.buffer.loaded) (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(this.toSeconds(loopStart), 0, this.buffer.duration);
        // get the current source
        this._activeSources.forEach((source)=>{
            source.loopStart = loopStart;
        });
    }
    /**
     * If loop is true, the loop will end at this position.
     */ get loopEnd() {
        return this._loopEnd;
    }
    set loopEnd(loopEnd) {
        this._loopEnd = loopEnd;
        if (this.buffer.loaded) (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(this.toSeconds(loopEnd), 0, this.buffer.duration);
        // get the current source
        this._activeSources.forEach((source)=>{
            source.loopEnd = loopEnd;
        });
    }
    /**
     * The audio buffer belonging to the player.
     */ get buffer() {
        return this._buffer;
    }
    set buffer(buffer) {
        this._buffer.set(buffer);
    }
    /**
     * If the buffer should loop once it's over.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/breakbeat.mp3").toDestination();
     * player.loop = true;
     * player.autostart = true;
     */ get loop() {
        return this._loop;
    }
    set loop(loop) {
        // if no change, do nothing
        if (this._loop === loop) return;
        this._loop = loop;
        // set the loop of all of the sources
        this._activeSources.forEach((source)=>{
            source.loop = loop;
        });
        if (loop) {
            // remove the next stopEvent
            const stopEvent = this._state.getNextState("stopped", this.now());
            if (stopEvent) this._state.cancel(stopEvent.time);
        }
    }
    /**
     * Normal speed is 1. The pitch will change with the playback rate.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/femalevoices_aa2_A5.mp3").toDestination();
     * // play at 1/4 speed
     * player.playbackRate = 0.25;
     * // play as soon as the buffer is loaded
     * player.autostart = true;
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        this._playbackRate = rate;
        const now = this.now();
        // cancel the stop event since it's at a different time now
        const stopEvent = this._state.getNextState("stopped", now);
        if (stopEvent && stopEvent.implicitEnd) {
            this._state.cancel(stopEvent.time);
            this._activeSources.forEach((source)=>source.cancelStop());
        }
        // set all the sources
        this._activeSources.forEach((source)=>{
            source.playbackRate.setValueAtTime(rate, now);
        });
    }
    /**
     * If the buffer should be reversed
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/chime_1.mp3").toDestination();
     * player.autostart = true;
     * player.reverse = true;
     */ get reverse() {
        return this._buffer.reverse;
    }
    set reverse(rev) {
        this._buffer.reverse = rev;
    }
    /**
     * If the buffer is loaded
     */ get loaded() {
        return this._buffer.loaded;
    }
    dispose() {
        super.dispose();
        // disconnect all of the players
        this._activeSources.forEach((source)=>source.dispose());
        this._activeSources.clear();
        this._buffer.dispose();
        return this;
    }
}
(0, $a522a8f63c306c1c$export$29e00dfd3077644b)([
    (0, $cfc784831c74bf36$export$4748a2e3a6d34ca5)(0)
], $e0e97fa89782754a$export$2616165974278734.prototype, "fadeIn", void 0);
(0, $a522a8f63c306c1c$export$29e00dfd3077644b)([
    (0, $cfc784831c74bf36$export$4748a2e3a6d34ca5)(0)
], $e0e97fa89782754a$export$2616165974278734.prototype, "fadeOut", void 0);










class $a23f185f5730393d$export$1912c9d78e93a6ed extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($a23f185f5730393d$export$1912c9d78e93a6ed.getDefaults(), arguments, [
            "urls",
            "onload"
        ], "urls"));
        this.name = "Players";
        /**
         * Players has no input.
         */ this.input = undefined;
        /**
         * The container of all of the players
         */ this._players = new Map();
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($a23f185f5730393d$export$1912c9d78e93a6ed.getDefaults(), arguments, [
            "urls",
            "onload"
        ], "urls");
        /**
         * The output volume node
         */ this._volume = this.output = new (0, $7d48f9af04226b93$export$dde279e52d625429)({
            context: this.context,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "volume");
        this._buffers = new (0, $11a3577f34f45a1d$export$7232b969b571e570)({
            urls: options.urls,
            onload: options.onload,
            baseUrl: options.baseUrl,
            onerror: options.onerror
        });
        // mute initially
        this.mute = options.mute;
        this._fadeIn = options.fadeIn;
        this._fadeOut = options.fadeOut;
    }
    static getDefaults() {
        return Object.assign((0, $fc0255c9fa8d003e$export$1d2df86270c81ecb).getDefaults(), {
            baseUrl: "",
            fadeIn: 0,
            fadeOut: 0,
            mute: false,
            onload: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            onerror: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            urls: {},
            volume: 0
        });
    }
    /**
     * Mute the output.
     */ get mute() {
        return this._volume.mute;
    }
    set mute(mute) {
        this._volume.mute = mute;
    }
    /**
     * The fadeIn time of the envelope applied to the source.
     */ get fadeIn() {
        return this._fadeIn;
    }
    set fadeIn(fadeIn) {
        this._fadeIn = fadeIn;
        this._players.forEach((player)=>{
            player.fadeIn = fadeIn;
        });
    }
    /**
     * The fadeOut time of the each of the sources.
     */ get fadeOut() {
        return this._fadeOut;
    }
    set fadeOut(fadeOut) {
        this._fadeOut = fadeOut;
        this._players.forEach((player)=>{
            player.fadeOut = fadeOut;
        });
    }
    /**
     * The state of the players object. Returns "started" if any of the players are playing.
     */ get state() {
        const playing = Array.from(this._players).some(([_, player])=>player.state === "started");
        return playing ? "started" : "stopped";
    }
    /**
     * True if the buffers object has a buffer by that name.
     * @param name  The key or index of the buffer.
     */ has(name) {
        return this._buffers.has(name);
    }
    /**
     * Get a player by name.
     * @param  name  The players name as defined in the constructor object or `add` method.
     */ player(name) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(this.has(name), `No Player with the name ${name} exists on this object`);
        if (!this._players.has(name)) {
            const player = new (0, $e0e97fa89782754a$export$2616165974278734)({
                context: this.context,
                fadeIn: this._fadeIn,
                fadeOut: this._fadeOut,
                url: this._buffers.get(name)
            }).connect(this.output);
            this._players.set(name, player);
        }
        return this._players.get(name);
    }
    /**
     * If all the buffers are loaded or not
     */ get loaded() {
        return this._buffers.loaded;
    }
    /**
     * Add a player by name and url to the Players
     * @param  name A unique name to give the player
     * @param  url  Either the url of the bufer or a buffer which will be added with the given name.
     * @param callback  The callback to invoke when the url is loaded.
     */ add(name, url, callback) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(!this._buffers.has(name), "A buffer with that name already exists on this object");
        this._buffers.add(name, url, callback);
        return this;
    }
    /**
     * Stop all of the players at the given time
     * @param time The time to stop all of the players.
     */ stopAll(time) {
        this._players.forEach((player)=>player.stop(time));
        return this;
    }
    dispose() {
        super.dispose();
        this._volume.dispose();
        this.volume.dispose();
        this._players.forEach((player)=>player.dispose());
        this._buffers.dispose();
        return this;
    }
}










class $881107010ebf9730$export$564c6bce96a1f8e extends (0, $fc0255c9fa8d003e$export$1d2df86270c81ecb) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($881107010ebf9730$export$564c6bce96a1f8e.getDefaults(), arguments, [
            "url",
            "onload"
        ]));
        this.name = "GrainPlayer";
        /**
         * Internal loopStart value
         */ this._loopStart = 0;
        /**
         * Internal loopStart value
         */ this._loopEnd = 0;
        /**
         * All of the currently playing BufferSources
         */ this._activeSources = [];
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($881107010ebf9730$export$564c6bce96a1f8e.getDefaults(), arguments, [
            "url",
            "onload"
        ]);
        this.buffer = new (0, $f8b2c4c1413d235f$export$424a335715b38178)({
            onload: options.onload,
            onerror: options.onerror,
            reverse: options.reverse,
            url: options.url
        });
        this._clock = new (0, $4303602842dc7b38$export$9735c82c4bae3302)({
            context: this.context,
            callback: this._tick.bind(this),
            frequency: 1 / options.grainSize
        });
        this._playbackRate = options.playbackRate;
        this._grainSize = options.grainSize;
        this._overlap = options.overlap;
        this.detune = options.detune;
        // setup
        this.overlap = options.overlap;
        this.loop = options.loop;
        this.playbackRate = options.playbackRate;
        this.grainSize = options.grainSize;
        this.loopStart = options.loopStart;
        this.loopEnd = options.loopEnd;
        this.reverse = options.reverse;
        this._clock.on("stop", this._onstop.bind(this));
    }
    static getDefaults() {
        return Object.assign((0, $fc0255c9fa8d003e$export$1d2df86270c81ecb).getDefaults(), {
            onload: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            onerror: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            overlap: 0.1,
            grainSize: 0.2,
            playbackRate: 1,
            detune: 0,
            loop: false,
            loopStart: 0,
            loopEnd: 0,
            reverse: false
        });
    }
    /**
     * Internal start method
     */ _start(time, offset, duration) {
        offset = (0, $1e273b197c429402$export$37721a79838ca038)(offset, 0);
        offset = this.toSeconds(offset);
        time = this.toSeconds(time);
        const grainSize = 1 / this._clock.frequency.getValueAtTime(time);
        this._clock.start(time, offset / grainSize);
        if (duration) this.stop(time + this.toSeconds(duration));
    }
    /**
     * Stop and then restart the player from the beginning (or offset)
     * @param  time When the player should start.
     * @param  offset The offset from the beginning of the sample to start at.
     * @param  duration How long the sample should play. If no duration is given,
     * 					it will default to the full length of the sample (minus any offset)
     */ restart(time, offset, duration) {
        super.restart(time, offset, duration);
        return this;
    }
    _restart(time, offset, duration) {
        this._stop(time);
        this._start(time, offset, duration);
    }
    /**
     * Internal stop method
     */ _stop(time) {
        this._clock.stop(time);
    }
    /**
     * Invoked when the clock is stopped
     */ _onstop(time) {
        // stop the players
        this._activeSources.forEach((source)=>{
            source.fadeOut = 0;
            source.stop(time);
        });
        this.onstop(this);
    }
    /**
     * Invoked on each clock tick. scheduled a new grain at this time.
     */ _tick(time) {
        // check if it should stop looping
        const ticks = this._clock.getTicksAtTime(time);
        const offset = ticks * this._grainSize;
        this.log("offset", offset);
        if (!this.loop && offset > this.buffer.duration) {
            this.stop(time);
            return;
        }
        // at the beginning of the file, the fade in should be 0
        const fadeIn = offset < this._overlap ? 0 : this._overlap;
        // create a buffer source
        const source = new (0, $ab1da665fc34fe83$export$30cbf4ba14db4fdd)({
            context: this.context,
            url: this.buffer,
            fadeIn: fadeIn,
            fadeOut: this._overlap,
            loop: this.loop,
            loopStart: this._loopStart,
            loopEnd: this._loopEnd,
            // compute the playbackRate based on the detune
            playbackRate: (0, $73949b14fe57a99a$export$5d18fe46719f6008)(this.detune / 100)
        }).connect(this.output);
        source.start(time, this._grainSize * ticks);
        source.stop(time + this._grainSize / this.playbackRate);
        // add it to the active sources
        this._activeSources.push(source);
        // remove it when it's done
        source.onended = ()=>{
            const index = this._activeSources.indexOf(source);
            if (index !== -1) this._activeSources.splice(index, 1);
        };
    }
    /**
     * The playback rate of the sample
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(rate, 0.001);
        this._playbackRate = rate;
        this.grainSize = this._grainSize;
    }
    /**
     * The loop start time.
     */ get loopStart() {
        return this._loopStart;
    }
    set loopStart(time) {
        if (this.buffer.loaded) (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(this.toSeconds(time), 0, this.buffer.duration);
        this._loopStart = this.toSeconds(time);
    }
    /**
     * The loop end time.
     */ get loopEnd() {
        return this._loopEnd;
    }
    set loopEnd(time) {
        if (this.buffer.loaded) (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(this.toSeconds(time), 0, this.buffer.duration);
        this._loopEnd = this.toSeconds(time);
    }
    /**
     * The direction the buffer should play in
     */ get reverse() {
        return this.buffer.reverse;
    }
    set reverse(rev) {
        this.buffer.reverse = rev;
    }
    /**
     * The size of each chunk of audio that the
     * buffer is chopped into and played back at.
     */ get grainSize() {
        return this._grainSize;
    }
    set grainSize(size) {
        this._grainSize = this.toSeconds(size);
        this._clock.frequency.setValueAtTime(this._playbackRate / this._grainSize, this.now());
    }
    /**
     * The duration of the cross-fade between successive grains.
     */ get overlap() {
        return this._overlap;
    }
    set overlap(time) {
        const computedTime = this.toSeconds(time);
        (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(computedTime, 0);
        this._overlap = computedTime;
    }
    /**
     * If all the buffer is loaded
     */ get loaded() {
        return this.buffer.loaded;
    }
    dispose() {
        super.dispose();
        this.buffer.dispose();
        this._clock.dispose();
        this._activeSources.forEach((source)=>source.dispose());
        return this;
    }
}







class $3624e6c3eff54480$export$b73c596ee8758a66 extends (0, $19ab555af422f940$export$5d271ddbaaaa6dbe) {
    constructor(){
        super(...arguments);
        this.name = "Abs";
        /**
         * The node which converts the audio ranges
         */ this._abs = new (0, $c802ebb611a7b944$export$4d933d013693e78)({
            context: this.context,
            mapping: (val)=>{
                if (Math.abs(val) < 0.001) return 0;
                else return Math.abs(val);
            }
        });
        /**
         * The AudioRange input [-1, 1]
         */ this.input = this._abs;
        /**
         * The output range [0, 1]
         */ this.output = this._abs;
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this._abs.dispose();
        return this;
    }
}





class $a47f143e502734f3$export$770438008a544d9b extends (0, $19ab555af422f940$export$5d271ddbaaaa6dbe) {
    constructor(){
        super(...arguments);
        this.name = "GainToAudio";
        /**
         * The node which converts the audio ranges
         */ this._norm = new (0, $c802ebb611a7b944$export$4d933d013693e78)({
            context: this.context,
            mapping: (x)=>Math.abs(x) * 2 - 1
        });
        /**
         * The NormalRange input [0, 1]
         */ this.input = this._norm;
        /**
         * The AudioRange output [-1, 1]
         */ this.output = this._norm;
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this._norm.dispose();
        return this;
    }
}








class $b3fa615a01f226fd$export$a4e82151127277b0 extends (0, $19ab555af422f940$export$5d271ddbaaaa6dbe) {
    constructor(){
        super(...arguments);
        this.name = "Negate";
        /**
         * negation is done by multiplying by -1
         */ this._multiply = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            value: -1
        });
        /**
         * The input and output are equal to the multiply node
         */ this.input = this._multiply;
        this.output = this._multiply;
    }
    /**
     * clean up
     * @returns {Negate} this
     */ dispose() {
        super.dispose();
        this._multiply.dispose();
        return this;
    }
}



class $26f37f85e6014122$export$8bc67ae85ef4b74f extends (0, $293163363e9daa43$export$8210dfe1863c478) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($26f37f85e6014122$export$8bc67ae85ef4b74f.getDefaults(), arguments, [
            "value"
        ])));
        this.override = false;
        this.name = "Subtract";
        /**
         * the summing node
         */ this._sum = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this.input = this._sum;
        this.output = this._sum;
        /**
         * Negate the input of the second input before connecting it to the summing node.
         */ this._neg = new (0, $b3fa615a01f226fd$export$a4e82151127277b0)({
            context: this.context
        });
        /**
         * The value which is subtracted from the main signal
         */ this.subtrahend = this._param;
        (0, $5ffbb5654e49c399$export$933c3b67552fb559)(this._constantSource, this._neg, this._sum);
    }
    static getDefaults() {
        return Object.assign((0, $293163363e9daa43$export$8210dfe1863c478).getDefaults(), {
            value: 0
        });
    }
    dispose() {
        super.dispose();
        this._neg.dispose();
        this._sum.dispose();
        return this;
    }
}







class $667316a8340e070b$export$fe50ca7dd7da9c45 extends (0, $19ab555af422f940$export$5d271ddbaaaa6dbe) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($667316a8340e070b$export$fe50ca7dd7da9c45.getDefaults(), arguments)));
        this.name = "GreaterThanZero";
        this._thresh = this.output = new (0, $c802ebb611a7b944$export$4d933d013693e78)({
            context: this.context,
            length: 127,
            mapping: (val)=>{
                if (val <= 0) return 0;
                else return 1;
            }
        });
        this._scale = this.input = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            value: 10000
        });
        // connections
        this._scale.connect(this._thresh);
    }
    dispose() {
        super.dispose();
        this._scale.dispose();
        this._thresh.dispose();
        return this;
    }
}



class $2a2ba9f2f3f1a12e$export$fdac76ab71aa5db6 extends (0, $293163363e9daa43$export$8210dfe1863c478) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($2a2ba9f2f3f1a12e$export$fdac76ab71aa5db6.getDefaults(), arguments, [
            "value"
        ])));
        this.name = "GreaterThan";
        this.override = false;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($2a2ba9f2f3f1a12e$export$fdac76ab71aa5db6.getDefaults(), arguments, [
            "value"
        ]);
        this._subtract = this.input = new (0, $26f37f85e6014122$export$8bc67ae85ef4b74f)({
            context: this.context,
            value: options.value
        });
        this._gtz = this.output = new (0, $667316a8340e070b$export$fe50ca7dd7da9c45)({
            context: this.context
        });
        this.comparator = this._param = this._subtract.subtrahend;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "comparator");
        // connect
        this._subtract.connect(this._gtz);
    }
    static getDefaults() {
        return Object.assign((0, $293163363e9daa43$export$8210dfe1863c478).getDefaults(), {
            value: 0
        });
    }
    dispose() {
        super.dispose();
        this._gtz.dispose();
        this._subtract.dispose();
        this.comparator.dispose();
        return this;
    }
}








class $b4b6cbb075d013a6$export$ce28d653ec559ee extends (0, $19ab555af422f940$export$5d271ddbaaaa6dbe) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($b4b6cbb075d013a6$export$ce28d653ec559ee.getDefaults(), arguments, [
            "value"
        ])));
        this.name = "Pow";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($b4b6cbb075d013a6$export$ce28d653ec559ee.getDefaults(), arguments, [
            "value"
        ]);
        this._exponentScaler = this.input = this.output = new (0, $c802ebb611a7b944$export$4d933d013693e78)({
            context: this.context,
            mapping: this._expFunc(options.value),
            length: 8192
        });
        this._exponent = options.value;
    }
    static getDefaults() {
        return Object.assign((0, $19ab555af422f940$export$5d271ddbaaaa6dbe).getDefaults(), {
            value: 1
        });
    }
    /**
     * the function which maps the waveshaper
     * @param exponent exponent value
     */ _expFunc(exponent) {
        return (val)=>{
            return Math.pow(Math.abs(val), exponent);
        };
    }
    /**
     * The value of the exponent.
     */ get value() {
        return this._exponent;
    }
    set value(exponent) {
        this._exponent = exponent;
        this._exponentScaler.setMap(this._expFunc(this._exponent));
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._exponentScaler.dispose();
        return this;
    }
}







class $4f921130c5388aed$export$92c7140174c78083 extends (0, $768d8baaf984bb1a$export$d60cfc58d3c358b6) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($4f921130c5388aed$export$92c7140174c78083.getDefaults(), arguments, [
            "min",
            "max",
            "exponent"
        ])));
        this.name = "ScaleExp";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($4f921130c5388aed$export$92c7140174c78083.getDefaults(), arguments, [
            "min",
            "max",
            "exponent"
        ]);
        this.input = this._exp = new (0, $b4b6cbb075d013a6$export$ce28d653ec559ee)({
            context: this.context,
            value: options.exponent
        });
        this._exp.connect(this._mult);
    }
    static getDefaults() {
        return Object.assign((0, $768d8baaf984bb1a$export$d60cfc58d3c358b6).getDefaults(), {
            exponent: 1
        });
    }
    /**
     * Instead of interpolating linearly between the [[min]] and
     * [[max]] values, setting the exponent will interpolate between
     * the two values with an exponential curve.
     */ get exponent() {
        return this._exp.value;
    }
    set exponent(exp) {
        this._exp.value = exp;
    }
    dispose() {
        super.dispose();
        this._exp.dispose();
        return this;
    }
}







class $fed48b3c9d03bef0$export$35743999fcf7d6a4 extends (0, $293163363e9daa43$export$8210dfe1863c478) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)((0, $293163363e9daa43$export$8210dfe1863c478).getDefaults(), arguments, [
            "value",
            "units"
        ]));
        this.name = "SyncedSignal";
        /**
         * Don't override when something is connected to the input
         */ this.override = false;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)((0, $293163363e9daa43$export$8210dfe1863c478).getDefaults(), arguments, [
            "value",
            "units"
        ]);
        this._lastVal = options.value;
        this._synced = this.context.transport.scheduleRepeat(this._onTick.bind(this), "1i");
        this._syncedCallback = this._anchorValue.bind(this);
        this.context.transport.on("start", this._syncedCallback);
        this.context.transport.on("pause", this._syncedCallback);
        this.context.transport.on("stop", this._syncedCallback);
        // disconnect the constant source from the output and replace it with another one
        this._constantSource.disconnect();
        this._constantSource.stop(0);
        // create a new one
        this._constantSource = this.output = new (0, $ef1d4c7c24882f1b$export$717f1ef4ba8fd295)({
            context: this.context,
            offset: options.value,
            units: options.units
        }).start(0);
        this.setValueAtTime(options.value, 0);
    }
    /**
     * Callback which is invoked every tick.
     */ _onTick(time) {
        const val = super.getValueAtTime(this.context.transport.seconds);
        // approximate ramp curves with linear ramps
        if (this._lastVal !== val) {
            this._lastVal = val;
            this._constantSource.offset.setValueAtTime(val, time);
        }
    }
    /**
     * Anchor the value at the start and stop of the Transport
     */ _anchorValue(time) {
        const val = super.getValueAtTime(this.context.transport.seconds);
        this._lastVal = val;
        this._constantSource.offset.cancelAndHoldAtTime(time);
        this._constantSource.offset.setValueAtTime(val, time);
    }
    getValueAtTime(time) {
        const computedTime = new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, time).toSeconds();
        return super.getValueAtTime(computedTime);
    }
    setValueAtTime(value, time) {
        const computedTime = new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, time).toSeconds();
        super.setValueAtTime(value, computedTime);
        return this;
    }
    linearRampToValueAtTime(value, time) {
        const computedTime = new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, time).toSeconds();
        super.linearRampToValueAtTime(value, computedTime);
        return this;
    }
    exponentialRampToValueAtTime(value, time) {
        const computedTime = new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, time).toSeconds();
        super.exponentialRampToValueAtTime(value, computedTime);
        return this;
    }
    setTargetAtTime(value, startTime, timeConstant) {
        const computedTime = new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, startTime).toSeconds();
        super.setTargetAtTime(value, computedTime, timeConstant);
        return this;
    }
    cancelScheduledValues(startTime) {
        const computedTime = new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, startTime).toSeconds();
        super.cancelScheduledValues(computedTime);
        return this;
    }
    setValueCurveAtTime(values, startTime, duration, scaling) {
        const computedTime = new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, startTime).toSeconds();
        duration = this.toSeconds(duration);
        super.setValueCurveAtTime(values, computedTime, duration, scaling);
        return this;
    }
    cancelAndHoldAtTime(time) {
        const computedTime = new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, time).toSeconds();
        super.cancelAndHoldAtTime(computedTime);
        return this;
    }
    setRampPoint(time) {
        const computedTime = new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, time).toSeconds();
        super.setRampPoint(computedTime);
        return this;
    }
    exponentialRampTo(value, rampTime, startTime) {
        const computedTime = new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, startTime).toSeconds();
        super.exponentialRampTo(value, rampTime, computedTime);
        return this;
    }
    linearRampTo(value, rampTime, startTime) {
        const computedTime = new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, startTime).toSeconds();
        super.linearRampTo(value, rampTime, computedTime);
        return this;
    }
    targetRampTo(value, rampTime, startTime) {
        const computedTime = new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, startTime).toSeconds();
        super.targetRampTo(value, rampTime, computedTime);
        return this;
    }
    dispose() {
        super.dispose();
        this.context.transport.clear(this._synced);
        this.context.transport.off("start", this._syncedCallback);
        this.context.transport.off("pause", this._syncedCallback);
        this.context.transport.off("stop", this._syncedCallback);
        this._constantSource.dispose();
        return this;
    }
}



















class $567da4194e00c5c2$export$4e2d65a9843399df extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($567da4194e00c5c2$export$4e2d65a9843399df.getDefaults(), arguments, [
            "attack",
            "decay",
            "sustain",
            "release"
        ]));
        this.name = "Envelope";
        /**
         * the signal which is output.
         */ this._sig = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            value: 0
        });
        /**
         * The output signal of the envelope
         */ this.output = this._sig;
        /**
         * Envelope has no input
         */ this.input = undefined;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($567da4194e00c5c2$export$4e2d65a9843399df.getDefaults(), arguments, [
            "attack",
            "decay",
            "sustain",
            "release"
        ]);
        this.attack = options.attack;
        this.decay = options.decay;
        this.sustain = options.sustain;
        this.release = options.release;
        this.attackCurve = options.attackCurve;
        this.releaseCurve = options.releaseCurve;
        this.decayCurve = options.decayCurve;
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            attack: 0.01,
            attackCurve: "linear",
            decay: 0.1,
            decayCurve: "exponential",
            release: 1,
            releaseCurve: "exponential",
            sustain: 0.5
        });
    }
    /**
     * Read the current value of the envelope. Useful for
     * synchronizing visual output to the envelope.
     */ get value() {
        return this.getValueAtTime(this.now());
    }
    /**
     * Get the curve
     * @param  curve
     * @param  direction  In/Out
     * @return The curve name
     */ _getCurve(curve, direction) {
        if ((0, $b63b9a75cba601b0$export$844ec244b1367d54)(curve)) return curve;
        else {
            // look up the name in the curves array
            let curveName;
            for(curveName in $567da4194e00c5c2$var$EnvelopeCurves){
                if ($567da4194e00c5c2$var$EnvelopeCurves[curveName][direction] === curve) return curveName;
            }
            // return the custom curve
            return curve;
        }
    }
    /**
     * Assign a the curve to the given name using the direction
     * @param  name
     * @param  direction In/Out
     * @param  curve
     */ _setCurve(name, direction, curve) {
        // check if it's a valid type
        if ((0, $b63b9a75cba601b0$export$844ec244b1367d54)(curve) && Reflect.has($567da4194e00c5c2$var$EnvelopeCurves, curve)) {
            const curveDef = $567da4194e00c5c2$var$EnvelopeCurves[curve];
            if ((0, $b63b9a75cba601b0$export$a6cdc56e425d0d0a)(curveDef)) {
                if (name !== "_decayCurve") this[name] = curveDef[direction];
            } else this[name] = curveDef;
        } else if ((0, $b63b9a75cba601b0$export$43bee75e5e14138e)(curve) && name !== "_decayCurve") this[name] = curve;
        else throw new Error("Envelope: invalid curve: " + curve);
    }
    /**
     * The shape of the attack.
     * Can be any of these strings:
     * * "linear"
     * * "exponential"
     * * "sine"
     * * "cosine"
     * * "bounce"
     * * "ripple"
     * * "step"
     *
     * Can also be an array which describes the curve. Values
     * in the array are evenly subdivided and linearly
     * interpolated over the duration of the attack.
     * @example
     * return Tone.Offline(() => {
     * 	const env = new Tone.Envelope(0.4).toDestination();
     * 	env.attackCurve = "linear";
     * 	env.triggerAttack();
     * }, 1, 1);
     */ get attackCurve() {
        return this._getCurve(this._attackCurve, "In");
    }
    set attackCurve(curve) {
        this._setCurve("_attackCurve", "In", curve);
    }
    /**
     * The shape of the release. See the attack curve types.
     * @example
     * return Tone.Offline(() => {
     * 	const env = new Tone.Envelope({
     * 		release: 0.8
     * 	}).toDestination();
     * 	env.triggerAttack();
     * 	// release curve could also be defined by an array
     * 	env.releaseCurve = [1, 0.3, 0.4, 0.2, 0.7, 0];
     * 	env.triggerRelease(0.2);
     * }, 1, 1);
     */ get releaseCurve() {
        return this._getCurve(this._releaseCurve, "Out");
    }
    set releaseCurve(curve) {
        this._setCurve("_releaseCurve", "Out", curve);
    }
    /**
     * The shape of the decay either "linear" or "exponential"
     * @example
     * return Tone.Offline(() => {
     * 	const env = new Tone.Envelope({
     * 		sustain: 0.1,
     * 		decay: 0.5
     * 	}).toDestination();
     * 	env.decayCurve = "linear";
     * 	env.triggerAttack();
     * }, 1, 1);
     */ get decayCurve() {
        return this._decayCurve;
    }
    set decayCurve(curve) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)([
            "linear",
            "exponential"
        ].some((c)=>c === curve), `Invalid envelope curve: ${curve}`);
        this._decayCurve = curve;
    }
    /**
     * Trigger the attack/decay portion of the ADSR envelope.
     * @param  time When the attack should start.
     * @param velocity The velocity of the envelope scales the vales.
     *                             number between 0-1
     * @example
     * const env = new Tone.AmplitudeEnvelope().toDestination();
     * const osc = new Tone.Oscillator().connect(env).start();
     * // trigger the attack 0.5 seconds from now with a velocity of 0.2
     * env.triggerAttack("+0.5", 0.2);
     */ triggerAttack(time, velocity = 1) {
        this.log("triggerAttack", time, velocity);
        time = this.toSeconds(time);
        const originalAttack = this.toSeconds(this.attack);
        let attack = originalAttack;
        const decay = this.toSeconds(this.decay);
        // check if it's not a complete attack
        const currentValue = this.getValueAtTime(time);
        if (currentValue > 0) {
            // subtract the current value from the attack time
            const attackRate = 1 / attack;
            const remainingDistance = 1 - currentValue;
            // the attack is now the remaining time
            attack = remainingDistance / attackRate;
        }
        // attack
        if (attack < this.sampleTime) {
            this._sig.cancelScheduledValues(time);
            // case where the attack time is 0 should set instantly
            this._sig.setValueAtTime(velocity, time);
        } else if (this._attackCurve === "linear") this._sig.linearRampTo(velocity, attack, time);
        else if (this._attackCurve === "exponential") this._sig.targetRampTo(velocity, attack, time);
        else {
            this._sig.cancelAndHoldAtTime(time);
            let curve = this._attackCurve;
            // find the starting position in the curve
            for(let i = 1; i < curve.length; i++)// the starting index is between the two values
            if (curve[i - 1] <= currentValue && currentValue <= curve[i]) {
                curve = this._attackCurve.slice(i);
                // the first index is the current value
                curve[0] = currentValue;
                break;
            }
            this._sig.setValueCurveAtTime(curve, time, attack, velocity);
        }
        // decay
        if (decay && this.sustain < 1) {
            const decayValue = velocity * this.sustain;
            const decayStart = time + attack;
            this.log("decay", decayStart);
            if (this._decayCurve === "linear") this._sig.linearRampToValueAtTime(decayValue, decay + decayStart);
            else this._sig.exponentialApproachValueAtTime(decayValue, decayStart, decay);
        }
        return this;
    }
    /**
     * Triggers the release of the envelope.
     * @param  time When the release portion of the envelope should start.
     * @example
     * const env = new Tone.AmplitudeEnvelope().toDestination();
     * const osc = new Tone.Oscillator({
     * 	type: "sawtooth"
     * }).connect(env).start();
     * env.triggerAttack();
     * // trigger the release half a second after the attack
     * env.triggerRelease("+0.5");
     */ triggerRelease(time) {
        this.log("triggerRelease", time);
        time = this.toSeconds(time);
        const currentValue = this.getValueAtTime(time);
        if (currentValue > 0) {
            const release = this.toSeconds(this.release);
            if (release < this.sampleTime) this._sig.setValueAtTime(0, time);
            else if (this._releaseCurve === "linear") this._sig.linearRampTo(0, release, time);
            else if (this._releaseCurve === "exponential") this._sig.targetRampTo(0, release, time);
            else {
                (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $b63b9a75cba601b0$export$43bee75e5e14138e)(this._releaseCurve), "releaseCurve must be either 'linear', 'exponential' or an array");
                this._sig.cancelAndHoldAtTime(time);
                this._sig.setValueCurveAtTime(this._releaseCurve, time, release, currentValue);
            }
        }
        return this;
    }
    /**
     * Get the scheduled value at the given time. This will
     * return the unconverted (raw) value.
     * @example
     * const env = new Tone.Envelope(0.5, 1, 0.4, 2);
     * env.triggerAttackRelease(2);
     * setInterval(() => console.log(env.getValueAtTime(Tone.now())), 100);
     */ getValueAtTime(time) {
        return this._sig.getValueAtTime(time);
    }
    /**
     * triggerAttackRelease is shorthand for triggerAttack, then waiting
     * some duration, then triggerRelease.
     * @param duration The duration of the sustain.
     * @param time When the attack should be triggered.
     * @param velocity The velocity of the envelope.
     * @example
     * const env = new Tone.AmplitudeEnvelope().toDestination();
     * const osc = new Tone.Oscillator().connect(env).start();
     * // trigger the release 0.5 seconds after the attack
     * env.triggerAttackRelease(0.5);
     */ triggerAttackRelease(duration, time, velocity = 1) {
        time = this.toSeconds(time);
        this.triggerAttack(time, velocity);
        this.triggerRelease(time + this.toSeconds(duration));
        return this;
    }
    /**
     * Cancels all scheduled envelope changes after the given time.
     */ cancel(after) {
        this._sig.cancelScheduledValues(this.toSeconds(after));
        return this;
    }
    /**
     * Connect the envelope to a destination node.
     */ connect(destination, outputNumber = 0, inputNumber = 0) {
        (0, $293163363e9daa43$export$c8174dc07173cff0)(this, destination, outputNumber, inputNumber);
        return this;
    }
    /**
     * Render the envelope curve to an array of the given length.
     * Good for visualizing the envelope curve. Rescales the duration of the
     * envelope to fit the length.
     */ asArray(length = 1024) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            const duration = length / this.context.sampleRate;
            const context = new (0, $d73ede3d936d3e15$export$46814dd5412c611c)(1, duration, this.context.sampleRate);
            // normalize the ADSR for the given duration with 20% sustain time
            const attackPortion = this.toSeconds(this.attack) + this.toSeconds(this.decay);
            const envelopeDuration = attackPortion + this.toSeconds(this.release);
            const sustainTime = envelopeDuration * 0.1;
            const totalDuration = envelopeDuration + sustainTime;
            // @ts-ignore
            const clone = new this.constructor(Object.assign(this.get(), {
                attack: duration * this.toSeconds(this.attack) / totalDuration,
                decay: duration * this.toSeconds(this.decay) / totalDuration,
                release: duration * this.toSeconds(this.release) / totalDuration,
                context: context
            }));
            clone._sig.toDestination();
            clone.triggerAttackRelease(duration * (attackPortion + sustainTime) / totalDuration, 0);
            const buffer = yield context.render();
            return buffer.getChannelData(0);
        });
    }
    dispose() {
        super.dispose();
        this._sig.dispose();
        return this;
    }
}
(0, $a522a8f63c306c1c$export$29e00dfd3077644b)([
    (0, $cfc784831c74bf36$export$4748a2e3a6d34ca5)(0)
], $567da4194e00c5c2$export$4e2d65a9843399df.prototype, "attack", void 0);
(0, $a522a8f63c306c1c$export$29e00dfd3077644b)([
    (0, $cfc784831c74bf36$export$4748a2e3a6d34ca5)(0)
], $567da4194e00c5c2$export$4e2d65a9843399df.prototype, "decay", void 0);
(0, $a522a8f63c306c1c$export$29e00dfd3077644b)([
    (0, $cfc784831c74bf36$export$d02631cccf789723)(0, 1)
], $567da4194e00c5c2$export$4e2d65a9843399df.prototype, "sustain", void 0);
(0, $a522a8f63c306c1c$export$29e00dfd3077644b)([
    (0, $cfc784831c74bf36$export$4748a2e3a6d34ca5)(0)
], $567da4194e00c5c2$export$4e2d65a9843399df.prototype, "release", void 0);
/**
 * Generate some complex envelope curves.
 */ const $567da4194e00c5c2$var$EnvelopeCurves = (()=>{
    const curveLen = 128;
    let i;
    let k;
    // cosine curve
    const cosineCurve = [];
    for(i = 0; i < curveLen; i++)cosineCurve[i] = Math.sin(i / (curveLen - 1) * (Math.PI / 2));
    // ripple curve
    const rippleCurve = [];
    const rippleCurveFreq = 6.4;
    for(i = 0; i < curveLen - 1; i++){
        k = i / (curveLen - 1);
        const sineWave = Math.sin(k * (Math.PI * 2) * rippleCurveFreq - Math.PI / 2) + 1;
        rippleCurve[i] = sineWave / 10 + k * 0.83;
    }
    rippleCurve[curveLen - 1] = 1;
    // stairs curve
    const stairsCurve = [];
    const steps = 5;
    for(i = 0; i < curveLen; i++)stairsCurve[i] = Math.ceil(i / (curveLen - 1) * steps) / steps;
    // in-out easing curve
    const sineCurve = [];
    for(i = 0; i < curveLen; i++){
        k = i / (curveLen - 1);
        sineCurve[i] = 0.5 * (1 - Math.cos(Math.PI * k));
    }
    // a bounce curve
    const bounceCurve = [];
    for(i = 0; i < curveLen; i++){
        k = i / (curveLen - 1);
        const freq = Math.pow(k, 3) * 4 + 0.2;
        const val = Math.cos(freq * Math.PI * 2 * k);
        bounceCurve[i] = Math.abs(val * (1 - k));
    }
    /**
     * Invert a value curve to make it work for the release
     */ function invertCurve(curve) {
        const out = new Array(curve.length);
        for(let j = 0; j < curve.length; j++)out[j] = 1 - curve[j];
        return out;
    }
    /**
     * reverse the curve
     */ function reverseCurve(curve) {
        return curve.slice(0).reverse();
    }
    /**
     * attack and release curve arrays
     */ return {
        bounce: {
            In: invertCurve(bounceCurve),
            Out: bounceCurve
        },
        cosine: {
            In: cosineCurve,
            Out: reverseCurve(cosineCurve)
        },
        exponential: "exponential",
        linear: "linear",
        ripple: {
            In: rippleCurve,
            Out: invertCurve(rippleCurve)
        },
        sine: {
            In: sineCurve,
            Out: invertCurve(sineCurve)
        },
        step: {
            In: stairsCurve,
            Out: invertCurve(stairsCurve)
        }
    };
})();











class $5e47eb9e1349f4fa$export$25ef33f358b07cf4 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($5e47eb9e1349f4fa$export$25ef33f358b07cf4.getDefaults(), arguments));
        /**
         * Keep track of all events scheduled to the transport
         * when the instrument is 'synced'
         */ this._scheduledEvents = [];
        /**
         * If the instrument is currently synced
         */ this._synced = false;
        this._original_triggerAttack = this.triggerAttack;
        this._original_triggerRelease = this.triggerRelease;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($5e47eb9e1349f4fa$export$25ef33f358b07cf4.getDefaults(), arguments);
        this._volume = this.output = new (0, $7d48f9af04226b93$export$dde279e52d625429)({
            context: this.context,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "volume");
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            volume: 0
        });
    }
    /**
     * Sync the instrument to the Transport. All subsequent calls of
     * [[triggerAttack]] and [[triggerRelease]] will be scheduled along the transport.
     * @example
     * const fmSynth = new Tone.FMSynth().toDestination();
     * fmSynth.volume.value = -6;
     * fmSynth.sync();
     * // schedule 3 notes when the transport first starts
     * fmSynth.triggerAttackRelease("C4", "8n", 0);
     * fmSynth.triggerAttackRelease("E4", "8n", "8n");
     * fmSynth.triggerAttackRelease("G4", "8n", "4n");
     * // start the transport to hear the notes
     * Tone.Transport.start();
     */ sync() {
        if (this._syncState()) {
            this._syncMethod("triggerAttack", 1);
            this._syncMethod("triggerRelease", 0);
        }
        return this;
    }
    /**
     * set _sync
     */ _syncState() {
        let changed = false;
        if (!this._synced) {
            this._synced = true;
            changed = true;
        }
        return changed;
    }
    /**
     * Wrap the given method so that it can be synchronized
     * @param method Which method to wrap and sync
     * @param  timePosition What position the time argument appears in
     */ _syncMethod(method, timePosition) {
        const originalMethod = this["_original_" + method] = this[method];
        this[method] = (...args)=>{
            const time = args[timePosition];
            const id = this.context.transport.schedule((t)=>{
                args[timePosition] = t;
                originalMethod.apply(this, args);
            }, time);
            this._scheduledEvents.push(id);
        };
    }
    /**
     * Unsync the instrument from the Transport
     */ unsync() {
        this._scheduledEvents.forEach((id)=>this.context.transport.clear(id));
        this._scheduledEvents = [];
        if (this._synced) {
            this._synced = false;
            this.triggerAttack = this._original_triggerAttack;
            this.triggerRelease = this._original_triggerRelease;
        }
        return this;
    }
    /**
     * Trigger the attack and then the release after the duration.
     * @param  note     The note to trigger.
     * @param  duration How long the note should be held for before
     *                         triggering the release. This value must be greater than 0.
     * @param time  When the note should be triggered.
     * @param  velocity The velocity the note should be triggered at.
     * @example
     * const synth = new Tone.Synth().toDestination();
     * // trigger "C4" for the duration of an 8th note
     * synth.triggerAttackRelease("C4", "8n");
     */ triggerAttackRelease(note, duration, time, velocity) {
        const computedTime = this.toSeconds(time);
        const computedDuration = this.toSeconds(duration);
        this.triggerAttack(note, computedTime, velocity);
        this.triggerRelease(computedTime + computedDuration);
        return this;
    }
    /**
     * clean up
     * @returns {Instrument} this
     */ dispose() {
        super.dispose();
        this._volume.dispose();
        this.unsync();
        this._scheduledEvents = [];
        return this;
    }
}



class $06eb6d10fd7b8c8a$export$f16a08bc2d920a12 extends (0, $5e47eb9e1349f4fa$export$25ef33f358b07cf4) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($06eb6d10fd7b8c8a$export$f16a08bc2d920a12.getDefaults(), arguments));
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($06eb6d10fd7b8c8a$export$f16a08bc2d920a12.getDefaults(), arguments);
        this.portamento = options.portamento;
        this.onsilence = options.onsilence;
    }
    static getDefaults() {
        return Object.assign((0, $5e47eb9e1349f4fa$export$25ef33f358b07cf4).getDefaults(), {
            detune: 0,
            onsilence: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            portamento: 0
        });
    }
    /**
     * Trigger the attack of the note optionally with a given velocity.
     * @param  note The note to trigger.
     * @param  time When the note should start.
     * @param  velocity The velocity scaler determines how "loud" the note will be triggered.
     * @example
     * const synth = new Tone.Synth().toDestination();
     * // trigger the note a half second from now at half velocity
     * synth.triggerAttack("C4", "+0.5", 0.5);
     */ triggerAttack(note, time, velocity = 1) {
        this.log("triggerAttack", note, time, velocity);
        const seconds = this.toSeconds(time);
        this._triggerEnvelopeAttack(seconds, velocity);
        this.setNote(note, seconds);
        return this;
    }
    /**
     * Trigger the release portion of the envelope
     * @param  time If no time is given, the release happens immediatly
     * @example
     * const synth = new Tone.Synth().toDestination();
     * synth.triggerAttack("C4");
     * // trigger the release a second from now
     * synth.triggerRelease("+1");
     */ triggerRelease(time) {
        this.log("triggerRelease", time);
        const seconds = this.toSeconds(time);
        this._triggerEnvelopeRelease(seconds);
        return this;
    }
    /**
     * Set the note at the given time. If no time is given, the note
     * will set immediately.
     * @param note The note to change to.
     * @param  time The time when the note should be set.
     * @example
     * const synth = new Tone.Synth().toDestination();
     * synth.triggerAttack("C4");
     * // change to F#6 in one quarter note from now.
     * synth.setNote("F#6", "+4n");
     */ setNote(note, time) {
        const computedTime = this.toSeconds(time);
        const computedFrequency = note instanceof (0, $5b410fbffb0274be$export$38b56155c8552868) ? note.toFrequency() : note;
        if (this.portamento > 0 && this.getLevelAtTime(computedTime) > 0.05) {
            const portTime = this.toSeconds(this.portamento);
            this.frequency.exponentialRampTo(computedFrequency, portTime, computedTime);
        } else this.frequency.setValueAtTime(computedFrequency, computedTime);
        return this;
    }
}
(0, $a522a8f63c306c1c$export$29e00dfd3077644b)([
    (0, $cfc784831c74bf36$export$4748a2e3a6d34ca5)(0)
], $06eb6d10fd7b8c8a$export$f16a08bc2d920a12.prototype, "portamento", void 0);







class $f7e83647bb4822ef$export$e04e0eedd8192587 extends (0, $567da4194e00c5c2$export$4e2d65a9843399df) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($f7e83647bb4822ef$export$e04e0eedd8192587.getDefaults(), arguments, [
            "attack",
            "decay",
            "sustain",
            "release"
        ]));
        this.name = "AmplitudeEnvelope";
        this._gainNode = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            gain: 0
        });
        this.output = this._gainNode;
        this.input = this._gainNode;
        this._sig.connect(this._gainNode.gain);
        this.output = this._gainNode;
        this.input = this._gainNode;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._gainNode.dispose();
        return this;
    }
}









class $a020c0c7c8b456d8$export$8ef26ca8e8d9bf70 extends (0, $06eb6d10fd7b8c8a$export$f16a08bc2d920a12) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($a020c0c7c8b456d8$export$8ef26ca8e8d9bf70.getDefaults(), arguments));
        this.name = "Synth";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($a020c0c7c8b456d8$export$8ef26ca8e8d9bf70.getDefaults(), arguments);
        this.oscillator = new (0, $579972729410c095$export$46c9f562e6d6ca6d)(Object.assign({
            context: this.context,
            detune: options.detune,
            onstop: ()=>this.onsilence(this)
        }, options.oscillator));
        this.frequency = this.oscillator.frequency;
        this.detune = this.oscillator.detune;
        this.envelope = new (0, $f7e83647bb4822ef$export$e04e0eedd8192587)(Object.assign({
            context: this.context
        }, options.envelope));
        // connect the oscillators to the output
        this.oscillator.chain(this.envelope, this.output);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "oscillator",
            "frequency",
            "detune",
            "envelope"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $06eb6d10fd7b8c8a$export$f16a08bc2d920a12).getDefaults(), {
            envelope: Object.assign((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $567da4194e00c5c2$export$4e2d65a9843399df).getDefaults(), Object.keys((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults())), {
                attack: 0.005,
                decay: 0.1,
                release: 1,
                sustain: 0.3
            }),
            oscillator: Object.assign((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $579972729410c095$export$46c9f562e6d6ca6d).getDefaults(), [
                ...Object.keys((0, $fc0255c9fa8d003e$export$1d2df86270c81ecb).getDefaults()),
                "frequency",
                "detune"
            ]), {
                type: "triangle"
            })
        });
    }
    /**
     * start the attack portion of the envelope
     * @param time the time the attack should start
     * @param velocity the velocity of the note (0-1)
     */ _triggerEnvelopeAttack(time, velocity) {
        // the envelopes
        this.envelope.triggerAttack(time, velocity);
        this.oscillator.start(time);
        // if there is no release portion, stop the oscillator
        if (this.envelope.sustain === 0) {
            const computedAttack = this.toSeconds(this.envelope.attack);
            const computedDecay = this.toSeconds(this.envelope.decay);
            this.oscillator.stop(time + computedAttack + computedDecay);
        }
    }
    /**
     * start the release portion of the envelope
     * @param time the time the release should start
     */ _triggerEnvelopeRelease(time) {
        this.envelope.triggerRelease(time);
        this.oscillator.stop(time + this.toSeconds(this.envelope.release));
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.envelope.getValueAtTime(time);
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this.oscillator.dispose();
        this.envelope.dispose();
        return this;
    }
}




class $8886d01f2e3ddb3f$export$aee9425caad4bd7e extends (0, $06eb6d10fd7b8c8a$export$f16a08bc2d920a12) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($8886d01f2e3ddb3f$export$aee9425caad4bd7e.getDefaults(), arguments));
        this.name = "ModulationSynth";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($8886d01f2e3ddb3f$export$aee9425caad4bd7e.getDefaults(), arguments);
        this._carrier = new (0, $a020c0c7c8b456d8$export$8ef26ca8e8d9bf70)({
            context: this.context,
            oscillator: options.oscillator,
            envelope: options.envelope,
            onsilence: ()=>this.onsilence(this),
            volume: -10
        });
        this._modulator = new (0, $a020c0c7c8b456d8$export$8ef26ca8e8d9bf70)({
            context: this.context,
            oscillator: options.modulation,
            envelope: options.modulationEnvelope,
            volume: -10
        });
        this.oscillator = this._carrier.oscillator;
        this.envelope = this._carrier.envelope;
        this.modulation = this._modulator.oscillator;
        this.modulationEnvelope = this._modulator.envelope;
        this.frequency = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "frequency"
        });
        this.detune = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            value: options.detune,
            units: "cents"
        });
        this.harmonicity = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            value: options.harmonicity,
            minValue: 0
        });
        this._modulationNode = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            gain: 0
        });
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "frequency",
            "harmonicity",
            "oscillator",
            "envelope",
            "modulation",
            "modulationEnvelope",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $06eb6d10fd7b8c8a$export$f16a08bc2d920a12).getDefaults(), {
            harmonicity: 3,
            oscillator: Object.assign((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $579972729410c095$export$46c9f562e6d6ca6d).getDefaults(), [
                ...Object.keys((0, $fc0255c9fa8d003e$export$1d2df86270c81ecb).getDefaults()),
                "frequency",
                "detune"
            ]), {
                type: "sine"
            }),
            envelope: Object.assign((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $567da4194e00c5c2$export$4e2d65a9843399df).getDefaults(), Object.keys((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults())), {
                attack: 0.01,
                decay: 0.01,
                sustain: 1,
                release: 0.5
            }),
            modulation: Object.assign((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $579972729410c095$export$46c9f562e6d6ca6d).getDefaults(), [
                ...Object.keys((0, $fc0255c9fa8d003e$export$1d2df86270c81ecb).getDefaults()),
                "frequency",
                "detune"
            ]), {
                type: "square"
            }),
            modulationEnvelope: Object.assign((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $567da4194e00c5c2$export$4e2d65a9843399df).getDefaults(), Object.keys((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults())), {
                attack: 0.5,
                decay: 0.0,
                sustain: 1,
                release: 0.5
            })
        });
    }
    /**
     * Trigger the attack portion of the note
     */ _triggerEnvelopeAttack(time, velocity) {
        // @ts-ignore
        this._carrier._triggerEnvelopeAttack(time, velocity);
        // @ts-ignore
        this._modulator._triggerEnvelopeAttack(time, velocity);
    }
    /**
     * Trigger the release portion of the note
     */ _triggerEnvelopeRelease(time) {
        // @ts-ignore
        this._carrier._triggerEnvelopeRelease(time);
        // @ts-ignore
        this._modulator._triggerEnvelopeRelease(time);
        return this;
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.envelope.getValueAtTime(time);
    }
    dispose() {
        super.dispose();
        this._carrier.dispose();
        this._modulator.dispose();
        this.frequency.dispose();
        this.detune.dispose();
        this.harmonicity.dispose();
        this._modulationNode.dispose();
        return this;
    }
}


class $379e1469ccc83129$export$cd421a3dd25cf75d extends (0, $8886d01f2e3ddb3f$export$aee9425caad4bd7e) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($379e1469ccc83129$export$cd421a3dd25cf75d.getDefaults(), arguments));
        this.name = "AMSynth";
        this._modulationScale = new (0, $17f3df4bd5004033$export$2e6ea0941c39f845)({
            context: this.context
        });
        // control the two voices frequency
        this.frequency.connect(this._carrier.frequency);
        this.frequency.chain(this.harmonicity, this._modulator.frequency);
        this.detune.fan(this._carrier.detune, this._modulator.detune);
        this._modulator.chain(this._modulationScale, this._modulationNode.gain);
        this._carrier.chain(this._modulationNode, this.output);
    }
    dispose() {
        super.dispose();
        this._modulationScale.dispose();
        return this;
    }
}
















class $e8d9115796c61b99$export$26bbc35c91a15e23 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($e8d9115796c61b99$export$26bbc35c91a15e23.getDefaults(), arguments, [
            "frequency",
            "type"
        ]));
        this.name = "BiquadFilter";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($e8d9115796c61b99$export$26bbc35c91a15e23.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        this._filter = this.context.createBiquadFilter();
        this.input = this.output = this._filter;
        this.Q = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            units: "number",
            value: options.Q,
            param: this._filter.Q
        });
        this.frequency = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            units: "frequency",
            value: options.frequency,
            param: this._filter.frequency
        });
        this.detune = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            units: "cents",
            value: options.detune,
            param: this._filter.detune
        });
        this.gain = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            units: "decibels",
            convert: false,
            value: options.gain,
            param: this._filter.gain
        });
        this.type = options.type;
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            Q: 1,
            type: "lowpass",
            frequency: 350,
            detune: 0,
            gain: 0
        });
    }
    /**
     * The type of this BiquadFilterNode. For a complete list of types and their attributes, see the
     * [Web Audio API](https://webaudio.github.io/web-audio-api/#dom-biquadfiltertype-lowpass)
     */ get type() {
        return this._filter.type;
    }
    set type(type) {
        const types = [
            "lowpass",
            "highpass",
            "bandpass",
            "lowshelf",
            "highshelf",
            "notch",
            "allpass",
            "peaking"
        ];
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(types.indexOf(type) !== -1, `Invalid filter type: ${type}`);
        this._filter.type = type;
    }
    /**
     * Get the frequency response curve. This curve represents how the filter
     * responses to frequencies between 20hz-20khz.
     * @param  len The number of values to return
     * @return The frequency response curve between 20-20kHz
     */ getFrequencyResponse(len = 128) {
        // start with all 1s
        const freqValues = new Float32Array(len);
        for(let i = 0; i < len; i++){
            const norm = Math.pow(i / len, 2);
            const freq = norm * 19980 + 20;
            freqValues[i] = freq;
        }
        const magValues = new Float32Array(len);
        const phaseValues = new Float32Array(len);
        // clone the filter to remove any connections which may be changing the value
        const filterClone = this.context.createBiquadFilter();
        filterClone.type = this.type;
        filterClone.Q.value = this.Q.value;
        filterClone.frequency.value = this.frequency.value;
        filterClone.gain.value = this.gain.value;
        filterClone.getFrequencyResponse(freqValues, magValues, phaseValues);
        return magValues;
    }
    dispose() {
        super.dispose();
        this._filter.disconnect();
        this.Q.dispose();
        this.frequency.dispose();
        this.gain.dispose();
        this.detune.dispose();
        return this;
    }
}


class $b43765906de8c71a$export$ec91da630f36d5ea extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($b43765906de8c71a$export$ec91da630f36d5ea.getDefaults(), arguments, [
            "frequency",
            "type",
            "rolloff"
        ]));
        this.name = "Filter";
        this.input = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this._filters = [];
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($b43765906de8c71a$export$ec91da630f36d5ea.getDefaults(), arguments, [
            "frequency",
            "type",
            "rolloff"
        ]);
        this._filters = [];
        this.Q = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "positive",
            value: options.Q
        });
        this.frequency = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        this.detune = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        this.gain = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "decibels",
            convert: false,
            value: options.gain
        });
        this._type = options.type;
        this.rolloff = options.rolloff;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "detune",
            "frequency",
            "gain",
            "Q"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            Q: 1,
            detune: 0,
            frequency: 350,
            gain: 0,
            rolloff: -12,
            type: "lowpass"
        });
    }
    /**
     * The type of the filter. Types: "lowpass", "highpass",
     * "bandpass", "lowshelf", "highshelf", "notch", "allpass", or "peaking".
     */ get type() {
        return this._type;
    }
    set type(type) {
        const types = [
            "lowpass",
            "highpass",
            "bandpass",
            "lowshelf",
            "highshelf",
            "notch",
            "allpass",
            "peaking"
        ];
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(types.indexOf(type) !== -1, `Invalid filter type: ${type}`);
        this._type = type;
        this._filters.forEach((filter)=>filter.type = type);
    }
    /**
     * The rolloff of the filter which is the drop in db
     * per octave. Implemented internally by cascading filters.
     * Only accepts the values -12, -24, -48 and -96.
     */ get rolloff() {
        return this._rolloff;
    }
    set rolloff(rolloff) {
        const rolloffNum = (0, $b63b9a75cba601b0$export$7e4aa119212bc614)(rolloff) ? rolloff : parseInt(rolloff, 10);
        const possibilities = [
            -12,
            -24,
            -48,
            -96
        ];
        let cascadingCount = possibilities.indexOf(rolloffNum);
        // check the rolloff is valid
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(cascadingCount !== -1, `rolloff can only be ${possibilities.join(", ")}`);
        cascadingCount += 1;
        this._rolloff = rolloffNum;
        this.input.disconnect();
        this._filters.forEach((filter)=>filter.disconnect());
        this._filters = new Array(cascadingCount);
        for(let count = 0; count < cascadingCount; count++){
            const filter = new (0, $e8d9115796c61b99$export$26bbc35c91a15e23)({
                context: this.context
            });
            filter.type = this._type;
            this.frequency.connect(filter.frequency);
            this.detune.connect(filter.detune);
            this.Q.connect(filter.Q);
            this.gain.connect(filter.gain);
            this._filters[count] = filter;
        }
        this._internalChannels = this._filters;
        (0, $5ffbb5654e49c399$export$933c3b67552fb559)(this.input, ...this._internalChannels, this.output);
    }
    /**
     * Get the frequency response curve. This curve represents how the filter
     * responses to frequencies between 20hz-20khz.
     * @param  len The number of values to return
     * @return The frequency response curve between 20-20kHz
     */ getFrequencyResponse(len = 128) {
        const filterClone = new (0, $e8d9115796c61b99$export$26bbc35c91a15e23)({
            frequency: this.frequency.value,
            gain: this.gain.value,
            Q: this.Q.value,
            type: this._type,
            detune: this.detune.value
        });
        // start with all 1s
        const totalResponse = new Float32Array(len).map(()=>1);
        this._filters.forEach(()=>{
            const response = filterClone.getFrequencyResponse(len);
            response.forEach((val, i)=>totalResponse[i] *= val);
        });
        filterClone.dispose();
        return totalResponse;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._filters.forEach((filter)=>{
            filter.dispose();
        });
        (0, $c0a1ee726091e30a$export$e6d3eada50a007b1)(this, [
            "detune",
            "frequency",
            "gain",
            "Q"
        ]);
        this.frequency.dispose();
        this.Q.dispose();
        this.detune.dispose();
        this.gain.dispose();
        return this;
    }
}












class $1cac2ecd773ce293$export$46ffd25e6533b005 extends (0, $567da4194e00c5c2$export$4e2d65a9843399df) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($1cac2ecd773ce293$export$46ffd25e6533b005.getDefaults(), arguments, [
            "attack",
            "decay",
            "sustain",
            "release"
        ]));
        this.name = "FrequencyEnvelope";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($1cac2ecd773ce293$export$46ffd25e6533b005.getDefaults(), arguments, [
            "attack",
            "decay",
            "sustain",
            "release"
        ]);
        this._octaves = options.octaves;
        this._baseFrequency = this.toFrequency(options.baseFrequency);
        this._exponent = this.input = new (0, $b4b6cbb075d013a6$export$ce28d653ec559ee)({
            context: this.context,
            value: options.exponent
        });
        this._scale = this.output = new (0, $768d8baaf984bb1a$export$d60cfc58d3c358b6)({
            context: this.context,
            min: this._baseFrequency,
            max: this._baseFrequency * Math.pow(2, this._octaves)
        });
        this._sig.chain(this._exponent, this._scale);
    }
    static getDefaults() {
        return Object.assign((0, $567da4194e00c5c2$export$4e2d65a9843399df).getDefaults(), {
            baseFrequency: 200,
            exponent: 1,
            octaves: 4
        });
    }
    /**
     * The envelope's minimum output value. This is the value which it
     * starts at.
     */ get baseFrequency() {
        return this._baseFrequency;
    }
    set baseFrequency(min) {
        const freq = this.toFrequency(min);
        (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(freq, 0);
        this._baseFrequency = freq;
        this._scale.min = this._baseFrequency;
        // update the max value when the min changes
        this.octaves = this._octaves;
    }
    /**
     * The number of octaves above the baseFrequency that the
     * envelope will scale to.
     */ get octaves() {
        return this._octaves;
    }
    set octaves(octaves) {
        this._octaves = octaves;
        this._scale.max = this._baseFrequency * Math.pow(2, octaves);
    }
    /**
     * The envelope's exponent value.
     */ get exponent() {
        return this._exponent.value;
    }
    set exponent(exponent) {
        this._exponent.value = exponent;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._exponent.dispose();
        this._scale.dispose();
        return this;
    }
}



class $7e49ea2e63f11aed$export$319ecdcd955e80a7 extends (0, $06eb6d10fd7b8c8a$export$f16a08bc2d920a12) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($7e49ea2e63f11aed$export$319ecdcd955e80a7.getDefaults(), arguments));
        this.name = "MonoSynth";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($7e49ea2e63f11aed$export$319ecdcd955e80a7.getDefaults(), arguments);
        this.oscillator = new (0, $579972729410c095$export$46c9f562e6d6ca6d)(Object.assign(options.oscillator, {
            context: this.context,
            detune: options.detune,
            onstop: ()=>this.onsilence(this)
        }));
        this.frequency = this.oscillator.frequency;
        this.detune = this.oscillator.detune;
        this.filter = new (0, $b43765906de8c71a$export$ec91da630f36d5ea)(Object.assign(options.filter, {
            context: this.context
        }));
        this.filterEnvelope = new (0, $1cac2ecd773ce293$export$46ffd25e6533b005)(Object.assign(options.filterEnvelope, {
            context: this.context
        }));
        this.envelope = new (0, $f7e83647bb4822ef$export$e04e0eedd8192587)(Object.assign(options.envelope, {
            context: this.context
        }));
        // connect the oscillators to the output
        this.oscillator.chain(this.filter, this.envelope, this.output);
        // connect the filter envelope
        this.filterEnvelope.connect(this.filter.frequency);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "oscillator",
            "frequency",
            "detune",
            "filter",
            "filterEnvelope",
            "envelope"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $06eb6d10fd7b8c8a$export$f16a08bc2d920a12).getDefaults(), {
            envelope: Object.assign((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $567da4194e00c5c2$export$4e2d65a9843399df).getDefaults(), Object.keys((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults())), {
                attack: 0.005,
                decay: 0.1,
                release: 1,
                sustain: 0.9
            }),
            filter: Object.assign((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $b43765906de8c71a$export$ec91da630f36d5ea).getDefaults(), Object.keys((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults())), {
                Q: 1,
                rolloff: -12,
                type: "lowpass"
            }),
            filterEnvelope: Object.assign((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $1cac2ecd773ce293$export$46ffd25e6533b005).getDefaults(), Object.keys((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults())), {
                attack: 0.6,
                baseFrequency: 200,
                decay: 0.2,
                exponent: 2,
                octaves: 3,
                release: 2,
                sustain: 0.5
            }),
            oscillator: Object.assign((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $579972729410c095$export$46c9f562e6d6ca6d).getDefaults(), Object.keys((0, $fc0255c9fa8d003e$export$1d2df86270c81ecb).getDefaults())), {
                type: "sawtooth"
            })
        });
    }
    /**
     * start the attack portion of the envelope
     * @param time the time the attack should start
     * @param velocity the velocity of the note (0-1)
     */ _triggerEnvelopeAttack(time, velocity = 1) {
        this.envelope.triggerAttack(time, velocity);
        this.filterEnvelope.triggerAttack(time);
        this.oscillator.start(time);
        if (this.envelope.sustain === 0) {
            const computedAttack = this.toSeconds(this.envelope.attack);
            const computedDecay = this.toSeconds(this.envelope.decay);
            this.oscillator.stop(time + computedAttack + computedDecay);
        }
    }
    /**
     * start the release portion of the envelope
     * @param time the time the release should start
     */ _triggerEnvelopeRelease(time) {
        this.envelope.triggerRelease(time);
        this.filterEnvelope.triggerRelease(time);
        this.oscillator.stop(time + this.toSeconds(this.envelope.release));
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.envelope.getValueAtTime(time);
    }
    dispose() {
        super.dispose();
        this.oscillator.dispose();
        this.envelope.dispose();
        this.filterEnvelope.dispose();
        this.filter.dispose();
        return this;
    }
}








class $94bd971ae5ae0119$export$374aff340bb3ea08 extends (0, $06eb6d10fd7b8c8a$export$f16a08bc2d920a12) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($94bd971ae5ae0119$export$374aff340bb3ea08.getDefaults(), arguments));
        this.name = "DuoSynth";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($94bd971ae5ae0119$export$374aff340bb3ea08.getDefaults(), arguments);
        this.voice0 = new (0, $7e49ea2e63f11aed$export$319ecdcd955e80a7)(Object.assign(options.voice0, {
            context: this.context,
            onsilence: ()=>this.onsilence(this)
        }));
        this.voice1 = new (0, $7e49ea2e63f11aed$export$319ecdcd955e80a7)(Object.assign(options.voice1, {
            context: this.context
        }));
        this.harmonicity = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            units: "positive",
            value: options.harmonicity
        });
        this._vibrato = new (0, $4a4529bace75b797$export$603054d5ec296d77)({
            frequency: options.vibratoRate,
            context: this.context,
            min: -50,
            max: 50
        });
        // start the vibrato immediately
        this._vibrato.start();
        this.vibratoRate = this._vibrato.frequency;
        this._vibratoGain = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            units: "normalRange",
            gain: options.vibratoAmount
        });
        this.vibratoAmount = this._vibratoGain.gain;
        this.frequency = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "frequency",
            value: 440
        });
        this.detune = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        // control the two voices frequency
        this.frequency.connect(this.voice0.frequency);
        this.frequency.chain(this.harmonicity, this.voice1.frequency);
        this._vibrato.connect(this._vibratoGain);
        this._vibratoGain.fan(this.voice0.detune, this.voice1.detune);
        this.detune.fan(this.voice0.detune, this.voice1.detune);
        this.voice0.connect(this.output);
        this.voice1.connect(this.output);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "voice0",
            "voice1",
            "frequency",
            "vibratoAmount",
            "vibratoRate"
        ]);
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.voice0.envelope.getValueAtTime(time) + this.voice1.envelope.getValueAtTime(time);
    }
    static getDefaults() {
        return (0, $1e273b197c429402$export$6969335ea1e4e77c)((0, $06eb6d10fd7b8c8a$export$f16a08bc2d920a12).getDefaults(), {
            vibratoAmount: 0.5,
            vibratoRate: 5,
            harmonicity: 1.5,
            voice0: (0, $1e273b197c429402$export$6969335ea1e4e77c)((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $7e49ea2e63f11aed$export$319ecdcd955e80a7).getDefaults(), Object.keys((0, $06eb6d10fd7b8c8a$export$f16a08bc2d920a12).getDefaults())), {
                filterEnvelope: {
                    attack: 0.01,
                    decay: 0.0,
                    sustain: 1,
                    release: 0.5
                },
                envelope: {
                    attack: 0.01,
                    decay: 0.0,
                    sustain: 1,
                    release: 0.5
                }
            }),
            voice1: (0, $1e273b197c429402$export$6969335ea1e4e77c)((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $7e49ea2e63f11aed$export$319ecdcd955e80a7).getDefaults(), Object.keys((0, $06eb6d10fd7b8c8a$export$f16a08bc2d920a12).getDefaults())), {
                filterEnvelope: {
                    attack: 0.01,
                    decay: 0.0,
                    sustain: 1,
                    release: 0.5
                },
                envelope: {
                    attack: 0.01,
                    decay: 0.0,
                    sustain: 1,
                    release: 0.5
                }
            })
        });
    }
    /**
     * Trigger the attack portion of the note
     */ _triggerEnvelopeAttack(time, velocity) {
        // @ts-ignore
        this.voice0._triggerEnvelopeAttack(time, velocity);
        // @ts-ignore
        this.voice1._triggerEnvelopeAttack(time, velocity);
    }
    /**
     * Trigger the release portion of the note
     */ _triggerEnvelopeRelease(time) {
        // @ts-ignore
        this.voice0._triggerEnvelopeRelease(time);
        // @ts-ignore
        this.voice1._triggerEnvelopeRelease(time);
        return this;
    }
    dispose() {
        super.dispose();
        this.voice0.dispose();
        this.voice1.dispose();
        this.frequency.dispose();
        this.detune.dispose();
        this._vibrato.dispose();
        this.vibratoRate.dispose();
        this._vibratoGain.dispose();
        this.harmonicity.dispose();
        return this;
    }
}





class $9aeb42e6cdc65ecc$export$45372df7fab1f04e extends (0, $8886d01f2e3ddb3f$export$aee9425caad4bd7e) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($9aeb42e6cdc65ecc$export$45372df7fab1f04e.getDefaults(), arguments));
        this.name = "FMSynth";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($9aeb42e6cdc65ecc$export$45372df7fab1f04e.getDefaults(), arguments);
        this.modulationIndex = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            value: options.modulationIndex
        });
        // control the two voices frequency
        this.frequency.connect(this._carrier.frequency);
        this.frequency.chain(this.harmonicity, this._modulator.frequency);
        this.frequency.chain(this.modulationIndex, this._modulationNode);
        this.detune.fan(this._carrier.detune, this._modulator.detune);
        this._modulator.connect(this._modulationNode.gain);
        this._modulationNode.connect(this._carrier.frequency);
        this._carrier.connect(this.output);
    }
    static getDefaults() {
        return Object.assign((0, $8886d01f2e3ddb3f$export$aee9425caad4bd7e).getDefaults(), {
            modulationIndex: 10
        });
    }
    dispose() {
        super.dispose();
        this.modulationIndex.dispose();
        return this;
    }
}













/**
 * Inharmonic ratio of frequencies based on the Roland TR-808
 * Taken from https://ccrma.stanford.edu/papers/tr-808-cymbal-physically-informed-circuit-bendable-digital-model
 */ const $38952779484412f8$var$inharmRatios = [
    1.0,
    1.483,
    1.932,
    2.546,
    2.630,
    3.897
];
class $38952779484412f8$export$65cb3eae8bee686d extends (0, $06eb6d10fd7b8c8a$export$f16a08bc2d920a12) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($38952779484412f8$export$65cb3eae8bee686d.getDefaults(), arguments));
        this.name = "MetalSynth";
        /**
         * The array of FMOscillators
         */ this._oscillators = [];
        /**
         * The frequency multipliers
         */ this._freqMultipliers = [];
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($38952779484412f8$export$65cb3eae8bee686d.getDefaults(), arguments);
        this.detune = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        this.frequency = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "frequency"
        });
        this._amplitude = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            gain: 0
        }).connect(this.output);
        this._highpass = new (0, $b43765906de8c71a$export$ec91da630f36d5ea)({
            // Q: -3.0102999566398125,
            Q: 0,
            context: this.context,
            type: "highpass"
        }).connect(this._amplitude);
        for(let i = 0; i < $38952779484412f8$var$inharmRatios.length; i++){
            const osc = new (0, $e0bc8dc1fcdfdb02$export$3055866937a7451d)({
                context: this.context,
                harmonicity: options.harmonicity,
                modulationIndex: options.modulationIndex,
                modulationType: "square",
                onstop: i === 0 ? ()=>this.onsilence(this) : (0, $c0a1ee726091e30a$export$b50b6e108474309b),
                type: "square"
            });
            osc.connect(this._highpass);
            this._oscillators[i] = osc;
            const mult = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
                context: this.context,
                value: $38952779484412f8$var$inharmRatios[i]
            });
            this._freqMultipliers[i] = mult;
            this.frequency.chain(mult, osc.frequency);
            this.detune.connect(osc.detune);
        }
        this._filterFreqScaler = new (0, $768d8baaf984bb1a$export$d60cfc58d3c358b6)({
            context: this.context,
            max: 7000,
            min: this.toFrequency(options.resonance)
        });
        this.envelope = new (0, $567da4194e00c5c2$export$4e2d65a9843399df)({
            attack: options.envelope.attack,
            attackCurve: "linear",
            context: this.context,
            decay: options.envelope.decay,
            release: options.envelope.release,
            sustain: 0
        });
        this.envelope.chain(this._filterFreqScaler, this._highpass.frequency);
        this.envelope.connect(this._amplitude.gain);
        // set the octaves
        this._octaves = options.octaves;
        this.octaves = options.octaves;
    }
    static getDefaults() {
        return (0, $1e273b197c429402$export$6969335ea1e4e77c)((0, $06eb6d10fd7b8c8a$export$f16a08bc2d920a12).getDefaults(), {
            envelope: Object.assign((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $567da4194e00c5c2$export$4e2d65a9843399df).getDefaults(), Object.keys((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults())), {
                attack: 0.001,
                decay: 1.4,
                release: 0.2
            }),
            harmonicity: 5.1,
            modulationIndex: 32,
            octaves: 1.5,
            resonance: 4000
        });
    }
    /**
     * Trigger the attack.
     * @param time When the attack should be triggered.
     * @param velocity The velocity that the envelope should be triggered at.
     */ _triggerEnvelopeAttack(time, velocity = 1) {
        this.envelope.triggerAttack(time, velocity);
        this._oscillators.forEach((osc)=>osc.start(time));
        if (this.envelope.sustain === 0) this._oscillators.forEach((osc)=>{
            osc.stop(time + this.toSeconds(this.envelope.attack) + this.toSeconds(this.envelope.decay));
        });
        return this;
    }
    /**
     * Trigger the release of the envelope.
     * @param time When the release should be triggered.
     */ _triggerEnvelopeRelease(time) {
        this.envelope.triggerRelease(time);
        this._oscillators.forEach((osc)=>osc.stop(time + this.toSeconds(this.envelope.release)));
        return this;
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.envelope.getValueAtTime(time);
    }
    /**
     * The modulationIndex of the oscillators which make up the source.
     * see [[FMOscillator.modulationIndex]]
     * @min 1
     * @max 100
     */ get modulationIndex() {
        return this._oscillators[0].modulationIndex.value;
    }
    set modulationIndex(val) {
        this._oscillators.forEach((osc)=>osc.modulationIndex.value = val);
    }
    /**
     * The harmonicity of the oscillators which make up the source.
     * see Tone.FMOscillator.harmonicity
     * @min 0.1
     * @max 10
     */ get harmonicity() {
        return this._oscillators[0].harmonicity.value;
    }
    set harmonicity(val) {
        this._oscillators.forEach((osc)=>osc.harmonicity.value = val);
    }
    /**
     * The lower level of the highpass filter which is attached to the envelope.
     * This value should be between [0, 7000]
     * @min 0
     * @max 7000
     */ get resonance() {
        return this._filterFreqScaler.min;
    }
    set resonance(val) {
        this._filterFreqScaler.min = this.toFrequency(val);
        this.octaves = this._octaves;
    }
    /**
     * The number of octaves above the "resonance" frequency
     * that the filter ramps during the attack/decay envelope
     * @min 0
     * @max 8
     */ get octaves() {
        return this._octaves;
    }
    set octaves(val) {
        this._octaves = val;
        this._filterFreqScaler.max = this._filterFreqScaler.min * Math.pow(2, val);
    }
    dispose() {
        super.dispose();
        this._oscillators.forEach((osc)=>osc.dispose());
        this._freqMultipliers.forEach((freqMult)=>freqMult.dispose());
        this.frequency.dispose();
        this.detune.dispose();
        this._filterFreqScaler.dispose();
        this._amplitude.dispose();
        this.envelope.dispose();
        this._highpass.dispose();
        return this;
    }
}









class $de2523d2c1cde5d2$export$e4f4b32b2e74f0e2 extends (0, $a020c0c7c8b456d8$export$8ef26ca8e8d9bf70) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($de2523d2c1cde5d2$export$e4f4b32b2e74f0e2.getDefaults(), arguments));
        this.name = "MembraneSynth";
        /**
         * Portamento is ignored in this synth. use pitch decay instead.
         */ this.portamento = 0;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($de2523d2c1cde5d2$export$e4f4b32b2e74f0e2.getDefaults(), arguments);
        this.pitchDecay = options.pitchDecay;
        this.octaves = options.octaves;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "oscillator",
            "envelope"
        ]);
    }
    static getDefaults() {
        return (0, $1e273b197c429402$export$6969335ea1e4e77c)((0, $06eb6d10fd7b8c8a$export$f16a08bc2d920a12).getDefaults(), (0, $a020c0c7c8b456d8$export$8ef26ca8e8d9bf70).getDefaults(), {
            envelope: {
                attack: 0.001,
                attackCurve: "exponential",
                decay: 0.4,
                release: 1.4,
                sustain: 0.01
            },
            octaves: 10,
            oscillator: {
                type: "sine"
            },
            pitchDecay: 0.05
        });
    }
    setNote(note, time) {
        const seconds = this.toSeconds(time);
        const hertz = this.toFrequency(note instanceof (0, $5b410fbffb0274be$export$38b56155c8552868) ? note.toFrequency() : note);
        const maxNote = hertz * this.octaves;
        this.oscillator.frequency.setValueAtTime(maxNote, seconds);
        this.oscillator.frequency.exponentialRampToValueAtTime(hertz, seconds + this.toSeconds(this.pitchDecay));
        return this;
    }
    dispose() {
        super.dispose();
        return this;
    }
}
(0, $a522a8f63c306c1c$export$29e00dfd3077644b)([
    (0, $cfc784831c74bf36$export$d02631cccf789723)(0)
], $de2523d2c1cde5d2$export$e4f4b32b2e74f0e2.prototype, "octaves", void 0);
(0, $a522a8f63c306c1c$export$29e00dfd3077644b)([
    (0, $cfc784831c74bf36$export$4748a2e3a6d34ca5)(0)
], $de2523d2c1cde5d2$export$e4f4b32b2e74f0e2.prototype, "pitchDecay", void 0);










class $44800a49db8956b6$export$a0d6f4d32fd5959 extends (0, $5e47eb9e1349f4fa$export$25ef33f358b07cf4) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($44800a49db8956b6$export$a0d6f4d32fd5959.getDefaults(), arguments));
        this.name = "NoiseSynth";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($44800a49db8956b6$export$a0d6f4d32fd5959.getDefaults(), arguments);
        this.noise = new (0, $76955c76dcac2d3e$export$484d33a0500a4ce1)(Object.assign({
            context: this.context
        }, options.noise));
        this.envelope = new (0, $f7e83647bb4822ef$export$e04e0eedd8192587)(Object.assign({
            context: this.context
        }, options.envelope));
        // connect the noise to the output
        this.noise.chain(this.envelope, this.output);
    }
    static getDefaults() {
        return Object.assign((0, $5e47eb9e1349f4fa$export$25ef33f358b07cf4).getDefaults(), {
            envelope: Object.assign((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $567da4194e00c5c2$export$4e2d65a9843399df).getDefaults(), Object.keys((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults())), {
                decay: 0.1,
                sustain: 0.0
            }),
            noise: Object.assign((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $76955c76dcac2d3e$export$484d33a0500a4ce1).getDefaults(), Object.keys((0, $fc0255c9fa8d003e$export$1d2df86270c81ecb).getDefaults())), {
                type: "white"
            })
        });
    }
    /**
     * Start the attack portion of the envelopes. Unlike other
     * instruments, Tone.NoiseSynth doesn't have a note.
     * @example
     * const noiseSynth = new Tone.NoiseSynth().toDestination();
     * noiseSynth.triggerAttack();
     */ triggerAttack(time, velocity = 1) {
        time = this.toSeconds(time);
        // the envelopes
        this.envelope.triggerAttack(time, velocity);
        // start the noise
        this.noise.start(time);
        if (this.envelope.sustain === 0) this.noise.stop(time + this.toSeconds(this.envelope.attack) + this.toSeconds(this.envelope.decay));
        return this;
    }
    /**
     * Start the release portion of the envelopes.
     */ triggerRelease(time) {
        time = this.toSeconds(time);
        this.envelope.triggerRelease(time);
        this.noise.stop(time + this.toSeconds(this.envelope.release));
        return this;
    }
    sync() {
        if (this._syncState()) {
            this._syncMethod("triggerAttack", 0);
            this._syncMethod("triggerRelease", 0);
        }
        return this;
    }
    triggerAttackRelease(duration, time, velocity = 1) {
        time = this.toSeconds(time);
        duration = this.toSeconds(duration);
        this.triggerAttack(time, velocity);
        this.triggerRelease(time + duration);
        return this;
    }
    dispose() {
        super.dispose();
        this.noise.dispose();
        this.envelope.dispose();
        return this;
    }
}











/**
 * All of the classes or functions which are loaded into the AudioWorkletGlobalScope
 */ const $5bc17f183cac76e3$var$workletContext = new Set();
function $5bc17f183cac76e3$export$4332289150d1c155(classOrFunction) {
    $5bc17f183cac76e3$var$workletContext.add(classOrFunction);
}
function $5bc17f183cac76e3$export$d575e6557ac1729f(name, classDesc) {
    const processor = /* javascript */ `registerProcessor("${name}", ${classDesc})`;
    $5bc17f183cac76e3$var$workletContext.add(processor);
}
function $5bc17f183cac76e3$export$b2ba7b9987bb8e81() {
    return Array.from($5bc17f183cac76e3$var$workletContext).join("\n");
}


class $0ce02f7f068b2658$export$212d912bd0512eff extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(options){
        super(options);
        this.name = "ToneAudioWorklet";
        /**
         * The constructor options for the node
         */ this.workletOptions = {};
        /**
         * Callback which is invoked when there is an error in the processing
         */ this.onprocessorerror = (0, $c0a1ee726091e30a$export$b50b6e108474309b);
        const blobUrl = URL.createObjectURL(new Blob([
            (0, $5bc17f183cac76e3$export$b2ba7b9987bb8e81)()
        ], {
            type: "text/javascript"
        }));
        const name = this._audioWorkletName();
        this._dummyGain = this.context.createGain();
        this._dummyParam = this._dummyGain.gain;
        // Register the processor
        this.context.addAudioWorkletModule(blobUrl, name).then(()=>{
            // create the worklet when it's read
            if (!this.disposed) {
                this._worklet = this.context.createAudioWorkletNode(name, this.workletOptions);
                this._worklet.onprocessorerror = this.onprocessorerror.bind(this);
                this.onReady(this._worklet);
            }
        });
    }
    dispose() {
        super.dispose();
        this._dummyGain.disconnect();
        if (this._worklet) {
            this._worklet.port.postMessage("dispose");
            this._worklet.disconnect();
        }
        return this;
    }
}



const $0ca5cee5dfb1db26$var$toneAudioWorkletProcessor = /* javascript */ `
	/**
	 * The base AudioWorkletProcessor for use in Tone.js. Works with the [[ToneAudioWorklet]]. 
	 */
	class ToneAudioWorkletProcessor extends AudioWorkletProcessor {

		constructor(options) {
			
			super(options);
			/**
			 * If the processor was disposed or not. Keep alive until it's disposed.
			 */
			this.disposed = false;
		   	/** 
			 * The number of samples in the processing block
			 */
			this.blockSize = 128;
			/**
			 * the sample rate
			 */
			this.sampleRate = sampleRate;

			this.port.onmessage = (event) => {
				// when it receives a dispose 
				if (event.data === "dispose") {
					this.disposed = true;
				}
			};
		}
	}
`;
(0, $5bc17f183cac76e3$export$4332289150d1c155)($0ca5cee5dfb1db26$var$toneAudioWorkletProcessor);



const $b3cb7ede76f1a8a7$export$3821b1427992e4a0 = /* javascript */ `
	/**
	 * Abstract class for a single input/output processor. 
	 * has a 'generate' function which processes one sample at a time
	 */
	class SingleIOProcessor extends ToneAudioWorkletProcessor {

		constructor(options) {
			super(Object.assign(options, {
				numberOfInputs: 1,
				numberOfOutputs: 1
			}));
			/**
			 * Holds the name of the parameter and a single value of that
			 * parameter at the current sample
			 * @type { [name: string]: number }
			 */
			this.params = {}
		}

		/**
		 * Generate an output sample from the input sample and parameters
		 * @abstract
		 * @param input number
		 * @param channel number
		 * @param parameters { [name: string]: number }
		 * @returns number
		 */
		generate(){}

		/**
		 * Update the private params object with the 
		 * values of the parameters at the given index
		 * @param parameters { [name: string]: Float32Array },
		 * @param index number
		 */
		updateParams(parameters, index) {
			for (const paramName in parameters) {
				const param = parameters[paramName];
				if (param.length > 1) {
					this.params[paramName] = parameters[paramName][index];
				} else {
					this.params[paramName] = parameters[paramName][0];
				}
			}
		}

		/**
		 * Process a single frame of the audio
		 * @param inputs Float32Array[][]
		 * @param outputs Float32Array[][]
		 */
		process(inputs, outputs, parameters) {
			const input = inputs[0];
			const output = outputs[0];
			// get the parameter values
			const channelCount = Math.max(input && input.length || 0, output.length);
			for (let sample = 0; sample < this.blockSize; sample++) {
				this.updateParams(parameters, sample);
				for (let channel = 0; channel < channelCount; channel++) {
					const inputSample = input && input.length ? input[channel][sample] : 0;
					output[channel][sample] = this.generate(inputSample, channel, this.params);
				}
			}
			return !this.disposed;
		}
	};
`;
(0, $5bc17f183cac76e3$export$4332289150d1c155)($b3cb7ede76f1a8a7$export$3821b1427992e4a0);



const $001794ff38d0d9f5$var$delayLine = /* javascript */ `
	/**
	 * A multichannel buffer for use within an AudioWorkletProcessor as a delay line
	 */
	class DelayLine {
		
		constructor(size, channels) {
			this.buffer = [];
			this.writeHead = []
			this.size = size;

			// create the empty channels
			for (let i = 0; i < channels; i++) {
				this.buffer[i] = new Float32Array(this.size);
				this.writeHead[i] = 0;
			}
		}

		/**
		 * Push a value onto the end
		 * @param channel number
		 * @param value number
		 */
		push(channel, value) {
			this.writeHead[channel] += 1;
			if (this.writeHead[channel] > this.size) {
				this.writeHead[channel] = 0;
			}
			this.buffer[channel][this.writeHead[channel]] = value;
		}

		/**
		 * Get the recorded value of the channel given the delay
		 * @param channel number
		 * @param delay number delay samples
		 */
		get(channel, delay) {
			let readHead = this.writeHead[channel] - Math.floor(delay);
			if (readHead < 0) {
				readHead += this.size;
			}
			return this.buffer[channel][readHead];
		}
	}
`;
(0, $5bc17f183cac76e3$export$4332289150d1c155)($001794ff38d0d9f5$var$delayLine);



const $ea0b652a780fd476$export$85343ada6050a795 = "feedback-comb-filter";
const $ea0b652a780fd476$var$feedbackCombFilter = /* javascript */ `
	class FeedbackCombFilterWorklet extends SingleIOProcessor {

		constructor(options) {
			super(options);
			this.delayLine = new DelayLine(this.sampleRate, options.channelCount || 2);
		}

		static get parameterDescriptors() {
			return [{
				name: "delayTime",
				defaultValue: 0.1,
				minValue: 0,
				maxValue: 1,
				automationRate: "k-rate"
			}, {
				name: "feedback",
				defaultValue: 0.5,
				minValue: 0,
				maxValue: 0.9999,
				automationRate: "k-rate"
			}];
		}

		generate(input, channel, parameters) {
			const delayedSample = this.delayLine.get(channel, parameters.delayTime * this.sampleRate);
			this.delayLine.push(channel, input + delayedSample * parameters.feedback);
			return delayedSample;
		}
	}
`;
(0, $5bc17f183cac76e3$export$d575e6557ac1729f)($ea0b652a780fd476$export$85343ada6050a795, $ea0b652a780fd476$var$feedbackCombFilter);


class $74e53ba3038a6a01$export$e7a685a7e8ffb78a extends (0, $0ce02f7f068b2658$export$212d912bd0512eff) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($74e53ba3038a6a01$export$e7a685a7e8ffb78a.getDefaults(), arguments, [
            "delayTime",
            "resonance"
        ]));
        this.name = "FeedbackCombFilter";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($74e53ba3038a6a01$export$e7a685a7e8ffb78a.getDefaults(), arguments, [
            "delayTime",
            "resonance"
        ]);
        this.input = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this.delayTime = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            value: options.delayTime,
            units: "time",
            minValue: 0,
            maxValue: 1,
            param: this._dummyParam,
            swappable: true
        });
        this.resonance = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            value: options.resonance,
            units: "normalRange",
            param: this._dummyParam,
            swappable: true
        });
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "resonance",
            "delayTime"
        ]);
    }
    _audioWorkletName() {
        return 0, $ea0b652a780fd476$export$85343ada6050a795;
    }
    /**
     * The default parameters
     */ static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            delayTime: 0.1,
            resonance: 0.5
        });
    }
    onReady(node) {
        (0, $5ffbb5654e49c399$export$933c3b67552fb559)(this.input, node, this.output);
        const delayTime = node.parameters.get("delayTime");
        this.delayTime.setParam(delayTime);
        const feedback = node.parameters.get("feedback");
        this.resonance.setParam(feedback);
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this.output.dispose();
        this.delayTime.dispose();
        this.resonance.dispose();
        return this;
    }
}





class $25eda6a987a6f37d$export$7961b18021b7c8c9 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($25eda6a987a6f37d$export$7961b18021b7c8c9.getDefaults(), arguments, [
            "frequency",
            "type"
        ]));
        this.name = "OnePoleFilter";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($25eda6a987a6f37d$export$7961b18021b7c8c9.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        this._frequency = options.frequency;
        this._type = options.type;
        this.input = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this._createFilter();
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            frequency: 880,
            type: "lowpass"
        });
    }
    /**
     * Create a filter and dispose the old one
     */ _createFilter() {
        const oldFilter = this._filter;
        const freq = this.toFrequency(this._frequency);
        const t = 1 / (2 * Math.PI * freq);
        if (this._type === "lowpass") {
            const a0 = 1 / (t * this.context.sampleRate);
            const b1 = a0 - 1;
            this._filter = this.context.createIIRFilter([
                a0,
                0
            ], [
                1,
                b1
            ]);
        } else {
            const b1 = 1 / (t * this.context.sampleRate) - 1;
            this._filter = this.context.createIIRFilter([
                1,
                -1
            ], [
                1,
                b1
            ]);
        }
        this.input.chain(this._filter, this.output);
        if (oldFilter) // dispose it on the next block
        this.context.setTimeout(()=>{
            if (!this.disposed) {
                this.input.disconnect(oldFilter);
                oldFilter.disconnect();
            }
        }, this.blockTime);
    }
    /**
     * The frequency value.
     */ get frequency() {
        return this._frequency;
    }
    set frequency(fq) {
        this._frequency = fq;
        this._createFilter();
    }
    /**
     * The OnePole Filter type, either "highpass" or "lowpass"
     */ get type() {
        return this._type;
    }
    set type(t) {
        this._type = t;
        this._createFilter();
    }
    /**
     * Get the frequency response curve. This curve represents how the filter
     * responses to frequencies between 20hz-20khz.
     * @param  len The number of values to return
     * @return The frequency response curve between 20-20kHz
     */ getFrequencyResponse(len = 128) {
        const freqValues = new Float32Array(len);
        for(let i = 0; i < len; i++){
            const norm = Math.pow(i / len, 2);
            const freq = norm * 19980 + 20;
            freqValues[i] = freq;
        }
        const magValues = new Float32Array(len);
        const phaseValues = new Float32Array(len);
        this._filter.getFrequencyResponse(freqValues, magValues, phaseValues);
        return magValues;
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this.output.dispose();
        this._filter.disconnect();
        return this;
    }
}


class $d5cfc15065c61b81$export$e83d2527589f5587 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($d5cfc15065c61b81$export$e83d2527589f5587.getDefaults(), arguments, [
            "delayTime",
            "resonance",
            "dampening"
        ]));
        this.name = "LowpassCombFilter";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($d5cfc15065c61b81$export$e83d2527589f5587.getDefaults(), arguments, [
            "delayTime",
            "resonance",
            "dampening"
        ]);
        this._combFilter = this.output = new (0, $74e53ba3038a6a01$export$e7a685a7e8ffb78a)({
            context: this.context,
            delayTime: options.delayTime,
            resonance: options.resonance
        });
        this.delayTime = this._combFilter.delayTime;
        this.resonance = this._combFilter.resonance;
        this._lowpass = this.input = new (0, $25eda6a987a6f37d$export$7961b18021b7c8c9)({
            context: this.context,
            frequency: options.dampening,
            type: "lowpass"
        });
        // connections
        this._lowpass.connect(this._combFilter);
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            dampening: 3000,
            delayTime: 0.1,
            resonance: 0.5
        });
    }
    /**
     * The dampening control of the feedback
     */ get dampening() {
        return this._lowpass.frequency;
    }
    set dampening(fq) {
        this._lowpass.frequency = fq;
    }
    dispose() {
        super.dispose();
        this._combFilter.dispose();
        this._lowpass.dispose();
        return this;
    }
}






class $375b8bffa7ecc8c3$export$8334f51ae3f4c97e extends (0, $5e47eb9e1349f4fa$export$25ef33f358b07cf4) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($375b8bffa7ecc8c3$export$8334f51ae3f4c97e.getDefaults(), arguments));
        this.name = "PluckSynth";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($375b8bffa7ecc8c3$export$8334f51ae3f4c97e.getDefaults(), arguments);
        this._noise = new (0, $76955c76dcac2d3e$export$484d33a0500a4ce1)({
            context: this.context,
            type: "pink"
        });
        this.attackNoise = options.attackNoise;
        this._lfcf = new (0, $d5cfc15065c61b81$export$e83d2527589f5587)({
            context: this.context,
            dampening: options.dampening,
            resonance: options.resonance
        });
        this.resonance = options.resonance;
        this.release = options.release;
        this._noise.connect(this._lfcf);
        this._lfcf.connect(this.output);
    }
    static getDefaults() {
        return (0, $1e273b197c429402$export$6969335ea1e4e77c)((0, $5e47eb9e1349f4fa$export$25ef33f358b07cf4).getDefaults(), {
            attackNoise: 1,
            dampening: 4000,
            resonance: 0.7,
            release: 1
        });
    }
    /**
     * The dampening control. i.e. the lowpass filter frequency of the comb filter
     * @min 0
     * @max 7000
     */ get dampening() {
        return this._lfcf.dampening;
    }
    set dampening(fq) {
        this._lfcf.dampening = fq;
    }
    triggerAttack(note, time) {
        const freq = this.toFrequency(note);
        time = this.toSeconds(time);
        const delayAmount = 1 / freq;
        this._lfcf.delayTime.setValueAtTime(delayAmount, time);
        this._noise.start(time);
        this._noise.stop(time + delayAmount * this.attackNoise);
        this._lfcf.resonance.cancelScheduledValues(time);
        this._lfcf.resonance.setValueAtTime(this.resonance, time);
        return this;
    }
    /**
     * Ramp down the [[resonance]] to 0 over the duration of the release time.
     */ triggerRelease(time) {
        this._lfcf.resonance.linearRampTo(0, this.release, time);
        return this;
    }
    dispose() {
        super.dispose();
        this._noise.dispose();
        this._lfcf.dispose();
        return this;
    }
}








class $5a4fe9f908d087df$export$a7e98a317490a78b extends (0, $5e47eb9e1349f4fa$export$25ef33f358b07cf4) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($5a4fe9f908d087df$export$a7e98a317490a78b.getDefaults(), arguments, [
            "voice",
            "options"
        ]));
        this.name = "PolySynth";
        /**
         * The voices which are not currently in use
         */ this._availableVoices = [];
        /**
         * The currently active voices
         */ this._activeVoices = [];
        /**
         * All of the allocated voices for this synth.
         */ this._voices = [];
        /**
         * The GC timeout. Held so that it could be cancelled when the node is disposed.
         */ this._gcTimeout = -1;
        /**
         * A moving average of the number of active voices
         */ this._averageActiveVoices = 0;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($5a4fe9f908d087df$export$a7e98a317490a78b.getDefaults(), arguments, [
            "voice",
            "options"
        ]);
        // check against the old API (pre 14.3.0)
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(!(0, $b63b9a75cba601b0$export$7e4aa119212bc614)(options.voice), "DEPRECATED: The polyphony count is no longer the first argument.");
        const defaults = options.voice.getDefaults();
        this.options = Object.assign(defaults, options.options);
        this.voice = options.voice;
        this.maxPolyphony = options.maxPolyphony;
        // create the first voice
        this._dummyVoice = this._getNextAvailableVoice();
        // remove it from the voices list
        const index = this._voices.indexOf(this._dummyVoice);
        this._voices.splice(index, 1);
        // kick off the GC interval
        this._gcTimeout = this.context.setInterval(this._collectGarbage.bind(this), 1);
    }
    static getDefaults() {
        return Object.assign((0, $5e47eb9e1349f4fa$export$25ef33f358b07cf4).getDefaults(), {
            maxPolyphony: 32,
            options: {},
            voice: (0, $a020c0c7c8b456d8$export$8ef26ca8e8d9bf70)
        });
    }
    /**
     * The number of active voices.
     */ get activeVoices() {
        return this._activeVoices.length;
    }
    /**
     * Invoked when the source is done making sound, so that it can be
     * readded to the pool of available voices
     */ _makeVoiceAvailable(voice) {
        this._availableVoices.push(voice);
        // remove the midi note from 'active voices'
        const activeVoiceIndex = this._activeVoices.findIndex((e)=>e.voice === voice);
        this._activeVoices.splice(activeVoiceIndex, 1);
    }
    /**
     * Get an available voice from the pool of available voices.
     * If one is not available and the maxPolyphony limit is reached,
     * steal a voice, otherwise return null.
     */ _getNextAvailableVoice() {
        // if there are available voices, return the first one
        if (this._availableVoices.length) return this._availableVoices.shift();
        else if (this._voices.length < this.maxPolyphony) {
            // otherwise if there is still more maxPolyphony, make a new voice
            const voice = new this.voice(Object.assign(this.options, {
                context: this.context,
                onsilence: this._makeVoiceAvailable.bind(this)
            }));
            voice.connect(this.output);
            this._voices.push(voice);
            return voice;
        } else (0, $23cf54af36cc9441$export$c106dd0671a0fc2d)("Max polyphony exceeded. Note dropped.");
    }
    /**
     * Occasionally check if there are any allocated voices which can be cleaned up.
     */ _collectGarbage() {
        this._averageActiveVoices = Math.max(this._averageActiveVoices * 0.95, this.activeVoices);
        if (this._availableVoices.length && this._voices.length > Math.ceil(this._averageActiveVoices + 1)) {
            // take off an available note
            const firstAvail = this._availableVoices.shift();
            const index = this._voices.indexOf(firstAvail);
            this._voices.splice(index, 1);
            if (!this.context.isOffline) firstAvail.dispose();
        }
    }
    /**
     * Internal method which triggers the attack
     */ _triggerAttack(notes, time, velocity) {
        notes.forEach((note)=>{
            const midiNote = new (0, $28d90c8ab77bc1a1$export$266cef4b055bf7de)(this.context, note).toMidi();
            const voice = this._getNextAvailableVoice();
            if (voice) {
                voice.triggerAttack(note, time, velocity);
                this._activeVoices.push({
                    midi: midiNote,
                    voice: voice,
                    released: false
                });
                this.log("triggerAttack", note, time);
            }
        });
    }
    /**
     * Internal method which triggers the release
     */ _triggerRelease(notes, time) {
        notes.forEach((note)=>{
            const midiNote = new (0, $28d90c8ab77bc1a1$export$266cef4b055bf7de)(this.context, note).toMidi();
            const event = this._activeVoices.find(({ midi: midi , released: released  })=>midi === midiNote && !released);
            if (event) {
                // trigger release on that note
                event.voice.triggerRelease(time);
                // mark it as released
                event.released = true;
                this.log("triggerRelease", note, time);
            }
        });
    }
    /**
     * Schedule the attack/release events. If the time is in the future, then it should set a timeout
     * to wait for just-in-time scheduling
     */ _scheduleEvent(type, notes, time, velocity) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(!this.disposed, "Synth was already disposed");
        // if the notes are greater than this amount of time in the future, they should be scheduled with setTimeout
        if (time <= this.now()) {
            // do it immediately
            if (type === "attack") this._triggerAttack(notes, time, velocity);
            else this._triggerRelease(notes, time);
        } else // schedule it to start in the future
        this.context.setTimeout(()=>{
            this._scheduleEvent(type, notes, time, velocity);
        }, time - this.now());
    }
    /**
     * Trigger the attack portion of the note
     * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.
     * @param  time  The start time of the note.
     * @param velocity The velocity of the note.
     * @example
     * const synth = new Tone.PolySynth(Tone.FMSynth).toDestination();
     * // trigger a chord immediately with a velocity of 0.2
     * synth.triggerAttack(["Ab3", "C4", "F5"], Tone.now(), 0.2);
     */ triggerAttack(notes, time, velocity) {
        if (!Array.isArray(notes)) notes = [
            notes
        ];
        const computedTime = this.toSeconds(time);
        this._scheduleEvent("attack", notes, computedTime, velocity);
        return this;
    }
    /**
     * Trigger the release of the note. Unlike monophonic instruments,
     * a note (or array of notes) needs to be passed in as the first argument.
     * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.
     * @param  time  When the release will be triggered.
     * @example
     * @example
     * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();
     * poly.triggerAttack(["Ab3", "C4", "F5"]);
     * // trigger the release of the given notes.
     * poly.triggerRelease(["Ab3", "C4"], "+1");
     * poly.triggerRelease("F5", "+3");
     */ triggerRelease(notes, time) {
        if (!Array.isArray(notes)) notes = [
            notes
        ];
        const computedTime = this.toSeconds(time);
        this._scheduleEvent("release", notes, computedTime);
        return this;
    }
    /**
     * Trigger the attack and release after the specified duration
     * @param  notes The notes to play. Accepts a single  Frequency or an array of frequencies.
     * @param  duration the duration of the note
     * @param  time  if no time is given, defaults to now
     * @param  velocity the velocity of the attack (0-1)
     * @example
     * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();
     * // can pass in an array of durations as well
     * poly.triggerAttackRelease(["Eb3", "G4", "Bb4", "D5"], [4, 3, 2, 1]);
     */ triggerAttackRelease(notes, duration, time, velocity) {
        const computedTime = this.toSeconds(time);
        this.triggerAttack(notes, computedTime, velocity);
        if ((0, $b63b9a75cba601b0$export$43bee75e5e14138e)(duration)) {
            (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $b63b9a75cba601b0$export$43bee75e5e14138e)(notes), "If the duration is an array, the notes must also be an array");
            notes;
            for(let i = 0; i < notes.length; i++){
                const d = duration[Math.min(i, duration.length - 1)];
                const durationSeconds = this.toSeconds(d);
                (0, $23cf54af36cc9441$export$a7a9523472993e97)(durationSeconds > 0, "The duration must be greater than 0");
                this.triggerRelease(notes[i], computedTime + durationSeconds);
            }
        } else {
            const durationSeconds = this.toSeconds(duration);
            (0, $23cf54af36cc9441$export$a7a9523472993e97)(durationSeconds > 0, "The duration must be greater than 0");
            this.triggerRelease(notes, computedTime + durationSeconds);
        }
        return this;
    }
    sync() {
        if (this._syncState()) {
            this._syncMethod("triggerAttack", 1);
            this._syncMethod("triggerRelease", 1);
        }
        return this;
    }
    /**
     * Set a member/attribute of the voices
     * @example
     * const poly = new Tone.PolySynth().toDestination();
     * // set all of the voices using an options object for the synth type
     * poly.set({
     * 	envelope: {
     * 		attack: 0.25
     * 	}
     * });
     * poly.triggerAttackRelease("Bb3", 0.2);
     */ set(options) {
        // remove options which are controlled by the PolySynth
        const sanitizedOptions = (0, $1e273b197c429402$export$e35a36a1f3b5e86b)(options, [
            "onsilence",
            "context"
        ]);
        // store all of the options
        this.options = (0, $1e273b197c429402$export$6969335ea1e4e77c)(this.options, sanitizedOptions);
        this._voices.forEach((voice)=>voice.set(sanitizedOptions));
        this._dummyVoice.set(sanitizedOptions);
        return this;
    }
    get() {
        return this._dummyVoice.get();
    }
    /**
     * Trigger the release portion of all the currently active voices immediately.
     * Useful for silencing the synth.
     */ releaseAll(time) {
        const computedTime = this.toSeconds(time);
        this._activeVoices.forEach(({ voice: voice  })=>{
            voice.triggerRelease(computedTime);
        });
        return this;
    }
    dispose() {
        super.dispose();
        this._dummyVoice.dispose();
        this._voices.forEach((v)=>v.dispose());
        this._activeVoices = [];
        this._availableVoices = [];
        this.context.clearInterval(this._gcTimeout);
        return this;
    }
}













class $3932bd81fc49731d$export$322f102bec719b22 extends (0, $5e47eb9e1349f4fa$export$25ef33f358b07cf4) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($3932bd81fc49731d$export$322f102bec719b22.getDefaults(), arguments, [
            "urls",
            "onload",
            "baseUrl"
        ], "urls"));
        this.name = "Sampler";
        /**
         * The object of all currently playing BufferSources
         */ this._activeSources = new Map();
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($3932bd81fc49731d$export$322f102bec719b22.getDefaults(), arguments, [
            "urls",
            "onload",
            "baseUrl"
        ], "urls");
        const urlMap = {};
        Object.keys(options.urls).forEach((note)=>{
            const noteNumber = parseInt(note, 10);
            (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $b63b9a75cba601b0$export$4dcca4501f2037f9)(note) || (0, $b63b9a75cba601b0$export$7e4aa119212bc614)(noteNumber) && isFinite(noteNumber), `url key is neither a note or midi pitch: ${note}`);
            if ((0, $b63b9a75cba601b0$export$4dcca4501f2037f9)(note)) {
                // convert the note name to MIDI
                const mid = new (0, $5b410fbffb0274be$export$38b56155c8552868)(this.context, note).toMidi();
                urlMap[mid] = options.urls[note];
            } else if ((0, $b63b9a75cba601b0$export$7e4aa119212bc614)(noteNumber) && isFinite(noteNumber)) // otherwise if it's numbers assume it's midi
            urlMap[noteNumber] = options.urls[noteNumber];
        });
        this._buffers = new (0, $11a3577f34f45a1d$export$7232b969b571e570)({
            urls: urlMap,
            onload: options.onload,
            baseUrl: options.baseUrl,
            onerror: options.onerror
        });
        this.attack = options.attack;
        this.release = options.release;
        this.curve = options.curve;
        // invoke the callback if it's already loaded
        if (this._buffers.loaded) // invoke onload deferred
        Promise.resolve().then(options.onload);
    }
    static getDefaults() {
        return Object.assign((0, $5e47eb9e1349f4fa$export$25ef33f358b07cf4).getDefaults(), {
            attack: 0,
            baseUrl: "",
            curve: "exponential",
            onload: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            onerror: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            release: 0.1,
            urls: {}
        });
    }
    /**
     * Returns the difference in steps between the given midi note at the closets sample.
     */ _findClosest(midi) {
        // searches within 8 octaves of the given midi note
        const MAX_INTERVAL = 96;
        let interval = 0;
        while(interval < MAX_INTERVAL){
            // check above and below
            if (this._buffers.has(midi + interval)) return -interval;
            else if (this._buffers.has(midi - interval)) return interval;
            interval++;
        }
        throw new Error(`No available buffers for note: ${midi}`);
    }
    /**
     * @param  notes	The note to play, or an array of notes.
     * @param  time     When to play the note
     * @param  velocity The velocity to play the sample back.
     */ triggerAttack(notes, time, velocity = 1) {
        this.log("triggerAttack", notes, time, velocity);
        if (!Array.isArray(notes)) notes = [
            notes
        ];
        notes.forEach((note)=>{
            const midiFloat = (0, $73949b14fe57a99a$export$12513e46625518e4)(new (0, $5b410fbffb0274be$export$38b56155c8552868)(this.context, note).toFrequency());
            const midi = Math.round(midiFloat);
            const remainder = midiFloat - midi;
            // find the closest note pitch
            const difference = this._findClosest(midi);
            const closestNote = midi - difference;
            const buffer = this._buffers.get(closestNote);
            const playbackRate = (0, $73949b14fe57a99a$export$5d18fe46719f6008)(difference + remainder);
            // play that note
            const source = new (0, $ab1da665fc34fe83$export$30cbf4ba14db4fdd)({
                url: buffer,
                context: this.context,
                curve: this.curve,
                fadeIn: this.attack,
                fadeOut: this.release,
                playbackRate: playbackRate
            }).connect(this.output);
            source.start(time, 0, buffer.duration / playbackRate, velocity);
            // add it to the active sources
            if (!(0, $b63b9a75cba601b0$export$43bee75e5e14138e)(this._activeSources.get(midi))) this._activeSources.set(midi, []);
            this._activeSources.get(midi).push(source);
            // remove it when it's done
            source.onended = ()=>{
                if (this._activeSources && this._activeSources.has(midi)) {
                    const sources = this._activeSources.get(midi);
                    const index = sources.indexOf(source);
                    if (index !== -1) sources.splice(index, 1);
                }
            };
        });
        return this;
    }
    /**
     * @param  notes	The note to release, or an array of notes.
     * @param  time     	When to release the note.
     */ triggerRelease(notes, time) {
        this.log("triggerRelease", notes, time);
        if (!Array.isArray(notes)) notes = [
            notes
        ];
        notes.forEach((note)=>{
            const midi = new (0, $5b410fbffb0274be$export$38b56155c8552868)(this.context, note).toMidi();
            // find the note
            if (this._activeSources.has(midi) && this._activeSources.get(midi).length) {
                const sources = this._activeSources.get(midi);
                time = this.toSeconds(time);
                sources.forEach((source)=>{
                    source.stop(time);
                });
                this._activeSources.set(midi, []);
            }
        });
        return this;
    }
    /**
     * Release all currently active notes.
     * @param  time     	When to release the notes.
     */ releaseAll(time) {
        const computedTime = this.toSeconds(time);
        this._activeSources.forEach((sources)=>{
            while(sources.length){
                const source = sources.shift();
                source.stop(computedTime);
            }
        });
        return this;
    }
    sync() {
        if (this._syncState()) {
            this._syncMethod("triggerAttack", 1);
            this._syncMethod("triggerRelease", 1);
        }
        return this;
    }
    /**
     * Invoke the attack phase, then after the duration, invoke the release.
     * @param  notes	The note to play and release, or an array of notes.
     * @param  duration The time the note should be held
     * @param  time     When to start the attack
     * @param  velocity The velocity of the attack
     */ triggerAttackRelease(notes, duration, time, velocity = 1) {
        const computedTime = this.toSeconds(time);
        this.triggerAttack(notes, computedTime, velocity);
        if ((0, $b63b9a75cba601b0$export$43bee75e5e14138e)(duration)) {
            (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $b63b9a75cba601b0$export$43bee75e5e14138e)(notes), "notes must be an array when duration is array");
            notes.forEach((note, index)=>{
                const d = duration[Math.min(index, duration.length - 1)];
                this.triggerRelease(note, computedTime + this.toSeconds(d));
            });
        } else this.triggerRelease(notes, computedTime + this.toSeconds(duration));
        return this;
    }
    /**
     * Add a note to the sampler.
     * @param  note      The buffer's pitch.
     * @param  url  Either the url of the buffer, or a buffer which will be added with the given name.
     * @param  callback  The callback to invoke when the url is loaded.
     */ add(note, url, callback) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)((0, $b63b9a75cba601b0$export$4dcca4501f2037f9)(note) || isFinite(note), `note must be a pitch or midi: ${note}`);
        if ((0, $b63b9a75cba601b0$export$4dcca4501f2037f9)(note)) {
            // convert the note name to MIDI
            const mid = new (0, $5b410fbffb0274be$export$38b56155c8552868)(this.context, note).toMidi();
            this._buffers.add(mid, url, callback);
        } else // otherwise if it's numbers assume it's midi
        this._buffers.add(note, url, callback);
        return this;
    }
    /**
     * If the buffers are loaded or not
     */ get loaded() {
        return this._buffers.loaded;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._buffers.dispose();
        this._activeSources.forEach((sources)=>{
            sources.forEach((source)=>source.dispose());
        });
        this._activeSources.clear();
        return this;
    }
}
(0, $a522a8f63c306c1c$export$29e00dfd3077644b)([
    (0, $cfc784831c74bf36$export$4748a2e3a6d34ca5)(0)
], $3932bd81fc49731d$export$322f102bec719b22.prototype, "attack", void 0);
(0, $a522a8f63c306c1c$export$29e00dfd3077644b)([
    (0, $cfc784831c74bf36$export$4748a2e3a6d34ca5)(0)
], $3932bd81fc49731d$export$322f102bec719b22.prototype, "release", void 0);












class $f5d34dad7cb65963$export$f99f73502b006764 extends (0, $60e11f0590acfc0d$export$4eb0ca57400aa172) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($f5d34dad7cb65963$export$f99f73502b006764.getDefaults(), arguments, [
            "callback",
            "value"
        ]));
        this.name = "ToneEvent";
        /**
         * Tracks the scheduled events
         */ this._state = new (0, $e9f51dc63c33b8a5$export$89221a927ffadcaf)("stopped");
        /**
         * A delay time from when the event is scheduled to start
         */ this._startOffset = 0;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($f5d34dad7cb65963$export$f99f73502b006764.getDefaults(), arguments, [
            "callback",
            "value"
        ]);
        this._loop = options.loop;
        this.callback = options.callback;
        this.value = options.value;
        this._loopStart = this.toTicks(options.loopStart);
        this._loopEnd = this.toTicks(options.loopEnd);
        this._playbackRate = options.playbackRate;
        this._probability = options.probability;
        this._humanize = options.humanize;
        this.mute = options.mute;
        this._playbackRate = options.playbackRate;
        this._state.increasing = true;
        // schedule the events for the first time
        this._rescheduleEvents();
    }
    static getDefaults() {
        return Object.assign((0, $60e11f0590acfc0d$export$4eb0ca57400aa172).getDefaults(), {
            callback: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            humanize: false,
            loop: false,
            loopEnd: "1m",
            loopStart: 0,
            mute: false,
            playbackRate: 1,
            probability: 1,
            value: null
        });
    }
    /**
     * Reschedule all of the events along the timeline
     * with the updated values.
     * @param after Only reschedules events after the given time.
     */ _rescheduleEvents(after = -1) {
        // if no argument is given, schedules all of the events
        this._state.forEachFrom(after, (event)=>{
            let duration;
            if (event.state === "started") {
                if (event.id !== -1) this.context.transport.clear(event.id);
                const startTick = event.time + Math.round(this.startOffset / this._playbackRate);
                if (this._loop === true || (0, $b63b9a75cba601b0$export$7e4aa119212bc614)(this._loop) && this._loop > 1) {
                    duration = Infinity;
                    if ((0, $b63b9a75cba601b0$export$7e4aa119212bc614)(this._loop)) duration = this._loop * this._getLoopDuration();
                    const nextEvent = this._state.getAfter(startTick);
                    if (nextEvent !== null) duration = Math.min(duration, nextEvent.time - startTick);
                    if (duration !== Infinity) {
                        // schedule a stop since it's finite duration
                        this._state.setStateAtTime("stopped", startTick + duration + 1, {
                            id: -1
                        });
                        duration = new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, duration);
                    }
                    const interval = new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, this._getLoopDuration());
                    event.id = this.context.transport.scheduleRepeat(this._tick.bind(this), interval, new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, startTick), duration);
                } else event.id = this.context.transport.schedule(this._tick.bind(this), new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, startTick));
            }
        });
    }
    /**
     * Returns the playback state of the note, either "started" or "stopped".
     */ get state() {
        return this._state.getValueAtTime(this.context.transport.ticks);
    }
    /**
     * The start from the scheduled start time.
     */ get startOffset() {
        return this._startOffset;
    }
    set startOffset(offset) {
        this._startOffset = offset;
    }
    /**
     * The probability of the notes being triggered.
     */ get probability() {
        return this._probability;
    }
    set probability(prob) {
        this._probability = prob;
    }
    /**
     * If set to true, will apply small random variation
     * to the callback time. If the value is given as a time, it will randomize
     * by that amount.
     * @example
     * const event = new Tone.ToneEvent();
     * event.humanize = true;
     */ get humanize() {
        return this._humanize;
    }
    set humanize(variation) {
        this._humanize = variation;
    }
    /**
     * Start the note at the given time.
     * @param  time  When the event should start.
     */ start(time) {
        const ticks = this.toTicks(time);
        if (this._state.getValueAtTime(ticks) === "stopped") {
            this._state.add({
                id: -1,
                state: "started",
                time: ticks
            });
            this._rescheduleEvents(ticks);
        }
        return this;
    }
    /**
     * Stop the Event at the given time.
     * @param  time  When the event should stop.
     */ stop(time) {
        this.cancel(time);
        const ticks = this.toTicks(time);
        if (this._state.getValueAtTime(ticks) === "started") {
            this._state.setStateAtTime("stopped", ticks, {
                id: -1
            });
            const previousEvent = this._state.getBefore(ticks);
            let reschedulTime = ticks;
            if (previousEvent !== null) reschedulTime = previousEvent.time;
            this._rescheduleEvents(reschedulTime);
        }
        return this;
    }
    /**
     * Cancel all scheduled events greater than or equal to the given time
     * @param  time  The time after which events will be cancel.
     */ cancel(time) {
        time = (0, $1e273b197c429402$export$37721a79838ca038)(time, -Infinity);
        const ticks = this.toTicks(time);
        this._state.forEachFrom(ticks, (event)=>{
            this.context.transport.clear(event.id);
        });
        this._state.cancel(ticks);
        return this;
    }
    /**
     * The callback function invoker. Also
     * checks if the Event is done playing
     * @param  time  The time of the event in seconds
     */ _tick(time) {
        const ticks = this.context.transport.getTicksAtTime(time);
        if (!this.mute && this._state.getValueAtTime(ticks) === "started") {
            if (this.probability < 1 && Math.random() > this.probability) return;
            if (this.humanize) {
                let variation = 0.02;
                if (!(0, $b63b9a75cba601b0$export$f9ce7b637dfbe238)(this.humanize)) variation = this.toSeconds(this.humanize);
                time += (Math.random() * 2 - 1) * variation;
            }
            this.callback(time, this.value);
        }
    }
    /**
     * Get the duration of the loop.
     */ _getLoopDuration() {
        return Math.round((this._loopEnd - this._loopStart) / this._playbackRate);
    }
    /**
     * If the note should loop or not
     * between ToneEvent.loopStart and
     * ToneEvent.loopEnd. If set to true,
     * the event will loop indefinitely,
     * if set to a number greater than 1
     * it will play a specific number of
     * times, if set to false, 0 or 1, the
     * part will only play once.
     */ get loop() {
        return this._loop;
    }
    set loop(loop) {
        this._loop = loop;
        this._rescheduleEvents();
    }
    /**
     * The playback rate of the note. Defaults to 1.
     * @example
     * const note = new Tone.ToneEvent();
     * note.loop = true;
     * // repeat the note twice as fast
     * note.playbackRate = 2;
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        this._playbackRate = rate;
        this._rescheduleEvents();
    }
    /**
     * The loopEnd point is the time the event will loop
     * if ToneEvent.loop is true.
     */ get loopEnd() {
        return new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, this._loopEnd).toSeconds();
    }
    set loopEnd(loopEnd) {
        this._loopEnd = this.toTicks(loopEnd);
        if (this._loop) this._rescheduleEvents();
    }
    /**
     * The time when the loop should start.
     */ get loopStart() {
        return new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, this._loopStart).toSeconds();
    }
    set loopStart(loopStart) {
        this._loopStart = this.toTicks(loopStart);
        if (this._loop) this._rescheduleEvents();
    }
    /**
     * The current progress of the loop interval.
     * Returns 0 if the event is not started yet or
     * it is not set to loop.
     */ get progress() {
        if (this._loop) {
            const ticks = this.context.transport.ticks;
            const lastEvent = this._state.get(ticks);
            if (lastEvent !== null && lastEvent.state === "started") {
                const loopDuration = this._getLoopDuration();
                const progress = (ticks - lastEvent.time) % loopDuration;
                return progress / loopDuration;
            } else return 0;
        } else return 0;
    }
    dispose() {
        super.dispose();
        this.cancel();
        this._state.dispose();
        return this;
    }
}





class $1f7e7461988afb9d$export$550acbd06a1f5a6a extends (0, $60e11f0590acfc0d$export$4eb0ca57400aa172) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($1f7e7461988afb9d$export$550acbd06a1f5a6a.getDefaults(), arguments, [
            "callback",
            "interval"
        ]));
        this.name = "Loop";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($1f7e7461988afb9d$export$550acbd06a1f5a6a.getDefaults(), arguments, [
            "callback",
            "interval"
        ]);
        this._event = new (0, $f5d34dad7cb65963$export$f99f73502b006764)({
            context: this.context,
            callback: this._tick.bind(this),
            loop: true,
            loopEnd: options.interval,
            playbackRate: options.playbackRate,
            probability: options.probability
        });
        this.callback = options.callback;
        // set the iterations
        this.iterations = options.iterations;
    }
    static getDefaults() {
        return Object.assign((0, $60e11f0590acfc0d$export$4eb0ca57400aa172).getDefaults(), {
            interval: "4n",
            callback: (0, $c0a1ee726091e30a$export$b50b6e108474309b),
            playbackRate: 1,
            iterations: Infinity,
            probability: 1,
            mute: false,
            humanize: false
        });
    }
    /**
     * Start the loop at the specified time along the Transport's timeline.
     * @param  time  When to start the Loop.
     */ start(time) {
        this._event.start(time);
        return this;
    }
    /**
     * Stop the loop at the given time.
     * @param  time  When to stop the Loop.
     */ stop(time) {
        this._event.stop(time);
        return this;
    }
    /**
     * Cancel all scheduled events greater than or equal to the given time
     * @param  time  The time after which events will be cancel.
     */ cancel(time) {
        this._event.cancel(time);
        return this;
    }
    /**
     * Internal function called when the notes should be called
     * @param time  The time the event occurs
     */ _tick(time) {
        this.callback(time);
    }
    /**
     * The state of the Loop, either started or stopped.
     */ get state() {
        return this._event.state;
    }
    /**
     * The progress of the loop as a value between 0-1. 0, when the loop is stopped or done iterating.
     */ get progress() {
        return this._event.progress;
    }
    /**
     * The time between successive callbacks.
     * @example
     * const loop = new Tone.Loop();
     * loop.interval = "8n"; // loop every 8n
     */ get interval() {
        return this._event.loopEnd;
    }
    set interval(interval) {
        this._event.loopEnd = interval;
    }
    /**
     * The playback rate of the loop. The normal playback rate is 1 (no change).
     * A `playbackRate` of 2 would be twice as fast.
     */ get playbackRate() {
        return this._event.playbackRate;
    }
    set playbackRate(rate) {
        this._event.playbackRate = rate;
    }
    /**
     * Random variation +/-0.01s to the scheduled time.
     * Or give it a time value which it will randomize by.
     */ get humanize() {
        return this._event.humanize;
    }
    set humanize(variation) {
        this._event.humanize = variation;
    }
    /**
     * The probably of the callback being invoked.
     */ get probability() {
        return this._event.probability;
    }
    set probability(prob) {
        this._event.probability = prob;
    }
    /**
     * Muting the Loop means that no callbacks are invoked.
     */ get mute() {
        return this._event.mute;
    }
    set mute(mute) {
        this._event.mute = mute;
    }
    /**
     * The number of iterations of the loop. The default value is `Infinity` (loop forever).
     */ get iterations() {
        if (this._event.loop === true) return Infinity;
        else return this._event.loop;
    }
    set iterations(iters) {
        if (iters === Infinity) this._event.loop = true;
        else this._event.loop = iters;
    }
    dispose() {
        super.dispose();
        this._event.dispose();
        return this;
    }
}








class $3dead49a17571b0f$export$7b5bf7981d51054e extends (0, $f5d34dad7cb65963$export$f99f73502b006764) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($3dead49a17571b0f$export$7b5bf7981d51054e.getDefaults(), arguments, [
            "callback",
            "events"
        ]));
        this.name = "Part";
        /**
         * Tracks the scheduled events
         */ this._state = new (0, $e9f51dc63c33b8a5$export$89221a927ffadcaf)("stopped");
        /**
         * The events that belong to this part
         */ this._events = new Set();
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($3dead49a17571b0f$export$7b5bf7981d51054e.getDefaults(), arguments, [
            "callback",
            "events"
        ]);
        // make sure things are assigned in the right order
        this._state.increasing = true;
        // add the events
        options.events.forEach((event)=>{
            if ((0, $b63b9a75cba601b0$export$43bee75e5e14138e)(event)) this.add(event[0], event[1]);
            else this.add(event);
        });
    }
    static getDefaults() {
        return Object.assign((0, $f5d34dad7cb65963$export$f99f73502b006764).getDefaults(), {
            events: []
        });
    }
    /**
     * Start the part at the given time.
     * @param  time    When to start the part.
     * @param  offset  The offset from the start of the part to begin playing at.
     */ start(time, offset) {
        const ticks = this.toTicks(time);
        if (this._state.getValueAtTime(ticks) !== "started") {
            offset = (0, $1e273b197c429402$export$37721a79838ca038)(offset, this._loop ? this._loopStart : 0);
            if (this._loop) offset = (0, $1e273b197c429402$export$37721a79838ca038)(offset, this._loopStart);
            else offset = (0, $1e273b197c429402$export$37721a79838ca038)(offset, 0);
            const computedOffset = this.toTicks(offset);
            this._state.add({
                id: -1,
                offset: computedOffset,
                state: "started",
                time: ticks
            });
            this._forEach((event)=>{
                this._startNote(event, ticks, computedOffset);
            });
        }
        return this;
    }
    /**
     * Start the event in the given event at the correct time given
     * the ticks and offset and looping.
     * @param  event
     * @param  ticks
     * @param  offset
     */ _startNote(event, ticks, offset) {
        ticks -= offset;
        if (this._loop) {
            if (event.startOffset >= this._loopStart && event.startOffset < this._loopEnd) {
                if (event.startOffset < offset) // start it on the next loop
                ticks += this._getLoopDuration();
                event.start(new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, ticks));
            } else if (event.startOffset < this._loopStart && event.startOffset >= offset) {
                event.loop = false;
                event.start(new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, ticks));
            }
        } else if (event.startOffset >= offset) event.start(new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, ticks));
    }
    get startOffset() {
        return this._startOffset;
    }
    set startOffset(offset) {
        this._startOffset = offset;
        this._forEach((event)=>{
            event.startOffset += this._startOffset;
        });
    }
    /**
     * Stop the part at the given time.
     * @param  time  When to stop the part.
     */ stop(time) {
        const ticks = this.toTicks(time);
        this._state.cancel(ticks);
        this._state.setStateAtTime("stopped", ticks);
        this._forEach((event)=>{
            event.stop(time);
        });
        return this;
    }
    /**
     * Get/Set an Event's value at the given time.
     * If a value is passed in and no event exists at
     * the given time, one will be created with that value.
     * If two events are at the same time, the first one will
     * be returned.
     * @example
     * const part = new Tone.Part();
     * part.at("1m"); // returns the part at the first measure
     * part.at("2m", "C2"); // set the value at "2m" to C2.
     * // if an event didn't exist at that time, it will be created.
     * @param time The time of the event to get or set.
     * @param value If a value is passed in, the value of the event at the given time will be set to it.
     */ at(time, value) {
        const timeInTicks = new (0, $16edc52e2d0df4ee$export$c824041178a9697)(this.context, time).toTicks();
        const tickTime = new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, 1).toSeconds();
        const iterator = this._events.values();
        let result = iterator.next();
        while(!result.done){
            const event = result.value;
            if (Math.abs(timeInTicks - event.startOffset) < tickTime) {
                if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(value)) event.value = value;
                return event;
            }
            result = iterator.next();
        }
        // if there was no event at that time, create one
        if ((0, $b63b9a75cba601b0$export$4e62c701997796c1)(value)) {
            this.add(time, value);
            // return the new event
            return this.at(time);
        } else return null;
    }
    add(time, value) {
        // extract the parameters
        if (time instanceof Object && Reflect.has(time, "time")) {
            value = time;
            time = value.time;
        }
        const ticks = this.toTicks(time);
        let event;
        if (value instanceof (0, $f5d34dad7cb65963$export$f99f73502b006764)) {
            event = value;
            event.callback = this._tick.bind(this);
        } else event = new (0, $f5d34dad7cb65963$export$f99f73502b006764)({
            callback: this._tick.bind(this),
            context: this.context,
            value: value
        });
        // the start offset
        event.startOffset = ticks;
        // initialize the values
        event.set({
            humanize: this.humanize,
            loop: this.loop,
            loopEnd: this.loopEnd,
            loopStart: this.loopStart,
            playbackRate: this.playbackRate,
            probability: this.probability
        });
        this._events.add(event);
        // start the note if it should be played right now
        this._restartEvent(event);
        return this;
    }
    /**
     * Restart the given event
     */ _restartEvent(event) {
        this._state.forEach((stateEvent)=>{
            if (stateEvent.state === "started") this._startNote(event, stateEvent.time, stateEvent.offset);
            else // stop the note
            event.stop(new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, stateEvent.time));
        });
    }
    remove(time, value) {
        // extract the parameters
        if ((0, $b63b9a75cba601b0$export$a6cdc56e425d0d0a)(time) && time.hasOwnProperty("time")) {
            value = time;
            time = value.time;
        }
        time = this.toTicks(time);
        this._events.forEach((event)=>{
            if (event.startOffset === time) {
                if ((0, $b63b9a75cba601b0$export$eb605f91c5895a5b)(value) || (0, $b63b9a75cba601b0$export$4e62c701997796c1)(value) && event.value === value) {
                    this._events.delete(event);
                    event.dispose();
                }
            }
        });
        return this;
    }
    /**
     * Remove all of the notes from the group.
     */ clear() {
        this._forEach((event)=>event.dispose());
        this._events.clear();
        return this;
    }
    /**
     * Cancel scheduled state change events: i.e. "start" and "stop".
     * @param after The time after which to cancel the scheduled events.
     */ cancel(after) {
        this._forEach((event)=>event.cancel(after));
        this._state.cancel(this.toTicks(after));
        return this;
    }
    /**
     * Iterate over all of the events
     */ _forEach(callback) {
        if (this._events) this._events.forEach((event)=>{
            if (event instanceof $3dead49a17571b0f$export$7b5bf7981d51054e) event._forEach(callback);
            else callback(event);
        });
        return this;
    }
    /**
     * Set the attribute of all of the events
     * @param  attr  the attribute to set
     * @param  value      The value to set it to
     */ _setAll(attr, value) {
        this._forEach((event)=>{
            event[attr] = value;
        });
    }
    /**
     * Internal tick method
     * @param  time  The time of the event in seconds
     */ _tick(time, value) {
        if (!this.mute) this.callback(time, value);
    }
    /**
     * Determine if the event should be currently looping
     * given the loop boundries of this Part.
     * @param  event  The event to test
     */ _testLoopBoundries(event) {
        if (this._loop && (event.startOffset < this._loopStart || event.startOffset >= this._loopEnd)) event.cancel(0);
        else if (event.state === "stopped") // reschedule it if it's stopped
        this._restartEvent(event);
    }
    get probability() {
        return this._probability;
    }
    set probability(prob) {
        this._probability = prob;
        this._setAll("probability", prob);
    }
    get humanize() {
        return this._humanize;
    }
    set humanize(variation) {
        this._humanize = variation;
        this._setAll("humanize", variation);
    }
    /**
     * If the part should loop or not
     * between Part.loopStart and
     * Part.loopEnd. If set to true,
     * the part will loop indefinitely,
     * if set to a number greater than 1
     * it will play a specific number of
     * times, if set to false, 0 or 1, the
     * part will only play once.
     * @example
     * const part = new Tone.Part();
     * // loop the part 8 times
     * part.loop = 8;
     */ get loop() {
        return this._loop;
    }
    set loop(loop) {
        this._loop = loop;
        this._forEach((event)=>{
            event.loopStart = this.loopStart;
            event.loopEnd = this.loopEnd;
            event.loop = loop;
            this._testLoopBoundries(event);
        });
    }
    /**
     * The loopEnd point determines when it will
     * loop if Part.loop is true.
     */ get loopEnd() {
        return new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, this._loopEnd).toSeconds();
    }
    set loopEnd(loopEnd) {
        this._loopEnd = this.toTicks(loopEnd);
        if (this._loop) this._forEach((event)=>{
            event.loopEnd = loopEnd;
            this._testLoopBoundries(event);
        });
    }
    /**
     * The loopStart point determines when it will
     * loop if Part.loop is true.
     */ get loopStart() {
        return new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, this._loopStart).toSeconds();
    }
    set loopStart(loopStart) {
        this._loopStart = this.toTicks(loopStart);
        if (this._loop) this._forEach((event)=>{
            event.loopStart = this.loopStart;
            this._testLoopBoundries(event);
        });
    }
    /**
     * The playback rate of the part
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        this._playbackRate = rate;
        this._setAll("playbackRate", rate);
    }
    /**
     * The number of scheduled notes in the part.
     */ get length() {
        return this._events.size;
    }
    dispose() {
        super.dispose();
        this.clear();
        return this;
    }
}





/**
 * Start at the first value and go up to the last
 */ function* $bbb9707fece8b9fe$var$upPatternGen(values) {
    let index = 0;
    while(index < values.length){
        index = $bbb9707fece8b9fe$var$clampToArraySize(index, values);
        yield values[index];
        index++;
    }
}
/**
 * Start at the last value and go down to 0
 */ function* $bbb9707fece8b9fe$var$downPatternGen(values) {
    let index = values.length - 1;
    while(index >= 0){
        index = $bbb9707fece8b9fe$var$clampToArraySize(index, values);
        yield values[index];
        index--;
    }
}
/**
 * Infinitely yield the generator
 */ function* $bbb9707fece8b9fe$var$infiniteGen(values, gen) {
    while(true)yield* gen(values);
}
/**
 * Make sure that the index is in the given range
 */ function $bbb9707fece8b9fe$var$clampToArraySize(index, values) {
    return (0, $e85238bb45fd87b7$export$7d15b64cf5a3a4c4)(index, 0, values.length - 1);
}
/**
 * Alternate between two generators
 */ function* $bbb9707fece8b9fe$var$alternatingGenerator(values, directionUp) {
    let index = directionUp ? 0 : values.length - 1;
    while(true){
        index = $bbb9707fece8b9fe$var$clampToArraySize(index, values);
        yield values[index];
        if (directionUp) {
            index++;
            if (index >= values.length - 1) directionUp = false;
        } else {
            index--;
            if (index <= 0) directionUp = true;
        }
    }
}
/**
 * Starting from the bottom move up 2, down 1
 */ function* $bbb9707fece8b9fe$var$jumpUp(values) {
    let index = 0;
    let stepIndex = 0;
    while(index < values.length){
        index = $bbb9707fece8b9fe$var$clampToArraySize(index, values);
        yield values[index];
        stepIndex++;
        index += stepIndex % 2 ? 2 : -1;
    }
}
/**
 * Starting from the top move down 2, up 1
 */ function* $bbb9707fece8b9fe$var$jumpDown(values) {
    let index = values.length - 1;
    let stepIndex = 0;
    while(index >= 0){
        index = $bbb9707fece8b9fe$var$clampToArraySize(index, values);
        yield values[index];
        stepIndex++;
        index += stepIndex % 2 ? -2 : 1;
    }
}
/**
 * Choose a random index each time
 */ function* $bbb9707fece8b9fe$var$randomGen(values) {
    while(true){
        const randomIndex = Math.floor(Math.random() * values.length);
        yield values[randomIndex];
    }
}
/**
 * Randomly go through all of the values once before choosing a new random order
 */ function* $bbb9707fece8b9fe$var$randomOnce(values) {
    // create an array of indices
    const copy = [];
    for(let i = 0; i < values.length; i++)copy.push(i);
    while(copy.length > 0){
        // random choose an index, and then remove it so it's not chosen again
        const randVal = copy.splice(Math.floor(copy.length * Math.random()), 1);
        const index = $bbb9707fece8b9fe$var$clampToArraySize(randVal[0], values);
        yield values[index];
    }
}
/**
 * Randomly choose to walk up or down 1 index in the values array
 */ function* $bbb9707fece8b9fe$var$randomWalk(values) {
    // randomly choose a starting index in the values array
    let index = Math.floor(Math.random() * values.length);
    while(true){
        if (index === 0) index++; // at bottom of array, so force upward step
        else if (index === values.length - 1) index--; // at top of array, so force downward step
        else if (Math.random() < 0.5) index--;
        else index++;
        yield values[index];
    }
}
function* $bbb9707fece8b9fe$export$891c3c0ea1af078a(values, pattern = "up", index = 0) {
    // safeguards
    (0, $23cf54af36cc9441$export$a7a9523472993e97)(values.length > 0, "The array must have more than one value in it");
    switch(pattern){
        case "up":
            yield* $bbb9707fece8b9fe$var$infiniteGen(values, $bbb9707fece8b9fe$var$upPatternGen);
        case "down":
            yield* $bbb9707fece8b9fe$var$infiniteGen(values, $bbb9707fece8b9fe$var$downPatternGen);
        case "upDown":
            yield* $bbb9707fece8b9fe$var$alternatingGenerator(values, true);
        case "downUp":
            yield* $bbb9707fece8b9fe$var$alternatingGenerator(values, false);
        case "alternateUp":
            yield* $bbb9707fece8b9fe$var$infiniteGen(values, $bbb9707fece8b9fe$var$jumpUp);
        case "alternateDown":
            yield* $bbb9707fece8b9fe$var$infiniteGen(values, $bbb9707fece8b9fe$var$jumpDown);
        case "random":
            yield* $bbb9707fece8b9fe$var$randomGen(values);
        case "randomOnce":
            yield* $bbb9707fece8b9fe$var$infiniteGen(values, $bbb9707fece8b9fe$var$randomOnce);
        case "randomWalk":
            yield* $bbb9707fece8b9fe$var$randomWalk(values);
    }
}




class $b8c2ad2a42966efa$export$47606a6ae3eaed8e extends (0, $1f7e7461988afb9d$export$550acbd06a1f5a6a) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($b8c2ad2a42966efa$export$47606a6ae3eaed8e.getDefaults(), arguments, [
            "callback",
            "values",
            "pattern"
        ]));
        this.name = "Pattern";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($b8c2ad2a42966efa$export$47606a6ae3eaed8e.getDefaults(), arguments, [
            "callback",
            "values",
            "pattern"
        ]);
        this.callback = options.callback;
        this._values = options.values;
        this._pattern = (0, $bbb9707fece8b9fe$export$891c3c0ea1af078a)(options.values, options.pattern);
        this._type = options.pattern;
    }
    static getDefaults() {
        return Object.assign((0, $1f7e7461988afb9d$export$550acbd06a1f5a6a).getDefaults(), {
            pattern: "up",
            values: [],
            callback: (0, $c0a1ee726091e30a$export$b50b6e108474309b)
        });
    }
    /**
     * Internal function called when the notes should be called
     */ _tick(time) {
        const value = this._pattern.next();
        this._value = value.value;
        this.callback(time, this._value);
    }
    /**
     * The array of events.
     */ get values() {
        return this._values;
    }
    set values(val) {
        this._values = val;
        // reset the pattern
        this.pattern = this._type;
    }
    /**
     * The current value of the pattern.
     */ get value() {
        return this._value;
    }
    /**
     * The pattern type. See Tone.CtrlPattern for the full list of patterns.
     */ get pattern() {
        return this._type;
    }
    set pattern(pattern) {
        this._type = pattern;
        this._pattern = (0, $bbb9707fece8b9fe$export$891c3c0ea1af078a)(this._values, this._type);
    }
}







class $7a09da34728fe232$export$edde1bcb1b2b310e extends (0, $f5d34dad7cb65963$export$f99f73502b006764) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($7a09da34728fe232$export$edde1bcb1b2b310e.getDefaults(), arguments, [
            "callback",
            "events",
            "subdivision"
        ]));
        this.name = "Sequence";
        /**
         * The object responsible for scheduling all of the events
         */ this._part = new (0, $3dead49a17571b0f$export$7b5bf7981d51054e)({
            callback: this._seqCallback.bind(this),
            context: this.context
        });
        /**
         * private reference to all of the sequence proxies
         */ this._events = [];
        /**
         * The proxied array
         */ this._eventsArray = [];
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($7a09da34728fe232$export$edde1bcb1b2b310e.getDefaults(), arguments, [
            "callback",
            "events",
            "subdivision"
        ]);
        this._subdivision = this.toTicks(options.subdivision);
        this.events = options.events;
        // set all of the values
        this.loop = options.loop;
        this.loopStart = options.loopStart;
        this.loopEnd = options.loopEnd;
        this.playbackRate = options.playbackRate;
        this.probability = options.probability;
        this.humanize = options.humanize;
        this.mute = options.mute;
        this.playbackRate = options.playbackRate;
    }
    static getDefaults() {
        return Object.assign((0, $1e273b197c429402$export$e35a36a1f3b5e86b)((0, $f5d34dad7cb65963$export$f99f73502b006764).getDefaults(), [
            "value"
        ]), {
            events: [],
            loop: true,
            loopEnd: 0,
            loopStart: 0,
            subdivision: "8n"
        });
    }
    /**
     * The internal callback for when an event is invoked
     */ _seqCallback(time, value) {
        if (value !== null) this.callback(time, value);
    }
    /**
     * The sequence
     */ get events() {
        return this._events;
    }
    set events(s) {
        this.clear();
        this._eventsArray = s;
        this._events = this._createSequence(this._eventsArray);
        this._eventsUpdated();
    }
    /**
     * Start the part at the given time.
     * @param  time    When to start the part.
     * @param  offset  The offset index to start at
     */ start(time, offset) {
        this._part.start(time, offset ? this._indexTime(offset) : offset);
        return this;
    }
    /**
     * Stop the part at the given time.
     * @param  time  When to stop the part.
     */ stop(time) {
        this._part.stop(time);
        return this;
    }
    /**
     * The subdivision of the sequence. This can only be
     * set in the constructor. The subdivision is the
     * interval between successive steps.
     */ get subdivision() {
        return new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, this._subdivision).toSeconds();
    }
    /**
     * Create a sequence proxy which can be monitored to create subsequences
     */ _createSequence(array) {
        return new Proxy(array, {
            get: (target, property)=>{
                // property is index in this case
                return target[property];
            },
            set: (target, property, value)=>{
                if ((0, $b63b9a75cba601b0$export$844ec244b1367d54)(property) && isFinite(parseInt(property, 10))) {
                    if ((0, $b63b9a75cba601b0$export$43bee75e5e14138e)(value)) target[property] = this._createSequence(value);
                    else target[property] = value;
                } else target[property] = value;
                this._eventsUpdated();
                // return true to accept the changes
                return true;
            }
        });
    }
    /**
     * When the sequence has changed, all of the events need to be recreated
     */ _eventsUpdated() {
        this._part.clear();
        this._rescheduleSequence(this._eventsArray, this._subdivision, this.startOffset);
        // update the loopEnd
        this.loopEnd = this.loopEnd;
    }
    /**
     * reschedule all of the events that need to be rescheduled
     */ _rescheduleSequence(sequence, subdivision, startOffset) {
        sequence.forEach((value, index)=>{
            const eventOffset = index * subdivision + startOffset;
            if ((0, $b63b9a75cba601b0$export$43bee75e5e14138e)(value)) this._rescheduleSequence(value, subdivision / value.length, eventOffset);
            else {
                const startTime = new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, eventOffset, "i").toSeconds();
                this._part.add(startTime, value);
            }
        });
    }
    /**
     * Get the time of the index given the Sequence's subdivision
     * @param  index
     * @return The time of that index
     */ _indexTime(index) {
        return new (0, $5a2725674ec35741$export$fe3569694b9f5728)(this.context, index * this._subdivision + this.startOffset).toSeconds();
    }
    /**
     * Clear all of the events
     */ clear() {
        this._part.clear();
        return this;
    }
    dispose() {
        super.dispose();
        this._part.dispose();
        return this;
    }
    //-------------------------------------
    // PROXY CALLS
    //-------------------------------------
    get loop() {
        return this._part.loop;
    }
    set loop(l) {
        this._part.loop = l;
    }
    /**
     * The index at which the sequence should start looping
     */ get loopStart() {
        return this._loopStart;
    }
    set loopStart(index) {
        this._loopStart = index;
        this._part.loopStart = this._indexTime(index);
    }
    /**
     * The index at which the sequence should end looping
     */ get loopEnd() {
        return this._loopEnd;
    }
    set loopEnd(index) {
        this._loopEnd = index;
        if (index === 0) this._part.loopEnd = this._indexTime(this._eventsArray.length);
        else this._part.loopEnd = this._indexTime(index);
    }
    get startOffset() {
        return this._part.startOffset;
    }
    set startOffset(start) {
        this._part.startOffset = start;
    }
    get playbackRate() {
        return this._part.playbackRate;
    }
    set playbackRate(rate) {
        this._part.playbackRate = rate;
    }
    get probability() {
        return this._part.probability;
    }
    set probability(prob) {
        this._part.probability = prob;
    }
    get progress() {
        return this._part.progress;
    }
    get humanize() {
        return this._part.humanize;
    }
    set humanize(variation) {
        this._part.humanize = variation;
    }
    /**
     * The number of scheduled events
     */ get length() {
        return this._part.length;
    }
}













class $75598ffdc68d5042$export$d78c8c6074541cf2 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($75598ffdc68d5042$export$d78c8c6074541cf2.getDefaults(), arguments, [
            "fade"
        ])));
        this.name = "CrossFade";
        /**
         * The crossfading is done by a StereoPannerNode
         */ this._panner = this.context.createStereoPanner();
        /**
         * Split the output of the panner node into two values used to control the gains.
         */ this._split = this.context.createChannelSplitter(2);
        /**
         * Convert the fade value into an audio range value so it can be connected
         * to the panner.pan AudioParam
         */ this._g2a = new (0, $a47f143e502734f3$export$770438008a544d9b)({
            context: this.context
        });
        /**
         * The input which is at full level when fade = 0
         */ this.a = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            gain: 0
        });
        /**
         * The input which is at full level when fade = 1
         */ this.b = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            gain: 0
        });
        /**
         * The output is a mix between `a` and `b` at the ratio of `fade`
         */ this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this._internalChannels = [
            this.a,
            this.b
        ];
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($75598ffdc68d5042$export$d78c8c6074541cf2.getDefaults(), arguments, [
            "fade"
        ]);
        this.fade = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "normalRange",
            value: options.fade
        });
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "fade");
        this.context.getConstant(1).connect(this._panner);
        this._panner.connect(this._split);
        // this is necessary for standardized-audio-context
        // doesn't make any difference for the native AudioContext
        // https://github.com/chrisguttandin/standardized-audio-context/issues/647
        this._panner.channelCount = 1;
        this._panner.channelCountMode = "explicit";
        (0, $5ffbb5654e49c399$export$64605811ab45167f)(this._split, this.a.gain, 0);
        (0, $5ffbb5654e49c399$export$64605811ab45167f)(this._split, this.b.gain, 1);
        this.fade.chain(this._g2a, this._panner.pan);
        this.a.connect(this.output);
        this.b.connect(this.output);
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            fade: 0.5
        });
    }
    dispose() {
        super.dispose();
        this.a.dispose();
        this.b.dispose();
        this.output.dispose();
        this.fade.dispose();
        this._g2a.dispose();
        this._panner.disconnect();
        this._split.disconnect();
        return this;
    }
}





class $afc8de7abeb2ad05$export$a32b0b1c1ac59d04 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(options){
        super(options);
        this.name = "Effect";
        /**
         * the drywet knob to control the amount of effect
         */ this._dryWet = new (0, $75598ffdc68d5042$export$d78c8c6074541cf2)({
            context: this.context
        });
        /**
         * The wet control is how much of the effected
         * will pass through to the output. 1 = 100% effected
         * signal, 0 = 100% dry signal.
         */ this.wet = this._dryWet.fade;
        /**
         * connect the effectSend to the input of hte effect
         */ this.effectSend = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        /**
         * connect the output of the effect to the effectReturn
         */ this.effectReturn = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        /**
         * The effect input node
         */ this.input = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        /**
         * The effect output
         */ this.output = this._dryWet;
        // connections
        this.input.fan(this._dryWet.a, this.effectSend);
        this.effectReturn.connect(this._dryWet.b);
        this.wet.setValueAtTime(options.wet, 0);
        this._internalChannels = [
            this.effectReturn,
            this.effectSend
        ];
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "wet");
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            wet: 1
        });
    }
    /**
     * chains the effect in between the effectSend and effectReturn
     */ connectEffect(effect) {
        // add it to the internal channels
        this._internalChannels.push(effect);
        this.effectSend.chain(effect, this.effectReturn);
        return this;
    }
    dispose() {
        super.dispose();
        this._dryWet.dispose();
        this.effectSend.dispose();
        this.effectReturn.dispose();
        this.wet.dispose();
        return this;
    }
}




class $1f05788947c8c326$export$de224a2741e4b2f8 extends (0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04) {
    constructor(options){
        super(options);
        this.name = "LFOEffect";
        this._lfo = new (0, $4a4529bace75b797$export$603054d5ec296d77)({
            context: this.context,
            frequency: options.frequency,
            amplitude: options.depth
        });
        this.depth = this._lfo.amplitude;
        this.frequency = this._lfo.frequency;
        this.type = options.type;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "frequency",
            "depth"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04).getDefaults(), {
            frequency: 1,
            type: "sine",
            depth: 1
        });
    }
    /**
     * Start the effect.
     */ start(time) {
        this._lfo.start(time);
        return this;
    }
    /**
     * Stop the lfo
     */ stop(time) {
        this._lfo.stop(time);
        return this;
    }
    /**
     * Sync the filter to the transport. See [[LFO.sync]]
     */ sync() {
        this._lfo.sync();
        return this;
    }
    /**
     * Unsync the filter from the transport.
     */ unsync() {
        this._lfo.unsync();
        return this;
    }
    /**
     * The type of the LFO's oscillator: See [[Oscillator.type]]
     * @example
     * const autoFilter = new Tone.AutoFilter().start().toDestination();
     * const noise = new Tone.Noise().start().connect(autoFilter);
     * autoFilter.type = "square";
     */ get type() {
        return this._lfo.type;
    }
    set type(type) {
        this._lfo.type = type;
    }
    dispose() {
        super.dispose();
        this._lfo.dispose();
        this.frequency.dispose();
        this.depth.dispose();
        return this;
    }
}


class $2c7dfb4be96c717c$export$b80f807aa51d8d02 extends (0, $1f05788947c8c326$export$de224a2741e4b2f8) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($2c7dfb4be96c717c$export$b80f807aa51d8d02.getDefaults(), arguments, [
            "frequency",
            "baseFrequency",
            "octaves"
        ]));
        this.name = "AutoFilter";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($2c7dfb4be96c717c$export$b80f807aa51d8d02.getDefaults(), arguments, [
            "frequency",
            "baseFrequency",
            "octaves"
        ]);
        this.filter = new (0, $b43765906de8c71a$export$ec91da630f36d5ea)(Object.assign(options.filter, {
            context: this.context
        }));
        // connections
        this.connectEffect(this.filter);
        this._lfo.connect(this.filter.frequency);
        this.octaves = options.octaves;
        this.baseFrequency = options.baseFrequency;
    }
    static getDefaults() {
        return Object.assign((0, $1f05788947c8c326$export$de224a2741e4b2f8).getDefaults(), {
            baseFrequency: 200,
            octaves: 2.6,
            filter: {
                type: "lowpass",
                rolloff: -12,
                Q: 1
            }
        });
    }
    /**
     * The minimum value of the filter's cutoff frequency.
     */ get baseFrequency() {
        return this._lfo.min;
    }
    set baseFrequency(freq) {
        this._lfo.min = this.toFrequency(freq);
        // and set the max
        this.octaves = this._octaves;
    }
    /**
     * The maximum value of the filter's cutoff frequency.
     */ get octaves() {
        return this._octaves;
    }
    set octaves(oct) {
        this._octaves = oct;
        this._lfo.max = this._lfo.min * Math.pow(2, oct);
    }
    dispose() {
        super.dispose();
        this.filter.dispose();
        return this;
    }
}






class $489e86a396f6a032$export$d6d7a1629e59823d extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($489e86a396f6a032$export$d6d7a1629e59823d.getDefaults(), arguments, [
            "pan"
        ])));
        this.name = "Panner";
        /**
         * the panner node
         */ this._panner = this.context.createStereoPanner();
        this.input = this._panner;
        this.output = this._panner;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($489e86a396f6a032$export$d6d7a1629e59823d.getDefaults(), arguments, [
            "pan"
        ]);
        this.pan = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this._panner.pan,
            value: options.pan,
            minValue: -1,
            maxValue: 1
        });
        // this is necessary for standardized-audio-context
        // doesn't make any difference for the native AudioContext
        // https://github.com/chrisguttandin/standardized-audio-context/issues/647
        this._panner.channelCount = options.channelCount;
        this._panner.channelCountMode = "explicit";
        // initial value
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "pan");
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            pan: 0,
            channelCount: 1
        });
    }
    dispose() {
        super.dispose();
        this._panner.disconnect();
        this.pan.dispose();
        return this;
    }
}




class $194f7ec34e02ae25$export$e9bd274ee70104df extends (0, $1f05788947c8c326$export$de224a2741e4b2f8) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($194f7ec34e02ae25$export$e9bd274ee70104df.getDefaults(), arguments, [
            "frequency"
        ]));
        this.name = "AutoPanner";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($194f7ec34e02ae25$export$e9bd274ee70104df.getDefaults(), arguments, [
            "frequency"
        ]);
        this._panner = new (0, $489e86a396f6a032$export$d6d7a1629e59823d)({
            context: this.context,
            channelCount: options.channelCount
        });
        // connections
        this.connectEffect(this._panner);
        this._lfo.connect(this._panner.pan);
        this._lfo.min = -1;
        this._lfo.max = 1;
    }
    static getDefaults() {
        return Object.assign((0, $1f05788947c8c326$export$de224a2741e4b2f8).getDefaults(), {
            channelCount: 1
        });
    }
    dispose() {
        super.dispose();
        this._panner.dispose();
        return this;
    }
}








class $da264d90e2c8a7c7$export$8ccab1ce4a46f extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($da264d90e2c8a7c7$export$8ccab1ce4a46f.getDefaults(), arguments, [
            "smoothing"
        ]));
        this.name = "Follower";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($da264d90e2c8a7c7$export$8ccab1ce4a46f.getDefaults(), arguments, [
            "smoothing"
        ]);
        this._abs = this.input = new (0, $3624e6c3eff54480$export$b73c596ee8758a66)({
            context: this.context
        });
        this._lowpass = this.output = new (0, $25eda6a987a6f37d$export$7961b18021b7c8c9)({
            context: this.context,
            frequency: 1 / this.toSeconds(options.smoothing),
            type: "lowpass"
        });
        this._abs.connect(this._lowpass);
        this._smoothing = options.smoothing;
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            smoothing: 0.05
        });
    }
    /**
     * The amount of time it takes a value change to arrive at the updated value.
     */ get smoothing() {
        return this._smoothing;
    }
    set smoothing(smoothing) {
        this._smoothing = smoothing;
        this._lowpass.frequency = 1 / this.toSeconds(this.smoothing);
    }
    dispose() {
        super.dispose();
        this._abs.dispose();
        this._lowpass.dispose();
        return this;
    }
}







class $c017f2be0b492603$export$7107ee8d8b759a00 extends (0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($c017f2be0b492603$export$7107ee8d8b759a00.getDefaults(), arguments, [
            "baseFrequency",
            "octaves",
            "sensitivity"
        ]));
        this.name = "AutoWah";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($c017f2be0b492603$export$7107ee8d8b759a00.getDefaults(), arguments, [
            "baseFrequency",
            "octaves",
            "sensitivity"
        ]);
        this._follower = new (0, $da264d90e2c8a7c7$export$8ccab1ce4a46f)({
            context: this.context,
            smoothing: options.follower
        });
        this._sweepRange = new (0, $4f921130c5388aed$export$92c7140174c78083)({
            context: this.context,
            min: 0,
            max: 1,
            exponent: 0.5
        });
        this._baseFrequency = this.toFrequency(options.baseFrequency);
        this._octaves = options.octaves;
        this._inputBoost = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this._bandpass = new (0, $b43765906de8c71a$export$ec91da630f36d5ea)({
            context: this.context,
            rolloff: -48,
            frequency: 0,
            Q: options.Q
        });
        this._peaking = new (0, $b43765906de8c71a$export$ec91da630f36d5ea)({
            context: this.context,
            type: "peaking"
        });
        this._peaking.gain.value = options.gain;
        this.gain = this._peaking.gain;
        this.Q = this._bandpass.Q;
        // the control signal path
        this.effectSend.chain(this._inputBoost, this._follower, this._sweepRange);
        this._sweepRange.connect(this._bandpass.frequency);
        this._sweepRange.connect(this._peaking.frequency);
        // the filtered path
        this.effectSend.chain(this._bandpass, this._peaking, this.effectReturn);
        // set the initial value
        this._setSweepRange();
        this.sensitivity = options.sensitivity;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "gain",
            "Q"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04).getDefaults(), {
            baseFrequency: 100,
            octaves: 6,
            sensitivity: 0,
            Q: 2,
            gain: 2,
            follower: 0.2
        });
    }
    /**
     * The number of octaves that the filter will sweep above the baseFrequency.
     */ get octaves() {
        return this._octaves;
    }
    set octaves(octaves) {
        this._octaves = octaves;
        this._setSweepRange();
    }
    /**
     * The follower's smoothing time
     */ get follower() {
        return this._follower.smoothing;
    }
    set follower(follower) {
        this._follower.smoothing = follower;
    }
    /**
     * The base frequency from which the sweep will start from.
     */ get baseFrequency() {
        return this._baseFrequency;
    }
    set baseFrequency(baseFreq) {
        this._baseFrequency = this.toFrequency(baseFreq);
        this._setSweepRange();
    }
    /**
     * The sensitivity to control how responsive to the input signal the filter is.
     */ get sensitivity() {
        return (0, $73949b14fe57a99a$export$6af3969727ca2a60)(1 / this._inputBoost.gain.value);
    }
    set sensitivity(sensitivity) {
        this._inputBoost.gain.value = 1 / (0, $73949b14fe57a99a$export$33ed28de027e9482)(sensitivity);
    }
    /**
     * sets the sweep range of the scaler
     */ _setSweepRange() {
        this._sweepRange.min = this._baseFrequency;
        this._sweepRange.max = Math.min(this._baseFrequency * Math.pow(2, this._octaves), this.context.sampleRate / 2);
    }
    dispose() {
        super.dispose();
        this._follower.dispose();
        this._sweepRange.dispose();
        this._bandpass.dispose();
        this._peaking.dispose();
        this._inputBoost.dispose();
        return this;
    }
}










const $aee6bdfd59062874$export$85343ada6050a795 = "bit-crusher";
const $aee6bdfd59062874$export$b0b3e57880d0a354 = /* javascript */ `
	class BitCrusherWorklet extends SingleIOProcessor {

		static get parameterDescriptors() {
			return [{
				name: "bits",
				defaultValue: 12,
				minValue: 1,
				maxValue: 16,
				automationRate: 'k-rate'
			}];
		}

		generate(input, _channel, parameters) {
			const step = Math.pow(0.5, parameters.bits - 1);
			const val = step * Math.floor(input / step + 0.5);
			return val;
		}
	}
`;
(0, $5bc17f183cac76e3$export$d575e6557ac1729f)($aee6bdfd59062874$export$85343ada6050a795, $aee6bdfd59062874$export$b0b3e57880d0a354);


class $7c1e5f6380696f95$export$89e1fd5b393fbb6e extends (0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($7c1e5f6380696f95$export$89e1fd5b393fbb6e.getDefaults(), arguments, [
            "bits"
        ]));
        this.name = "BitCrusher";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($7c1e5f6380696f95$export$89e1fd5b393fbb6e.getDefaults(), arguments, [
            "bits"
        ]);
        this._bitCrusherWorklet = new $7c1e5f6380696f95$var$BitCrusherWorklet({
            context: this.context,
            bits: options.bits
        });
        // connect it up
        this.connectEffect(this._bitCrusherWorklet);
        this.bits = this._bitCrusherWorklet.bits;
    }
    static getDefaults() {
        return Object.assign((0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04).getDefaults(), {
            bits: 4
        });
    }
    dispose() {
        super.dispose();
        this._bitCrusherWorklet.dispose();
        return this;
    }
}
/**
 * Internal class which creates an AudioWorklet to do the bit crushing
 */ class $7c1e5f6380696f95$var$BitCrusherWorklet extends (0, $0ce02f7f068b2658$export$212d912bd0512eff) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($7c1e5f6380696f95$var$BitCrusherWorklet.getDefaults(), arguments));
        this.name = "BitCrusherWorklet";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($7c1e5f6380696f95$var$BitCrusherWorklet.getDefaults(), arguments);
        this.input = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this.bits = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            value: options.bits,
            units: "positive",
            minValue: 1,
            maxValue: 16,
            param: this._dummyParam,
            swappable: true
        });
    }
    static getDefaults() {
        return Object.assign((0, $0ce02f7f068b2658$export$212d912bd0512eff).getDefaults(), {
            bits: 12
        });
    }
    _audioWorkletName() {
        return 0, $aee6bdfd59062874$export$85343ada6050a795;
    }
    onReady(node) {
        (0, $5ffbb5654e49c399$export$933c3b67552fb559)(this.input, node, this.output);
        const bits = node.parameters.get("bits");
        this.bits.setParam(bits);
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this.output.dispose();
        this.bits.dispose();
        return this;
    }
}





class $33a1fb59977c9e11$export$9e28f5c57e778427 extends (0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($33a1fb59977c9e11$export$9e28f5c57e778427.getDefaults(), arguments, [
            "order"
        ]));
        this.name = "Chebyshev";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($33a1fb59977c9e11$export$9e28f5c57e778427.getDefaults(), arguments, [
            "order"
        ]);
        this._shaper = new (0, $c802ebb611a7b944$export$4d933d013693e78)({
            context: this.context,
            length: 4096
        });
        this._order = options.order;
        this.connectEffect(this._shaper);
        this.order = options.order;
        this.oversample = options.oversample;
    }
    static getDefaults() {
        return Object.assign((0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04).getDefaults(), {
            order: 1,
            oversample: "none"
        });
    }
    /**
     * get the coefficient for that degree
     * @param  x the x value
     * @param  degree
     * @param  memo memoize the computed value. this speeds up computation greatly.
     */ _getCoefficient(x, degree, memo) {
        if (memo.has(degree)) return memo.get(degree);
        else if (degree === 0) memo.set(degree, 0);
        else if (degree === 1) memo.set(degree, x);
        else memo.set(degree, 2 * x * this._getCoefficient(x, degree - 1, memo) - this._getCoefficient(x, degree - 2, memo));
        return memo.get(degree);
    }
    /**
     * The order of the Chebyshev polynomial which creates the equation which is applied to the incoming
     * signal through a Tone.WaveShaper. The equations are in the form:
     * ```
     * order 2: 2x^2 + 1
     * order 3: 4x^3 + 3x
     * ```
     * @min 1
     * @max 100
     */ get order() {
        return this._order;
    }
    set order(order) {
        this._order = order;
        this._shaper.setMap((x)=>{
            return this._getCoefficient(x, order, new Map());
        });
    }
    /**
     * The oversampling of the effect. Can either be "none", "2x" or "4x".
     */ get oversample() {
        return this._shaper.oversample;
    }
    set oversample(oversampling) {
        this._shaper.oversample = oversampling;
    }
    dispose() {
        super.dispose();
        this._shaper.dispose();
        return this;
    }
}






class $bbae2f8bfe6afb52$export$f836382419f64c98 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($bbae2f8bfe6afb52$export$f836382419f64c98.getDefaults(), arguments, [
            "channels"
        ]));
        this.name = "Split";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($bbae2f8bfe6afb52$export$f836382419f64c98.getDefaults(), arguments, [
            "channels"
        ]);
        this._splitter = this.input = this.output = this.context.createChannelSplitter(options.channels);
        this._internalChannels = [
            this._splitter
        ];
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            channels: 2
        });
    }
    dispose() {
        super.dispose();
        this._splitter.disconnect();
        return this;
    }
}





class $4541bd4bd7add640$export$70ce1d34efd3b886 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($4541bd4bd7add640$export$70ce1d34efd3b886.getDefaults(), arguments, [
            "channels"
        ]));
        this.name = "Merge";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($4541bd4bd7add640$export$70ce1d34efd3b886.getDefaults(), arguments, [
            "channels"
        ]);
        this._merger = this.output = this.input = this.context.createChannelMerger(options.channels);
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            channels: 2
        });
    }
    dispose() {
        super.dispose();
        this._merger.disconnect();
        return this;
    }
}



class $b5261ce805244afa$export$f02761adf21def8a extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(options){
        super(options);
        this.name = "StereoEffect";
        this.input = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        // force mono sources to be stereo
        this.input.channelCount = 2;
        this.input.channelCountMode = "explicit";
        this._dryWet = this.output = new (0, $75598ffdc68d5042$export$d78c8c6074541cf2)({
            context: this.context,
            fade: options.wet
        });
        this.wet = this._dryWet.fade;
        this._split = new (0, $bbae2f8bfe6afb52$export$f836382419f64c98)({
            context: this.context,
            channels: 2
        });
        this._merge = new (0, $4541bd4bd7add640$export$70ce1d34efd3b886)({
            context: this.context,
            channels: 2
        });
        // connections
        this.input.connect(this._split);
        // dry wet connections
        this.input.connect(this._dryWet.a);
        this._merge.connect(this._dryWet.b);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "wet"
        ]);
    }
    /**
     * Connect the left part of the effect
     */ connectEffectLeft(...nodes) {
        this._split.connect(nodes[0], 0, 0);
        (0, $5ffbb5654e49c399$export$933c3b67552fb559)(...nodes);
        (0, $5ffbb5654e49c399$export$64605811ab45167f)(nodes[nodes.length - 1], this._merge, 0, 0);
    }
    /**
     * Connect the right part of the effect
     */ connectEffectRight(...nodes) {
        this._split.connect(nodes[0], 1, 0);
        (0, $5ffbb5654e49c399$export$933c3b67552fb559)(...nodes);
        (0, $5ffbb5654e49c399$export$64605811ab45167f)(nodes[nodes.length - 1], this._merge, 0, 1);
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            wet: 1
        });
    }
    dispose() {
        super.dispose();
        this._dryWet.dispose();
        this._split.dispose();
        this._merge.dispose();
        return this;
    }
}







class $ca4464851f4de725$export$d911e987c738486e extends (0, $b5261ce805244afa$export$f02761adf21def8a) {
    constructor(options){
        super(options);
        this.feedback = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            value: options.feedback,
            units: "normalRange"
        });
        this._feedbackL = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this._feedbackR = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this._feedbackSplit = new (0, $bbae2f8bfe6afb52$export$f836382419f64c98)({
            context: this.context,
            channels: 2
        });
        this._feedbackMerge = new (0, $4541bd4bd7add640$export$70ce1d34efd3b886)({
            context: this.context,
            channels: 2
        });
        this._merge.connect(this._feedbackSplit);
        this._feedbackMerge.connect(this._split);
        // the left output connected to the left input
        this._feedbackSplit.connect(this._feedbackL, 0, 0);
        this._feedbackL.connect(this._feedbackMerge, 0, 0);
        // the right output connected to the right input
        this._feedbackSplit.connect(this._feedbackR, 1, 0);
        this._feedbackR.connect(this._feedbackMerge, 0, 1);
        // the feedback control
        this.feedback.fan(this._feedbackL.gain, this._feedbackR.gain);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "feedback"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $b5261ce805244afa$export$f02761adf21def8a).getDefaults(), {
            feedback: 0.5
        });
    }
    dispose() {
        super.dispose();
        this.feedback.dispose();
        this._feedbackL.dispose();
        this._feedbackR.dispose();
        this._feedbackSplit.dispose();
        this._feedbackMerge.dispose();
        return this;
    }
}






class $0580ff942b86d3cf$export$e876320b09eb8124 extends (0, $ca4464851f4de725$export$d911e987c738486e) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($0580ff942b86d3cf$export$e876320b09eb8124.getDefaults(), arguments, [
            "frequency",
            "delayTime",
            "depth"
        ]));
        this.name = "Chorus";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($0580ff942b86d3cf$export$e876320b09eb8124.getDefaults(), arguments, [
            "frequency",
            "delayTime",
            "depth"
        ]);
        this._depth = options.depth;
        this._delayTime = options.delayTime / 1000;
        this._lfoL = new (0, $4a4529bace75b797$export$603054d5ec296d77)({
            context: this.context,
            frequency: options.frequency,
            min: 0,
            max: 1
        });
        this._lfoR = new (0, $4a4529bace75b797$export$603054d5ec296d77)({
            context: this.context,
            frequency: options.frequency,
            min: 0,
            max: 1,
            phase: 180
        });
        this._delayNodeL = new (0, $56c02e4cadfbd835$export$7419ff430885d61c)({
            context: this.context
        });
        this._delayNodeR = new (0, $56c02e4cadfbd835$export$7419ff430885d61c)({
            context: this.context
        });
        this.frequency = this._lfoL.frequency;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "frequency"
        ]);
        // have one LFO frequency control the other
        this._lfoL.frequency.connect(this._lfoR.frequency);
        // connections
        this.connectEffectLeft(this._delayNodeL);
        this.connectEffectRight(this._delayNodeR);
        // lfo setup
        this._lfoL.connect(this._delayNodeL.delayTime);
        this._lfoR.connect(this._delayNodeR.delayTime);
        // set the initial values
        this.depth = this._depth;
        this.type = options.type;
        this.spread = options.spread;
    }
    static getDefaults() {
        return Object.assign((0, $ca4464851f4de725$export$d911e987c738486e).getDefaults(), {
            frequency: 1.5,
            delayTime: 3.5,
            depth: 0.7,
            type: "sine",
            spread: 180,
            feedback: 0,
            wet: 0.5
        });
    }
    /**
     * The depth of the effect. A depth of 1 makes the delayTime
     * modulate between 0 and 2*delayTime (centered around the delayTime).
     */ get depth() {
        return this._depth;
    }
    set depth(depth) {
        this._depth = depth;
        const deviation = this._delayTime * depth;
        this._lfoL.min = Math.max(this._delayTime - deviation, 0);
        this._lfoL.max = this._delayTime + deviation;
        this._lfoR.min = Math.max(this._delayTime - deviation, 0);
        this._lfoR.max = this._delayTime + deviation;
    }
    /**
     * The delayTime in milliseconds of the chorus. A larger delayTime
     * will give a more pronounced effect. Nominal range a delayTime
     * is between 2 and 20ms.
     */ get delayTime() {
        return this._delayTime * 1000;
    }
    set delayTime(delayTime) {
        this._delayTime = delayTime / 1000;
        this.depth = this._depth;
    }
    /**
     * The oscillator type of the LFO.
     */ get type() {
        return this._lfoL.type;
    }
    set type(type) {
        this._lfoL.type = type;
        this._lfoR.type = type;
    }
    /**
     * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.
     * When set to 180, LFO's will be panned hard left and right respectively.
     */ get spread() {
        return this._lfoR.phase - this._lfoL.phase;
    }
    set spread(spread) {
        this._lfoL.phase = 90 - spread / 2;
        this._lfoR.phase = spread / 2 + 90;
    }
    /**
     * Start the effect.
     */ start(time) {
        this._lfoL.start(time);
        this._lfoR.start(time);
        return this;
    }
    /**
     * Stop the lfo
     */ stop(time) {
        this._lfoL.stop(time);
        this._lfoR.stop(time);
        return this;
    }
    /**
     * Sync the filter to the transport. See [[LFO.sync]]
     */ sync() {
        this._lfoL.sync();
        this._lfoR.sync();
        return this;
    }
    /**
     * Unsync the filter from the transport.
     */ unsync() {
        this._lfoL.unsync();
        this._lfoR.unsync();
        return this;
    }
    dispose() {
        super.dispose();
        this._lfoL.dispose();
        this._lfoR.dispose();
        this._delayNodeL.dispose();
        this._delayNodeR.dispose();
        this.frequency.dispose();
        return this;
    }
}





class $50c94488d85f7cab$export$406bc4309a3e7a54 extends (0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($50c94488d85f7cab$export$406bc4309a3e7a54.getDefaults(), arguments, [
            "distortion"
        ]));
        this.name = "Distortion";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($50c94488d85f7cab$export$406bc4309a3e7a54.getDefaults(), arguments, [
            "distortion"
        ]);
        this._shaper = new (0, $c802ebb611a7b944$export$4d933d013693e78)({
            context: this.context,
            length: 4096
        });
        this._distortion = options.distortion;
        this.connectEffect(this._shaper);
        this.distortion = options.distortion;
        this.oversample = options.oversample;
    }
    static getDefaults() {
        return Object.assign((0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04).getDefaults(), {
            distortion: 0.4,
            oversample: "none"
        });
    }
    /**
     * The amount of distortion. Nominal range is between 0 and 1.
     */ get distortion() {
        return this._distortion;
    }
    set distortion(amount) {
        this._distortion = amount;
        const k = amount * 100;
        const deg = Math.PI / 180;
        this._shaper.setMap((x)=>{
            if (Math.abs(x) < 0.001) // should output 0 when input is 0
            return 0;
            else return (3 + k) * x * 20 * deg / (Math.PI + k * Math.abs(x));
        });
    }
    /**
     * The oversampling of the effect. Can either be "none", "2x" or "4x".
     */ get oversample() {
        return this._shaper.oversample;
    }
    set oversample(oversampling) {
        this._shaper.oversample = oversampling;
    }
    dispose() {
        super.dispose();
        this._shaper.dispose();
        return this;
    }
}








class $02ba9c59a192f645$export$125ce1b19cf7db0d extends (0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04) {
    constructor(options){
        super(options);
        this.name = "FeedbackEffect";
        this._feedbackGain = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            gain: options.feedback,
            units: "normalRange"
        });
        this.feedback = this._feedbackGain.gain;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "feedback");
        // the feedback loop
        this.effectReturn.chain(this._feedbackGain, this.effectSend);
    }
    static getDefaults() {
        return Object.assign((0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04).getDefaults(), {
            feedback: 0.125
        });
    }
    dispose() {
        super.dispose();
        this._feedbackGain.dispose();
        this.feedback.dispose();
        return this;
    }
}


class $8c7ffa1824c6758b$export$28e4d032ddc580fa extends (0, $02ba9c59a192f645$export$125ce1b19cf7db0d) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($8c7ffa1824c6758b$export$28e4d032ddc580fa.getDefaults(), arguments, [
            "delayTime",
            "feedback"
        ]));
        this.name = "FeedbackDelay";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($8c7ffa1824c6758b$export$28e4d032ddc580fa.getDefaults(), arguments, [
            "delayTime",
            "feedback"
        ]);
        this._delayNode = new (0, $56c02e4cadfbd835$export$7419ff430885d61c)({
            context: this.context,
            delayTime: options.delayTime,
            maxDelay: options.maxDelay
        });
        this.delayTime = this._delayNode.delayTime;
        // connect it up
        this.connectEffect(this._delayNode);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "delayTime");
    }
    static getDefaults() {
        return Object.assign((0, $02ba9c59a192f645$export$125ce1b19cf7db0d).getDefaults(), {
            delayTime: 0.25,
            maxDelay: 1
        });
    }
    dispose() {
        super.dispose();
        this._delayNode.dispose();
        this.delayTime.dispose();
        return this;
    }
}




class $c5b5299073c0aed7$export$fc0fd2e096a27936 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(options){
        super(options);
        this.name = "PhaseShiftAllpass";
        this.input = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        /**
         * The phase shifted output
         */ this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        /**
         * The PhaseShifted allpass output
         */ this.offset90 = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        const allpassBank1Values = [
            0.6923878,
            0.9360654322959,
            0.9882295226860,
            0.9987488452737
        ];
        const allpassBank2Values = [
            0.4021921162426,
            0.8561710882420,
            0.9722909545651,
            0.9952884791278
        ];
        this._bank0 = this._createAllPassFilterBank(allpassBank1Values);
        this._bank1 = this._createAllPassFilterBank(allpassBank2Values);
        this._oneSampleDelay = this.context.createIIRFilter([
            0.0,
            1.0
        ], [
            1.0,
            0.0
        ]);
        // connect Allpass filter banks
        (0, $5ffbb5654e49c399$export$933c3b67552fb559)(this.input, ...this._bank0, this._oneSampleDelay, this.output);
        (0, $5ffbb5654e49c399$export$933c3b67552fb559)(this.input, ...this._bank1, this.offset90);
    }
    /**
     * Create all of the IIR filters from an array of values using the coefficient calculation.
     */ _createAllPassFilterBank(bankValues) {
        const nodes = bankValues.map((value)=>{
            const coefficients = [
                [
                    value * value,
                    0,
                    -1
                ],
                [
                    1,
                    0,
                    -(value * value)
                ]
            ];
            return this.context.createIIRFilter(coefficients[0], coefficients[1]);
        });
        return nodes;
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this.output.dispose();
        this.offset90.dispose();
        this._bank0.forEach((f)=>f.disconnect());
        this._bank1.forEach((f)=>f.disconnect());
        this._oneSampleDelay.disconnect();
        return this;
    }
}










class $599f671f2fd73281$export$183131474cdbc063 extends (0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($599f671f2fd73281$export$183131474cdbc063.getDefaults(), arguments, [
            "frequency"
        ]));
        this.name = "FrequencyShifter";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($599f671f2fd73281$export$183131474cdbc063.getDefaults(), arguments, [
            "frequency"
        ]);
        this.frequency = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "frequency",
            value: options.frequency,
            minValue: -this.context.sampleRate / 2,
            maxValue: this.context.sampleRate / 2
        });
        this._sine = new (0, $6cdf93678f18ee88$export$284532b021137a4a)({
            context: this.context,
            type: "sine"
        });
        this._cosine = new (0, $72f1219056ac35e7$export$c01c5c7b81696d70)({
            context: this.context,
            phase: -90,
            type: "sine"
        });
        this._sineMultiply = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context
        });
        this._cosineMultiply = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context
        });
        this._negate = new (0, $b3fa615a01f226fd$export$a4e82151127277b0)({
            context: this.context
        });
        this._add = new (0, $8af016fb6845f5f0$export$d0265b2c425512d6)({
            context: this.context
        });
        this._phaseShifter = new (0, $c5b5299073c0aed7$export$fc0fd2e096a27936)({
            context: this.context
        });
        this.effectSend.connect(this._phaseShifter);
        // connect the carrier frequency signal to the two oscillators
        this.frequency.fan(this._sine.frequency, this._cosine.frequency);
        this._phaseShifter.offset90.connect(this._cosineMultiply);
        this._cosine.connect(this._cosineMultiply.factor);
        this._phaseShifter.connect(this._sineMultiply);
        this._sine.connect(this._sineMultiply.factor);
        this._sineMultiply.connect(this._negate);
        this._cosineMultiply.connect(this._add);
        this._negate.connect(this._add.addend);
        this._add.connect(this.effectReturn);
        // start the oscillators at the same time
        const now = this.immediate();
        this._sine.start(now);
        this._cosine.start(now);
    }
    static getDefaults() {
        return Object.assign((0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04).getDefaults(), {
            frequency: 0
        });
    }
    dispose() {
        super.dispose();
        this.frequency.dispose();
        this._add.dispose();
        this._cosine.dispose();
        this._cosineMultiply.dispose();
        this._negate.dispose();
        this._phaseShifter.dispose();
        this._sine.dispose();
        this._sineMultiply.dispose();
        return this;
    }
}







/**
 * An array of comb filter delay values from Freeverb implementation
 */ const $d39bd5dc1652468f$var$combFilterTunings = [
    1557 / 44100,
    1617 / 44100,
    1491 / 44100,
    1422 / 44100,
    1277 / 44100,
    1356 / 44100,
    1188 / 44100,
    1116 / 44100
];
/**
 * An array of allpass filter frequency values from Freeverb implementation
 */ const $d39bd5dc1652468f$var$allpassFilterFrequencies = [
    225,
    556,
    441,
    341
];
class $d39bd5dc1652468f$export$8f91cfa34e3c0ba extends (0, $b5261ce805244afa$export$f02761adf21def8a) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($d39bd5dc1652468f$export$8f91cfa34e3c0ba.getDefaults(), arguments, [
            "roomSize",
            "dampening"
        ]));
        this.name = "Freeverb";
        /**
         * the comb filters
         */ this._combFilters = [];
        /**
         * the allpass filters on the left
         */ this._allpassFiltersL = [];
        /**
         * the allpass filters on the right
         */ this._allpassFiltersR = [];
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($d39bd5dc1652468f$export$8f91cfa34e3c0ba.getDefaults(), arguments, [
            "roomSize",
            "dampening"
        ]);
        this.roomSize = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            value: options.roomSize,
            units: "normalRange"
        });
        // make the allpass filters on the right
        this._allpassFiltersL = $d39bd5dc1652468f$var$allpassFilterFrequencies.map((freq)=>{
            const allpassL = this.context.createBiquadFilter();
            allpassL.type = "allpass";
            allpassL.frequency.value = freq;
            return allpassL;
        });
        // make the allpass filters on the left
        this._allpassFiltersR = $d39bd5dc1652468f$var$allpassFilterFrequencies.map((freq)=>{
            const allpassR = this.context.createBiquadFilter();
            allpassR.type = "allpass";
            allpassR.frequency.value = freq;
            return allpassR;
        });
        // make the comb filters
        this._combFilters = $d39bd5dc1652468f$var$combFilterTunings.map((delayTime, index)=>{
            const lfpf = new (0, $d5cfc15065c61b81$export$e83d2527589f5587)({
                context: this.context,
                dampening: options.dampening,
                delayTime: delayTime
            });
            if (index < $d39bd5dc1652468f$var$combFilterTunings.length / 2) this.connectEffectLeft(lfpf, ...this._allpassFiltersL);
            else this.connectEffectRight(lfpf, ...this._allpassFiltersR);
            this.roomSize.connect(lfpf.resonance);
            return lfpf;
        });
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "roomSize"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $b5261ce805244afa$export$f02761adf21def8a).getDefaults(), {
            roomSize: 0.7,
            dampening: 3000
        });
    }
    /**
     * The amount of dampening of the reverberant signal.
     */ get dampening() {
        return this._combFilters[0].dampening;
    }
    set dampening(d) {
        this._combFilters.forEach((c)=>c.dampening = d);
    }
    dispose() {
        super.dispose();
        this._allpassFiltersL.forEach((al)=>al.disconnect());
        this._allpassFiltersR.forEach((ar)=>ar.disconnect());
        this._combFilters.forEach((cf)=>cf.dispose());
        this.roomSize.dispose();
        return this;
    }
}








/**
 * an array of the comb filter delay time values
 */ const $8b72924b675a0287$var$combFilterDelayTimes = [
    0.06748,
    0.06404,
    0.08212,
    0.09004
];
/**
 * the resonances of each of the comb filters
 */ const $8b72924b675a0287$var$combFilterResonances = [
    0.773,
    0.802,
    0.753,
    0.733
];
/**
 * the allpass filter frequencies
 */ const $8b72924b675a0287$var$allpassFilterFreqs = [
    347,
    113,
    37
];
class $8b72924b675a0287$export$d0cb5d67c6f5133d extends (0, $b5261ce805244afa$export$f02761adf21def8a) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($8b72924b675a0287$export$d0cb5d67c6f5133d.getDefaults(), arguments, [
            "roomSize"
        ]));
        this.name = "JCReverb";
        /**
         * a series of allpass filters
         */ this._allpassFilters = [];
        /**
         * parallel feedback comb filters
         */ this._feedbackCombFilters = [];
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($8b72924b675a0287$export$d0cb5d67c6f5133d.getDefaults(), arguments, [
            "roomSize"
        ]);
        this.roomSize = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            value: options.roomSize,
            units: "normalRange"
        });
        this._scaleRoomSize = new (0, $768d8baaf984bb1a$export$d60cfc58d3c358b6)({
            context: this.context,
            min: -0.733,
            max: 0.197
        });
        // make the allpass filters
        this._allpassFilters = $8b72924b675a0287$var$allpassFilterFreqs.map((freq)=>{
            const allpass = this.context.createBiquadFilter();
            allpass.type = "allpass";
            allpass.frequency.value = freq;
            return allpass;
        });
        // and the comb filters
        this._feedbackCombFilters = $8b72924b675a0287$var$combFilterDelayTimes.map((delayTime, index)=>{
            const fbcf = new (0, $74e53ba3038a6a01$export$e7a685a7e8ffb78a)({
                context: this.context,
                delayTime: delayTime
            });
            this._scaleRoomSize.connect(fbcf.resonance);
            fbcf.resonance.value = $8b72924b675a0287$var$combFilterResonances[index];
            if (index < $8b72924b675a0287$var$combFilterDelayTimes.length / 2) this.connectEffectLeft(...this._allpassFilters, fbcf);
            else this.connectEffectRight(...this._allpassFilters, fbcf);
            return fbcf;
        });
        // chain the allpass filters together
        this.roomSize.connect(this._scaleRoomSize);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "roomSize"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $b5261ce805244afa$export$f02761adf21def8a).getDefaults(), {
            roomSize: 0.5
        });
    }
    dispose() {
        super.dispose();
        this._allpassFilters.forEach((apf)=>apf.disconnect());
        this._feedbackCombFilters.forEach((fbcf)=>fbcf.dispose());
        this.roomSize.dispose();
        this._scaleRoomSize.dispose();
        return this;
    }
}




class $69062ece8473fcd8$export$a40db16ae36574f7 extends (0, $ca4464851f4de725$export$d911e987c738486e) {
    constructor(options){
        super(options);
        // the left output connected to the right input
        this._feedbackL.disconnect();
        this._feedbackL.connect(this._feedbackMerge, 0, 1);
        // the left output connected to the right input
        this._feedbackR.disconnect();
        this._feedbackR.connect(this._feedbackMerge, 0, 0);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "feedback"
        ]);
    }
}






class $cc63d54c075fb4ba$export$7920b8962af65831 extends (0, $69062ece8473fcd8$export$a40db16ae36574f7) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($cc63d54c075fb4ba$export$7920b8962af65831.getDefaults(), arguments, [
            "delayTime",
            "feedback"
        ]));
        this.name = "PingPongDelay";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($cc63d54c075fb4ba$export$7920b8962af65831.getDefaults(), arguments, [
            "delayTime",
            "feedback"
        ]);
        this._leftDelay = new (0, $56c02e4cadfbd835$export$7419ff430885d61c)({
            context: this.context,
            maxDelay: options.maxDelay
        });
        this._rightDelay = new (0, $56c02e4cadfbd835$export$7419ff430885d61c)({
            context: this.context,
            maxDelay: options.maxDelay
        });
        this._rightPreDelay = new (0, $56c02e4cadfbd835$export$7419ff430885d61c)({
            context: this.context,
            maxDelay: options.maxDelay
        });
        this.delayTime = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "time",
            value: options.delayTime
        });
        // connect it up
        this.connectEffectLeft(this._leftDelay);
        this.connectEffectRight(this._rightPreDelay, this._rightDelay);
        this.delayTime.fan(this._leftDelay.delayTime, this._rightDelay.delayTime, this._rightPreDelay.delayTime);
        // rearranged the feedback to be after the rightPreDelay
        this._feedbackL.disconnect();
        this._feedbackL.connect(this._rightDelay);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "delayTime"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $69062ece8473fcd8$export$a40db16ae36574f7).getDefaults(), {
            delayTime: 0.25,
            maxDelay: 1
        });
    }
    dispose() {
        super.dispose();
        this._leftDelay.dispose();
        this._rightDelay.dispose();
        this._rightPreDelay.dispose();
        this.delayTime.dispose();
        return this;
    }
}










class $1c49b11c5dd9e120$export$996a02cfaea06f8f extends (0, $02ba9c59a192f645$export$125ce1b19cf7db0d) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($1c49b11c5dd9e120$export$996a02cfaea06f8f.getDefaults(), arguments, [
            "pitch"
        ]));
        this.name = "PitchShift";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($1c49b11c5dd9e120$export$996a02cfaea06f8f.getDefaults(), arguments, [
            "pitch"
        ]);
        this._frequency = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context
        });
        this._delayA = new (0, $56c02e4cadfbd835$export$7419ff430885d61c)({
            maxDelay: 1,
            context: this.context
        });
        this._lfoA = new (0, $4a4529bace75b797$export$603054d5ec296d77)({
            context: this.context,
            min: 0,
            max: 0.1,
            type: "sawtooth"
        }).connect(this._delayA.delayTime);
        this._delayB = new (0, $56c02e4cadfbd835$export$7419ff430885d61c)({
            maxDelay: 1,
            context: this.context
        });
        this._lfoB = new (0, $4a4529bace75b797$export$603054d5ec296d77)({
            context: this.context,
            min: 0,
            max: 0.1,
            type: "sawtooth",
            phase: 180
        }).connect(this._delayB.delayTime);
        this._crossFade = new (0, $75598ffdc68d5042$export$d78c8c6074541cf2)({
            context: this.context
        });
        this._crossFadeLFO = new (0, $4a4529bace75b797$export$603054d5ec296d77)({
            context: this.context,
            min: 0,
            max: 1,
            type: "triangle",
            phase: 90
        }).connect(this._crossFade.fade);
        this._feedbackDelay = new (0, $56c02e4cadfbd835$export$7419ff430885d61c)({
            delayTime: options.delayTime,
            context: this.context
        });
        this.delayTime = this._feedbackDelay.delayTime;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "delayTime");
        this._pitch = options.pitch;
        this._windowSize = options.windowSize;
        // connect the two delay lines up
        this._delayA.connect(this._crossFade.a);
        this._delayB.connect(this._crossFade.b);
        // connect the frequency
        this._frequency.fan(this._lfoA.frequency, this._lfoB.frequency, this._crossFadeLFO.frequency);
        // route the input
        this.effectSend.fan(this._delayA, this._delayB);
        this._crossFade.chain(this._feedbackDelay, this.effectReturn);
        // start the LFOs at the same time
        const now = this.now();
        this._lfoA.start(now);
        this._lfoB.start(now);
        this._crossFadeLFO.start(now);
        // set the initial value
        this.windowSize = this._windowSize;
    }
    static getDefaults() {
        return Object.assign((0, $02ba9c59a192f645$export$125ce1b19cf7db0d).getDefaults(), {
            pitch: 0,
            windowSize: 0.1,
            delayTime: 0,
            feedback: 0
        });
    }
    /**
     * Repitch the incoming signal by some interval (measured in semi-tones).
     * @example
     * const pitchShift = new Tone.PitchShift().toDestination();
     * const osc = new Tone.Oscillator().connect(pitchShift).start().toDestination();
     * pitchShift.pitch = -12; // down one octave
     * pitchShift.pitch = 7; // up a fifth
     */ get pitch() {
        return this._pitch;
    }
    set pitch(interval) {
        this._pitch = interval;
        let factor = 0;
        if (interval < 0) {
            this._lfoA.min = 0;
            this._lfoA.max = this._windowSize;
            this._lfoB.min = 0;
            this._lfoB.max = this._windowSize;
            factor = (0, $73949b14fe57a99a$export$5d18fe46719f6008)(interval - 1) + 1;
        } else {
            this._lfoA.min = this._windowSize;
            this._lfoA.max = 0;
            this._lfoB.min = this._windowSize;
            this._lfoB.max = 0;
            factor = (0, $73949b14fe57a99a$export$5d18fe46719f6008)(interval) - 1;
        }
        this._frequency.value = factor * (1.2 / this._windowSize);
    }
    /**
     * The window size corresponds roughly to the sample length in a looping sampler.
     * Smaller values are desirable for a less noticeable delay time of the pitch shifted
     * signal, but larger values will result in smoother pitch shifting for larger intervals.
     * A nominal range of 0.03 to 0.1 is recommended.
     */ get windowSize() {
        return this._windowSize;
    }
    set windowSize(size) {
        this._windowSize = this.toSeconds(size);
        this.pitch = this._pitch;
    }
    dispose() {
        super.dispose();
        this._frequency.dispose();
        this._delayA.dispose();
        this._delayB.dispose();
        this._lfoA.dispose();
        this._lfoB.dispose();
        this._crossFade.dispose();
        this._crossFadeLFO.dispose();
        this._feedbackDelay.dispose();
        return this;
    }
}







class $ffd2cb46801c7692$export$1be4418d8537c3f5 extends (0, $b5261ce805244afa$export$f02761adf21def8a) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($ffd2cb46801c7692$export$1be4418d8537c3f5.getDefaults(), arguments, [
            "frequency",
            "octaves",
            "baseFrequency"
        ]));
        this.name = "Phaser";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($ffd2cb46801c7692$export$1be4418d8537c3f5.getDefaults(), arguments, [
            "frequency",
            "octaves",
            "baseFrequency"
        ]);
        this._lfoL = new (0, $4a4529bace75b797$export$603054d5ec296d77)({
            context: this.context,
            frequency: options.frequency,
            min: 0,
            max: 1
        });
        this._lfoR = new (0, $4a4529bace75b797$export$603054d5ec296d77)({
            context: this.context,
            frequency: options.frequency,
            min: 0,
            max: 1,
            phase: 180
        });
        this._baseFrequency = this.toFrequency(options.baseFrequency);
        this._octaves = options.octaves;
        this.Q = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            value: options.Q,
            units: "positive"
        });
        this._filtersL = this._makeFilters(options.stages, this._lfoL);
        this._filtersR = this._makeFilters(options.stages, this._lfoR);
        this.frequency = this._lfoL.frequency;
        this.frequency.value = options.frequency;
        // connect them up
        this.connectEffectLeft(...this._filtersL);
        this.connectEffectRight(...this._filtersR);
        // control the frequency with one LFO
        this._lfoL.frequency.connect(this._lfoR.frequency);
        // set the options
        this.baseFrequency = options.baseFrequency;
        this.octaves = options.octaves;
        // start the lfo
        this._lfoL.start();
        this._lfoR.start();
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "frequency",
            "Q"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $b5261ce805244afa$export$f02761adf21def8a).getDefaults(), {
            frequency: 0.5,
            octaves: 3,
            stages: 10,
            Q: 10,
            baseFrequency: 350
        });
    }
    _makeFilters(stages, connectToFreq) {
        const filters = [];
        // make all the filters
        for(let i = 0; i < stages; i++){
            const filter = this.context.createBiquadFilter();
            filter.type = "allpass";
            this.Q.connect(filter.Q);
            connectToFreq.connect(filter.frequency);
            filters.push(filter);
        }
        return filters;
    }
    /**
     * The number of octaves the phase goes above the baseFrequency
     */ get octaves() {
        return this._octaves;
    }
    set octaves(octaves) {
        this._octaves = octaves;
        const max = this._baseFrequency * Math.pow(2, octaves);
        this._lfoL.max = max;
        this._lfoR.max = max;
    }
    /**
     * The the base frequency of the filters.
     */ get baseFrequency() {
        return this._baseFrequency;
    }
    set baseFrequency(freq) {
        this._baseFrequency = this.toFrequency(freq);
        this._lfoL.min = this._baseFrequency;
        this._lfoR.min = this._baseFrequency;
        this.octaves = this._octaves;
    }
    dispose() {
        super.dispose();
        this.Q.dispose();
        this._lfoL.dispose();
        this._lfoR.dispose();
        this._filtersL.forEach((f)=>f.disconnect());
        this._filtersR.forEach((f)=>f.disconnect());
        this.frequency.dispose();
        return this;
    }
}











class $2e8f4e99de55838b$export$6fb1520d4329a18d extends (0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($2e8f4e99de55838b$export$6fb1520d4329a18d.getDefaults(), arguments, [
            "decay"
        ]));
        this.name = "Reverb";
        /**
         * Convolver node
         */ this._convolver = this.context.createConvolver();
        /**
         * Resolves when the reverb buffer is generated. Whenever either [[decay]]
         * or [[preDelay]] are set, you have to wait until [[ready]] resolves
         * before the IR is generated with the latest values.
         */ this.ready = Promise.resolve();
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($2e8f4e99de55838b$export$6fb1520d4329a18d.getDefaults(), arguments, [
            "decay"
        ]);
        this._decay = options.decay;
        this._preDelay = options.preDelay;
        this.generate();
        this.connectEffect(this._convolver);
    }
    static getDefaults() {
        return Object.assign((0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04).getDefaults(), {
            decay: 1.5,
            preDelay: 0.01
        });
    }
    /**
     * The duration of the reverb.
     */ get decay() {
        return this._decay;
    }
    set decay(time) {
        time = this.toSeconds(time);
        (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(time, 0.001);
        this._decay = time;
        this.generate();
    }
    /**
     * The amount of time before the reverb is fully ramped in.
     */ get preDelay() {
        return this._preDelay;
    }
    set preDelay(time) {
        time = this.toSeconds(time);
        (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(time, 0);
        this._preDelay = time;
        this.generate();
    }
    /**
     * Generate the Impulse Response. Returns a promise while the IR is being generated.
     * @return Promise which returns this object.
     */ generate() {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            const previousReady = this.ready;
            // create a noise burst which decays over the duration in each channel
            const context = new (0, $d73ede3d936d3e15$export$46814dd5412c611c)(2, this._decay + this._preDelay, this.context.sampleRate);
            const noiseL = new (0, $76955c76dcac2d3e$export$484d33a0500a4ce1)({
                context: context
            });
            const noiseR = new (0, $76955c76dcac2d3e$export$484d33a0500a4ce1)({
                context: context
            });
            const merge = new (0, $4541bd4bd7add640$export$70ce1d34efd3b886)({
                context: context
            });
            noiseL.connect(merge, 0, 0);
            noiseR.connect(merge, 0, 1);
            const gainNode = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
                context: context
            }).toDestination();
            merge.connect(gainNode);
            noiseL.start(0);
            noiseR.start(0);
            // predelay
            gainNode.gain.setValueAtTime(0, 0);
            gainNode.gain.setValueAtTime(1, this._preDelay);
            // decay
            gainNode.gain.exponentialApproachValueAtTime(0, this._preDelay, this.decay);
            // render the buffer
            const renderPromise = context.render();
            this.ready = renderPromise.then((0, $c0a1ee726091e30a$export$b50b6e108474309b));
            // wait for the previous `ready` to resolve
            yield previousReady;
            // set the buffer
            this._convolver.buffer = (yield renderPromise).get();
            return this;
        });
    }
    dispose() {
        super.dispose();
        this._convolver.disconnect();
        return this;
    }
}









class $6310c804325bea77$export$17b3caaa07b8690f extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($6310c804325bea77$export$17b3caaa07b8690f.getDefaults(), arguments));
        this.name = "MidSideSplit";
        this._split = this.input = new (0, $bbae2f8bfe6afb52$export$f836382419f64c98)({
            channels: 2,
            context: this.context
        });
        this._midAdd = new (0, $8af016fb6845f5f0$export$d0265b2c425512d6)({
            context: this.context
        });
        this.mid = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            value: Math.SQRT1_2
        });
        this._sideSubtract = new (0, $26f37f85e6014122$export$8bc67ae85ef4b74f)({
            context: this.context
        });
        this.side = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            value: Math.SQRT1_2
        });
        this._split.connect(this._midAdd, 0);
        this._split.connect(this._midAdd.addend, 1);
        this._split.connect(this._sideSubtract, 0);
        this._split.connect(this._sideSubtract.subtrahend, 1);
        this._midAdd.connect(this.mid);
        this._sideSubtract.connect(this.side);
    }
    dispose() {
        super.dispose();
        this.mid.dispose();
        this.side.dispose();
        this._midAdd.dispose();
        this._sideSubtract.dispose();
        this._split.dispose();
        return this;
    }
}









class $10d6ea2b5230f5e8$export$be84ddbe7b4fbb5a extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($10d6ea2b5230f5e8$export$be84ddbe7b4fbb5a.getDefaults(), arguments));
        this.name = "MidSideMerge";
        this.mid = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this.side = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this._left = new (0, $8af016fb6845f5f0$export$d0265b2c425512d6)({
            context: this.context
        });
        this._leftMult = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            value: Math.SQRT1_2
        });
        this._right = new (0, $26f37f85e6014122$export$8bc67ae85ef4b74f)({
            context: this.context
        });
        this._rightMult = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            value: Math.SQRT1_2
        });
        this._merge = this.output = new (0, $4541bd4bd7add640$export$70ce1d34efd3b886)({
            context: this.context
        });
        this.mid.fan(this._left);
        this.side.connect(this._left.addend);
        this.mid.connect(this._right);
        this.side.connect(this._right.subtrahend);
        this._left.connect(this._leftMult);
        this._right.connect(this._rightMult);
        this._leftMult.connect(this._merge, 0, 0);
        this._rightMult.connect(this._merge, 0, 1);
    }
    dispose() {
        super.dispose();
        this.mid.dispose();
        this.side.dispose();
        this._leftMult.dispose();
        this._rightMult.dispose();
        this._left.dispose();
        this._right.dispose();
        return this;
    }
}


class $45c7d1c8cad0f27b$export$67948bb93e06c2e extends (0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04) {
    constructor(options){
        super(options);
        this.name = "MidSideEffect";
        this._midSideMerge = new (0, $10d6ea2b5230f5e8$export$be84ddbe7b4fbb5a)({
            context: this.context
        });
        this._midSideSplit = new (0, $6310c804325bea77$export$17b3caaa07b8690f)({
            context: this.context
        });
        this._midSend = this._midSideSplit.mid;
        this._sideSend = this._midSideSplit.side;
        this._midReturn = this._midSideMerge.mid;
        this._sideReturn = this._midSideMerge.side;
        // the connections
        this.effectSend.connect(this._midSideSplit);
        this._midSideMerge.connect(this.effectReturn);
    }
    /**
     * Connect the mid chain of the effect
     */ connectEffectMid(...nodes) {
        this._midSend.chain(...nodes, this._midReturn);
    }
    /**
     * Connect the side chain of the effect
     */ connectEffectSide(...nodes) {
        this._sideSend.chain(...nodes, this._sideReturn);
    }
    dispose() {
        super.dispose();
        this._midSideSplit.dispose();
        this._midSideMerge.dispose();
        this._midSend.dispose();
        this._sideSend.dispose();
        this._midReturn.dispose();
        this._sideReturn.dispose();
        return this;
    }
}








class $635da1bb654ffce6$export$54593a5432d0d54c extends (0, $45c7d1c8cad0f27b$export$67948bb93e06c2e) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($635da1bb654ffce6$export$54593a5432d0d54c.getDefaults(), arguments, [
            "width"
        ]));
        this.name = "StereoWidener";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($635da1bb654ffce6$export$54593a5432d0d54c.getDefaults(), arguments, [
            "width"
        ]);
        this.width = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            value: options.width,
            units: "normalRange"
        });
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "width"
        ]);
        this._twoTimesWidthMid = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            value: 2
        });
        this._twoTimesWidthSide = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context,
            value: 2
        });
        this._midMult = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context
        });
        this._twoTimesWidthMid.connect(this._midMult.factor);
        this.connectEffectMid(this._midMult);
        this._oneMinusWidth = new (0, $26f37f85e6014122$export$8bc67ae85ef4b74f)({
            context: this.context
        });
        this._oneMinusWidth.connect(this._twoTimesWidthMid);
        (0, $5ffbb5654e49c399$export$64605811ab45167f)(this.context.getConstant(1), this._oneMinusWidth);
        this.width.connect(this._oneMinusWidth.subtrahend);
        this._sideMult = new (0, $cc8144811f713d56$export$f14f83b3b531d498)({
            context: this.context
        });
        this.width.connect(this._twoTimesWidthSide);
        this._twoTimesWidthSide.connect(this._sideMult.factor);
        this.connectEffectSide(this._sideMult);
    }
    static getDefaults() {
        return Object.assign((0, $45c7d1c8cad0f27b$export$67948bb93e06c2e).getDefaults(), {
            width: 0.5
        });
    }
    dispose() {
        super.dispose();
        this.width.dispose();
        this._midMult.dispose();
        this._sideMult.dispose();
        this._twoTimesWidthMid.dispose();
        this._twoTimesWidthSide.dispose();
        this._oneMinusWidth.dispose();
        return this;
    }
}








class $6fff70457d338dae$export$74a4578e446afdc7 extends (0, $b5261ce805244afa$export$f02761adf21def8a) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($6fff70457d338dae$export$74a4578e446afdc7.getDefaults(), arguments, [
            "frequency",
            "depth"
        ]));
        this.name = "Tremolo";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($6fff70457d338dae$export$74a4578e446afdc7.getDefaults(), arguments, [
            "frequency",
            "depth"
        ]);
        this._lfoL = new (0, $4a4529bace75b797$export$603054d5ec296d77)({
            context: this.context,
            type: options.type,
            min: 1,
            max: 0
        });
        this._lfoR = new (0, $4a4529bace75b797$export$603054d5ec296d77)({
            context: this.context,
            type: options.type,
            min: 1,
            max: 0
        });
        this._amplitudeL = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this._amplitudeR = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this.frequency = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            value: options.frequency,
            units: "frequency"
        });
        this.depth = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            value: options.depth,
            units: "normalRange"
        });
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "frequency",
            "depth"
        ]);
        this.connectEffectLeft(this._amplitudeL);
        this.connectEffectRight(this._amplitudeR);
        this._lfoL.connect(this._amplitudeL.gain);
        this._lfoR.connect(this._amplitudeR.gain);
        this.frequency.fan(this._lfoL.frequency, this._lfoR.frequency);
        this.depth.fan(this._lfoR.amplitude, this._lfoL.amplitude);
        this.spread = options.spread;
    }
    static getDefaults() {
        return Object.assign((0, $b5261ce805244afa$export$f02761adf21def8a).getDefaults(), {
            frequency: 10,
            type: "sine",
            depth: 0.5,
            spread: 180
        });
    }
    /**
     * Start the tremolo.
     */ start(time) {
        this._lfoL.start(time);
        this._lfoR.start(time);
        return this;
    }
    /**
     * Stop the tremolo.
     */ stop(time) {
        this._lfoL.stop(time);
        this._lfoR.stop(time);
        return this;
    }
    /**
     * Sync the effect to the transport.
     */ sync() {
        this._lfoL.sync();
        this._lfoR.sync();
        this.context.transport.syncSignal(this.frequency);
        return this;
    }
    /**
     * Unsync the filter from the transport
     */ unsync() {
        this._lfoL.unsync();
        this._lfoR.unsync();
        this.context.transport.unsyncSignal(this.frequency);
        return this;
    }
    /**
     * The oscillator type.
     */ get type() {
        return this._lfoL.type;
    }
    set type(type) {
        this._lfoL.type = type;
        this._lfoR.type = type;
    }
    /**
     * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.
     * When set to 180, LFO's will be panned hard left and right respectively.
     */ get spread() {
        return this._lfoR.phase - this._lfoL.phase; // 180
    }
    set spread(spread) {
        this._lfoL.phase = 90 - spread / 2;
        this._lfoR.phase = spread / 2 + 90;
    }
    dispose() {
        super.dispose();
        this._lfoL.dispose();
        this._lfoR.dispose();
        this._amplitudeL.dispose();
        this._amplitudeR.dispose();
        this.frequency.dispose();
        this.depth.dispose();
        return this;
    }
}







class $bc9299b2342538fb$export$eb898fc31d087455 extends (0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($bc9299b2342538fb$export$eb898fc31d087455.getDefaults(), arguments, [
            "frequency",
            "depth"
        ]));
        this.name = "Vibrato";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($bc9299b2342538fb$export$eb898fc31d087455.getDefaults(), arguments, [
            "frequency",
            "depth"
        ]);
        this._delayNode = new (0, $56c02e4cadfbd835$export$7419ff430885d61c)({
            context: this.context,
            delayTime: 0,
            maxDelay: options.maxDelay
        });
        this._lfo = new (0, $4a4529bace75b797$export$603054d5ec296d77)({
            context: this.context,
            type: options.type,
            min: 0,
            max: options.maxDelay,
            frequency: options.frequency,
            phase: -90 // offse the phase so the resting position is in the center
        }).start().connect(this._delayNode.delayTime);
        this.frequency = this._lfo.frequency;
        this.depth = this._lfo.amplitude;
        this.depth.value = options.depth;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "frequency",
            "depth"
        ]);
        this.effectSend.chain(this._delayNode, this.effectReturn);
    }
    static getDefaults() {
        return Object.assign((0, $afc8de7abeb2ad05$export$a32b0b1c1ac59d04).getDefaults(), {
            maxDelay: 0.005,
            frequency: 5,
            depth: 0.1,
            type: "sine"
        });
    }
    /**
     * Type of oscillator attached to the Vibrato.
     */ get type() {
        return this._lfo.type;
    }
    set type(type) {
        this._lfo.type = type;
    }
    dispose() {
        super.dispose();
        this._delayNode.dispose();
        this._lfo.dispose();
        this.frequency.dispose();
        this.depth.dispose();
        return this;
    }
}









class $8a7fae7f19e5c503$export$86a05438820989b0 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($8a7fae7f19e5c503$export$86a05438820989b0.getDefaults(), arguments, [
            "type",
            "size"
        ]));
        this.name = "Analyser";
        /**
         * The analyser node.
         */ this._analysers = [];
        /**
         * The buffer that the FFT data is written to
         */ this._buffers = [];
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($8a7fae7f19e5c503$export$86a05438820989b0.getDefaults(), arguments, [
            "type",
            "size"
        ]);
        this.input = this.output = this._gain = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this._split = new (0, $bbae2f8bfe6afb52$export$f836382419f64c98)({
            context: this.context,
            channels: options.channels
        });
        this.input.connect(this._split);
        (0, $23cf54af36cc9441$export$6698b6d148bc9b0c)(options.channels, 1);
        // create the analysers
        for(let channel = 0; channel < options.channels; channel++){
            this._analysers[channel] = this.context.createAnalyser();
            this._split.connect(this._analysers[channel], channel, 0);
        }
        // set the values initially
        this.size = options.size;
        this.type = options.type;
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            size: 1024,
            smoothing: 0.8,
            type: "fft",
            channels: 1
        });
    }
    /**
     * Run the analysis given the current settings. If [[channels]] = 1,
     * it will return a Float32Array. If [[channels]] > 1, it will
     * return an array of Float32Arrays where each index in the array
     * represents the analysis done on a channel.
     */ getValue() {
        this._analysers.forEach((analyser, index)=>{
            const buffer = this._buffers[index];
            if (this._type === "fft") analyser.getFloatFrequencyData(buffer);
            else if (this._type === "waveform") analyser.getFloatTimeDomainData(buffer);
        });
        if (this.channels === 1) return this._buffers[0];
        else return this._buffers;
    }
    /**
     * The size of analysis. This must be a power of two in the range 16 to 16384.
     */ get size() {
        return this._analysers[0].frequencyBinCount;
    }
    set size(size) {
        this._analysers.forEach((analyser, index)=>{
            analyser.fftSize = size * 2;
            this._buffers[index] = new Float32Array(size);
        });
    }
    /**
     * The number of channels the analyser does the analysis on. Channel
     * separation is done using [[Split]]
     */ get channels() {
        return this._analysers.length;
    }
    /**
     * The analysis function returned by analyser.getValue(), either "fft" or "waveform".
     */ get type() {
        return this._type;
    }
    set type(type) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(type === "waveform" || type === "fft", `Analyser: invalid type: ${type}`);
        this._type = type;
    }
    /**
     * 0 represents no time averaging with the last analysis frame.
     */ get smoothing() {
        return this._analysers[0].smoothingTimeConstant;
    }
    set smoothing(val) {
        this._analysers.forEach((a)=>a.smoothingTimeConstant = val);
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._analysers.forEach((a)=>a.disconnect());
        this._split.dispose();
        this._gain.dispose();
        return this;
    }
}







class $22d420f559d9ede9$export$67f5eb90858fca69 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($22d420f559d9ede9$export$67f5eb90858fca69.getDefaults(), arguments));
        this.name = "MeterBase";
        this.input = this.output = this._analyser = new (0, $8a7fae7f19e5c503$export$86a05438820989b0)({
            context: this.context,
            size: 256,
            type: "waveform"
        });
    }
    dispose() {
        super.dispose();
        this._analyser.dispose();
        return this;
    }
}




class $714e20bcd3b19d1f$export$62e3ae2a4090b879 extends (0, $22d420f559d9ede9$export$67f5eb90858fca69) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($714e20bcd3b19d1f$export$62e3ae2a4090b879.getDefaults(), arguments, [
            "smoothing"
        ]));
        this.name = "Meter";
        /**
         * The previous frame's value
         */ this._rms = 0;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($714e20bcd3b19d1f$export$62e3ae2a4090b879.getDefaults(), arguments, [
            "smoothing"
        ]);
        this.input = this.output = this._analyser = new (0, $8a7fae7f19e5c503$export$86a05438820989b0)({
            context: this.context,
            size: 256,
            type: "waveform",
            channels: options.channels
        });
        this.smoothing = options.smoothing, this.normalRange = options.normalRange;
    }
    static getDefaults() {
        return Object.assign((0, $22d420f559d9ede9$export$67f5eb90858fca69).getDefaults(), {
            smoothing: 0.8,
            normalRange: false,
            channels: 1
        });
    }
    /**
     * Use [[getValue]] instead. For the previous getValue behavior, use DCMeter.
     * @deprecated
     */ getLevel() {
        (0, $23cf54af36cc9441$export$c106dd0671a0fc2d)("'getLevel' has been changed to 'getValue'");
        return this.getValue();
    }
    /**
     * Get the current value of the incoming signal.
     * Output is in decibels when [[normalRange]] is `false`.
     * If [[channels]] = 1, then the output is a single number
     * representing the value of the input signal. When [[channels]] > 1,
     * then each channel is returned as a value in a number array.
     */ getValue() {
        const aValues = this._analyser.getValue();
        const channelValues = this.channels === 1 ? [
            aValues
        ] : aValues;
        const vals = channelValues.map((values)=>{
            const totalSquared = values.reduce((total, current)=>total + current * current, 0);
            const rms = Math.sqrt(totalSquared / values.length);
            // the rms can only fall at the rate of the smoothing
            // but can jump up instantly
            this._rms = Math.max(rms, this._rms * this.smoothing);
            return this.normalRange ? this._rms : (0, $73949b14fe57a99a$export$6af3969727ca2a60)(this._rms);
        });
        if (this.channels === 1) return vals[0];
        else return vals;
    }
    /**
     * The number of channels of analysis.
     */ get channels() {
        return this._analyser.channels;
    }
    dispose() {
        super.dispose();
        this._analyser.dispose();
        return this;
    }
}







class $2b31ea7f46276f24$export$677347237c014ba extends (0, $22d420f559d9ede9$export$67f5eb90858fca69) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($2b31ea7f46276f24$export$677347237c014ba.getDefaults(), arguments, [
            "size"
        ]));
        this.name = "FFT";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($2b31ea7f46276f24$export$677347237c014ba.getDefaults(), arguments, [
            "size"
        ]);
        this.normalRange = options.normalRange;
        this._analyser.type = "fft";
        this.size = options.size;
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            normalRange: false,
            size: 1024,
            smoothing: 0.8
        });
    }
    /**
     * Gets the current frequency data from the connected audio source.
     * Returns the frequency data of length [[size]] as a Float32Array of decibel values.
     */ getValue() {
        const values = this._analyser.getValue();
        return values.map((v)=>this.normalRange ? (0, $73949b14fe57a99a$export$33ed28de027e9482)(v) : v);
    }
    /**
     * The size of analysis. This must be a power of two in the range 16 to 16384.
     * Determines the size of the array returned by [[getValue]] (i.e. the number of
     * frequency bins). Large FFT sizes may be costly to compute.
     */ get size() {
        return this._analyser.size;
    }
    set size(size) {
        this._analyser.size = size;
    }
    /**
     * 0 represents no time averaging with the last analysis frame.
     */ get smoothing() {
        return this._analyser.smoothing;
    }
    set smoothing(val) {
        this._analyser.smoothing = val;
    }
    /**
     * Returns the frequency value in hertz of each of the indices of the FFT's [[getValue]] response.
     * @example
     * const fft = new Tone.FFT(32);
     * console.log([0, 1, 2, 3, 4].map(index => fft.getFrequencyOfIndex(index)));
     */ getFrequencyOfIndex(index) {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(0 <= index && index < this.size, `index must be greater than or equal to 0 and less than ${this.size}`);
        return index * this.context.sampleRate / (this.size * 2);
    }
}




class $90a978df890ffdd4$export$29aa14d256c74cc6 extends (0, $22d420f559d9ede9$export$67f5eb90858fca69) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($90a978df890ffdd4$export$29aa14d256c74cc6.getDefaults(), arguments));
        this.name = "DCMeter";
        this._analyser.type = "waveform";
        this._analyser.size = 256;
    }
    /**
     * Get the signal value of the incoming signal
     */ getValue() {
        const value = this._analyser.getValue();
        return value[0];
    }
}




class $55a479a86f3c7c48$export$4c2f72a4f17a358e extends (0, $22d420f559d9ede9$export$67f5eb90858fca69) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($55a479a86f3c7c48$export$4c2f72a4f17a358e.getDefaults(), arguments, [
            "size"
        ]));
        this.name = "Waveform";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($55a479a86f3c7c48$export$4c2f72a4f17a358e.getDefaults(), arguments, [
            "size"
        ]);
        this._analyser.type = "waveform";
        this.size = options.size;
    }
    static getDefaults() {
        return Object.assign((0, $22d420f559d9ede9$export$67f5eb90858fca69).getDefaults(), {
            size: 1024
        });
    }
    /**
     * Return the waveform for the current time as a Float32Array where each value in the array
     * represents a sample in the waveform.
     */ getValue() {
        return this._analyser.getValue();
    }
    /**
     * The size of analysis. This must be a power of two in the range 16 to 16384.
     * Determines the size of the array returned by [[getValue]].
     */ get size() {
        return this._analyser.size;
    }
    set size(size) {
        this._analyser.size = size;
    }
}








class $4ee2a341645e5b23$export$43343ff6c11f7ee5 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($4ee2a341645e5b23$export$43343ff6c11f7ee5.getDefaults(), arguments, [
            "solo"
        ]));
        this.name = "Solo";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($4ee2a341645e5b23$export$43343ff6c11f7ee5.getDefaults(), arguments, [
            "solo"
        ]);
        this.input = this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        if (!$4ee2a341645e5b23$export$43343ff6c11f7ee5._allSolos.has(this.context)) $4ee2a341645e5b23$export$43343ff6c11f7ee5._allSolos.set(this.context, new Set());
        $4ee2a341645e5b23$export$43343ff6c11f7ee5._allSolos.get(this.context).add(this);
        // set initially
        this.solo = options.solo;
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            solo: false
        });
    }
    /**
     * Isolates this instance and mutes all other instances of Solo.
     * Only one instance can be soloed at a time. A soloed
     * instance will report `solo=false` when another instance is soloed.
     */ get solo() {
        return this._isSoloed();
    }
    set solo(solo) {
        if (solo) this._addSolo();
        else this._removeSolo();
        $4ee2a341645e5b23$export$43343ff6c11f7ee5._allSolos.get(this.context).forEach((instance)=>instance._updateSolo());
    }
    /**
     * If the current instance is muted, i.e. another instance is soloed
     */ get muted() {
        return this.input.gain.value === 0;
    }
    /**
     * Add this to the soloed array
     */ _addSolo() {
        if (!$4ee2a341645e5b23$export$43343ff6c11f7ee5._soloed.has(this.context)) $4ee2a341645e5b23$export$43343ff6c11f7ee5._soloed.set(this.context, new Set());
        $4ee2a341645e5b23$export$43343ff6c11f7ee5._soloed.get(this.context).add(this);
    }
    /**
     * Remove this from the soloed array
     */ _removeSolo() {
        if ($4ee2a341645e5b23$export$43343ff6c11f7ee5._soloed.has(this.context)) $4ee2a341645e5b23$export$43343ff6c11f7ee5._soloed.get(this.context).delete(this);
    }
    /**
     * Is this on the soloed array
     */ _isSoloed() {
        return $4ee2a341645e5b23$export$43343ff6c11f7ee5._soloed.has(this.context) && $4ee2a341645e5b23$export$43343ff6c11f7ee5._soloed.get(this.context).has(this);
    }
    /**
     * Returns true if no one is soloed
     */ _noSolos() {
        // either does not have any soloed added
        return !$4ee2a341645e5b23$export$43343ff6c11f7ee5._soloed.has(this.context) || $4ee2a341645e5b23$export$43343ff6c11f7ee5._soloed.has(this.context) && $4ee2a341645e5b23$export$43343ff6c11f7ee5._soloed.get(this.context).size === 0;
    }
    /**
     * Solo the current instance and unsolo all other instances.
     */ _updateSolo() {
        if (this._isSoloed()) this.input.gain.value = 1;
        else if (this._noSolos()) // no one is soloed
        this.input.gain.value = 1;
        else this.input.gain.value = 0;
    }
    dispose() {
        super.dispose();
        $4ee2a341645e5b23$export$43343ff6c11f7ee5._allSolos.get(this.context).delete(this);
        this._removeSolo();
        return this;
    }
}
/**
 * Hold all of the solo'ed tracks belonging to a specific context
 */ $4ee2a341645e5b23$export$43343ff6c11f7ee5._allSolos = new Map();
/**
 * Hold the currently solo'ed instance(s)
 */ $4ee2a341645e5b23$export$43343ff6c11f7ee5._soloed = new Map();







class $908111c09a511b50$export$e62efb0df83a5c7c extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($908111c09a511b50$export$e62efb0df83a5c7c.getDefaults(), arguments, [
            "pan",
            "volume"
        ]));
        this.name = "PanVol";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($908111c09a511b50$export$e62efb0df83a5c7c.getDefaults(), arguments, [
            "pan",
            "volume"
        ]);
        this._panner = this.input = new (0, $489e86a396f6a032$export$d6d7a1629e59823d)({
            context: this.context,
            pan: options.pan,
            channelCount: options.channelCount
        });
        this.pan = this._panner.pan;
        this._volume = this.output = new (0, $7d48f9af04226b93$export$dde279e52d625429)({
            context: this.context,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        // connections
        this._panner.connect(this._volume);
        this.mute = options.mute;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "pan",
            "volume"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            mute: false,
            pan: 0,
            volume: 0,
            channelCount: 1
        });
    }
    /**
     * Mute/unmute the volume
     */ get mute() {
        return this._volume.mute;
    }
    set mute(mute) {
        this._volume.mute = mute;
    }
    dispose() {
        super.dispose();
        this._panner.dispose();
        this.pan.dispose();
        this._volume.dispose();
        this.volume.dispose();
        return this;
    }
}




class $33b35f3b363c45bc$export$cfdacaa37f9b4dd7 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($33b35f3b363c45bc$export$cfdacaa37f9b4dd7.getDefaults(), arguments, [
            "volume",
            "pan"
        ]));
        this.name = "Channel";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($33b35f3b363c45bc$export$cfdacaa37f9b4dd7.getDefaults(), arguments, [
            "volume",
            "pan"
        ]);
        this._solo = this.input = new (0, $4ee2a341645e5b23$export$43343ff6c11f7ee5)({
            solo: options.solo,
            context: this.context
        });
        this._panVol = this.output = new (0, $908111c09a511b50$export$e62efb0df83a5c7c)({
            context: this.context,
            pan: options.pan,
            volume: options.volume,
            mute: options.mute,
            channelCount: options.channelCount
        });
        this.pan = this._panVol.pan;
        this.volume = this._panVol.volume;
        this._solo.connect(this._panVol);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "pan",
            "volume"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            pan: 0,
            volume: 0,
            mute: false,
            solo: false,
            channelCount: 1
        });
    }
    /**
     * Solo/unsolo the channel. Soloing is only relative to other [[Channels]] and [[Solo]] instances
     */ get solo() {
        return this._solo.solo;
    }
    set solo(solo) {
        this._solo.solo = solo;
    }
    /**
     * If the current instance is muted, i.e. another instance is soloed,
     * or the channel is muted
     */ get muted() {
        return this._solo.muted || this.mute;
    }
    /**
     * Mute/unmute the volume
     */ get mute() {
        return this._panVol.mute;
    }
    set mute(mute) {
        this._panVol.mute = mute;
    }
    /**
     * Get the gain node belonging to the bus name. Create it if
     * it doesn't exist
     * @param name The bus name
     */ _getBus(name) {
        if (!$33b35f3b363c45bc$export$cfdacaa37f9b4dd7.buses.has(name)) $33b35f3b363c45bc$export$cfdacaa37f9b4dd7.buses.set(name, new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        }));
        return $33b35f3b363c45bc$export$cfdacaa37f9b4dd7.buses.get(name);
    }
    /**
     * Send audio to another channel using a string. `send` is a lot like
     * [[connect]], except it uses a string instead of an object. This can
     * be useful in large applications to decouple sections since [[send]]
     * and [[receive]] can be invoked separately in order to connect an object
     * @param name The channel name to send the audio
     * @param volume The amount of the signal to send.
     * 	Defaults to 0db, i.e. send the entire signal
     * @returns Returns the gain node of this connection.
     */ send(name, volume = 0) {
        const bus = this._getBus(name);
        const sendKnob = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            units: "decibels",
            gain: volume
        });
        this.connect(sendKnob);
        sendKnob.connect(bus);
        return sendKnob;
    }
    /**
     * Receive audio from a channel which was connected with [[send]].
     * @param name The channel name to receive audio from.
     */ receive(name) {
        const bus = this._getBus(name);
        bus.connect(this);
        return this;
    }
    dispose() {
        super.dispose();
        this._panVol.dispose();
        this.pan.dispose();
        this.volume.dispose();
        this._solo.dispose();
        return this;
    }
}
/**
 * Store the send/receive channels by name.
 */ $33b35f3b363c45bc$export$cfdacaa37f9b4dd7.buses = new Map();










class $13eb5115754e2e30$export$6a6cc05ddf64d43 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($13eb5115754e2e30$export$6a6cc05ddf64d43.getDefaults(), arguments));
        this.name = "Mono";
        this.input = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this._merge = this.output = new (0, $4541bd4bd7add640$export$70ce1d34efd3b886)({
            channels: 2,
            context: this.context
        });
        this.input.connect(this._merge, 0, 0);
        this.input.connect(this._merge, 0, 1);
    }
    dispose() {
        super.dispose();
        this._merge.dispose();
        this.input.dispose();
        return this;
    }
}








class $ab92cfe388083930$export$8243399b0243bc0b extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($ab92cfe388083930$export$8243399b0243bc0b.getDefaults(), arguments, [
            "lowFrequency",
            "highFrequency"
        ]));
        this.name = "MultibandSplit";
        /**
         * the input
         */ this.input = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        /**
         * no output node, use either low, mid or high outputs
         */ this.output = undefined;
        /**
         * The low band.
         */ this.low = new (0, $b43765906de8c71a$export$ec91da630f36d5ea)({
            context: this.context,
            frequency: 0,
            type: "lowpass"
        });
        /**
         * the lower filter of the mid band
         */ this._lowMidFilter = new (0, $b43765906de8c71a$export$ec91da630f36d5ea)({
            context: this.context,
            frequency: 0,
            type: "highpass"
        });
        /**
         * The mid band output.
         */ this.mid = new (0, $b43765906de8c71a$export$ec91da630f36d5ea)({
            context: this.context,
            frequency: 0,
            type: "lowpass"
        });
        /**
         * The high band output.
         */ this.high = new (0, $b43765906de8c71a$export$ec91da630f36d5ea)({
            context: this.context,
            frequency: 0,
            type: "highpass"
        });
        this._internalChannels = [
            this.low,
            this.mid,
            this.high
        ];
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($ab92cfe388083930$export$8243399b0243bc0b.getDefaults(), arguments, [
            "lowFrequency",
            "highFrequency"
        ]);
        this.lowFrequency = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "frequency",
            value: options.lowFrequency
        });
        this.highFrequency = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "frequency",
            value: options.highFrequency
        });
        this.Q = new (0, $293163363e9daa43$export$8210dfe1863c478)({
            context: this.context,
            units: "positive",
            value: options.Q
        });
        this.input.fan(this.low, this.high);
        this.input.chain(this._lowMidFilter, this.mid);
        // the frequency control signal
        this.lowFrequency.fan(this.low.frequency, this._lowMidFilter.frequency);
        this.highFrequency.fan(this.mid.frequency, this.high.frequency);
        // the Q value
        this.Q.connect(this.low.Q);
        this.Q.connect(this._lowMidFilter.Q);
        this.Q.connect(this.mid.Q);
        this.Q.connect(this.high.Q);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "high",
            "mid",
            "low",
            "highFrequency",
            "lowFrequency"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            Q: 1,
            highFrequency: 2500,
            lowFrequency: 400
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        (0, $c0a1ee726091e30a$export$e6d3eada50a007b1)(this, [
            "high",
            "mid",
            "low",
            "highFrequency",
            "lowFrequency"
        ]);
        this.low.dispose();
        this._lowMidFilter.dispose();
        this.mid.dispose();
        this.high.dispose();
        this.lowFrequency.dispose();
        this.highFrequency.dispose();
        this.Q.dispose();
        return this;
    }
}









class $b573b298cc9ef0b0$export$c92b1d5f43586026 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super(...arguments);
        this.name = "Listener";
        this.positionX = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this.context.rawContext.listener.positionX
        });
        this.positionY = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this.context.rawContext.listener.positionY
        });
        this.positionZ = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this.context.rawContext.listener.positionZ
        });
        this.forwardX = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this.context.rawContext.listener.forwardX
        });
        this.forwardY = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this.context.rawContext.listener.forwardY
        });
        this.forwardZ = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this.context.rawContext.listener.forwardZ
        });
        this.upX = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this.context.rawContext.listener.upX
        });
        this.upY = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this.context.rawContext.listener.upY
        });
        this.upZ = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this.context.rawContext.listener.upZ
        });
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            positionX: 0,
            positionY: 0,
            positionZ: 0,
            forwardX: 0,
            forwardY: 0,
            forwardZ: -1,
            upX: 0,
            upY: 1,
            upZ: 0
        });
    }
    dispose() {
        super.dispose();
        this.positionX.dispose();
        this.positionY.dispose();
        this.positionZ.dispose();
        this.forwardX.dispose();
        this.forwardY.dispose();
        this.forwardZ.dispose();
        this.upX.dispose();
        this.upY.dispose();
        this.upZ.dispose();
        return this;
    }
}
//-------------------------------------
// 	INITIALIZATION
//-------------------------------------
(0, $5845e19ca4e07c3f$export$cdd816203a02e74e)((context)=>{
    context.listener = new $b573b298cc9ef0b0$export$c92b1d5f43586026({
        context: context
    });
});
(0, $5845e19ca4e07c3f$export$7e1ecadd06ae8222)((context)=>{
    context.listener.dispose();
});


class $f670eac9355452c0$export$40229b68a3be8579 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($f670eac9355452c0$export$40229b68a3be8579.getDefaults(), arguments, [
            "positionX",
            "positionY",
            "positionZ"
        ]));
        this.name = "Panner3D";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($f670eac9355452c0$export$40229b68a3be8579.getDefaults(), arguments, [
            "positionX",
            "positionY",
            "positionZ"
        ]);
        this._panner = this.input = this.output = this.context.createPanner();
        // set some values
        this.panningModel = options.panningModel;
        this.maxDistance = options.maxDistance;
        this.distanceModel = options.distanceModel;
        this.coneOuterGain = options.coneOuterGain;
        this.coneOuterAngle = options.coneOuterAngle;
        this.coneInnerAngle = options.coneInnerAngle;
        this.refDistance = options.refDistance;
        this.rolloffFactor = options.rolloffFactor;
        this.positionX = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this._panner.positionX,
            value: options.positionX
        });
        this.positionY = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this._panner.positionY,
            value: options.positionY
        });
        this.positionZ = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this._panner.positionZ,
            value: options.positionZ
        });
        this.orientationX = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this._panner.orientationX,
            value: options.orientationX
        });
        this.orientationY = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this._panner.orientationY,
            value: options.orientationY
        });
        this.orientationZ = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            context: this.context,
            param: this._panner.orientationZ,
            value: options.orientationZ
        });
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            coneInnerAngle: 360,
            coneOuterAngle: 360,
            coneOuterGain: 0,
            distanceModel: "inverse",
            maxDistance: 10000,
            orientationX: 0,
            orientationY: 0,
            orientationZ: 0,
            panningModel: "equalpower",
            positionX: 0,
            positionY: 0,
            positionZ: 0,
            refDistance: 1,
            rolloffFactor: 1
        });
    }
    /**
     * Sets the position of the source in 3d space.
     */ setPosition(x, y, z) {
        this.positionX.value = x;
        this.positionY.value = y;
        this.positionZ.value = z;
        return this;
    }
    /**
     * Sets the orientation of the source in 3d space.
     */ setOrientation(x, y, z) {
        this.orientationX.value = x;
        this.orientationY.value = y;
        this.orientationZ.value = z;
        return this;
    }
    /**
     * The panning model. Either "equalpower" or "HRTF".
     */ get panningModel() {
        return this._panner.panningModel;
    }
    set panningModel(val) {
        this._panner.panningModel = val;
    }
    /**
     * A reference distance for reducing volume as source move further from the listener
     */ get refDistance() {
        return this._panner.refDistance;
    }
    set refDistance(val) {
        this._panner.refDistance = val;
    }
    /**
     * Describes how quickly the volume is reduced as source moves away from listener.
     */ get rolloffFactor() {
        return this._panner.rolloffFactor;
    }
    set rolloffFactor(val) {
        this._panner.rolloffFactor = val;
    }
    /**
     * The distance model used by,  "linear", "inverse", or "exponential".
     */ get distanceModel() {
        return this._panner.distanceModel;
    }
    set distanceModel(val) {
        this._panner.distanceModel = val;
    }
    /**
     * The angle, in degrees, inside of which there will be no volume reduction
     */ get coneInnerAngle() {
        return this._panner.coneInnerAngle;
    }
    set coneInnerAngle(val) {
        this._panner.coneInnerAngle = val;
    }
    /**
     * The angle, in degrees, outside of which the volume will be reduced
     * to a constant value of coneOuterGain
     */ get coneOuterAngle() {
        return this._panner.coneOuterAngle;
    }
    set coneOuterAngle(val) {
        this._panner.coneOuterAngle = val;
    }
    /**
     * The gain outside of the coneOuterAngle
     */ get coneOuterGain() {
        return this._panner.coneOuterGain;
    }
    set coneOuterGain(val) {
        this._panner.coneOuterGain = val;
    }
    /**
     * The maximum distance between source and listener,
     * after which the volume will not be reduced any further.
     */ get maxDistance() {
        return this._panner.maxDistance;
    }
    set maxDistance(val) {
        this._panner.maxDistance = val;
    }
    dispose() {
        super.dispose();
        this._panner.disconnect();
        this.orientationX.dispose();
        this.orientationY.dispose();
        this.orientationZ.dispose();
        this.positionX.dispose();
        this.positionY.dispose();
        this.positionZ.dispose();
        return this;
    }
}









class $4ce9bd6931843ba1$export$336a011955157f9a extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($4ce9bd6931843ba1$export$336a011955157f9a.getDefaults(), arguments));
        this.name = "Recorder";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($4ce9bd6931843ba1$export$336a011955157f9a.getDefaults(), arguments);
        this.input = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        (0, $23cf54af36cc9441$export$a7a9523472993e97)($4ce9bd6931843ba1$export$336a011955157f9a.supported, "Media Recorder API is not available");
        this._stream = this.context.createMediaStreamDestination();
        this.input.connect(this._stream);
        this._recorder = new MediaRecorder(this._stream.stream, {
            mimeType: options.mimeType
        });
    }
    static getDefaults() {
        return (0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults();
    }
    /**
     * The mime type is the format that the audio is encoded in. For Chrome
     * that is typically webm encoded as "vorbis".
     */ get mimeType() {
        return this._recorder.mimeType;
    }
    /**
     * Test if your platform supports the Media Recorder API. If it's not available,
     * try installing this (polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].
     */ static get supported() {
        return (0, $4d32d9be36060d13$export$a3ddad83b7a6ba2) !== null && Reflect.has((0, $4d32d9be36060d13$export$a3ddad83b7a6ba2), "MediaRecorder");
    }
    /**
     * Get the playback state of the Recorder, either "started", "stopped" or "paused"
     */ get state() {
        if (this._recorder.state === "inactive") return "stopped";
        else if (this._recorder.state === "paused") return "paused";
        else return "started";
    }
    /**
     * Start the Recorder. Returns a promise which resolves
     * when the recorder has started.
     */ start() {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            (0, $23cf54af36cc9441$export$a7a9523472993e97)(this.state !== "started", "Recorder is already started");
            const startPromise = new Promise((done)=>{
                const handleStart = ()=>{
                    this._recorder.removeEventListener("start", handleStart, false);
                    done();
                };
                this._recorder.addEventListener("start", handleStart, false);
            });
            this._recorder.start();
            return yield startPromise;
        });
    }
    /**
     * Stop the recorder. Returns a promise with the recorded content until this point
     * encoded as [[mimeType]]
     */ stop() {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            (0, $23cf54af36cc9441$export$a7a9523472993e97)(this.state !== "stopped", "Recorder is not started");
            const dataPromise = new Promise((done)=>{
                const handleData = (e)=>{
                    this._recorder.removeEventListener("dataavailable", handleData, false);
                    done(e.data);
                };
                this._recorder.addEventListener("dataavailable", handleData, false);
            });
            this._recorder.stop();
            return yield dataPromise;
        });
    }
    /**
     * Pause the recorder
     */ pause() {
        (0, $23cf54af36cc9441$export$a7a9523472993e97)(this.state === "started", "Recorder must be started");
        this._recorder.pause();
        return this;
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this._stream.disconnect();
        return this;
    }
}









class $a032be33a91a2384$export$41ba31ea44cbf87a extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($a032be33a91a2384$export$41ba31ea44cbf87a.getDefaults(), arguments, [
            "threshold",
            "ratio"
        ]));
        this.name = "Compressor";
        /**
         * the compressor node
         */ this._compressor = this.context.createDynamicsCompressor();
        this.input = this._compressor;
        this.output = this._compressor;
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($a032be33a91a2384$export$41ba31ea44cbf87a.getDefaults(), arguments, [
            "threshold",
            "ratio"
        ]);
        this.threshold = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            minValue: this._compressor.threshold.minValue,
            maxValue: this._compressor.threshold.maxValue,
            context: this.context,
            convert: false,
            param: this._compressor.threshold,
            units: "decibels",
            value: options.threshold
        });
        this.attack = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            minValue: this._compressor.attack.minValue,
            maxValue: this._compressor.attack.maxValue,
            context: this.context,
            param: this._compressor.attack,
            units: "time",
            value: options.attack
        });
        this.release = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            minValue: this._compressor.release.minValue,
            maxValue: this._compressor.release.maxValue,
            context: this.context,
            param: this._compressor.release,
            units: "time",
            value: options.release
        });
        this.knee = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            minValue: this._compressor.knee.minValue,
            maxValue: this._compressor.knee.maxValue,
            context: this.context,
            convert: false,
            param: this._compressor.knee,
            units: "decibels",
            value: options.knee
        });
        this.ratio = new (0, $139d674b4982de8e$export$1ca45c9a47aec42c)({
            minValue: this._compressor.ratio.minValue,
            maxValue: this._compressor.ratio.maxValue,
            context: this.context,
            convert: false,
            param: this._compressor.ratio,
            units: "positive",
            value: options.ratio
        });
        // set the defaults
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "knee",
            "release",
            "attack",
            "ratio",
            "threshold"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            attack: 0.003,
            knee: 30,
            ratio: 12,
            release: 0.25,
            threshold: -24
        });
    }
    /**
     * A read-only decibel value for metering purposes, representing the current amount of gain
     * reduction that the compressor is applying to the signal. If fed no signal the value will be 0 (no gain reduction).
     */ get reduction() {
        return this._compressor.reduction;
    }
    dispose() {
        super.dispose();
        this._compressor.disconnect();
        this.attack.dispose();
        this.release.dispose();
        this.threshold.dispose();
        this.ratio.dispose();
        this.knee.dispose();
        return this;
    }
}








class $1ec8eaa2876e50cc$export$b4bc28ee584f979c extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($1ec8eaa2876e50cc$export$b4bc28ee584f979c.getDefaults(), arguments, [
            "threshold",
            "smoothing"
        ])));
        this.name = "Gate";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($1ec8eaa2876e50cc$export$b4bc28ee584f979c.getDefaults(), arguments, [
            "threshold",
            "smoothing"
        ]);
        this._follower = new (0, $da264d90e2c8a7c7$export$8ccab1ce4a46f)({
            context: this.context,
            smoothing: options.smoothing
        });
        this._gt = new (0, $2a2ba9f2f3f1a12e$export$fdac76ab71aa5db6)({
            context: this.context,
            value: (0, $73949b14fe57a99a$export$33ed28de027e9482)(options.threshold)
        });
        this.input = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this._gate = this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        // connections
        this.input.connect(this._gate);
        // the control signal
        this.input.chain(this._follower, this._gt, this._gate.gain);
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            smoothing: 0.1,
            threshold: -40
        });
    }
    /**
     * The threshold of the gate in decibels
     */ get threshold() {
        return (0, $73949b14fe57a99a$export$6af3969727ca2a60)(this._gt.value);
    }
    set threshold(thresh) {
        this._gt.value = (0, $73949b14fe57a99a$export$33ed28de027e9482)(thresh);
    }
    /**
     * The attack/decay speed of the gate. See [[Follower.smoothing]]
     */ get smoothing() {
        return this._follower.smoothing;
    }
    set smoothing(smoothingTime) {
        this._follower.smoothing = smoothingTime;
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this._follower.dispose();
        this._gt.dispose();
        this._gate.dispose();
        return this;
    }
}






class $3028028622c75f19$export$18d8154f27ea9172 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($3028028622c75f19$export$18d8154f27ea9172.getDefaults(), arguments, [
            "threshold"
        ])));
        this.name = "Limiter";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($3028028622c75f19$export$18d8154f27ea9172.getDefaults(), arguments, [
            "threshold"
        ]);
        this._compressor = this.input = this.output = new (0, $a032be33a91a2384$export$41ba31ea44cbf87a)({
            context: this.context,
            ratio: 20,
            attack: 0.003,
            release: 0.01,
            threshold: options.threshold
        });
        this.threshold = this._compressor.threshold;
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, "threshold");
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            threshold: -12
        });
    }
    /**
     * A read-only decibel value for metering purposes, representing the current amount of gain
     * reduction that the compressor is applying to the signal.
     */ get reduction() {
        return this._compressor.reduction;
    }
    dispose() {
        super.dispose();
        this._compressor.dispose();
        this.threshold.dispose();
        return this;
    }
}








class $7bdd7742aa7ece46$export$4fe244964f9889ae extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($7bdd7742aa7ece46$export$4fe244964f9889ae.getDefaults(), arguments)));
        this.name = "MidSideCompressor";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($7bdd7742aa7ece46$export$4fe244964f9889ae.getDefaults(), arguments);
        this._midSideSplit = this.input = new (0, $6310c804325bea77$export$17b3caaa07b8690f)({
            context: this.context
        });
        this._midSideMerge = this.output = new (0, $10d6ea2b5230f5e8$export$be84ddbe7b4fbb5a)({
            context: this.context
        });
        this.mid = new (0, $a032be33a91a2384$export$41ba31ea44cbf87a)(Object.assign(options.mid, {
            context: this.context
        }));
        this.side = new (0, $a032be33a91a2384$export$41ba31ea44cbf87a)(Object.assign(options.side, {
            context: this.context
        }));
        this._midSideSplit.mid.chain(this.mid, this._midSideMerge.mid);
        this._midSideSplit.side.chain(this.side, this._midSideMerge.side);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "mid",
            "side"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            mid: {
                ratio: 3,
                threshold: -24,
                release: 0.03,
                attack: 0.02,
                knee: 16
            },
            side: {
                ratio: 6,
                threshold: -30,
                release: 0.25,
                attack: 0.03,
                knee: 10
            }
        });
    }
    dispose() {
        super.dispose();
        this.mid.dispose();
        this.side.dispose();
        this._midSideSplit.dispose();
        this._midSideMerge.dispose();
        return this;
    }
}








class $bcc0c60f3c248402$export$7cd9eb83d48f580b extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super(Object.assign((0, $1e273b197c429402$export$71d3255081da70a3)($bcc0c60f3c248402$export$7cd9eb83d48f580b.getDefaults(), arguments)));
        this.name = "MultibandCompressor";
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($bcc0c60f3c248402$export$7cd9eb83d48f580b.getDefaults(), arguments);
        this._splitter = this.input = new (0, $ab92cfe388083930$export$8243399b0243bc0b)({
            context: this.context,
            lowFrequency: options.lowFrequency,
            highFrequency: options.highFrequency
        });
        this.lowFrequency = this._splitter.lowFrequency;
        this.highFrequency = this._splitter.highFrequency;
        this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this.low = new (0, $a032be33a91a2384$export$41ba31ea44cbf87a)(Object.assign(options.low, {
            context: this.context
        }));
        this.mid = new (0, $a032be33a91a2384$export$41ba31ea44cbf87a)(Object.assign(options.mid, {
            context: this.context
        }));
        this.high = new (0, $a032be33a91a2384$export$41ba31ea44cbf87a)(Object.assign(options.high, {
            context: this.context
        }));
        // connect the compressor
        this._splitter.low.chain(this.low, this.output);
        this._splitter.mid.chain(this.mid, this.output);
        this._splitter.high.chain(this.high, this.output);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "high",
            "mid",
            "low",
            "highFrequency",
            "lowFrequency"
        ]);
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            lowFrequency: 250,
            highFrequency: 2000,
            low: {
                ratio: 6,
                threshold: -30,
                release: 0.25,
                attack: 0.03,
                knee: 10
            },
            mid: {
                ratio: 3,
                threshold: -24,
                release: 0.03,
                attack: 0.02,
                knee: 16
            },
            high: {
                ratio: 3,
                threshold: -24,
                release: 0.03,
                attack: 0.02,
                knee: 16
            }
        });
    }
    dispose() {
        super.dispose();
        this._splitter.dispose();
        this.low.dispose();
        this.mid.dispose();
        this.high.dispose();
        this.output.dispose();
        return this;
    }
}










class $d5b9bf13f6ee2dd7$export$2adf407ed955ca5d extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($d5b9bf13f6ee2dd7$export$2adf407ed955ca5d.getDefaults(), arguments, [
            "low",
            "mid",
            "high"
        ]));
        this.name = "EQ3";
        /**
         * the output
         */ this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this._internalChannels = [];
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($d5b9bf13f6ee2dd7$export$2adf407ed955ca5d.getDefaults(), arguments, [
            "low",
            "mid",
            "high"
        ]);
        this.input = this._multibandSplit = new (0, $ab92cfe388083930$export$8243399b0243bc0b)({
            context: this.context,
            highFrequency: options.highFrequency,
            lowFrequency: options.lowFrequency
        });
        this._lowGain = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            gain: options.low,
            units: "decibels"
        });
        this._midGain = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            gain: options.mid,
            units: "decibels"
        });
        this._highGain = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context,
            gain: options.high,
            units: "decibels"
        });
        this.low = this._lowGain.gain;
        this.mid = this._midGain.gain;
        this.high = this._highGain.gain;
        this.Q = this._multibandSplit.Q;
        this.lowFrequency = this._multibandSplit.lowFrequency;
        this.highFrequency = this._multibandSplit.highFrequency;
        // the frequency bands
        this._multibandSplit.low.chain(this._lowGain, this.output);
        this._multibandSplit.mid.chain(this._midGain, this.output);
        this._multibandSplit.high.chain(this._highGain, this.output);
        (0, $c0a1ee726091e30a$export$b2cbc93d4da94977)(this, [
            "low",
            "mid",
            "high",
            "lowFrequency",
            "highFrequency"
        ]);
        this._internalChannels = [
            this._multibandSplit
        ];
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            high: 0,
            highFrequency: 2500,
            low: 0,
            lowFrequency: 400,
            mid: 0
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        (0, $c0a1ee726091e30a$export$e6d3eada50a007b1)(this, [
            "low",
            "mid",
            "high",
            "lowFrequency",
            "highFrequency"
        ]);
        this._multibandSplit.dispose();
        this.lowFrequency.dispose();
        this.highFrequency.dispose();
        this._lowGain.dispose();
        this._midGain.dispose();
        this._highGain.dispose();
        this.low.dispose();
        this.mid.dispose();
        this.high.dispose();
        this.Q.dispose();
        return this;
    }
}












class $7cbe0e82f1931ee0$export$f48597cb240e2420 extends (0, $5ffbb5654e49c399$export$14a6d069f26d1d33) {
    constructor(){
        super((0, $1e273b197c429402$export$71d3255081da70a3)($7cbe0e82f1931ee0$export$f48597cb240e2420.getDefaults(), arguments, [
            "url",
            "onload"
        ]));
        this.name = "Convolver";
        /**
         * The native ConvolverNode
         */ this._convolver = this.context.createConvolver();
        const options = (0, $1e273b197c429402$export$71d3255081da70a3)($7cbe0e82f1931ee0$export$f48597cb240e2420.getDefaults(), arguments, [
            "url",
            "onload"
        ]);
        this._buffer = new (0, $f8b2c4c1413d235f$export$424a335715b38178)(options.url, (buffer)=>{
            this.buffer = buffer;
            options.onload();
        });
        this.input = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        this.output = new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
            context: this.context
        });
        // set if it's already loaded, set it immediately
        if (this._buffer.loaded) this.buffer = this._buffer;
        // initially set normalization
        this.normalize = options.normalize;
        // connect it up
        this.input.chain(this._convolver, this.output);
    }
    static getDefaults() {
        return Object.assign((0, $5ffbb5654e49c399$export$14a6d069f26d1d33).getDefaults(), {
            normalize: true,
            onload: (0, $c0a1ee726091e30a$export$b50b6e108474309b)
        });
    }
    /**
     * Load an impulse response url as an audio buffer.
     * Decodes the audio asynchronously and invokes
     * the callback once the audio buffer loads.
     * @param url The url of the buffer to load. filetype support depends on the browser.
     */ load(url) {
        return (0, $a522a8f63c306c1c$export$1050f835b63b671e)(this, void 0, void 0, function*() {
            this.buffer = yield this._buffer.load(url);
        });
    }
    /**
     * The convolver's buffer
     */ get buffer() {
        if (this._buffer.length) return this._buffer;
        else return null;
    }
    set buffer(buffer) {
        if (buffer) this._buffer.set(buffer);
        // if it's already got a buffer, create a new one
        if (this._convolver.buffer) {
            // disconnect the old one
            this.input.disconnect();
            this._convolver.disconnect();
            // create and connect a new one
            this._convolver = this.context.createConvolver();
            this.input.chain(this._convolver, this.output);
        }
        const buff = this._buffer.get();
        this._convolver.buffer = buff ? buff : null;
    }
    /**
     * The normalize property of the ConvolverNode interface is a boolean that
     * controls whether the impulse response from the buffer will be scaled by
     * an equal-power normalization when the buffer attribute is set, or not.
     */ get normalize() {
        return this._convolver.normalize;
    }
    set normalize(norm) {
        this._convolver.normalize = norm;
    }
    dispose() {
        super.dispose();
        this._buffer.dispose();
        this._convolver.disconnect();
        return this;
    }
}










function $193d86afce95aa9f$export$461939dd4422153() {
    return (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().now();
}
function $193d86afce95aa9f$export$7aea7eb3d7f025ec() {
    return (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().immediate();
}
const $193d86afce95aa9f$export$86495b081fef8e52 = (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().transport;
function $193d86afce95aa9f$export$867d8b939ab7f43e() {
    return (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().transport;
}
const $193d86afce95aa9f$export$5c4bdf44e1e9cea1 = (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().destination;
const $193d86afce95aa9f$export$44fd2db2d162647d = (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().destination;
function $193d86afce95aa9f$export$be071a6ef30bc5f7() {
    return (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().destination;
}
const $193d86afce95aa9f$export$c92b1d5f43586026 = (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().listener;
function $193d86afce95aa9f$export$12abb5141c6fdc9c() {
    return (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().listener;
}
const $193d86afce95aa9f$export$dca20402ebea5ece = (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().draw;
function $193d86afce95aa9f$export$dc345928c36e8deb() {
    return (0, $3d00f6854e3cc34b$export$31553aaa555c1514)().draw;
}
const $193d86afce95aa9f$export$a078c61943f9dbbe = (0, $3d00f6854e3cc34b$export$31553aaa555c1514)();
function $193d86afce95aa9f$export$b40fc69c4a2927a1() {
    return (0, $f8b2c4c1413d235f$export$424a335715b38178).loaded();
}
const $193d86afce95aa9f$export$a143d493d941bafc = (0, $f8b2c4c1413d235f$export$424a335715b38178);
const $193d86afce95aa9f$export$2a73594b5be3a068 = (0, $11a3577f34f45a1d$export$7232b969b571e570);
const $193d86afce95aa9f$export$54a46af252275b4d = (0, $ab1da665fc34fe83$export$30cbf4ba14db4fdd);



const $48e418653d1eb56b$var$rfx = fxrand;
function $48e418653d1eb56b$var$generateRandom(min, max) {
    // find diff
    let difference = max - min;
    // generate random number 
    let rand = $48e418653d1eb56b$var$rfx();
    // multiply with difference 
    rand = Math.round(rand * difference * 100) / 100;
    // add with min value 
    rand = rand + min;
    return rand;
}
function $48e418653d1eb56b$var$checklastTrigger(array) {
    if (array[14] === 1) return 1;
    else return 0;
}
function $48e418653d1eb56b$var$triggerABS(array) {
    const arrayABS = [];
    var x = 0;
    var z = 0;
    var y = new Boolean(false);
    var a = new Boolean(false);
    for(var i = 0; i < 16; i++){
        if (i === 15) {
            z++;
            arrayABS[x] = z;
        } else if (array[i] === 0) {
            if (y === true) {
                a = true;
                z++;
            }
        } else if (array[i] === 1) {
            y = true;
            if (i > 0 && a === true) {
                z++;
                arrayABS[x] = z;
                x++;
                z = 0;
            }
        }
    }
    return arrayABS;
}
function $48e418653d1eb56b$var$shuffle(array) {
    const r = (from = 0, to = 1)=>from + $48e418653d1eb56b$var$rfx() * (to - from);
    var m = array.length, t, i;
    while(m){
        i = Math.floor(r() * m--);
        t = array[m]; // temporary storage
        array[m] = array[i];
        array[i] = t;
    }
    return array;
}
/*
1. Rule: every trigger lands on even index incl. 0:             [1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0]
2. Rule: every trigger has min 4 tringgers distance:            [1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0]
3. Rule: expertion: last trigger can have 2 trigger dicance:    [1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0]
4. Rule: if there is a trigger on the 2nd last trigger of the bar before, the trigger cant land on the 2nd trigger becuase of 2. Rule: Bar1: [1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0], Bar2: [0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0]*/ function $48e418653d1eb56b$var$kickRhythm(array, flag) {
    //count how much triggers are in array
    var count = 0;
    array.forEach((e, i)=>{
        if (e === 1) count++;
    });
    var arrayABS = [];
    while(true){
        //1. Rule
        while(true){
            array = $48e418653d1eb56b$var$shuffle(array);
            if (array.every((e, i)=>{
                if (e === 1) return i % 2 === 0;
                else return true; // wenns kein schlag ist alles gut, soll weither ggehen
            })) break;
        }
        //2. Rule
        arrayABS = $48e418653d1eb56b$var$triggerABS(array);
        if (flag === 1) {
            if (array[0] === 0) {
                if (arrayABS.every((e, i)=>{
                    if (e < 4 && i === count - 1) return true;
                    else if (e < 4) return false;
                    else return true;
                })) break;
            }
        } else if (flag === 0) {
            if (arrayABS.every((e, i)=>{
                if (e < 4 && i === count - 1) return true;
                else if (e < 4) return false;
                else return true;
            })) break;
        }
    }
    return array;
}
function $48e418653d1eb56b$var$kickRhythm2(array, flag) {
    //count how much triggers are in array
    let count = 0;
    array.forEach((e, i)=>{
        if (e === 1) count++;
    });
    var arrayABS = [];
    while(true){
        //1. Rule
        while(true){
            array = $48e418653d1eb56b$var$shuffle(array);
            if (array.every((e, i)=>{
                if (e === 1) return i % 2 === 0;
                else return true; // wenns kein schlag ist alles gut, soll weither ggehen
            })) break;
        }
        //2. Rule
        arrayABS = $48e418653d1eb56b$var$triggerABS(array);
        if (flag === 1) {
            if (array[0] === 0) {
                if (arrayABS.every((e, i)=>{
                    if (e < 2 && i === count - 1) return true;
                    else if (e < 2) return false;
                    else return true;
                })) break;
            }
        } else if (flag === 0) {
            if (arrayABS.every((e, i)=>{
                if (e < 2 && i === count - 1) return true;
                else if (e < 2) return false;
                else return true;
            })) break;
        }
    }
    return array;
}
function $48e418653d1eb56b$var$fillKick(size, alternate) {
    let flag = 0;
    let array = [
        [],
        []
    ];
    for(var i = 0; i < 9; i++){
        array[i] = [];
        //console.log(array[i]);
        for(var j = 0; j < 16; j++)if (alternate === 0) {
            if (j < size) array[i][j] = 1;
            else array[i][j] = 0;
        } else {
            if (flag === 0) {
                if (j < size) {
                    array[i][j] = 1;
                    flag = 1;
                } else {
                    array[i][j] = 0;
                    flag = 1;
                }
            } else if (j < size) {
                array[i][j] = 0;
                flag = 0;
            } else {
                array[i][j] = 0;
                flag = 0;
            }
        }
    }
    return array;
}
class $48e418653d1eb56b$export$7f6d62d95a630450 {
    out;
    kit;
    constructor(volume){
        this.out = new (0, $7d48f9af04226b93$export$dde279e52d625429)(volume);
        this.eq = new (0, $d5b9bf13f6ee2dd7$export$2adf407ed955ca5d)(0, 0, 0);
        this.biquad = new (0, $e8d9115796c61b99$export$26bbc35c91a15e23)(0, "highpass");
        this.kit = new (0, $a23f185f5730393d$export$1912c9d78e93a6ed)({
            "C1": "./samples/kick01.mp3",
            "D1": "./samples/kick02.mp3",
            "E1": "./samples/kick03.mp3",
            "F1": "./samples/kick04.mp3",
            "G1": "./samples/kick05.mp3",
            "A1": "./samples/kick06.mp3",
            "B1": "./samples/kick07.mp3"
        }, ()=>{
            console.log("Kicks loaded");
            this.kit.chain(this.eq, this.biquad, this.out);
        });
    }
}
function $48e418653d1eb56b$export$d0727105f16910fe(rhythmDensity) {
    let kickInput = [
        [],
        []
    ];
    let generatedKick = [
        ...Array(9)
    ];
    let flag = 0;
    if (rhythmDensity === 3) {
        let random = Math.floor($48e418653d1eb56b$var$rfx() * 3);
        console.log("random is " + random);
        if (random === 0) kickInput = $48e418653d1eb56b$var$fillKick(3, 0);
        else if (random === 1) kickInput = $48e418653d1eb56b$var$fillKick(2, 1);
        else kickInput = $48e418653d1eb56b$var$fillKick(1, 0);
    } else if (rhythmDensity === 4) {
        let random = Math.floor($48e418653d1eb56b$var$rfx() * 3);
        if (random === 0) kickInput = $48e418653d1eb56b$var$fillKick(4, 1);
        if (random === 1) kickInput = $48e418653d1eb56b$var$fillKick(3, 1);
        if (random === 2) kickInput = $48e418653d1eb56b$var$fillKick(2, 1);
    } else if (rhythmDensity === 5) kickInput = $48e418653d1eb56b$var$fillKick(1, 0);
    else if (rhythmDensity === 6) kickInput = $48e418653d1eb56b$var$fillKick(2, 0);
    else if (rhythmDensity === 7) //random = rfx()
    kickInput = $48e418653d1eb56b$var$fillKick(2, 0);
    else if (rhythmDensity === 8) kickInput = $48e418653d1eb56b$var$fillKick(3, 0);
    else if (rhythmDensity === 9) kickInput = $48e418653d1eb56b$var$fillKick(3, 0);
    if (rhythmDensity === 4) generatedKick.map((e, i)=>{
        e = $48e418653d1eb56b$var$kickRhythm2(kickInput[i], flag);
        flag = $48e418653d1eb56b$var$checklastTrigger(kickInput[i]);
        return generatedKick[i] = e;
    });
    if (rhythmDensity === 8) generatedKick.forEach((e, i)=>{
        e = $48e418653d1eb56b$var$kickRhythm2(kickInput[i], flag);
        flag = $48e418653d1eb56b$var$checklastTrigger(kickInput[i]);
        return generatedKick[i] = e;
    });
    else generatedKick.map((e, i)=>{
        e = $48e418653d1eb56b$var$kickRhythm(kickInput[i], flag);
        flag = $48e418653d1eb56b$var$checklastTrigger(kickInput[i]);
        return generatedKick[i] = e;
    });
    return generatedKick;
}



const $1e8cb74b9ccead8b$var$rfx = fxrand;
function $1e8cb74b9ccead8b$var$doubleTime(array, amount) {
    for(let i = 0; i < amount; i++){
        const random = Math.floor($1e8cb74b9ccead8b$var$rfx() * 72) * 2 - 1;
        array[random] = 1;
    }
    return array;
}
function $1e8cb74b9ccead8b$var$converto2Dto1D(array) {
    var newArr = [];
    for(var i = 0; i < array.length; i++)newArr = newArr.concat(array[i]);
    return newArr;
}
/*
1. Rule: Klicks dÃ¼fren Ã¼berall laden
2. Rule: Klicks werden in zwei Gruppen abwechselnd abgespielt
3. Rule: Wenn Gruppe1(Klicks werde nicht gepielt, Pause) dann wird bis zu 4 SchlÃ¤ge lang keine Klicks abgespielt
4. Rule: Wenn Gruppe2(Klicks werden gepielt) dann werden bis zu 6 Klicks hintereinander abgespielt
5. Rule: Wenn Gruppe2(Klicks werden gepielt) dann werden kommt danach immer Gruppe1 mit einer Pause
6. Rule: LÃ¤nge von beiden Gruppen sind zufÃ¤llig
*/ function $1e8cb74b9ccead8b$var$generateKlicks2() {
    var array = new Array(144).fill(0);
    array = array.map((e, i)=>{
        if (i % 2 === 0) return 1;
        else return 0;
    });
    return array;
}
function $1e8cb74b9ccead8b$var$generateKlicks3() {
    var array = new Array(144).fill(0);
    array = array.map((e, i)=>{
        if (i % 6 === 0) return 1;
        else if (i % 6 === 2) {
            const random = $1e8cb74b9ccead8b$var$rfx();
            if (random >= 0.5) return 1;
            else return 0;
        } else return 0;
    });
    return array;
}
function $1e8cb74b9ccead8b$var$generateKlicks5() {
    var array = new Array(144).fill(0);
    array = array.map((e, i)=>{
        if (i % 8 === 2) return 1;
        else return 0;
    });
    return array;
}
function $1e8cb74b9ccead8b$var$generateKlicks1() {
    var array = new Array(144).fill(0);
    array = array.map((e, i)=>{
        if (i % 8 === 0) return 1;
        else return 0;
    });
    return array;
}
function $1e8cb74b9ccead8b$var$generateKlicks4() {
    var array = new Array(144).fill(0);
    array = array.map((e, i)=>{
        if (i % 2 === 1) return 1;
        else return 0;
    });
    return array;
}
function $1e8cb74b9ccead8b$var$generateRF2() {
    var array = new Array(144).fill(0);
    array = array.map((e, i)=>{
        if (i % 24 === 4) {
            random = $1e8cb74b9ccead8b$var$rfx();
            if (random > 0.5) return 1;
            else return 0;
        } else return 0;
    });
    return array;
}
class $1e8cb74b9ccead8b$export$4050a8406ef7a0ff {
    out;
    kit;
    constructor(volume){
        this.out = new (0, $7d48f9af04226b93$export$dde279e52d625429)(volume);
        this.eq = new (0, $d5b9bf13f6ee2dd7$export$2adf407ed955ca5d)({
            low: 0,
            mid: 0,
            high: 0,
            highFrequency: 8000
        });
        this.reverb = new (0, $2e8f4e99de55838b$export$6fb1520d4329a18d)(100);
        this.reverb.wet.value = 0;
        this.delay = new (0, $8c7ffa1824c6758b$export$28e4d032ddc580fa)("4n", 0.5);
        this.delay.wet.value = 0;
        this.kit = new (0, $a23f185f5730393d$export$1912c9d78e93a6ed)({
            C1: "./samples/klick1.mp3",
            D1: "./samples/klick2.mp3",
            E1: "./samples/klick3.mp3",
            F1: "./samples/klick4.mp3",
            G1: "./samples/klick5.mp3",
            A1: "./samples/klick6.mp3",
            B1: "./samples/klick7.mp3",
            C2: "./samples/klick8.mp3",
            D2: "./samples/klick9.mp3",
            E2: "./samples/klick10.mp3",
            F2: "./samples/klick11.mp3",
            G2: "./samples/klick12.mp3",
            A2: "./samples/klick13.mp3",
            B2: "./samples/klick14.mp3",
            C3: "./samples/klick15.mp3",
            D3: "./samples/klick16.mp3"
        }, ()=>{
            console.log("Klicks loaded");
            this.kit.chain(this.eq, this.reverb, this.delay, this.out);
        });
    }
}
function $1e8cb74b9ccead8b$export$6f06ea81d179a00b(rhythmDensity) {
    let fullgeneratedKlicks;
    if (rhythmDensity === 3) {
        let random = Math.ceil($1e8cb74b9ccead8b$var$rfx() * 5);
        if (random === 1) fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks1();
        else if (random === 2) fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks2();
        else if (random === 3) fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks3();
        else if (random === 4) fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks5();
        else fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks2();
        fullgeneratedKlicks = $1e8cb74b9ccead8b$var$doubleTime(fullgeneratedKlicks, 2);
    } else if (rhythmDensity === 4) {
        let random = Math.ceil($1e8cb74b9ccead8b$var$rfx() * 4);
        if (random === 1) fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks1();
        else if (random === 2) fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks2();
        else if (random === 3) fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks3();
        else fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks5();
        fullgeneratedKlicks = $1e8cb74b9ccead8b$var$doubleTime(fullgeneratedKlicks, 2);
    } else if (rhythmDensity === 5) {
        fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks3();
        fullgeneratedKlicks = $1e8cb74b9ccead8b$var$doubleTime(fullgeneratedKlicks, 2);
    } else if (rhythmDensity === 6) {
        fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks3();
        fullgeneratedKlicks = $1e8cb74b9ccead8b$var$doubleTime(fullgeneratedKlicks, 2);
    } else if (rhythmDensity === 7) {
        let random = Math.ceil($1e8cb74b9ccead8b$var$rfx() * 4);
        if (random === 1) fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks1();
        else if (random === 3) fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks3();
        else fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks5();
    } else if (rhythmDensity === 8) {
        let random = Math.ceil($1e8cb74b9ccead8b$var$rfx() * 7);
        if (random === 1) fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks1();
        else if (random === 2) fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks2();
        else if (random === 3) fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks3();
        else if (random === 4) fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks5();
        else fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks2();
    } else if (rhythmDensity === 9) fullgeneratedKlicks = $1e8cb74b9ccead8b$var$generateKlicks4();
    return $1e8cb74b9ccead8b$var$converto2Dto1D(fullgeneratedKlicks);
}



const $2dca7dec7a08b206$var$rfx = fxrand;
function $2dca7dec7a08b206$var$fillBass(size, alternate) {
    let flag = 0;
    let kickInputTriggers = [
        [],
        []
    ];
    for(var i = 0; i < 9; i++){
        kickInputTriggers[i] = [];
        for(var j = 0; j < 16; j++)if (alternate === 0) {
            if (j < size) kickInputTriggers[i][j] = 1;
            else kickInputTriggers[i][j] = 0;
        } else {
            if (flag === 0) {
                if (j < size) {
                    kickInputTriggers[i][j] = 1;
                    flag = 1;
                } else {
                    kickInputTriggers[i][j] = 0;
                    flag = 1;
                }
            } else if (j < size) {
                kickInputTriggers[i][j] = 0;
                flag = 0;
            } else {
                kickInputTriggers[i][j] = 0;
                flag = 0;
            }
        }
    }
    return kickInputTriggers;
}
function $2dca7dec7a08b206$var$converto2Dto1D(array) {
    var newArr = [];
    for(var i = 0; i < array.length; i++)newArr = newArr.concat(array[i]);
    return newArr;
}
function $2dca7dec7a08b206$var$checklastTrigger(array) {
    if (array[14] === 1) return 1;
    else return 0;
}
function $2dca7dec7a08b206$var$shuffle(array) {
    const r = (from = 0, to = 1)=>from + $2dca7dec7a08b206$var$rfx() * (to - from);
    var m = array.length, t, i;
    while(m){
        i = Math.floor(r() * m--);
        t = array[m]; // temporary storage
        array[m] = array[i];
        array[i] = t;
    }
    return array;
}
function $2dca7dec7a08b206$var$triggerABS(array) {
    const arrayABS = [];
    var x = 0;
    var z = 0;
    var y = new Boolean(false);
    var a = new Boolean(false);
    for(var i = 0; i < 16; i++){
        if (i === 15) {
            z++;
            arrayABS[x] = z;
        } else if (array[i] === 0) {
            if (y === true) {
                a = true;
                z++;
            }
        } else if (array[i] === 1) {
            y = true;
            if (i > 0 && a === true) {
                z++;
                arrayABS[x] = z;
                x++;
                z = 0;
            }
        }
    }
    return arrayABS;
}
/*
1. Rule: every trigger lands on even index incl. 0:             [1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0]
2. Rule: every trigger has min 4 tringgers distance:            [1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0]
3. Rule: expertion: last trigger can have 2 trigger dicance:    [1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0]
4. Rule: if there is a trigger on the 2nd last trigger of the bar before, the trigger cant land on the 2nd trigger becuase of 2. Rule: Bar1: [1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0], Bar2: [0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0]
5. Rule: tirgger can not land on Kick tirgger*/ function $2dca7dec7a08b206$var$bassRhythm(array, fullKickOutput, flag) {
    //count how much triggers are in array
    var count = 0;
    array.forEach((e, i)=>{
        if (e === 1) count++;
    });
    var arrayABS = [];
    while(true){
        while(true){
            //1. Rule
            while(true){
                array = $2dca7dec7a08b206$var$shuffle(array);
                if (array.every((e, i)=>{
                    if (e === 1) return i % 2 === 0;
                    else return true; // wenns kein schlag ist alles gut, soll weither ggehen
                })) break;
            }
            //2. Rule
            arrayABS = $2dca7dec7a08b206$var$triggerABS(array);
            if (flag === 1) {
                if (array[0] === 0) {
                    if (arrayABS.every((e, i)=>{
                        if (e < 4 && i === count - 1) return true;
                        else if (e < 4) return false;
                        else return true;
                    })) break;
                }
            } else {
                if (arrayABS.every((e, i)=>{
                    if (e < 4 && i === count - 1) return true;
                    else if (e < 4) return false;
                    else return true;
                })) break;
            }
        }
        // 5. Rule 
        array.map((e, i)=>{
            if (array[i] === 1 && fullKickOutput[i] === 1) return array[i] = 0;
            else return e;
        });
        break;
    }
    return array;
}
function $2dca7dec7a08b206$var$bassRhythm2(array, fullKickOutput, flag) {
    //count how much triggers are in array
    var count = 0;
    array.forEach((e, i)=>{
        if (e === 1) count++;
    });
    var arrayABS = [];
    while(true){
        while(true){
            //1. Rule
            while(true){
                array = $2dca7dec7a08b206$var$shuffle(array);
                if (array.every((e, i)=>{
                    if (e === 1) return i % 2 === 0;
                    else return true; // wenns kein schlag ist alles gut, soll weither ggehen
                })) break;
            }
            //2. Rule
            arrayABS = $2dca7dec7a08b206$var$triggerABS(array);
            if (flag === 1) {
                if (array[0] === 0) {
                    if (arrayABS.every((e, i)=>{
                        if (e < 2 && i === count - 1) return true;
                        else if (e < 2) return false;
                        else return true;
                    })) break;
                }
            } else {
                if (arrayABS.every((e, i)=>{
                    if (e < 2 && i === count - 1) return true;
                    else if (e < 2) return false;
                    else return true;
                })) break;
            }
        }
        // 5. Rule 
        array.map((e, i)=>{
            if (array[i] === 1 && fullKickOutput[i] === 1) return array[i] = 0;
            else return e;
        });
        break;
    }
    return array;
}
class $2dca7dec7a08b206$export$4371c5e3dd55b9f7 {
    out;
    kit;
    constructor(volume){
        this.out = new (0, $200a6bd89d4579f9$export$acd19d919666900d)(volume);
        this.eq = new (0, $d5b9bf13f6ee2dd7$export$2adf407ed955ca5d)(0, 0, 0);
        this.kit = new (0, $a23f185f5730393d$export$1912c9d78e93a6ed)({
            C1: "./samples/bass101.mp3",
            D1: "./samples/bass102.mp3",
            E1: "./samples/bass103.mp3",
            F1: "./samples/bass104.mp3",
            G1: "./samples/bass105.mp3"
        }, ()=>{
            console.log("Bass loaded");
            this.kit.chain(this.eq, this.out);
        });
    }
}
function $2dca7dec7a08b206$export$13fb70779939d2e0(rhythmDensity, kicksForBass) {
    let bassInputTriggers = [
        [],
        []
    ];
    let generatedBass = [
        ...Array(9)
    ];
    let flag = 0;
    if (rhythmDensity === 3) bassInputTriggers = $2dca7dec7a08b206$var$fillBass(3, 0);
    else if (rhythmDensity === 4) bassInputTriggers = $2dca7dec7a08b206$var$fillBass(2, 0);
    else if (rhythmDensity === 5) bassInputTriggers = $2dca7dec7a08b206$var$fillBass(1, 0);
    else if (rhythmDensity === 6) bassInputTriggers = $2dca7dec7a08b206$var$fillBass(1, 0);
    else if (rhythmDensity === 7) bassInputTriggers = $2dca7dec7a08b206$var$fillBass(1, 0);
    else if (rhythmDensity === 8) bassInputTriggers = $2dca7dec7a08b206$var$fillBass(1, 0);
    else if (rhythmDensity === 9) bassInputTriggers = $2dca7dec7a08b206$var$fillBass(1, 0);
    if (rhythmDensity === 8) generatedBass.map((e, i)=>{
        e = $2dca7dec7a08b206$var$bassRhythm2(bassInputTriggers[i], kicksForBass[i], flag);
        flag = $2dca7dec7a08b206$var$checklastTrigger(bassInputTriggers[i]);
        return generatedBass[i] = e;
    });
    else generatedBass.map((e, i)=>{
        e = $2dca7dec7a08b206$var$bassRhythm(bassInputTriggers[i], kicksForBass[i], flag);
        flag = $2dca7dec7a08b206$var$checklastTrigger(bassInputTriggers[i]);
        return generatedBass[i] = e;
    });
    return $2dca7dec7a08b206$var$converto2Dto1D(generatedBass);
}



let $b2c93cc76e2da2ab$var$frequenciesRF1 = [
    ...Array(32)
];
let $b2c93cc76e2da2ab$var$frequenciesRF13 = [
    ...Array(5)
];
let $b2c93cc76e2da2ab$var$oscillatorRhythmFigure1 = [
    ...Array(32)
];
let $b2c93cc76e2da2ab$var$gainsRythmFigure1 = [
    ...Array(32)
];
const $b2c93cc76e2da2ab$var$rfx = fxrand;
function $b2c93cc76e2da2ab$var$shuffle(array) {
    const r = (from = 0, to = 1)=>from + $b2c93cc76e2da2ab$var$rfx() * (to - from);
    var m = array.length, t, i;
    while(m){
        i = Math.floor(r() * m--);
        t = array[m]; // temporary storage
        array[m] = array[i];
        array[i] = t;
    }
    return array;
}
/*
1. Rule: every trigger lands on even index incl. 0:             [1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0]
2. Rule: every trigger has min 4 tringgers distance:            [1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0]
3. Rule: expertion: last trigger can have 2 trigger dicance:    [1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0]
4. Rule: if there is a trigger on the 2nd last trigger of the bar before, the trigger cant land on the 2nd trigger becuase of 2. Rule: Bar1: [1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0], Bar2: [0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0]*/ function $b2c93cc76e2da2ab$var$RhythmFigures(array, flag) {
    //CHECK IF ARRAY EVEN HAVE TRIGGER
    //count how much triggers are in array
    var count = 0;
    array.forEach((e, i)=>{
        if (e === 1) count++;
    });
    var arrayABS = [];
    while(true){
        while(true){
            //1. Rule
            while(true){
                array = $b2c93cc76e2da2ab$var$shuffle(array);
                if (array.every((e, i)=>{
                    if (e === 1) return i % 2 === 0;
                    else return true; // wenns kein schlag ist alles gut, soll weither ggehen
                })) break;
            }
            //2. Rule
            arrayABS = $b2c93cc76e2da2ab$var$triggerABS(array);
            if (flag === 1) {
                if (array[0] === 0) {
                    if (arrayABS.every((e, i)=>{
                        if (e < 4 && i === count - 1) return true;
                        else if (e < 4) return false;
                        else return true;
                    })) break;
                }
            } else if (flag === 0) {
                if (arrayABS.every((e, i)=>{
                    if (e < 4 && i === count - 1) return true;
                    else if (e < 4) return false;
                    else return true;
                })) break;
            }
        }
        break;
    }
    return array;
}
function $b2c93cc76e2da2ab$var$converto2Dto1D(array) {
    var newArr = [];
    for(var i = 0; i < array.length; i++)newArr = newArr.concat(array[i]);
    return newArr;
}
function $b2c93cc76e2da2ab$var$exponentialGain(index, dropgains, loudnessControl) {
    const scaledIndex = index / 32;
    const random = Math.ceil($b2c93cc76e2da2ab$var$rfx() * 32);
    let exponentialGainValue = Math.round(Math.pow(scaledIndex - 1, 2) * 100) / loudnessControl;
    exponentialGainValue *= Math.round($b2c93cc76e2da2ab$var$rfx() * 10) / 10;
    if (random <= dropgains) return exponentialGainValue;
    else return 0;
}
function $b2c93cc76e2da2ab$var$fillRF1(size) {
    let RF1InputTriggers = [
        [],
        []
    ];
    for(var i = 0; i < 9; i++){
        RF1InputTriggers[i] = [];
        for(var j = 0; j < 16; j++)if (j < size) RF1InputTriggers[i][j] = 1;
        else RF1InputTriggers[i][j] = 0;
    }
    return RF1InputTriggers;
}
function $b2c93cc76e2da2ab$var$triggerABS(array) {
    const arrayABS = [];
    var x = 0;
    var z = 0;
    var y = new Boolean(false);
    var a = new Boolean(false);
    for(var i = 0; i < 16; i++){
        if (i === 15) {
            z++;
            arrayABS[x] = z;
        } else if (array[i] === 0) {
            if (y === true) {
                a = true;
                z++;
            }
        } else if (array[i] === 1) {
            y = true;
            if (i > 0 && a === true) {
                z++;
                arrayABS[x] = z;
                x++;
                z = 0;
            }
        }
    }
    return arrayABS;
}
function $b2c93cc76e2da2ab$var$checklastTrigger(array) {
    if (array[14] === 1) return 1;
    else return 0;
}
$b2c93cc76e2da2ab$var$frequenciesRF1.forEach((item, index)=>{
    $b2c93cc76e2da2ab$var$frequenciesRF1[index] = (0, $28d90c8ab77bc1a1$export$266cef4b055bf7de).mtof((0, $28d90c8ab77bc1a1$export$266cef4b055bf7de).ftom(Math.pow(index + 2, 2)));
});
$b2c93cc76e2da2ab$var$frequenciesRF13.forEach((item, index)=>{
    $b2c93cc76e2da2ab$var$frequenciesRF13[index] = (0, $28d90c8ab77bc1a1$export$266cef4b055bf7de).mtof((0, $28d90c8ab77bc1a1$export$266cef4b055bf7de).ftom(Math.pow(index + 2, 3)));
});
class $b2c93cc76e2da2ab$export$56d9c0f62401e959 {
    out;
    env;
    constructor(volume){
        this.out = new (0, $7d48f9af04226b93$export$dde279e52d625429)(volume);
        this.eq = new (0, $d5b9bf13f6ee2dd7$export$2adf407ed955ca5d)(0, 0, 0);
        this.env = new (0, $f7e83647bb4822ef$export$e04e0eedd8192587)({
            attack: 0.01,
            decay: 0.5,
            sustain: 0.0,
            release: 0.0
        });
        $b2c93cc76e2da2ab$var$gainsRythmFigure1 = $b2c93cc76e2da2ab$var$gainsRythmFigure1.map((item, index)=>{
            return new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
                gain: $b2c93cc76e2da2ab$var$exponentialGain(index, 15, 200)
            }).connect(this.env);
        });
        this.oscillatorRhythmFigure1 = $b2c93cc76e2da2ab$var$oscillatorRhythmFigure1.map((item, index)=>{
            return new (0, $72f1219056ac35e7$export$c01c5c7b81696d70)({
                frequency: $b2c93cc76e2da2ab$var$frequenciesRF1[index],
                type: "sine"
            }).connect($b2c93cc76e2da2ab$var$gainsRythmFigure1[index]);
        });
        console.log("RhyhtmFigure1 ready");
        this.env.chain(this.eq, this.out);
    }
}
class $b2c93cc76e2da2ab$export$c4c19a222f9ff2dc {
    env;
    out;
    noise;
    constructor(volume){
        this.out = new (0, $7d48f9af04226b93$export$dde279e52d625429)(volume);
        this.eq = new (0, $d5b9bf13f6ee2dd7$export$2adf407ed955ca5d)(0, 0, 0);
        this.bitcrusher = new (0, $7c1e5f6380696f95$export$89e1fd5b393fbb6e)(4);
        this.bitcrusher.wet.value = 0;
        this.distortion = new (0, $50c94488d85f7cab$export$406bc4309a3e7a54)(0.5);
        this.distortion.wet.value = 0;
        this.compressor = new (0, $a032be33a91a2384$export$41ba31ea44cbf87a)({
            threshold: -1,
            ratio: 1,
            attack: 0.01,
            release: 0.1
        });
        this.env = new (0, $f7e83647bb4822ef$export$e04e0eedd8192587)({
            attack: 0.01,
            decay: 0.3,
            sustain: 0.0,
            release: 0.0
        });
        this.noise = new (0, $76955c76dcac2d3e$export$484d33a0500a4ce1)("pink");
        this.noise.chain(this.env, this.bitcrusher, this.distortion, this.eq, this.compressor, this.out);
    }
}
function $b2c93cc76e2da2ab$export$9623113201233140(rhythmDensity) {
    let flag = 0;
    let rf1InputTriggers = [
        [],
        []
    ];
    let generatedRF1 = [
        ...Array(9)
    ];
    rf1InputTriggers = $b2c93cc76e2da2ab$var$fillRF1(1);
    generatedRF1.map((e, i)=>{
        e = $b2c93cc76e2da2ab$var$RhythmFigures(rf1InputTriggers[i], flag);
        flag = $b2c93cc76e2da2ab$var$checklastTrigger(rf1InputTriggers[i]);
        return generatedRF1[i] = e;
    });
    return $b2c93cc76e2da2ab$var$converto2Dto1D(generatedRF1);
}



const $ad81f6362d05f163$var$rfx = fxrand;
let $ad81f6362d05f163$var$osc = [
    ...Array(32)
];
let $ad81f6362d05f163$var$gains = [
    ...Array(32)
];
let $ad81f6362d05f163$var$freq = [
    ...Array(32)
];
let $ad81f6362d05f163$var$numberofSineDrone = 15;
function $ad81f6362d05f163$var$exponentialGain(index, dropgains, loudnessControl) {
    const scaledIndex = index / 32;
    const random = Math.ceil($ad81f6362d05f163$var$rfx() * 32);
    let exponentialGainValue = Math.round(Math.pow(scaledIndex - 1, 2) * 100) / loudnessControl;
    exponentialGainValue *= Math.round($ad81f6362d05f163$var$rfx() * 10) / 10;
    if (random <= dropgains) return exponentialGainValue;
    else return 0;
}
$ad81f6362d05f163$var$freq.forEach((item, index)=>{
    $ad81f6362d05f163$var$freq[index] = (0, $28d90c8ab77bc1a1$export$266cef4b055bf7de).mtof((0, $28d90c8ab77bc1a1$export$266cef4b055bf7de).ftom(Math.pow(index + 2, 2)));
});
class $ad81f6362d05f163$export$3bf9263b7cac56ad {
    out;
    constructor(volume){
        this.out = new (0, $7d48f9af04226b93$export$dde279e52d625429)(volume);
        this.eq = new (0, $d5b9bf13f6ee2dd7$export$2adf407ed955ca5d)(0, 0, 0);
        this.distortion = new (0, $50c94488d85f7cab$export$406bc4309a3e7a54)({
            distortion: 0.5,
            wet: 0
        });
        this.chorus = new (0, $0580ff942b86d3cf$export$e876320b09eb8124)({
            frequency: "4n",
            delayTime: 2.5,
            depth: 0.5,
            wet: 0
        });
        this.gain = new (0, $200a6bd89d4579f9$export$acd19d919666900d)(1);
        this.gains = $ad81f6362d05f163$var$gains.map((item, index)=>{
            return new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
                gain: $ad81f6362d05f163$var$exponentialGain(index, $ad81f6362d05f163$var$numberofSineDrone, 800)
            }).connect(this.gain);
        });
        this.osc = $ad81f6362d05f163$var$osc.map((item, index)=>{
            return new (0, $72f1219056ac35e7$export$c01c5c7b81696d70)({
                frequency: $ad81f6362d05f163$var$freq[index],
                type: "sine"
            }).connect(this.gains[index]);
        });
        console.log("Drone ready");
        this.gain.chain(this.distortion, this.chorus, this.eq, this.out);
    }
}
class $ad81f6362d05f163$export$dce84c771bd35990 {
    out;
    noise;
    constructor(volume){
        this.out = new (0, $7d48f9af04226b93$export$dde279e52d625429)(volume);
        this.eq = new (0, $d5b9bf13f6ee2dd7$export$2adf407ed955ca5d)(0, 0, 0);
        this.bitcrusher = new (0, $7c1e5f6380696f95$export$89e1fd5b393fbb6e)(10);
        this.bitcrusher.wet.value = 0;
        this.distortion = new (0, $50c94488d85f7cab$export$406bc4309a3e7a54)(1);
        this.distortion.wet.value = 0;
        this.filter = new (0, $e8d9115796c61b99$export$26bbc35c91a15e23)(2000, "highpass");
        this.lfo = new (0, $4a4529bace75b797$export$603054d5ec296d77)({
            frequency: 0.1,
            min: 1000,
            max: 4500,
            amplitude: 1,
            phase: 0
        }).connect(this.filter.frequency);
        this.gain = new (0, $7d48f9af04226b93$export$dde279e52d625429)(-50);
        this.noise = new (0, $76955c76dcac2d3e$export$484d33a0500a4ce1)("pink");
        this.noise.chain(this.gain, this.filter, this.bitcrusher, this.distortion, this.eq, this.out);
    }
}
function $ad81f6362d05f163$export$a2b2d7914a45f81b(rhythmDensity) {
    const droneTrigger = [
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0
    ];
    let droneTriggerGains = [
        ...Array(144)
    ];
    if (rhythmDensity === 3) droneTriggerGains = [
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0
    ];
    else if (rhythmDensity === 4) {
        let random = $ad81f6362d05f163$var$rfx();
        if (random > 0.5) droneTriggerGains = [
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ];
        else droneTriggerGains = [
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ];
    } else if (rhythmDensity === 5) {
        let random = $ad81f6362d05f163$var$rfx();
        if (random > 0.5) droneTriggerGains = [
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ];
        else droneTriggerGains = [
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ];
    } else if (rhythmDensity === 6) {
        let random = $ad81f6362d05f163$var$rfx();
        if (random > 0.5) droneTriggerGains = [
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ];
        else droneTriggerGains = [
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ];
    } else if (rhythmDensity === 7) droneTriggerGains = [
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0
    ];
    else if (rhythmDensity === 8) {
        let random = $ad81f6362d05f163$var$rfx();
        if (random > 0.5) droneTriggerGains = [
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ];
        else droneTriggerGains = [
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ];
    } else if (rhythmDensity === 9) {
        let random = $ad81f6362d05f163$var$rfx();
        if (random > 0.5) droneTriggerGains = [
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ];
        else droneTriggerGains = [
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0
        ];
    }
    return droneTriggerGains;
}



let $6200da4dfb771318$var$oscillatorRhythmFigure2 = [
    ...Array(32)
];
let $6200da4dfb771318$var$gains = [
    ...Array(32)
];
let $6200da4dfb771318$var$frequenciesZwei = [
    ...Array(32)
];
const $6200da4dfb771318$var$rfx = fxrand;
function $6200da4dfb771318$var$exponentialGain(index, dropgains, loudnessControl) {
    const scaledIndex = index / 32;
    const random = Math.ceil($6200da4dfb771318$var$rfx() * 32);
    let exponentialGainValue = Math.round(Math.pow(scaledIndex - 1, 2) * 100) / loudnessControl;
    exponentialGainValue *= Math.round($6200da4dfb771318$var$rfx() * 10) / 10;
    if (random <= dropgains) return exponentialGainValue;
    else return 0;
}
$6200da4dfb771318$var$frequenciesZwei.forEach((item, index)=>{
    $6200da4dfb771318$var$frequenciesZwei[index] = (0, $28d90c8ab77bc1a1$export$266cef4b055bf7de).mtof((0, $28d90c8ab77bc1a1$export$266cef4b055bf7de).ftom(Math.pow(index + 3, 2)));
});
function $6200da4dfb771318$var$generateRhythmFigure2() {
    var array = new Array(144).fill(0);
    array = array.map((e, i)=>{
        if (i % 24 === 4) {
            let random = $6200da4dfb771318$var$rfx();
            if (random > 0.5) return 1;
            else return 0;
        } else return 0;
    });
    return array;
}
class $6200da4dfb771318$export$696465113711a6c9 {
    out;
    env;
    constructor(volume){
        this.out = new (0, $7d48f9af04226b93$export$dde279e52d625429)(volume);
        this.eq = new (0, $d5b9bf13f6ee2dd7$export$2adf407ed955ca5d)(0, 0, 0);
        this.filter = new (0, $e8d9115796c61b99$export$26bbc35c91a15e23)(750, "bandpass");
        this.filter.type = "highpass";
        this.filter.frequency.value = 0;
        this.reverb = new (0, $2e8f4e99de55838b$export$6fb1520d4329a18d)(150);
        this.reverb.wet.value = 0;
        this.delay = new (0, $8c7ffa1824c6758b$export$28e4d032ddc580fa)("2n", 0.5);
        this.delay.wet.value = 0;
        this.env = new (0, $f7e83647bb4822ef$export$e04e0eedd8192587)({
            attack: 0.9,
            decay: 0.01,
            sustain: 1,
            release: 0.01
        });
        this.gains = $6200da4dfb771318$var$gains.map((item, index)=>{
            return new (0, $200a6bd89d4579f9$export$acd19d919666900d)({
                gain: $6200da4dfb771318$var$exponentialGain(index, 32, 500)
            }).connect(this.env);
        });
        this.oscillatorRhythmFigure2 = $6200da4dfb771318$var$oscillatorRhythmFigure2.map((item, index)=>{
            return new (0, $72f1219056ac35e7$export$c01c5c7b81696d70)({
                frequency: $6200da4dfb771318$var$frequenciesZwei[index],
                type: "sine"
            }).connect(this.gains[index]);
        });
        console.log("RhyhtmFigure2 ready");
        this.env.chain(this.delay, this.reverb, this.filter, this.eq, this.out);
    }
}
class $6200da4dfb771318$export$c4c19a222f9ff2dc {
    env;
    out;
    noise;
    constructor(volume){
        this.out = new (0, $7d48f9af04226b93$export$dde279e52d625429)(volume);
        this.eq = new (0, $d5b9bf13f6ee2dd7$export$2adf407ed955ca5d)(0, 0, 0);
        this.bitcrusher = new (0, $7c1e5f6380696f95$export$89e1fd5b393fbb6e)(4);
        this.bitcrusher.wet.value = 0;
        this.distortion = new (0, $50c94488d85f7cab$export$406bc4309a3e7a54)(0.5);
        this.distortion.wet.value = 0;
        this.env = new (0, $f7e83647bb4822ef$export$e04e0eedd8192587)({
            attack: 0.01,
            decay: 0.3,
            sustain: 0.0,
            release: 0.0
        });
        this.noise = new (0, $76955c76dcac2d3e$export$484d33a0500a4ce1)("pink").connect(this.env);
        this.env.chain(this.bitcrusher, this.distortion, this.eq, this.out);
    }
}
function $6200da4dfb771318$export$1b7687825ff5a57e(rhythmDensity) {
    return $6200da4dfb771318$var$generateRhythmFigure2();
}



"use strict";
const $21df9c1ea4331da7$var$kicks = new (0, $48e418653d1eb56b$export$7f6d62d95a630450)(3);
const $21df9c1ea4331da7$var$klicks = new (0, $1e8cb74b9ccead8b$export$4050a8406ef7a0ff)(0);
const $21df9c1ea4331da7$var$bass = new (0, $2dca7dec7a08b206$export$4371c5e3dd55b9f7)(1);
const $21df9c1ea4331da7$var$rF1 = new (0, $b2c93cc76e2da2ab$export$56d9c0f62401e959)(12);
const $21df9c1ea4331da7$var$rF1Noise = new (0, $b2c93cc76e2da2ab$export$c4c19a222f9ff2dc)(0);
const $21df9c1ea4331da7$var$drone = new (0, $ad81f6362d05f163$export$3bf9263b7cac56ad)(0);
const $21df9c1ea4331da7$var$droneNoise = new (0, $ad81f6362d05f163$export$dce84c771bd35990)(0);
const $21df9c1ea4331da7$var$rfx = fxrand;
const $21df9c1ea4331da7$var$rf2 = new (0, $6200da4dfb771318$export$696465113711a6c9);
function $21df9c1ea4331da7$var$nonRepeatingRhythmArray(length) {
    let arr = [];
    do {
        let ran = Math.floor($21df9c1ea4331da7$var$rfx() * length);
        arr = arr.indexOf(ran) > -1 ? arr : arr.concat(ran);
    }while (arr.length < length);
    return arr;
}
function $21df9c1ea4331da7$var$converto2Dto1D(array) {
    var newArr = [];
    for(var i = 0; i < array.length; i++)newArr = newArr.concat(array[i]);
    return newArr;
}
function $21df9c1ea4331da7$var$shuffle(array) {
    const r = (from = 0, to = 1)=>from + $21df9c1ea4331da7$var$rfx() * (to - from);
    var m = array.length, t, i;
    while(m){
        i = Math.floor(r() * m--);
        t = array[m]; // temporary storage
        array[m] = array[i];
        array[i] = t;
    }
    return array;
}
function $21df9c1ea4331da7$var$checklastTrigger(array) {
    if (array[14] === 1) return 1;
    else return 0;
}
function $21df9c1ea4331da7$var$triggerABS(array) {
    const arrayABS = [];
    var x = 0;
    var z = 0;
    var y = new Boolean(false);
    var a = new Boolean(false);
    for(var i = 0; i < 16; i++){
        if (i === 15) {
            z++;
            arrayABS[x] = z;
        } else if (array[i] === 0) {
            if (y === true) {
                a = true;
                z++;
            }
        } else if (array[i] === 1) {
            y = true;
            if (i > 0 && a === true) {
                z++;
                arrayABS[x] = z;
                x++;
                z = 0;
            }
        }
    }
    return arrayABS;
}
function $21df9c1ea4331da7$var$translateBinarytoTone(array) {
    let current = 0;
    var returnArray = array.map((e, i)=>{
        if (i <= 15) {
            current = i;
            return [
                e,
                `0:${Math.floor(current / 4)}:${i % 4}`
            ];
        } else if (i >= 16 && i < 32) {
            current = i - 16;
            return [
                e,
                `1:${Math.floor(current / 4)}:${i % 4}`
            ];
        } else if (i >= 32 && i < 48) {
            current = i - 32;
            return [
                e,
                `2:${Math.floor(current / 4)}:${i % 4}`
            ];
        } else if (i >= 48 && i < 64) {
            current = i - 48;
            return [
                e,
                `3:${Math.floor(current / 4)}:${i % 4}`
            ];
        } else if (i >= 64 && i < 80) {
            current = i - 64;
            return [
                e,
                `4:${Math.floor(current / 4)}:${i % 4}`
            ];
        } else if (i >= 80 && i < 96) {
            current = i - 80;
            return [
                e,
                `5:${Math.floor(current / 4)}:${i % 4}`
            ];
        } else if (i >= 96 && i < 112) {
            current = i - 96;
            return [
                e,
                `6:${Math.floor(current / 4)}:${i % 4}`
            ];
        } else if (i >= 112 && i < 128) {
            current = i - 112;
            return [
                e,
                `7:${Math.floor(current / 4)}:${i % 4}`
            ];
        } else {
            current = i - 128;
            return [
                e,
                `8:${Math.floor(current / 4)}:${i % 4}`
            ];
        }
    });
    returnArray = returnArray.filter((e)=>e[0] === 1);
    returnArray = returnArray.map((e, i)=>[
            e[1],
            `C${i}`
        ]);
    return returnArray;
}
function $21df9c1ea4331da7$var$generateRandom(min, max) {
    // find diff
    let difference = max - min;
    // generate random number 
    let rand = $21df9c1ea4331da7$var$rfx();
    // multiply with difference 
    rand = Math.round(rand * difference * 100) / 100;
    // add with min value 
    rand = rand + min;
    return rand;
}
function $21df9c1ea4331da7$var$exponentialGain(index, dropgains, loudnessControl) {
    const scaledIndex = index / 32;
    const random = Math.ceil($21df9c1ea4331da7$var$rfx() * 32);
    let exponentialGainValue = Math.round(Math.pow(scaledIndex - 1, 2) * 100) / loudnessControl;
    exponentialGainValue *= Math.round($21df9c1ea4331da7$var$rfx() * 10) / 10;
    if (random <= dropgains) return exponentialGainValue;
    else return 0;
}
function $21df9c1ea4331da7$var$startAudio() {
    //////////////////////////////////////////////////////////////////<<DENSITY------------------------------------------------------------------------------
    let rhythmDensity = Math.round($21df9c1ea4331da7$var$generateRandom(3, 9));
    rhythmDensity = 9;
    console.log(rhythmDensity);
    //////////////////////////////////////////////////////////////////<<MASTER------------------------------------------------------------------------------
    const finalMasterVolume = new (0, $7d48f9af04226b93$export$dde279e52d625429)(0).toDestination();
    const limiter = new (0, $3028028622c75f19$export$18d8154f27ea9172)(0).connect(finalMasterVolume);
    const volMaster = new (0, $7d48f9af04226b93$export$dde279e52d625429)(10).connect(limiter);
    const eq = new (0, $d5b9bf13f6ee2dd7$export$2adf407ed955ca5d)({
        low: -6,
        mid: -3,
        high: 0,
        highFrequency: 8600
    }).connect(volMaster);
    const masterGain = new (0, $200a6bd89d4579f9$export$acd19d919666900d)(1).connect(eq);
    (0, $193d86afce95aa9f$export$86495b081fef8e52).bpm.value = 150;
    volMaster.volume.value = -100;
    volMaster.volume.rampTo(6, 1);
    //////////////////////////////////////////////////////////////////<<KICK------------------------------------------------------------------------------
    const kickEvent = new CustomEvent("kick", {
        "detail": "kick trigger"
    });
    const masterVolumeKick = new (0, $7d48f9af04226b93$export$dde279e52d625429)(0).connect(masterGain);
    $21df9c1ea4331da7$var$kicks.out.connect(masterVolumeKick);
    const kicksForBass = (0, $48e418653d1eb56b$export$d0727105f16910fe)(rhythmDensity);
    const kick = $21df9c1ea4331da7$var$converto2Dto1D(kicksForBass);
    let nonRepeatingArray = $21df9c1ea4331da7$var$nonRepeatingRhythmArray(7);
    let kickCounter = 1;
    //console.log(nonRepeatingArray);
    function playKick(time, note) {
        document.dispatchEvent(kickEvent);
        //const random = Math.ceil(rfx() * 4);
        kickCounter++;
        //console.log('Kick Counter: ' +kickCounter)
        let random;
        if (kickCounter > 6) {
            kickCounter = 0;
            random = nonRepeatingArray[kickCounter];
            let lastNumberofArray = nonRepeatingArray[6];
            while(true){
                nonRepeatingArray = $21df9c1ea4331da7$var$nonRepeatingRhythmArray(7);
                //console.log(nonRepeatingArray);
                if (lastNumberofArray === nonRepeatingArray[6]) return false;
                else return true;
            }
        } else //console.log('ELSE: ' +kickCounter);
        random = nonRepeatingArray[kickCounter];
        //onsole.log(random);
        if (random === 6) $21df9c1ea4331da7$var$kicks.kit.player("G1").start(time);
        if (random === 5) $21df9c1ea4331da7$var$kicks.kit.player("A1").start(time);
        if (random === 4) $21df9c1ea4331da7$var$kicks.kit.player("B1").start(time);
        if (random === 3) $21df9c1ea4331da7$var$kicks.kit.player("C1").start(time);
        else if (random === 2) $21df9c1ea4331da7$var$kicks.kit.player("D1").start(time);
        else if (random === 1) $21df9c1ea4331da7$var$kicks.kit.player("E1").start(time);
        else $21df9c1ea4331da7$var$kicks.kit.player("F1").start(time);
    }
    const patternKick = $21df9c1ea4331da7$var$translateBinarytoTone(kick);
    const partKick = new (0, $3dead49a17571b0f$export$7b5bf7981d51054e)(playKick, patternKick);
    partKick.loopEnd = "9:0:0";
    partKick.loop = true;
    //////////////////////////////////////////////////////////////////<<BASS------------------------------------------------------------------------------
    const bassEvent = new CustomEvent("bass", {
        "detail": "bass trigger"
    });
    const bassMasterGain = new (0, $7d48f9af04226b93$export$dde279e52d625429)(0).connect(masterGain);
    $21df9c1ea4331da7$var$bass.out.connect(bassMasterGain);
    const generatedBass = (0, $2dca7dec7a08b206$export$13fb70779939d2e0)(rhythmDensity, kicksForBass);
    function playBass(time, note) {
        document.dispatchEvent(bassEvent);
        const random = Math.ceil($21df9c1ea4331da7$var$rfx() * 5);
        if (random === 5) $21df9c1ea4331da7$var$bass.kit.player("C1").start(time);
        else if (random === 4) $21df9c1ea4331da7$var$bass.kit.player("D1").start(time);
        else if (random === 3) $21df9c1ea4331da7$var$bass.kit.player("E1").start(time);
        else if (random === 2) $21df9c1ea4331da7$var$bass.kit.player("F1").start(time);
        else $21df9c1ea4331da7$var$bass.kit.player("G1").start(time);
    }
    const patternBass = $21df9c1ea4331da7$var$translateBinarytoTone($21df9c1ea4331da7$var$converto2Dto1D(generatedBass));
    const partBass = new (0, $3dead49a17571b0f$export$7b5bf7981d51054e)(playBass, patternBass);
    partBass.loopEnd = "9:0:0";
    partBass.loop = true;
    //////////////////////////////////////////////////////////////////<<RF1------------------------------------------------------------------------------
    //let rhythmFigure1 = await import('./class.rhythmFigure1');
    const rf1Event = new CustomEvent("rf1", {
        "detail": "rf1 trigger"
    });
    const masterRhythmFigureGain1 = new (0, $7d48f9af04226b93$export$dde279e52d625429)(-10).connect(masterGain);
    $21df9c1ea4331da7$var$rF1.out.connect(masterRhythmFigureGain1);
    $21df9c1ea4331da7$var$rF1.oscillatorRhythmFigure1.forEach((e)=>e.start());
    $21df9c1ea4331da7$var$rF1Noise.out.connect(masterRhythmFigureGain1);
    $21df9c1ea4331da7$var$rF1Noise.noise.start();
    const generatedRF1 = (0, $b2c93cc76e2da2ab$export$9623113201233140)(rhythmDensity);
    function playRhythmFigure1(time, note) {
        document.dispatchEvent(rf1Event);
        $21df9c1ea4331da7$var$rF1.env.triggerAttackRelease(time);
        $21df9c1ea4331da7$var$rF1.env.decay = $21df9c1ea4331da7$var$generateRandom(0.2, 1);
        $21df9c1ea4331da7$var$rF1Noise.env.decay = $21df9c1ea4331da7$var$generateRandom(0.2, 0.8);
        $21df9c1ea4331da7$var$rF1Noise.env.triggerAttackRelease(time);
        console.log(limiter.reduction);
    }
    const patternRhythmFigure1 = $21df9c1ea4331da7$var$translateBinarytoTone(generatedRF1);
    const partRhythmFigure1 = new (0, $3dead49a17571b0f$export$7b5bf7981d51054e)(playRhythmFigure1, patternRhythmFigure1);
    partRhythmFigure1.loopEnd = "9:0:0";
    partRhythmFigure1.loop = true;
    //////////////////////////////////////////////////////////////////<<RF2------------------------------------------------------------------------------
    const masterRhythmFigureGain2 = new (0, $7d48f9af04226b93$export$dde279e52d625429)(-10).connect(masterGain);
    const rf2Event = new CustomEvent("rf2", {
        "detail": "rf2 trigger"
    });
    $21df9c1ea4331da7$var$rf2.out.connect(masterRhythmFigureGain2);
    $21df9c1ea4331da7$var$rf2.oscillatorRhythmFigure2.forEach((e)=>e.start());
    const fullgeneratedRhythmFigure2 = (0, $6200da4dfb771318$export$1b7687825ff5a57e)();
    function playRhythmFigure2(time, note) {
        document.dispatchEvent(rf2Event);
        $21df9c1ea4331da7$var$rf2.gains.forEach((e, i)=>{
            e.gain.rampTo($21df9c1ea4331da7$var$exponentialGain(i, numberofSineDrone, 800), rampTimeDroneGain);
        });
        $21df9c1ea4331da7$var$rf2.env.triggerAttackRelease(time, "8n");
    }
    const patternRhythmFigure2 = $21df9c1ea4331da7$var$translateBinarytoTone(fullgeneratedRhythmFigure2);
    const partRhythmFigure2 = new (0, $3dead49a17571b0f$export$7b5bf7981d51054e)(playRhythmFigure2, patternRhythmFigure2);
    partRhythmFigure2.loopEnd = "9:0:0";
    partRhythmFigure2.loop = true;
    //////////////////////////////////////////////////////////////////<<KLICK------------------------------------------------------------------------------
    const masterVolumeKlick = new (0, $7d48f9af04226b93$export$dde279e52d625429)(6).connect(masterGain);
    const klickEvent = new CustomEvent("klick", {
        "detail": "kick trigger"
    });
    $21df9c1ea4331da7$var$klicks.out.connect(masterVolumeKlick);
    const fullgeneratedKlicks = (0, $1e8cb74b9ccead8b$export$6f06ea81d179a00b)(rhythmDensity);
    const oscNoiseClickVolume = new (0, $7d48f9af04226b93$export$dde279e52d625429)(-4).connect(masterGain);
    const envNoiseKlick = new (0, $f7e83647bb4822ef$export$e04e0eedd8192587)({
        attack: 0.01,
        decay: 0.0001,
        sustain: 0.0,
        release: 0.0
    }).connect(oscNoiseClickVolume);
    const oscNoiseClick = new (0, $72f1219056ac35e7$export$c01c5c7b81696d70)(440, "sine8").connect(envNoiseKlick).start();
    let randomOSCNoiseClicktype = Math.floor($21df9c1ea4331da7$var$rfx() * 4);
    if (randomOSCNoiseClicktype === 0) oscNoiseClick.type = "sine2";
    if (randomOSCNoiseClicktype === 1) oscNoiseClick.type = "triangle2";
    if (randomOSCNoiseClicktype === 2) oscNoiseClick.type = "sawtooth2";
    if (randomOSCNoiseClicktype === 3) oscNoiseClick.type = "sine16";
    function playKlick(time, note) {
        document.dispatchEvent(klickEvent);
        const random = Math.floor($21df9c1ea4331da7$var$rfx() * 16);
        const random2 = Math.floor($21df9c1ea4331da7$var$rfx() * 3);
        if (random === 0) $21df9c1ea4331da7$var$klicks.kit.player("C1").start(time);
        if (random === 1) $21df9c1ea4331da7$var$klicks.kit.player("D1").start(time);
        if (random === 2) $21df9c1ea4331da7$var$klicks.kit.player("E1").start(time);
        if (random === 3) $21df9c1ea4331da7$var$klicks.kit.player("F1").start(time);
        if (random === 4) $21df9c1ea4331da7$var$klicks.kit.player("G1").start(time);
        if (random === 5) $21df9c1ea4331da7$var$klicks.kit.player("A1").start(time);
        if (random === 6) $21df9c1ea4331da7$var$klicks.kit.player("B1").start(time);
        if (random === 7) $21df9c1ea4331da7$var$klicks.kit.player("C2").start(time);
        if (random === 8) $21df9c1ea4331da7$var$klicks.kit.player("D2").start(time);
        if (random === 9) $21df9c1ea4331da7$var$klicks.kit.player("E2").start(time);
        if (random === 10) $21df9c1ea4331da7$var$klicks.kit.player("F2").start(time);
        if (random === 11) $21df9c1ea4331da7$var$klicks.kit.player("G2").start(time);
        if (random === 12) $21df9c1ea4331da7$var$klicks.kit.player("A2").start(time);
        if (random === 13) $21df9c1ea4331da7$var$klicks.kit.player("B2").start(time);
        if (random === 14) $21df9c1ea4331da7$var$klicks.kit.player("C3").start(time);
        if (random === 15) $21df9c1ea4331da7$var$klicks.kit.player("D3").start(time);
        if (rhythmDensity === 7) {
            if (random2 === 0) {
                $21df9c1ea4331da7$var$klicks.reverb.wet.value = $21df9c1ea4331da7$var$generateRandom(0.01, 0.15);
                $21df9c1ea4331da7$var$klicks.delay.wet.value = $21df9c1ea4331da7$var$generateRandom(0.01, 0.2);
                $21df9c1ea4331da7$var$klicks.delay.delayTime.value = "4n";
            }
            if (random2 === 1) {
                $21df9c1ea4331da7$var$klicks.reverb.wet.value = $21df9c1ea4331da7$var$generateRandom(0.01, 0.15);
                $21df9c1ea4331da7$var$klicks.delay.wet.value = $21df9c1ea4331da7$var$generateRandom(0.01, 0.2);
                $21df9c1ea4331da7$var$klicks.delay.delayTime.value = "8n";
            }
            if (random2 === 2) {
                $21df9c1ea4331da7$var$klicks.reverb.wet.value = $21df9c1ea4331da7$var$generateRandom(0.01, 0.15);
                $21df9c1ea4331da7$var$klicks.delay.wet.value = $21df9c1ea4331da7$var$generateRandom(0.01, 0.2);
                $21df9c1ea4331da7$var$klicks.delay.delayTime.value = "2n";
            }
        } else if (rhythmDensity === 9) {
            envNoiseKlick.attack = $21df9c1ea4331da7$var$generateRandom(0.001, 0.0001);
            envNoiseKlick.triggerAttack(time);
        }
    }
    let patternKlick = $21df9c1ea4331da7$var$translateBinarytoTone(fullgeneratedKlicks);
    const partKlick = new (0, $3dead49a17571b0f$export$7b5bf7981d51054e)(playKlick, patternKlick);
    partKlick.loopEnd = "3:0:0";
    partKlick.loop = true;
    //////////////////////////////////////////////////////////////////<<DRONE------------------------------------------------------------------------------
    const masterVolumeDrone = new (0, $7d48f9af04226b93$export$dde279e52d625429)(6).connect(masterGain);
    const droneEvent = new CustomEvent("drone", {
        "detail": "drone trigger"
    });
    $21df9c1ea4331da7$var$drone.out.connect(masterVolumeDrone);
    $21df9c1ea4331da7$var$droneNoise.out.connect(masterVolumeDrone);
    $21df9c1ea4331da7$var$droneNoise.lfo.start();
    $21df9c1ea4331da7$var$drone.chorus.start();
    let filterFRQDrone = 100;
    const autoFilterDrone = new (0, $e8d9115796c61b99$export$26bbc35c91a15e23)(filterFRQDrone, "highpass").connect(masterVolumeDrone);
    let masterDroneGain = new (0, $200a6bd89d4579f9$export$acd19d919666900d)(1).connect(autoFilterDrone);
    if (rhythmDensity === 0) autoFilterDrone.type = "bandpass";
    let rampTimeDroneGain = 0.6;
    let numberofSineDrone = 15;
    const droneTriggerGains = (0, $ad81f6362d05f163$export$a2b2d7914a45f81b)(rhythmDensity);
    function playDroneGains(time, note) {
        document.dispatchEvent(droneEvent);
        $21df9c1ea4331da7$var$drone.gains.forEach((e, i)=>{
            e.gain.rampTo($21df9c1ea4331da7$var$exponentialGain(i, numberofSineDrone, 800), rampTimeDroneGain);
        });
        if (rhythmDensity === 7) numberofSineDrone = Math.round($21df9c1ea4331da7$var$generateRandom(5, 12));
    }
    const patternDroneGains = $21df9c1ea4331da7$var$translateBinarytoTone(droneTriggerGains);
    const partDroneGains = new (0, $3dead49a17571b0f$export$7b5bf7981d51054e)(playDroneGains, patternDroneGains);
    partDroneGains.loopEnd = "9:0:0";
    partDroneGains.loop = true;
    const bar = [
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0
    ];
    const quarterNote = [
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0
    ];
    /////////////PLAY BEAT-------------------------------------------------------------------------------------------------
    if (rhythmDensity == 0) {
        partKick.start();
        partBass.start();
        //partRhythmFigure1.start();
        masterRhythmFigureGain1.volume.value = 10;
        //noiseRhythmFigure1.volume.value = 5;
        //partRhythmFigure2.start();
        partKlick.start();
        partDrone.start();
        partDroneGains.start();
    }
    if (rhythmDensity == 3) {
        (0, $193d86afce95aa9f$export$86495b081fef8e52).bpm.value = $21df9c1ea4331da7$var$generateRandom(100, 160);
        partKick.start();
        partKlick.start();
        partBass.start();
        partRhythmFigure1.start();
        masterRhythmFigureGain1.volume.value = -10;
        $21df9c1ea4331da7$var$rF1Noise.bitcrusher.wet.value = $21df9c1ea4331da7$var$generateRandom(0.2, 0.6);
        $21df9c1ea4331da7$var$rF1Noise.compressor.threshold.value = -50;
        $21df9c1ea4331da7$var$rF1Noise.compressor.ratio.value = 3;
        //DRONE
        partDroneGains.start();
        masterVolumeDrone.volume.value = 2;
        $21df9c1ea4331da7$var$droneNoise.gain.volume.value = $21df9c1ea4331da7$var$generateRandom(-55, -50);
        $21df9c1ea4331da7$var$droneNoise.distortion.wet.value = 1;
        $21df9c1ea4331da7$var$drone.distortion.wet.value = $21df9c1ea4331da7$var$generateRandom(0.01, 0.1);
        $21df9c1ea4331da7$var$drone.chorus.wet.value = $21df9c1ea4331da7$var$generateRandom(0.1, 0.2);
        rampTimeDroneGain = $21df9c1ea4331da7$var$generateRandom(0.01, 1);
        numberofSineDrone = Math.round($21df9c1ea4331da7$var$generateRandom(5, 20));
    }
    if (rhythmDensity == 4) {
        (0, $193d86afce95aa9f$export$86495b081fef8e52).bpm.value = $21df9c1ea4331da7$var$generateRandom(180, 200);
        partKick.start();
        partBass.start();
        partRhythmFigure1.start();
        //partRhythmFigure2.start();
        masterRhythmFigureGain2.volume.value = -5;
        //partKlick.start();
        //DRONE
        partDroneGains.start();
        masterVolumeDrone.volume.value = 0;
        $21df9c1ea4331da7$var$droneNoise.gain.volume.value = $21df9c1ea4331da7$var$generateRandom(-45, -30);
        $21df9c1ea4331da7$var$droneNoise.lfo.frequency.value = "16n";
        $21df9c1ea4331da7$var$droneNoise.lfo.min = $21df9c1ea4331da7$var$generateRandom(500, 8000);
        $21df9c1ea4331da7$var$droneNoise.lfo.min = $21df9c1ea4331da7$var$droneNoise.lfo.min + 100;
        $21df9c1ea4331da7$var$droneNoise.lfo.phase = 10;
        rampTimeDroneGain = 0.6;
        numberofSineDrone = Math.round($21df9c1ea4331da7$var$generateRandom(5, 15));
    }
    if (rhythmDensity === 5) {
        (0, $193d86afce95aa9f$export$86495b081fef8e52).bpm.value = $21df9c1ea4331da7$var$generateRandom(120, 150);
        partKlick.start();
        partBass.start();
        $21df9c1ea4331da7$var$rf2.reverb.decay = 400;
        $21df9c1ea4331da7$var$rf2.reverb.wet.value = 0.3;
        $21df9c1ea4331da7$var$rf2.delay.wet.value = 0.3;
        $21df9c1ea4331da7$var$rf2.filter.type = "highpass";
        $21df9c1ea4331da7$var$rf2.filter.frequency.value = 400;
        partRhythmFigure2.start();
        partDroneGains.start();
        masterVolumeKlick.volume.value = -5;
        //reverbKlickVolume.volume.value = -10;
        $21df9c1ea4331da7$var$klicks.reverb.wet.value = 0.5;
        $21df9c1ea4331da7$var$klicks.reverb.decay = 100;
        rampTimeDroneGain = 0.6;
        numberofSineDrone = 15;
        masterRhythmFigureGain2.volume.value = 0;
        //amplitudeLFODrone = 0;
        masterVolumeDrone.volume.value = 2;
        $21df9c1ea4331da7$var$droneNoise.gain.volume.value = -37;
        $21df9c1ea4331da7$var$droneNoise.lfo.min = 1000;
        $21df9c1ea4331da7$var$droneNoise.lfo.max = 6000;
    }
    if (rhythmDensity === 6) {
        (0, $193d86afce95aa9f$export$86495b081fef8e52).bpm.value = $21df9c1ea4331da7$var$generateRandom(120, 150);
        $21df9c1ea4331da7$var$kicks.kit.player.playbackRate = 20;
        $21df9c1ea4331da7$var$kicks.kit.player.playbackRate = 20;
        $21df9c1ea4331da7$var$kicks.kit.player.playbackRate = 20;
        $21df9c1ea4331da7$var$kicks.kit.player.playbackRate = 20;
        $21df9c1ea4331da7$var$kicks.biquad.frequency.value = 300;
        $21df9c1ea4331da7$var$kicks.biquad.type = "bandpass";
        partKick.start();
        partBass.start();
        partKlick.start();
        partRhythmFigure2.start();
        $21df9c1ea4331da7$var$rf2.reverb.decay = 400;
        $21df9c1ea4331da7$var$rf2.reverb.wet.value = 0.3;
        $21df9c1ea4331da7$var$rf2.delay.wet.value = 0.3;
        $21df9c1ea4331da7$var$rf2.filter.type = "highpass";
        $21df9c1ea4331da7$var$rf2.filter.frequency.value = 400;
        partDroneGains.start();
        masterVolumeKlick.volume.value = -5;
        $21df9c1ea4331da7$var$klicks.reverb.wet.value = 0.5;
        $21df9c1ea4331da7$var$klicks.reverb.decay = 100;
        rampTimeDroneGain = 10;
        numberofSineDrone = Math.round($21df9c1ea4331da7$var$generateRandom(1, 5));
        masterRhythmFigureGain2.volume.value = 0;
        masterVolumeDrone.volume.value = 2;
        $21df9c1ea4331da7$var$droneNoise.gain.volume.value = -37;
        $21df9c1ea4331da7$var$droneNoise.lfo.min = 1000;
        $21df9c1ea4331da7$var$droneNoise.lfo.max = 6000;
    }
    if (rhythmDensity === 7) {
        let random1 = $21df9c1ea4331da7$var$rfx();
        let random2 = $21df9c1ea4331da7$var$rfx();
        (0, $193d86afce95aa9f$export$86495b081fef8e52).bpm.value = $21df9c1ea4331da7$var$generateRandom(120, 180);
        if (random1 >= 0.5) partKick.start();
        partBass.start();
        //KLICKS
        if (random2 >= 0.5) partKlick.start();
        if (random1 >= 0.5 && random2 < 0.5) masterVolumeKick.volume.value = -10;
        masterVolumeKlick.volume.value = 4;
        $21df9c1ea4331da7$var$klicks.eq.highFrequency.value = 3;
        //DRONE
        partDroneGains.start();
        masterVolumeDrone.volume.value = 2;
        $21df9c1ea4331da7$var$droneNoise.gain.volume.value = $21df9c1ea4331da7$var$generateRandom(-50, -40);
        $21df9c1ea4331da7$var$droneNoise.distortion.wet.value = 1;
        $21df9c1ea4331da7$var$drone.distortion.wet.value = $21df9c1ea4331da7$var$generateRandom(0.01, 0.1);
        $21df9c1ea4331da7$var$droneNoise.lfo.min = 5500;
        $21df9c1ea4331da7$var$droneNoise.lfo.max = 6000;
        $21df9c1ea4331da7$var$klicks.delay.wet.value = 0;
        $21df9c1ea4331da7$var$klicks.reverb.wet.value = 0.9;
        rampTimeDroneGain = Math.round($21df9c1ea4331da7$var$generateRandom(4, 7));
        numberofSineDrone = Math.round($21df9c1ea4331da7$var$generateRandom(5, 20));
    }
    if (rhythmDensity === 8) {
        let random1 = $21df9c1ea4331da7$var$rfx();
        let random2 = $21df9c1ea4331da7$var$rfx();
        (0, $193d86afce95aa9f$export$86495b081fef8e52).bpm.value = $21df9c1ea4331da7$var$generateRandom(160, 185);
        bassMasterGain.volume.value = 2;
        partKick.start();
        if (random1 >= 0.5) partBass.start();
        if (random2 >= 0.5) partKlick.start();
        //DRONE
        partDroneGains.start();
        masterVolumeDrone.volume.value = 3;
        $21df9c1ea4331da7$var$droneNoise.gain.volume.value = -45;
        $21df9c1ea4331da7$var$droneNoise.lfo.min = Math.round($21df9c1ea4331da7$var$generateRandom(3000, 5000));
        $21df9c1ea4331da7$var$droneNoise.lfo.max = Math.round($21df9c1ea4331da7$var$generateRandom(6000, 8000));
        $21df9c1ea4331da7$var$droneNoise.bitcrusher.wet.value = $21df9c1ea4331da7$var$generateRandom(0.3, 0.6);
        $21df9c1ea4331da7$var$droneNoise.distortion.wet.value = $21df9c1ea4331da7$var$generateRandom(0.3, 0.6);
        rampTimeDroneGain = Math.round($21df9c1ea4331da7$var$generateRandom(5, 9));
    }
    if (rhythmDensity === 9) {
        (0, $193d86afce95aa9f$export$86495b081fef8e52).bpm.value = $21df9c1ea4331da7$var$generateRandom(160, 185);
        bassMasterGain.volume.value = 2;
        masterVolumeKlick.volume.value = -100;
        partKick.start();
        partBass.start();
        partKlick.start();
        masterRhythmFigureGain2.volume.value = 0;
        partDroneGains.start();
        masterVolumeDrone.volume.value = 3;
        rampTimeDroneGain = Math.round($21df9c1ea4331da7$var$generateRandom(4, 7));
        numberofSineDrone = Math.round($21df9c1ea4331da7$var$generateRandom(5, 20));
        $21df9c1ea4331da7$var$droneNoise.gain.volume.value = -45;
        $21df9c1ea4331da7$var$droneNoise.lfo.min = 4000;
        $21df9c1ea4331da7$var$droneNoise.lfo.max = 6000;
        $21df9c1ea4331da7$var$droneNoise.bitcrusher.wet.value = 0.5;
        $21df9c1ea4331da7$var$droneNoise.distortion.wet.value = 0.5;
    }
    console.log("BPM: " + (0, $193d86afce95aa9f$export$86495b081fef8e52).bpm.value);
    (0, $193d86afce95aa9f$export$86495b081fef8e52).start();
    $21df9c1ea4331da7$var$droneNoise.noise.start();
    $21df9c1ea4331da7$var$drone.osc.forEach((e)=>e.start());
}
//console.log(context.state);
console.log((0, $0eb7340e2d092af9$export$12b11dc969d02fed).version);
console.log((0, $193d86afce95aa9f$export$a078c61943f9dbbe).state);
let $21df9c1ea4331da7$var$alreadyKlicked = false;
if ((0, $193d86afce95aa9f$export$a078c61943f9dbbe).state === "suspended") window.addEventListener("click", ()=>{
    if ($21df9c1ea4331da7$var$alreadyKlicked === false) {
        $21df9c1ea4331da7$var$alreadyKlicked = true;
        console.log("Clicked!");
        //StartAudioContext(Tone.context) https://codepen.io/enteleform/pen/PepqYV?__cf_chl_tk=v.XU_dfJYahRSsy0rdIL8X.eOLfqOMFlWbje9wiTnWE-1658652732-0-gaNycGzNB30
        $21df9c1ea4331da7$var$startAudio();
        window.removeEventListener("click", undefined);
        console.log((0, $193d86afce95aa9f$export$a078c61943f9dbbe).state);
    }
});
else if ((0, $193d86afce95aa9f$export$a078c61943f9dbbe).state === "running") $21df9c1ea4331da7$var$startAudio();


